{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "# from missingpy import MissForest #impute missing value\n",
    "from sklearn.preprocessing import MinMaxScaler #standardized data\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#deep learning package\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "#self-design pacakge\n",
    "from models import CNN_RNN\n",
    "from models import CNN_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitbit_survey2 = pd.read_csv('fitbit_survey.csv')\n",
    "select_survey = pd.read_csv('select_survey.csv')\n",
    "\n",
    "fitbit_survey2.drop(columns = ['Unnamed: 0'], inplace = True)\n",
    "select_survey.drop(columns = ['Unnamed: 0'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mental_health1 =  select_survey['mental_health_1'].values\n",
    "mental_health2 =  select_survey['mental_health_2'].values\n",
    "\n",
    "ids = fitbit_survey2['Id'].unique()\n",
    "max_short_day = 0\n",
    "max_long_day = 0\n",
    "for id in ids:\n",
    "    individual_data_short = fitbit_survey2[(fitbit_survey2['Id'] == id) & (fitbit_survey2['survey_date'] < 2)]\n",
    "    individual_data_long = fitbit_survey2[(fitbit_survey2['Id'] == id) & (fitbit_survey2['survey_date'] < 4)]\n",
    "    if len(individual_data_short) > max_short_day:\n",
    "        max_short_day = len(individual_data_short)\n",
    "\n",
    "    if len(individual_data_long) > max_long_day:\n",
    "        max_long_day = len(individual_data_long)\n",
    "\n",
    "# List to store padded matrices for each ID\n",
    "padded_matrices = []\n",
    "\n",
    "for id_val in ids:\n",
    "    # Filter data for the current `id_val` and specified condition\n",
    "    id_data = fitbit_survey2[(fitbit_survey2['Id'] == id_val) & (fitbit_survey2['survey_date'] < 2)]\n",
    "\n",
    "    max_rows = max_short_day\n",
    "    col = id_data.shape[1]\n",
    "    \n",
    "    # Convert to matrix (numpy array) without 'Id' and 'survey_date' columns\n",
    "    id_matrix = id_data.drop(columns=['Id', 'survey_date']).values\n",
    "    \n",
    "    # Pad each matrix to the target shape (max_rows, max_cols)\n",
    "    padded_id_matrix = np.pad(id_matrix, ((0, max_rows - id_matrix.shape[0]), (0, col - id_matrix.shape[1])), mode='constant', constant_values=0) \n",
    "    #pad the dataset with the same length with 0 and the padding value will be ignored by masking\n",
    "    \n",
    "    # Append the padded matrix to the list\n",
    "    padded_matrices.append(padded_id_matrix) #add 2D matrix to 3D\n",
    "\n",
    "# Stack all matrices into a single 3D array (number of IDs, max_rows, max_cols)\n",
    "final_padded_matrix = np.stack(padded_matrices, axis=0) \n",
    "\n",
    "\n",
    "# List to store padded matrices for each ID\n",
    "padded_matrices2 = []\n",
    "\n",
    "for id_val in ids:\n",
    "    # Filter data for the current `id_val` and specified condition\n",
    "    id_data = fitbit_survey2[(fitbit_survey2['Id'] == id_val) & (fitbit_survey2['survey_date'] < 4)]\n",
    "\n",
    "    max_rows = max_long_day\n",
    "    col = id_data.shape[1]\n",
    "    \n",
    "    # Convert to matrix (numpy array) without 'Id' and 'survey_date' columns\n",
    "    id_matrix = id_data.drop(columns=['Id', 'survey_date']).values\n",
    "    \n",
    "    # Pad each matrix to the target shape (max_rows, max_cols)\n",
    "    padded_id_matrix = np.pad(id_matrix, ((0, max_rows - id_matrix.shape[0]), (0, col - id_matrix.shape[1])), mode='constant', constant_values=0) \n",
    "    #pad the dataset with the same length with 0 and the padding value will be ignored by masking\n",
    "    \n",
    "    # Append the padded matrix to the list\n",
    "    padded_matrices2.append(padded_id_matrix) #add 2D matrix to 3D\n",
    "\n",
    "# Stack all matrices into a single 3D array (number of IDs, max_rows, max_cols)\n",
    "final_padded_matrix2 = np.stack(padded_matrices2, axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_short_data = final_padded_matrix.copy()\n",
    "X_long_data = final_padded_matrix2.copy()\n",
    "y_short_data = mental_health1.copy()\n",
    "y_long_data = mental_health2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize the data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_reshpaed = X_short_data.reshape(-1, X_short_data.shape[2])\n",
    "X_standardized = scaler.fit_transform(X_reshpaed)\n",
    "X_short_standardized = X_standardized.reshape(X_short_data.shape)\n",
    "\n",
    "X_reshpaed2 = X_long_data.reshape(-1, X_long_data.shape[2])\n",
    "X_standardized2 = scaler.fit_transform(X_reshpaed2)\n",
    "X_short_standardized2 = X_standardized2.reshape(X_long_data.shape) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataX, datay, shuffle = True, train_percentage = 0.7):\n",
    "    if shuffle:\n",
    "        random_indices = np.arange(len(dataX))\n",
    "        np.random.shuffle(random_indices)\n",
    "        dataX = dataX[random_indices]\n",
    "        datay = datay[random_indices]\n",
    "    \n",
    "    # Compute split indices\n",
    "    train_end = int(len(dataX) * train_percentage)\n",
    "\n",
    "    # Split the data\n",
    "    train_X, train_y = dataX[:train_end], datay[:train_end]\n",
    "    test_X, test_y = dataX[train_end:], datay[train_end:]\n",
    "    \n",
    "    return train_X, train_y, test_X, test_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data to training and validating\n",
    "train_X_data, train_y_data, test_X_data, test_y_data = train_test_split(X_short_standardized, y_short_data) \n",
    "train_y_data = train_y_data.reshape(-1, 1)\n",
    "test_y_data = test_y_data.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize y in order to decrease the value of loss function\n",
    "train_y_mean = train_y_data.mean()\n",
    "train_y_std = train_y_data.std()\n",
    "\n",
    "train_y = (train_y_data - train_y_mean) / train_y_std\n",
    "test_y = (test_y_data - train_y_mean) / train_y_std\n",
    "\n",
    "train_X_new = torch.tensor(train_X_data, dtype=torch.float32) # torch.Size([58, 109, 39])\n",
    "train_y_new = torch.tensor(train_y, dtype=torch.float32) # torch.Size([58, 1]) \n",
    "test_X_new = torch.tensor(test_X_data, dtype=torch.float32)  # torch.Size([14, 109, 39])\n",
    "test_y_new = torch.tensor(test_y, dtype=torch.float32) # torch.Size([14, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline: CNN-RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified training function to return training and testing losses\n",
    "def train_and_evaluate(model, train_X, train_y, test_X, test_y, criterion, optimizer, num_epochs):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass on training data\n",
    "        outputs = model(train_X)\n",
    "        train_loss = criterion(outputs, train_y)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store the training loss\n",
    "        train_losses.append(train_loss.item())\n",
    "\n",
    "        # Evaluate on the test data\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(test_X)\n",
    "            test_loss = criterion(test_outputs, test_y).item()\n",
    "            test_losses.append(test_loss)\n",
    "\n",
    "        # Print loss every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Training Loss: {train_loss.item():.4f}, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing hyperparameters: {'hidden_size': 16, 'learning_rate': 0.01, 'num_layers': 1}\n",
      "Epoch [10/50], Training Loss: 1.0009, Test Loss: 0.9232\n",
      "Epoch [20/50], Training Loss: 1.0001, Test Loss: 0.9311\n",
      "Epoch [30/50], Training Loss: 0.9998, Test Loss: 0.9302\n",
      "Epoch [40/50], Training Loss: 0.9970, Test Loss: 0.9237\n",
      "Epoch [50/50], Training Loss: 1.0008, Test Loss: 0.9251\n",
      "Test Loss: 0.9643\n",
      "Testing hyperparameters: {'hidden_size': 16, 'learning_rate': 0.01, 'num_layers': 2}\n",
      "Epoch [10/50], Training Loss: 1.0016, Test Loss: 0.9183\n",
      "Epoch [20/50], Training Loss: 0.9998, Test Loss: 0.9194\n",
      "Epoch [30/50], Training Loss: 0.9546, Test Loss: 1.0332\n",
      "Epoch [40/50], Training Loss: 0.8930, Test Loss: 1.2066\n",
      "Epoch [50/50], Training Loss: 0.8968, Test Loss: 1.0591\n",
      "Test Loss: 0.9775\n",
      "Testing hyperparameters: {'hidden_size': 16, 'learning_rate': 0.01, 'num_layers': 3}\n",
      "Epoch [10/50], Training Loss: 1.0017, Test Loss: 0.9264\n",
      "Epoch [20/50], Training Loss: 1.0003, Test Loss: 0.9268\n",
      "Epoch [30/50], Training Loss: 0.9994, Test Loss: 0.9239\n",
      "Epoch [40/50], Training Loss: 1.0031, Test Loss: 0.9217\n",
      "Epoch [50/50], Training Loss: 0.9764, Test Loss: 1.0320\n",
      "Test Loss: 0.9671\n",
      "Testing hyperparameters: {'hidden_size': 16, 'learning_rate': 0.001, 'num_layers': 1}\n",
      "Epoch [10/50], Training Loss: 1.0000, Test Loss: 0.9267\n",
      "Epoch [20/50], Training Loss: 1.0000, Test Loss: 0.9276\n",
      "Epoch [30/50], Training Loss: 1.0000, Test Loss: 0.9273\n",
      "Epoch [40/50], Training Loss: 1.0000, Test Loss: 0.9282\n",
      "Epoch [50/50], Training Loss: 1.0000, Test Loss: 0.9293\n",
      "Test Loss: 0.9638\n",
      "Testing hyperparameters: {'hidden_size': 16, 'learning_rate': 0.001, 'num_layers': 2}\n",
      "Epoch [10/50], Training Loss: 1.0018, Test Loss: 0.9326\n",
      "Epoch [20/50], Training Loss: 1.0006, Test Loss: 0.9287\n",
      "Epoch [30/50], Training Loss: 1.0002, Test Loss: 0.9304\n",
      "Epoch [40/50], Training Loss: 1.0000, Test Loss: 0.9290\n",
      "Epoch [50/50], Training Loss: 1.0000, Test Loss: 0.9295\n",
      "Test Loss: 0.9652\n",
      "Testing hyperparameters: {'hidden_size': 16, 'learning_rate': 0.001, 'num_layers': 3}\n",
      "Epoch [10/50], Training Loss: 1.0145, Test Loss: 0.9280\n",
      "Epoch [20/50], Training Loss: 1.0071, Test Loss: 0.9303\n",
      "Epoch [30/50], Training Loss: 1.0000, Test Loss: 0.9186\n",
      "Epoch [40/50], Training Loss: 1.0010, Test Loss: 0.9177\n",
      "Epoch [50/50], Training Loss: 1.0000, Test Loss: 0.9160\n",
      "Test Loss: 0.9739\n",
      "Testing hyperparameters: {'hidden_size': 16, 'learning_rate': 0.0001, 'num_layers': 1}\n",
      "Epoch [10/50], Training Loss: 1.1400, Test Loss: 1.0502\n",
      "Epoch [20/50], Training Loss: 1.1262, Test Loss: 1.0374\n",
      "Epoch [30/50], Training Loss: 1.1134, Test Loss: 1.0256\n",
      "Epoch [40/50], Training Loss: 1.1015, Test Loss: 1.0147\n",
      "Epoch [50/50], Training Loss: 1.0906, Test Loss: 1.0048\n",
      "Test Loss: 1.0759\n",
      "Testing hyperparameters: {'hidden_size': 16, 'learning_rate': 0.0001, 'num_layers': 2}\n",
      "Epoch [10/50], Training Loss: 1.2311, Test Loss: 1.1362\n",
      "Epoch [20/50], Training Loss: 1.2030, Test Loss: 1.1091\n",
      "Epoch [30/50], Training Loss: 1.1776, Test Loss: 1.0849\n",
      "Epoch [40/50], Training Loss: 1.1549, Test Loss: 1.0633\n",
      "Epoch [50/50], Training Loss: 1.1345, Test Loss: 1.0440\n",
      "Test Loss: 1.1449\n",
      "Testing hyperparameters: {'hidden_size': 16, 'learning_rate': 0.0001, 'num_layers': 3}\n",
      "Epoch [10/50], Training Loss: 1.0517, Test Loss: 0.9602\n",
      "Epoch [20/50], Training Loss: 1.0230, Test Loss: 0.9346\n",
      "Epoch [30/50], Training Loss: 1.0074, Test Loss: 0.9218\n",
      "Epoch [40/50], Training Loss: 1.0013, Test Loss: 0.9178\n",
      "Epoch [50/50], Training Loss: 1.0000, Test Loss: 0.9178\n",
      "Test Loss: 0.9807\n",
      "Testing hyperparameters: {'hidden_size': 32, 'learning_rate': 0.01, 'num_layers': 1}\n",
      "Epoch [10/50], Training Loss: 1.0011, Test Loss: 0.9159\n",
      "Epoch [20/50], Training Loss: 0.9991, Test Loss: 0.9096\n",
      "Epoch [30/50], Training Loss: 0.9846, Test Loss: 0.8481\n",
      "Epoch [40/50], Training Loss: 1.1014, Test Loss: 1.0757\n",
      "Epoch [50/50], Training Loss: 0.9640, Test Loss: 0.9379\n",
      "Test Loss: 0.9576\n",
      "Testing hyperparameters: {'hidden_size': 32, 'learning_rate': 0.01, 'num_layers': 2}\n",
      "Epoch [10/50], Training Loss: 1.0018, Test Loss: 0.9192\n",
      "Epoch [20/50], Training Loss: 0.9968, Test Loss: 0.9191\n",
      "Epoch [30/50], Training Loss: 0.9994, Test Loss: 0.9155\n",
      "Epoch [40/50], Training Loss: 0.9986, Test Loss: 0.9121\n",
      "Epoch [50/50], Training Loss: 0.9936, Test Loss: 0.9098\n",
      "Test Loss: 0.9657\n",
      "Testing hyperparameters: {'hidden_size': 32, 'learning_rate': 0.01, 'num_layers': 3}\n",
      "Epoch [10/50], Training Loss: 1.0048, Test Loss: 0.9193\n",
      "Epoch [20/50], Training Loss: 1.0011, Test Loss: 0.9143\n",
      "Epoch [30/50], Training Loss: 1.0255, Test Loss: 0.9174\n",
      "Epoch [40/50], Training Loss: 0.9907, Test Loss: 0.9312\n",
      "Epoch [50/50], Training Loss: 0.9827, Test Loss: 0.9143\n",
      "Test Loss: 0.9737\n",
      "Testing hyperparameters: {'hidden_size': 32, 'learning_rate': 0.001, 'num_layers': 1}\n",
      "Epoch [10/50], Training Loss: 1.0000, Test Loss: 0.9238\n",
      "Epoch [20/50], Training Loss: 1.0000, Test Loss: 0.9261\n",
      "Epoch [30/50], Training Loss: 0.9998, Test Loss: 0.9283\n",
      "Epoch [40/50], Training Loss: 0.9985, Test Loss: 0.9297\n",
      "Epoch [50/50], Training Loss: 0.9910, Test Loss: 0.9670\n",
      "Test Loss: 0.9639\n",
      "Testing hyperparameters: {'hidden_size': 32, 'learning_rate': 0.001, 'num_layers': 2}\n",
      "Epoch [10/50], Training Loss: 1.0007, Test Loss: 0.9199\n",
      "Epoch [20/50], Training Loss: 1.0001, Test Loss: 0.9201\n",
      "Epoch [30/50], Training Loss: 1.0000, Test Loss: 0.9201\n",
      "Epoch [40/50], Training Loss: 1.0000, Test Loss: 0.9199\n",
      "Epoch [50/50], Training Loss: 1.0000, Test Loss: 0.9194\n",
      "Test Loss: 0.9602\n",
      "Testing hyperparameters: {'hidden_size': 32, 'learning_rate': 0.001, 'num_layers': 3}\n",
      "Epoch [10/50], Training Loss: 1.0000, Test Loss: 0.9205\n",
      "Epoch [20/50], Training Loss: 1.0000, Test Loss: 0.9196\n",
      "Epoch [30/50], Training Loss: 0.9999, Test Loss: 0.9201\n",
      "Epoch [40/50], Training Loss: 0.9999, Test Loss: 0.9201\n",
      "Epoch [50/50], Training Loss: 0.9997, Test Loss: 0.9200\n",
      "Test Loss: 0.9611\n",
      "Testing hyperparameters: {'hidden_size': 32, 'learning_rate': 0.0001, 'num_layers': 1}\n",
      "Epoch [10/50], Training Loss: 1.0209, Test Loss: 0.9451\n",
      "Epoch [20/50], Training Loss: 1.0121, Test Loss: 0.9346\n",
      "Epoch [30/50], Training Loss: 1.0062, Test Loss: 0.9273\n",
      "Epoch [40/50], Training Loss: 1.0028, Test Loss: 0.9228\n",
      "Epoch [50/50], Training Loss: 1.0010, Test Loss: 0.9201\n",
      "Test Loss: 0.9723\n",
      "Testing hyperparameters: {'hidden_size': 32, 'learning_rate': 0.0001, 'num_layers': 2}\n",
      "Epoch [10/50], Training Loss: 1.0115, Test Loss: 0.9299\n",
      "Epoch [20/50], Training Loss: 1.0023, Test Loss: 0.9199\n",
      "Epoch [30/50], Training Loss: 1.0000, Test Loss: 0.9172\n",
      "Epoch [40/50], Training Loss: 1.0003, Test Loss: 0.9175\n",
      "Epoch [50/50], Training Loss: 1.0001, Test Loss: 0.9180\n",
      "Test Loss: 0.9640\n",
      "Testing hyperparameters: {'hidden_size': 32, 'learning_rate': 0.0001, 'num_layers': 3}\n",
      "Epoch [10/50], Training Loss: 1.0001, Test Loss: 0.9211\n",
      "Epoch [20/50], Training Loss: 1.0002, Test Loss: 0.9212\n",
      "Epoch [30/50], Training Loss: 1.0001, Test Loss: 0.9218\n",
      "Epoch [40/50], Training Loss: 1.0000, Test Loss: 0.9216\n",
      "Epoch [50/50], Training Loss: 1.0000, Test Loss: 0.9217\n",
      "Test Loss: 0.9610\n",
      "Testing hyperparameters: {'hidden_size': 64, 'learning_rate': 0.01, 'num_layers': 1}\n",
      "Epoch [10/50], Training Loss: 1.0025, Test Loss: 0.9107\n",
      "Epoch [20/50], Training Loss: 1.1449, Test Loss: 1.1777\n",
      "Epoch [30/50], Training Loss: 1.0650, Test Loss: 0.9259\n",
      "Epoch [40/50], Training Loss: 0.9052, Test Loss: 1.2478\n",
      "Epoch [50/50], Training Loss: 0.9537, Test Loss: 1.1892\n",
      "Test Loss: 1.0190\n",
      "Testing hyperparameters: {'hidden_size': 64, 'learning_rate': 0.01, 'num_layers': 2}\n",
      "Epoch [10/50], Training Loss: 1.2246, Test Loss: 0.9156\n",
      "Epoch [20/50], Training Loss: 1.0053, Test Loss: 0.9610\n",
      "Epoch [30/50], Training Loss: 1.0039, Test Loss: 0.9161\n",
      "Epoch [40/50], Training Loss: 1.0012, Test Loss: 0.9116\n",
      "Epoch [50/50], Training Loss: 1.0001, Test Loss: 0.9142\n",
      "Test Loss: 0.9896\n",
      "Testing hyperparameters: {'hidden_size': 64, 'learning_rate': 0.01, 'num_layers': 3}\n",
      "Epoch [10/50], Training Loss: 0.9972, Test Loss: 1.4234\n",
      "Epoch [20/50], Training Loss: 0.9992, Test Loss: 0.9622\n",
      "Epoch [30/50], Training Loss: 1.0041, Test Loss: 0.9313\n",
      "Epoch [40/50], Training Loss: 1.0024, Test Loss: 0.9138\n",
      "Epoch [50/50], Training Loss: 1.0027, Test Loss: 0.9135\n",
      "Test Loss: 1.0126\n",
      "Testing hyperparameters: {'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 1}\n",
      "Epoch [10/50], Training Loss: 1.0011, Test Loss: 0.9239\n",
      "Epoch [20/50], Training Loss: 1.0000, Test Loss: 0.9239\n",
      "Epoch [30/50], Training Loss: 1.0001, Test Loss: 0.9247\n",
      "Epoch [40/50], Training Loss: 1.0000, Test Loss: 0.9266\n",
      "Epoch [50/50], Training Loss: 0.9999, Test Loss: 0.9276\n",
      "Test Loss: 0.9625\n",
      "Testing hyperparameters: {'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 2}\n",
      "Epoch [10/50], Training Loss: 1.0007, Test Loss: 0.9153\n",
      "Epoch [20/50], Training Loss: 0.9999, Test Loss: 0.9161\n",
      "Epoch [30/50], Training Loss: 0.9999, Test Loss: 0.9179\n",
      "Epoch [40/50], Training Loss: 0.9973, Test Loss: 0.9204\n",
      "Epoch [50/50], Training Loss: 0.9809, Test Loss: 0.9250\n",
      "Test Loss: 0.9582\n",
      "Testing hyperparameters: {'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 3}\n",
      "Epoch [10/50], Training Loss: 1.0010, Test Loss: 0.9187\n",
      "Epoch [20/50], Training Loss: 1.0001, Test Loss: 0.9182\n",
      "Epoch [30/50], Training Loss: 0.9998, Test Loss: 0.9181\n",
      "Epoch [40/50], Training Loss: 0.9871, Test Loss: 0.9185\n",
      "Epoch [50/50], Training Loss: 0.9458, Test Loss: 0.8833\n",
      "Test Loss: 0.9546\n",
      "Testing hyperparameters: {'hidden_size': 64, 'learning_rate': 0.0001, 'num_layers': 1}\n",
      "Epoch [10/50], Training Loss: 1.0010, Test Loss: 0.9207\n",
      "Epoch [20/50], Training Loss: 1.0001, Test Loss: 0.9188\n",
      "Epoch [30/50], Training Loss: 1.0002, Test Loss: 0.9191\n",
      "Epoch [40/50], Training Loss: 1.0000, Test Loss: 0.9197\n",
      "Epoch [50/50], Training Loss: 1.0000, Test Loss: 0.9201\n",
      "Test Loss: 0.9606\n",
      "Testing hyperparameters: {'hidden_size': 64, 'learning_rate': 0.0001, 'num_layers': 2}\n",
      "Epoch [10/50], Training Loss: 1.0000, Test Loss: 0.9145\n",
      "Epoch [20/50], Training Loss: 1.0000, Test Loss: 0.9149\n",
      "Epoch [30/50], Training Loss: 1.0000, Test Loss: 0.9151\n",
      "Epoch [40/50], Training Loss: 1.0000, Test Loss: 0.9151\n",
      "Epoch [50/50], Training Loss: 0.9999, Test Loss: 0.9150\n",
      "Test Loss: 0.9574\n",
      "Testing hyperparameters: {'hidden_size': 64, 'learning_rate': 0.0001, 'num_layers': 3}\n",
      "Epoch [10/50], Training Loss: 1.0001, Test Loss: 0.9180\n",
      "Epoch [20/50], Training Loss: 1.0015, Test Loss: 0.9182\n",
      "Epoch [30/50], Training Loss: 1.0000, Test Loss: 0.9178\n",
      "Epoch [40/50], Training Loss: 1.0002, Test Loss: 0.9177\n",
      "Epoch [50/50], Training Loss: 1.0000, Test Loss: 0.9170\n",
      "Test Loss: 0.9607\n",
      "Best Hyperparameters: {'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 3}\n",
      "Best Loss: 0.9546\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters tuning\n",
    "input_size = train_X_new.shape[2]  # Feature size\n",
    "output_size = 1\n",
    "# Define the hyperparameter space\n",
    "hyperparameter_space = {\n",
    "    'hidden_size': [16, 32, 64],\n",
    "    'num_layers': [1, 2, 3],\n",
    "    'learning_rate': [0.01, 0.001, 0.0001],\n",
    "}\n",
    "\n",
    "param_grid = ParameterGrid(hyperparameter_space)\n",
    "\n",
    "# Track the best hyperparameters\n",
    "best_params = None\n",
    "best_loss = float('inf')\n",
    "\n",
    "for params in param_grid:\n",
    "    print(f\"Testing hyperparameters: {params}\")\n",
    "\n",
    "    # Extract hyperparameters\n",
    "    hidden_size = params['hidden_size']\n",
    "    num_layers = params['num_layers']\n",
    "    learning_rate = params['learning_rate']\n",
    "\n",
    "    # Initialize the model, criterion, and optimizer\n",
    "    model = CNN_RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, output_size=output_size)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    test_loss = train_and_evaluate(\n",
    "        model,\n",
    "        train_X_new,\n",
    "        train_y_new,\n",
    "        test_X_new,\n",
    "        test_y_new,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        num_epochs=50\n",
    "    )\n",
    "    mean_loss = np.mean(test_loss)\n",
    "    print(f\"Test Loss: {mean_loss:.4f}\")\n",
    "\n",
    "    # Check if this is the best model so far\n",
    "    if mean_loss < best_loss:\n",
    "        best_loss = mean_loss\n",
    "        best_params = params\n",
    "\n",
    "# Print the best hyperparameters and loss\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Loss: {best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/500], Training Loss: 1.0014, Test Loss: 0.9203\n",
      "Epoch [20/500], Training Loss: 1.0000, Test Loss: 0.9187\n",
      "Epoch [30/500], Training Loss: 1.0001, Test Loss: 0.9181\n",
      "Epoch [40/500], Training Loss: 1.0000, Test Loss: 0.9167\n",
      "Epoch [50/500], Training Loss: 0.9997, Test Loss: 0.9160\n",
      "Epoch [60/500], Training Loss: 0.9928, Test Loss: 0.9168\n",
      "Epoch [70/500], Training Loss: 0.9845, Test Loss: 0.9128\n",
      "Epoch [80/500], Training Loss: 0.9771, Test Loss: 0.9026\n",
      "Epoch [90/500], Training Loss: 0.9738, Test Loss: 0.9029\n",
      "Epoch [100/500], Training Loss: 0.9518, Test Loss: 0.8973\n",
      "Epoch [110/500], Training Loss: 0.9787, Test Loss: 0.9078\n",
      "Epoch [120/500], Training Loss: 0.9727, Test Loss: 0.9083\n",
      "Epoch [130/500], Training Loss: 0.9708, Test Loss: 0.9165\n",
      "Epoch [140/500], Training Loss: 0.9678, Test Loss: 0.9228\n",
      "Epoch [150/500], Training Loss: 0.9675, Test Loss: 0.9241\n",
      "Epoch [160/500], Training Loss: 0.9671, Test Loss: 0.9235\n",
      "Epoch [170/500], Training Loss: 0.9669, Test Loss: 0.9254\n",
      "Epoch [180/500], Training Loss: 0.9665, Test Loss: 0.9265\n",
      "Epoch [190/500], Training Loss: 0.9662, Test Loss: 0.9287\n",
      "Epoch [200/500], Training Loss: 0.9657, Test Loss: 0.9294\n",
      "Epoch [210/500], Training Loss: 0.9648, Test Loss: 0.9288\n",
      "Epoch [220/500], Training Loss: 0.9588, Test Loss: 0.9215\n",
      "Epoch [230/500], Training Loss: 0.9459, Test Loss: 0.9116\n",
      "Epoch [240/500], Training Loss: 0.9290, Test Loss: 0.9615\n",
      "Epoch [250/500], Training Loss: 0.9219, Test Loss: 0.9264\n",
      "Epoch [260/500], Training Loss: 0.9061, Test Loss: 0.9068\n",
      "Epoch [270/500], Training Loss: 0.9085, Test Loss: 0.9151\n",
      "Epoch [280/500], Training Loss: 1.0314, Test Loss: 1.1063\n",
      "Epoch [290/500], Training Loss: 0.9819, Test Loss: 0.9113\n",
      "Epoch [300/500], Training Loss: 0.9769, Test Loss: 0.9082\n",
      "Epoch [310/500], Training Loss: 0.9747, Test Loss: 0.9074\n",
      "Epoch [320/500], Training Loss: 0.9677, Test Loss: 0.9030\n",
      "Epoch [330/500], Training Loss: 0.9042, Test Loss: 0.8920\n",
      "Epoch [340/500], Training Loss: 0.8845, Test Loss: 0.8951\n",
      "Epoch [350/500], Training Loss: 0.9073, Test Loss: 0.8490\n",
      "Epoch [360/500], Training Loss: 0.6845, Test Loss: 1.0160\n",
      "Epoch [370/500], Training Loss: 0.6418, Test Loss: 0.9170\n",
      "Epoch [380/500], Training Loss: 0.5071, Test Loss: 1.1538\n",
      "Epoch [390/500], Training Loss: 0.4737, Test Loss: 1.2120\n",
      "Epoch [400/500], Training Loss: 0.4212, Test Loss: 1.3538\n",
      "Epoch [410/500], Training Loss: 0.3595, Test Loss: 1.5261\n",
      "Epoch [420/500], Training Loss: 0.2973, Test Loss: 1.6401\n",
      "Epoch [430/500], Training Loss: 0.2372, Test Loss: 1.5290\n",
      "Epoch [440/500], Training Loss: 0.3326, Test Loss: 1.3200\n",
      "Epoch [450/500], Training Loss: 0.2449, Test Loss: 1.3230\n",
      "Epoch [460/500], Training Loss: 0.1906, Test Loss: 1.4038\n",
      "Epoch [470/500], Training Loss: 0.2228, Test Loss: 1.2897\n",
      "Epoch [480/500], Training Loss: 0.1448, Test Loss: 1.3915\n",
      "Epoch [490/500], Training Loss: 0.1373, Test Loss: 1.4156\n",
      "Epoch [500/500], Training Loss: 0.1190, Test Loss: 1.5047\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_size = train_X_new.shape[2]  # Feature size\n",
    "output_size = 1  # Continuous output variable\n",
    "hidden_size = 64 # Number of hidden units\n",
    "num_layers = 2 # Number of RNN layers\n",
    "learning_rate = 0.001\n",
    "num_epochs = 500\n",
    "\n",
    "# Initialize the model, criterion, and optimizer\n",
    "model = CNN_RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, output_size=output_size)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for continuous variables\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_losses, test_losses = train_and_evaluate(\n",
    "    model,\n",
    "    train_X_new,\n",
    "    train_y_new,\n",
    "    test_X_new,\n",
    "    test_y_new,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    num_epochs=num_epochs\n",
    ")\n",
    "\n",
    "# Plot the training and testing losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, len(test_losses) + 1), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Testing Loss over Epochs (CNN-RNN)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced: CNN-LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(params, train_X, train_y, test_X, test_y, num_epochs):\n",
    "    hidden_size = params['hidden_size']\n",
    "    num_layers = params['num_layers']\n",
    "    learning_rate = params['learning_rate']\n",
    "    batch_size = params['batch_size']\n",
    "    \n",
    "    # Model instantiation\n",
    "    model = CNN_LSTM(\n",
    "        input_size=train_X.shape[2],\n",
    "        seq_len=train_X.shape[1],\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers,\n",
    "        output_size=1\n",
    "    )\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Initialize lists to track losses\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for i in range(0, len(train_X), batch_size):\n",
    "            batch_X = train_X[i:i + batch_size]\n",
    "            batch_y = train_y[i:i + batch_size]\n",
    "\n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Average training loss for the epoch\n",
    "        avg_train_loss = total_train_loss / (len(train_X) // batch_size)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Evaluation loop\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            total_test_loss = 0\n",
    "            for i in range(0, len(test_X), batch_size):\n",
    "                batch_X = test_X[i:i + batch_size]\n",
    "                batch_y = test_y[i:i + batch_size]\n",
    "\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                total_test_loss += loss.item()\n",
    "\n",
    "        # Average testing loss for the epoch\n",
    "        avg_test_loss = total_test_loss / (len(test_X) // batch_size)\n",
    "        test_losses.append(avg_test_loss)\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}] - Train Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "    return train_losses, test_losses, avg_test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing combination: (4, 1, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1317, Test Loss: 1.0972\n",
      "Epoch [2/50] - Train Loss: 1.1181, Test Loss: 1.1057\n",
      "Epoch [3/50] - Train Loss: 1.1146, Test Loss: 1.1023\n",
      "Epoch [4/50] - Train Loss: 1.1105, Test Loss: 1.1002\n",
      "Epoch [5/50] - Train Loss: 1.1081, Test Loss: 1.1015\n",
      "Epoch [6/50] - Train Loss: 1.1062, Test Loss: 1.1037\n",
      "Epoch [7/50] - Train Loss: 1.1044, Test Loss: 1.1072\n",
      "Epoch [8/50] - Train Loss: 1.1022, Test Loss: 1.1121\n",
      "Epoch [9/50] - Train Loss: 1.0996, Test Loss: 1.1184\n",
      "Epoch [10/50] - Train Loss: 1.0963, Test Loss: 1.1262\n",
      "Epoch [11/50] - Train Loss: 1.0921, Test Loss: 1.1359\n",
      "Epoch [12/50] - Train Loss: 1.0875, Test Loss: 1.1469\n",
      "Epoch [13/50] - Train Loss: 1.0847, Test Loss: 1.1571\n",
      "Epoch [14/50] - Train Loss: 1.0834, Test Loss: 1.1642\n",
      "Epoch [15/50] - Train Loss: 1.0816, Test Loss: 1.1698\n",
      "Epoch [16/50] - Train Loss: 1.0797, Test Loss: 1.1753\n",
      "Epoch [17/50] - Train Loss: 1.0784, Test Loss: 1.1807\n",
      "Epoch [18/50] - Train Loss: 1.0775, Test Loss: 1.1856\n",
      "Epoch [19/50] - Train Loss: 1.0770, Test Loss: 1.1899\n",
      "Epoch [20/50] - Train Loss: 1.0766, Test Loss: 1.1937\n",
      "Epoch [21/50] - Train Loss: 1.0762, Test Loss: 1.1970\n",
      "Epoch [22/50] - Train Loss: 1.0759, Test Loss: 1.2000\n",
      "Epoch [23/50] - Train Loss: 1.0757, Test Loss: 1.2026\n",
      "Epoch [24/50] - Train Loss: 1.0755, Test Loss: 1.2050\n",
      "Epoch [25/50] - Train Loss: 1.0753, Test Loss: 1.2071\n",
      "Epoch [26/50] - Train Loss: 1.0752, Test Loss: 1.2090\n",
      "Epoch [27/50] - Train Loss: 1.0751, Test Loss: 1.2107\n",
      "Epoch [28/50] - Train Loss: 1.0750, Test Loss: 1.2122\n",
      "Epoch [29/50] - Train Loss: 1.0749, Test Loss: 1.2135\n",
      "Epoch [30/50] - Train Loss: 1.0748, Test Loss: 1.2148\n",
      "Epoch [31/50] - Train Loss: 1.0747, Test Loss: 1.2158\n",
      "Epoch [32/50] - Train Loss: 1.0747, Test Loss: 1.2168\n",
      "Epoch [33/50] - Train Loss: 1.0746, Test Loss: 1.2177\n",
      "Epoch [34/50] - Train Loss: 1.0745, Test Loss: 1.2186\n",
      "Epoch [35/50] - Train Loss: 1.0745, Test Loss: 1.2194\n",
      "Epoch [36/50] - Train Loss: 1.0744, Test Loss: 1.2201\n",
      "Epoch [37/50] - Train Loss: 1.0744, Test Loss: 1.2209\n",
      "Epoch [38/50] - Train Loss: 1.0743, Test Loss: 1.2217\n",
      "Epoch [39/50] - Train Loss: 1.0743, Test Loss: 1.2225\n",
      "Epoch [40/50] - Train Loss: 1.0742, Test Loss: 1.2233\n",
      "Epoch [41/50] - Train Loss: 1.0741, Test Loss: 1.2241\n",
      "Epoch [42/50] - Train Loss: 1.0741, Test Loss: 1.2250\n",
      "Epoch [43/50] - Train Loss: 1.0740, Test Loss: 1.2260\n",
      "Epoch [44/50] - Train Loss: 1.0740, Test Loss: 1.2271\n",
      "Epoch [45/50] - Train Loss: 1.0739, Test Loss: 1.2283\n",
      "Epoch [46/50] - Train Loss: 1.0737, Test Loss: 1.2297\n",
      "Epoch [47/50] - Train Loss: 1.0736, Test Loss: 1.2312\n",
      "Epoch [48/50] - Train Loss: 1.0733, Test Loss: 1.2330\n",
      "Epoch [49/50] - Train Loss: 1.0726, Test Loss: 1.2351\n",
      "Epoch [50/50] - Train Loss: 1.0709, Test Loss: 1.2377\n",
      "Avg Test Loss: 1.2377\n",
      "Testing combination: (4, 1, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1615, Test Loss: 1.1691\n",
      "Epoch [2/50] - Train Loss: 1.1497, Test Loss: 1.1710\n",
      "Epoch [3/50] - Train Loss: 1.1470, Test Loss: 1.1729\n",
      "Epoch [4/50] - Train Loss: 1.1434, Test Loss: 1.1772\n",
      "Epoch [5/50] - Train Loss: 1.1352, Test Loss: 1.1817\n",
      "Epoch [6/50] - Train Loss: 1.1153, Test Loss: 1.1813\n",
      "Epoch [7/50] - Train Loss: 1.0892, Test Loss: 1.1780\n",
      "Epoch [8/50] - Train Loss: 1.0745, Test Loss: 1.1809\n",
      "Epoch [9/50] - Train Loss: 1.0654, Test Loss: 1.1866\n",
      "Epoch [10/50] - Train Loss: 1.0607, Test Loss: 1.1921\n",
      "Epoch [11/50] - Train Loss: 1.0567, Test Loss: 1.1954\n",
      "Epoch [12/50] - Train Loss: 1.0531, Test Loss: 1.1979\n",
      "Epoch [13/50] - Train Loss: 1.0509, Test Loss: 1.1999\n",
      "Epoch [14/50] - Train Loss: 1.0496, Test Loss: 1.2010\n",
      "Epoch [15/50] - Train Loss: 1.0487, Test Loss: 1.2012\n",
      "Epoch [16/50] - Train Loss: 1.0479, Test Loss: 1.2004\n",
      "Epoch [17/50] - Train Loss: 1.0471, Test Loss: 1.1990\n",
      "Epoch [18/50] - Train Loss: 1.0464, Test Loss: 1.1972\n",
      "Epoch [19/50] - Train Loss: 1.0456, Test Loss: 1.1955\n",
      "Epoch [20/50] - Train Loss: 1.0450, Test Loss: 1.1941\n",
      "Epoch [21/50] - Train Loss: 1.0444, Test Loss: 1.1930\n",
      "Epoch [22/50] - Train Loss: 1.0438, Test Loss: 1.1922\n",
      "Epoch [23/50] - Train Loss: 1.0434, Test Loss: 1.1919\n",
      "Epoch [24/50] - Train Loss: 1.0430, Test Loss: 1.1914\n",
      "Epoch [25/50] - Train Loss: 1.0426, Test Loss: 1.1911\n",
      "Epoch [26/50] - Train Loss: 1.0422, Test Loss: 1.1911\n",
      "Epoch [27/50] - Train Loss: 1.0419, Test Loss: 1.1912\n",
      "Epoch [28/50] - Train Loss: 1.0416, Test Loss: 1.1917\n",
      "Epoch [29/50] - Train Loss: 1.0413, Test Loss: 1.1921\n",
      "Epoch [30/50] - Train Loss: 1.0410, Test Loss: 1.1929\n",
      "Epoch [31/50] - Train Loss: 1.0407, Test Loss: 1.1938\n",
      "Epoch [32/50] - Train Loss: 1.0403, Test Loss: 1.1949\n",
      "Epoch [33/50] - Train Loss: 1.0397, Test Loss: 1.1959\n",
      "Epoch [34/50] - Train Loss: 1.0389, Test Loss: 1.1965\n",
      "Epoch [35/50] - Train Loss: 1.0377, Test Loss: 1.1958\n",
      "Epoch [36/50] - Train Loss: 1.0360, Test Loss: 1.1945\n",
      "Epoch [37/50] - Train Loss: 1.0325, Test Loss: 1.1989\n",
      "Epoch [38/50] - Train Loss: 1.0284, Test Loss: 1.1878\n",
      "Epoch [39/50] - Train Loss: 1.0327, Test Loss: 1.2093\n",
      "Epoch [40/50] - Train Loss: 1.0114, Test Loss: 1.1731\n",
      "Epoch [41/50] - Train Loss: 1.0233, Test Loss: 1.2319\n",
      "Epoch [42/50] - Train Loss: 1.0080, Test Loss: 1.2378\n",
      "Epoch [43/50] - Train Loss: 1.0287, Test Loss: 1.2027\n",
      "Epoch [44/50] - Train Loss: 1.0176, Test Loss: 1.1801\n",
      "Epoch [45/50] - Train Loss: 1.0449, Test Loss: 1.1787\n",
      "Epoch [46/50] - Train Loss: 1.0286, Test Loss: 1.1909\n",
      "Epoch [47/50] - Train Loss: 1.0125, Test Loss: 1.2482\n",
      "Epoch [48/50] - Train Loss: 1.0028, Test Loss: 1.2611\n",
      "Epoch [49/50] - Train Loss: 0.9784, Test Loss: 1.2419\n",
      "Epoch [50/50] - Train Loss: 0.9628, Test Loss: 1.2216\n",
      "Avg Test Loss: 1.2216\n",
      "Testing combination: (4, 1, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5029, Test Loss: 1.7372\n",
      "Epoch [2/50] - Train Loss: 1.4896, Test Loss: 1.7407\n",
      "Epoch [3/50] - Train Loss: 1.4873, Test Loss: 1.7428\n",
      "Epoch [4/50] - Train Loss: 1.4861, Test Loss: 1.7432\n",
      "Epoch [5/50] - Train Loss: 1.4853, Test Loss: 1.7422\n",
      "Epoch [6/50] - Train Loss: 1.4846, Test Loss: 1.7409\n",
      "Epoch [7/50] - Train Loss: 1.4839, Test Loss: 1.7396\n",
      "Epoch [8/50] - Train Loss: 1.4831, Test Loss: 1.7383\n",
      "Epoch [9/50] - Train Loss: 1.4822, Test Loss: 1.7371\n",
      "Epoch [10/50] - Train Loss: 1.4815, Test Loss: 1.7359\n",
      "Epoch [11/50] - Train Loss: 1.4807, Test Loss: 1.7351\n",
      "Epoch [12/50] - Train Loss: 1.4794, Test Loss: 1.7344\n",
      "Epoch [13/50] - Train Loss: 1.4774, Test Loss: 1.7340\n",
      "Epoch [14/50] - Train Loss: 1.4745, Test Loss: 1.7338\n",
      "Epoch [15/50] - Train Loss: 1.4714, Test Loss: 1.7342\n",
      "Epoch [16/50] - Train Loss: 1.4689, Test Loss: 1.7353\n",
      "Epoch [17/50] - Train Loss: 1.4668, Test Loss: 1.7374\n",
      "Epoch [18/50] - Train Loss: 1.4649, Test Loss: 1.7419\n",
      "Epoch [19/50] - Train Loss: 1.4630, Test Loss: 1.7495\n",
      "Epoch [20/50] - Train Loss: 1.4611, Test Loss: 1.7608\n",
      "Epoch [21/50] - Train Loss: 1.4593, Test Loss: 1.7749\n",
      "Epoch [22/50] - Train Loss: 1.4573, Test Loss: 1.7882\n",
      "Epoch [23/50] - Train Loss: 1.4552, Test Loss: 1.7987\n",
      "Epoch [24/50] - Train Loss: 1.4529, Test Loss: 1.8069\n",
      "Epoch [25/50] - Train Loss: 1.4503, Test Loss: 1.8141\n",
      "Epoch [26/50] - Train Loss: 1.4475, Test Loss: 1.8214\n",
      "Epoch [27/50] - Train Loss: 1.4444, Test Loss: 1.8289\n",
      "Epoch [28/50] - Train Loss: 1.4410, Test Loss: 1.8364\n",
      "Epoch [29/50] - Train Loss: 1.4364, Test Loss: 1.8429\n",
      "Epoch [30/50] - Train Loss: 1.4304, Test Loss: 1.8514\n",
      "Epoch [31/50] - Train Loss: 1.4261, Test Loss: 1.8625\n",
      "Epoch [32/50] - Train Loss: 1.4222, Test Loss: 1.8723\n",
      "Epoch [33/50] - Train Loss: 1.4243, Test Loss: 1.8774\n",
      "Epoch [34/50] - Train Loss: 1.4261, Test Loss: 1.8795\n",
      "Epoch [35/50] - Train Loss: 1.4264, Test Loss: 1.8792\n",
      "Epoch [36/50] - Train Loss: 1.4248, Test Loss: 1.8779\n",
      "Epoch [37/50] - Train Loss: 1.4244, Test Loss: 1.8764\n",
      "Epoch [38/50] - Train Loss: 1.4241, Test Loss: 1.8753\n",
      "Epoch [39/50] - Train Loss: 1.4235, Test Loss: 1.8748\n",
      "Epoch [40/50] - Train Loss: 1.4227, Test Loss: 1.8747\n",
      "Epoch [41/50] - Train Loss: 1.4219, Test Loss: 1.8748\n",
      "Epoch [42/50] - Train Loss: 1.4216, Test Loss: 1.8749\n",
      "Epoch [43/50] - Train Loss: 1.4214, Test Loss: 1.8741\n",
      "Epoch [44/50] - Train Loss: 1.4210, Test Loss: 1.8754\n",
      "Epoch [45/50] - Train Loss: 1.4198, Test Loss: 1.8673\n",
      "Epoch [46/50] - Train Loss: 1.4188, Test Loss: 1.8545\n",
      "Epoch [47/50] - Train Loss: 1.4192, Test Loss: 1.8330\n",
      "Epoch [48/50] - Train Loss: 1.4216, Test Loss: 1.7612\n",
      "Epoch [49/50] - Train Loss: 1.3783, Test Loss: 2.3371\n",
      "Epoch [50/50] - Train Loss: 1.6130, Test Loss: 1.7799\n",
      "Avg Test Loss: 1.7799\n",
      "Testing combination: (4, 1, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1527, Test Loss: 1.1557\n",
      "Epoch [2/50] - Train Loss: 1.1476, Test Loss: 1.1490\n",
      "Epoch [3/50] - Train Loss: 1.1434, Test Loss: 1.1429\n",
      "Epoch [4/50] - Train Loss: 1.1396, Test Loss: 1.1377\n",
      "Epoch [5/50] - Train Loss: 1.1363, Test Loss: 1.1330\n",
      "Epoch [6/50] - Train Loss: 1.1333, Test Loss: 1.1290\n",
      "Epoch [7/50] - Train Loss: 1.1306, Test Loss: 1.1258\n",
      "Epoch [8/50] - Train Loss: 1.1282, Test Loss: 1.1231\n",
      "Epoch [9/50] - Train Loss: 1.1261, Test Loss: 1.1205\n",
      "Epoch [10/50] - Train Loss: 1.1242, Test Loss: 1.1175\n",
      "Epoch [11/50] - Train Loss: 1.1225, Test Loss: 1.1145\n",
      "Epoch [12/50] - Train Loss: 1.1211, Test Loss: 1.1115\n",
      "Epoch [13/50] - Train Loss: 1.1198, Test Loss: 1.1087\n",
      "Epoch [14/50] - Train Loss: 1.1187, Test Loss: 1.1060\n",
      "Epoch [15/50] - Train Loss: 1.1177, Test Loss: 1.1035\n",
      "Epoch [16/50] - Train Loss: 1.1168, Test Loss: 1.1013\n",
      "Epoch [17/50] - Train Loss: 1.1160, Test Loss: 1.0991\n",
      "Epoch [18/50] - Train Loss: 1.1153, Test Loss: 1.0971\n",
      "Epoch [19/50] - Train Loss: 1.1146, Test Loss: 1.0952\n",
      "Epoch [20/50] - Train Loss: 1.1139, Test Loss: 1.0933\n",
      "Epoch [21/50] - Train Loss: 1.1132, Test Loss: 1.0914\n",
      "Epoch [22/50] - Train Loss: 1.1124, Test Loss: 1.0896\n",
      "Epoch [23/50] - Train Loss: 1.1114, Test Loss: 1.0881\n",
      "Epoch [24/50] - Train Loss: 1.1102, Test Loss: 1.0870\n",
      "Epoch [25/50] - Train Loss: 1.1087, Test Loss: 1.0864\n",
      "Epoch [26/50] - Train Loss: 1.1072, Test Loss: 1.0859\n",
      "Epoch [27/50] - Train Loss: 1.1056, Test Loss: 1.0855\n",
      "Epoch [28/50] - Train Loss: 1.1039, Test Loss: 1.0853\n",
      "Epoch [29/50] - Train Loss: 1.1022, Test Loss: 1.0851\n",
      "Epoch [30/50] - Train Loss: 1.1005, Test Loss: 1.0850\n",
      "Epoch [31/50] - Train Loss: 1.0991, Test Loss: 1.0851\n",
      "Epoch [32/50] - Train Loss: 1.0978, Test Loss: 1.0852\n",
      "Epoch [33/50] - Train Loss: 1.0966, Test Loss: 1.0854\n",
      "Epoch [34/50] - Train Loss: 1.0956, Test Loss: 1.0858\n",
      "Epoch [35/50] - Train Loss: 1.0948, Test Loss: 1.0862\n",
      "Epoch [36/50] - Train Loss: 1.0940, Test Loss: 1.0867\n",
      "Epoch [37/50] - Train Loss: 1.0932, Test Loss: 1.0872\n",
      "Epoch [38/50] - Train Loss: 1.0925, Test Loss: 1.0878\n",
      "Epoch [39/50] - Train Loss: 1.0919, Test Loss: 1.0885\n",
      "Epoch [40/50] - Train Loss: 1.0913, Test Loss: 1.0892\n",
      "Epoch [41/50] - Train Loss: 1.0907, Test Loss: 1.0899\n",
      "Epoch [42/50] - Train Loss: 1.0902, Test Loss: 1.0906\n",
      "Epoch [43/50] - Train Loss: 1.0897, Test Loss: 1.0914\n",
      "Epoch [44/50] - Train Loss: 1.0892, Test Loss: 1.0923\n",
      "Epoch [45/50] - Train Loss: 1.0887, Test Loss: 1.0931\n",
      "Epoch [46/50] - Train Loss: 1.0882, Test Loss: 1.0940\n",
      "Epoch [47/50] - Train Loss: 1.0878, Test Loss: 1.0948\n",
      "Epoch [48/50] - Train Loss: 1.0874, Test Loss: 1.0958\n",
      "Epoch [49/50] - Train Loss: 1.0870, Test Loss: 1.0967\n",
      "Epoch [50/50] - Train Loss: 1.0866, Test Loss: 1.0976\n",
      "Avg Test Loss: 1.0976\n",
      "Testing combination: (4, 1, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1682, Test Loss: 1.2442\n",
      "Epoch [2/50] - Train Loss: 1.1653, Test Loss: 1.2398\n",
      "Epoch [3/50] - Train Loss: 1.1636, Test Loss: 1.2362\n",
      "Epoch [4/50] - Train Loss: 1.1621, Test Loss: 1.2329\n",
      "Epoch [5/50] - Train Loss: 1.1607, Test Loss: 1.2295\n",
      "Epoch [6/50] - Train Loss: 1.1595, Test Loss: 1.2262\n",
      "Epoch [7/50] - Train Loss: 1.1584, Test Loss: 1.2232\n",
      "Epoch [8/50] - Train Loss: 1.1574, Test Loss: 1.2203\n",
      "Epoch [9/50] - Train Loss: 1.1564, Test Loss: 1.2177\n",
      "Epoch [10/50] - Train Loss: 1.1555, Test Loss: 1.2153\n",
      "Epoch [11/50] - Train Loss: 1.1547, Test Loss: 1.2130\n",
      "Epoch [12/50] - Train Loss: 1.1540, Test Loss: 1.2110\n",
      "Epoch [13/50] - Train Loss: 1.1533, Test Loss: 1.2090\n",
      "Epoch [14/50] - Train Loss: 1.1527, Test Loss: 1.2072\n",
      "Epoch [15/50] - Train Loss: 1.1521, Test Loss: 1.2055\n",
      "Epoch [16/50] - Train Loss: 1.1515, Test Loss: 1.2039\n",
      "Epoch [17/50] - Train Loss: 1.1510, Test Loss: 1.2024\n",
      "Epoch [18/50] - Train Loss: 1.1505, Test Loss: 1.2010\n",
      "Epoch [19/50] - Train Loss: 1.1500, Test Loss: 1.1996\n",
      "Epoch [20/50] - Train Loss: 1.1495, Test Loss: 1.1984\n",
      "Epoch [21/50] - Train Loss: 1.1490, Test Loss: 1.1972\n",
      "Epoch [22/50] - Train Loss: 1.1485, Test Loss: 1.1960\n",
      "Epoch [23/50] - Train Loss: 1.1480, Test Loss: 1.1950\n",
      "Epoch [24/50] - Train Loss: 1.1474, Test Loss: 1.1940\n",
      "Epoch [25/50] - Train Loss: 1.1468, Test Loss: 1.1930\n",
      "Epoch [26/50] - Train Loss: 1.1460, Test Loss: 1.1921\n",
      "Epoch [27/50] - Train Loss: 1.1448, Test Loss: 1.1912\n",
      "Epoch [28/50] - Train Loss: 1.1428, Test Loss: 1.1905\n",
      "Epoch [29/50] - Train Loss: 1.1398, Test Loss: 1.1900\n",
      "Epoch [30/50] - Train Loss: 1.1356, Test Loss: 1.1897\n",
      "Epoch [31/50] - Train Loss: 1.1305, Test Loss: 1.1896\n",
      "Epoch [32/50] - Train Loss: 1.1255, Test Loss: 1.1895\n",
      "Epoch [33/50] - Train Loss: 1.1212, Test Loss: 1.1893\n",
      "Epoch [34/50] - Train Loss: 1.1178, Test Loss: 1.1889\n",
      "Epoch [35/50] - Train Loss: 1.1151, Test Loss: 1.1884\n",
      "Epoch [36/50] - Train Loss: 1.1128, Test Loss: 1.1877\n",
      "Epoch [37/50] - Train Loss: 1.1108, Test Loss: 1.1870\n",
      "Epoch [38/50] - Train Loss: 1.1090, Test Loss: 1.1863\n",
      "Epoch [39/50] - Train Loss: 1.1073, Test Loss: 1.1856\n",
      "Epoch [40/50] - Train Loss: 1.1058, Test Loss: 1.1850\n",
      "Epoch [41/50] - Train Loss: 1.1044, Test Loss: 1.1845\n",
      "Epoch [42/50] - Train Loss: 1.1031, Test Loss: 1.1841\n",
      "Epoch [43/50] - Train Loss: 1.1019, Test Loss: 1.1838\n",
      "Epoch [44/50] - Train Loss: 1.1007, Test Loss: 1.1836\n",
      "Epoch [45/50] - Train Loss: 1.0996, Test Loss: 1.1834\n",
      "Epoch [46/50] - Train Loss: 1.0987, Test Loss: 1.1833\n",
      "Epoch [47/50] - Train Loss: 1.0976, Test Loss: 1.1833\n",
      "Epoch [48/50] - Train Loss: 1.0967, Test Loss: 1.1834\n",
      "Epoch [49/50] - Train Loss: 1.0958, Test Loss: 1.1835\n",
      "Epoch [50/50] - Train Loss: 1.0950, Test Loss: 1.1836\n",
      "Avg Test Loss: 1.1836\n",
      "Testing combination: (4, 1, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5252, Test Loss: 1.7953\n",
      "Epoch [2/50] - Train Loss: 1.5224, Test Loss: 1.7924\n",
      "Epoch [3/50] - Train Loss: 1.5205, Test Loss: 1.7897\n",
      "Epoch [4/50] - Train Loss: 1.5187, Test Loss: 1.7873\n",
      "Epoch [5/50] - Train Loss: 1.5171, Test Loss: 1.7852\n",
      "Epoch [6/50] - Train Loss: 1.5156, Test Loss: 1.7832\n",
      "Epoch [7/50] - Train Loss: 1.5142, Test Loss: 1.7813\n",
      "Epoch [8/50] - Train Loss: 1.5128, Test Loss: 1.7795\n",
      "Epoch [9/50] - Train Loss: 1.5115, Test Loss: 1.7778\n",
      "Epoch [10/50] - Train Loss: 1.5103, Test Loss: 1.7762\n",
      "Epoch [11/50] - Train Loss: 1.5092, Test Loss: 1.7748\n",
      "Epoch [12/50] - Train Loss: 1.5081, Test Loss: 1.7733\n",
      "Epoch [13/50] - Train Loss: 1.5071, Test Loss: 1.7720\n",
      "Epoch [14/50] - Train Loss: 1.5061, Test Loss: 1.7706\n",
      "Epoch [15/50] - Train Loss: 1.5052, Test Loss: 1.7694\n",
      "Epoch [16/50] - Train Loss: 1.5042, Test Loss: 1.7682\n",
      "Epoch [17/50] - Train Loss: 1.5034, Test Loss: 1.7670\n",
      "Epoch [18/50] - Train Loss: 1.5025, Test Loss: 1.7659\n",
      "Epoch [19/50] - Train Loss: 1.5017, Test Loss: 1.7648\n",
      "Epoch [20/50] - Train Loss: 1.5010, Test Loss: 1.7638\n",
      "Epoch [21/50] - Train Loss: 1.5003, Test Loss: 1.7628\n",
      "Epoch [22/50] - Train Loss: 1.4996, Test Loss: 1.7618\n",
      "Epoch [23/50] - Train Loss: 1.4989, Test Loss: 1.7609\n",
      "Epoch [24/50] - Train Loss: 1.4982, Test Loss: 1.7600\n",
      "Epoch [25/50] - Train Loss: 1.4976, Test Loss: 1.7592\n",
      "Epoch [26/50] - Train Loss: 1.4970, Test Loss: 1.7584\n",
      "Epoch [27/50] - Train Loss: 1.4965, Test Loss: 1.7576\n",
      "Epoch [28/50] - Train Loss: 1.4959, Test Loss: 1.7569\n",
      "Epoch [29/50] - Train Loss: 1.4954, Test Loss: 1.7560\n",
      "Epoch [30/50] - Train Loss: 1.4949, Test Loss: 1.7551\n",
      "Epoch [31/50] - Train Loss: 1.4943, Test Loss: 1.7544\n",
      "Epoch [32/50] - Train Loss: 1.4938, Test Loss: 1.7536\n",
      "Epoch [33/50] - Train Loss: 1.4933, Test Loss: 1.7529\n",
      "Epoch [34/50] - Train Loss: 1.4928, Test Loss: 1.7522\n",
      "Epoch [35/50] - Train Loss: 1.4924, Test Loss: 1.7516\n",
      "Epoch [36/50] - Train Loss: 1.4920, Test Loss: 1.7510\n",
      "Epoch [37/50] - Train Loss: 1.4916, Test Loss: 1.7504\n",
      "Epoch [38/50] - Train Loss: 1.4912, Test Loss: 1.7498\n",
      "Epoch [39/50] - Train Loss: 1.4908, Test Loss: 1.7493\n",
      "Epoch [40/50] - Train Loss: 1.4905, Test Loss: 1.7487\n",
      "Epoch [41/50] - Train Loss: 1.4901, Test Loss: 1.7482\n",
      "Epoch [42/50] - Train Loss: 1.4898, Test Loss: 1.7477\n",
      "Epoch [43/50] - Train Loss: 1.4895, Test Loss: 1.7472\n",
      "Epoch [44/50] - Train Loss: 1.4892, Test Loss: 1.7467\n",
      "Epoch [45/50] - Train Loss: 1.4889, Test Loss: 1.7461\n",
      "Epoch [46/50] - Train Loss: 1.4886, Test Loss: 1.7456\n",
      "Epoch [47/50] - Train Loss: 1.4883, Test Loss: 1.7451\n",
      "Epoch [48/50] - Train Loss: 1.4880, Test Loss: 1.7446\n",
      "Epoch [49/50] - Train Loss: 1.4877, Test Loss: 1.7442\n",
      "Epoch [50/50] - Train Loss: 1.4873, Test Loss: 1.7437\n",
      "Avg Test Loss: 1.7437\n",
      "Testing combination: (4, 1, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1222, Test Loss: 1.1068\n",
      "Epoch [2/50] - Train Loss: 1.1220, Test Loss: 1.1067\n",
      "Epoch [3/50] - Train Loss: 1.1219, Test Loss: 1.1065\n",
      "Epoch [4/50] - Train Loss: 1.1218, Test Loss: 1.1063\n",
      "Epoch [5/50] - Train Loss: 1.1217, Test Loss: 1.1061\n",
      "Epoch [6/50] - Train Loss: 1.1216, Test Loss: 1.1059\n",
      "Epoch [7/50] - Train Loss: 1.1215, Test Loss: 1.1057\n",
      "Epoch [8/50] - Train Loss: 1.1214, Test Loss: 1.1055\n",
      "Epoch [9/50] - Train Loss: 1.1214, Test Loss: 1.1053\n",
      "Epoch [10/50] - Train Loss: 1.1213, Test Loss: 1.1051\n",
      "Epoch [11/50] - Train Loss: 1.1212, Test Loss: 1.1050\n",
      "Epoch [12/50] - Train Loss: 1.1211, Test Loss: 1.1048\n",
      "Epoch [13/50] - Train Loss: 1.1210, Test Loss: 1.1046\n",
      "Epoch [14/50] - Train Loss: 1.1209, Test Loss: 1.1044\n",
      "Epoch [15/50] - Train Loss: 1.1209, Test Loss: 1.1043\n",
      "Epoch [16/50] - Train Loss: 1.1208, Test Loss: 1.1041\n",
      "Epoch [17/50] - Train Loss: 1.1207, Test Loss: 1.1039\n",
      "Epoch [18/50] - Train Loss: 1.1206, Test Loss: 1.1038\n",
      "Epoch [19/50] - Train Loss: 1.1206, Test Loss: 1.1036\n",
      "Epoch [20/50] - Train Loss: 1.1205, Test Loss: 1.1035\n",
      "Epoch [21/50] - Train Loss: 1.1204, Test Loss: 1.1033\n",
      "Epoch [22/50] - Train Loss: 1.1203, Test Loss: 1.1031\n",
      "Epoch [23/50] - Train Loss: 1.1203, Test Loss: 1.1030\n",
      "Epoch [24/50] - Train Loss: 1.1202, Test Loss: 1.1028\n",
      "Epoch [25/50] - Train Loss: 1.1201, Test Loss: 1.1027\n",
      "Epoch [26/50] - Train Loss: 1.1201, Test Loss: 1.1025\n",
      "Epoch [27/50] - Train Loss: 1.1200, Test Loss: 1.1024\n",
      "Epoch [28/50] - Train Loss: 1.1199, Test Loss: 1.1022\n",
      "Epoch [29/50] - Train Loss: 1.1199, Test Loss: 1.1021\n",
      "Epoch [30/50] - Train Loss: 1.1198, Test Loss: 1.1020\n",
      "Epoch [31/50] - Train Loss: 1.1198, Test Loss: 1.1018\n",
      "Epoch [32/50] - Train Loss: 1.1197, Test Loss: 1.1017\n",
      "Epoch [33/50] - Train Loss: 1.1196, Test Loss: 1.1015\n",
      "Epoch [34/50] - Train Loss: 1.1196, Test Loss: 1.1014\n",
      "Epoch [35/50] - Train Loss: 1.1195, Test Loss: 1.1013\n",
      "Epoch [36/50] - Train Loss: 1.1195, Test Loss: 1.1011\n",
      "Epoch [37/50] - Train Loss: 1.1194, Test Loss: 1.1010\n",
      "Epoch [38/50] - Train Loss: 1.1193, Test Loss: 1.1009\n",
      "Epoch [39/50] - Train Loss: 1.1193, Test Loss: 1.1008\n",
      "Epoch [40/50] - Train Loss: 1.1192, Test Loss: 1.1006\n",
      "Epoch [41/50] - Train Loss: 1.1192, Test Loss: 1.1005\n",
      "Epoch [42/50] - Train Loss: 1.1191, Test Loss: 1.1004\n",
      "Epoch [43/50] - Train Loss: 1.1191, Test Loss: 1.1003\n",
      "Epoch [44/50] - Train Loss: 1.1190, Test Loss: 1.1002\n",
      "Epoch [45/50] - Train Loss: 1.1190, Test Loss: 1.1000\n",
      "Epoch [46/50] - Train Loss: 1.1189, Test Loss: 1.0999\n",
      "Epoch [47/50] - Train Loss: 1.1189, Test Loss: 1.0998\n",
      "Epoch [48/50] - Train Loss: 1.1188, Test Loss: 1.0997\n",
      "Epoch [49/50] - Train Loss: 1.1188, Test Loss: 1.0996\n",
      "Epoch [50/50] - Train Loss: 1.1187, Test Loss: 1.0995\n",
      "Avg Test Loss: 1.0995\n",
      "Testing combination: (4, 1, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1538, Test Loss: 1.2024\n",
      "Epoch [2/50] - Train Loss: 1.1535, Test Loss: 1.2020\n",
      "Epoch [3/50] - Train Loss: 1.1534, Test Loss: 1.2016\n",
      "Epoch [4/50] - Train Loss: 1.1533, Test Loss: 1.2012\n",
      "Epoch [5/50] - Train Loss: 1.1532, Test Loss: 1.2009\n",
      "Epoch [6/50] - Train Loss: 1.1531, Test Loss: 1.2006\n",
      "Epoch [7/50] - Train Loss: 1.1530, Test Loss: 1.2002\n",
      "Epoch [8/50] - Train Loss: 1.1529, Test Loss: 1.1999\n",
      "Epoch [9/50] - Train Loss: 1.1528, Test Loss: 1.1996\n",
      "Epoch [10/50] - Train Loss: 1.1527, Test Loss: 1.1993\n",
      "Epoch [11/50] - Train Loss: 1.1527, Test Loss: 1.1989\n",
      "Epoch [12/50] - Train Loss: 1.1526, Test Loss: 1.1987\n",
      "Epoch [13/50] - Train Loss: 1.1525, Test Loss: 1.1984\n",
      "Epoch [14/50] - Train Loss: 1.1524, Test Loss: 1.1981\n",
      "Epoch [15/50] - Train Loss: 1.1524, Test Loss: 1.1978\n",
      "Epoch [16/50] - Train Loss: 1.1523, Test Loss: 1.1975\n",
      "Epoch [17/50] - Train Loss: 1.1523, Test Loss: 1.1973\n",
      "Epoch [18/50] - Train Loss: 1.1522, Test Loss: 1.1970\n",
      "Epoch [19/50] - Train Loss: 1.1521, Test Loss: 1.1967\n",
      "Epoch [20/50] - Train Loss: 1.1521, Test Loss: 1.1964\n",
      "Epoch [21/50] - Train Loss: 1.1520, Test Loss: 1.1962\n",
      "Epoch [22/50] - Train Loss: 1.1520, Test Loss: 1.1959\n",
      "Epoch [23/50] - Train Loss: 1.1519, Test Loss: 1.1956\n",
      "Epoch [24/50] - Train Loss: 1.1519, Test Loss: 1.1954\n",
      "Epoch [25/50] - Train Loss: 1.1518, Test Loss: 1.1951\n",
      "Epoch [26/50] - Train Loss: 1.1517, Test Loss: 1.1949\n",
      "Epoch [27/50] - Train Loss: 1.1517, Test Loss: 1.1946\n",
      "Epoch [28/50] - Train Loss: 1.1516, Test Loss: 1.1944\n",
      "Epoch [29/50] - Train Loss: 1.1516, Test Loss: 1.1941\n",
      "Epoch [30/50] - Train Loss: 1.1515, Test Loss: 1.1939\n",
      "Epoch [31/50] - Train Loss: 1.1515, Test Loss: 1.1936\n",
      "Epoch [32/50] - Train Loss: 1.1514, Test Loss: 1.1934\n",
      "Epoch [33/50] - Train Loss: 1.1514, Test Loss: 1.1932\n",
      "Epoch [34/50] - Train Loss: 1.1514, Test Loss: 1.1929\n",
      "Epoch [35/50] - Train Loss: 1.1513, Test Loss: 1.1927\n",
      "Epoch [36/50] - Train Loss: 1.1513, Test Loss: 1.1925\n",
      "Epoch [37/50] - Train Loss: 1.1512, Test Loss: 1.1922\n",
      "Epoch [38/50] - Train Loss: 1.1512, Test Loss: 1.1920\n",
      "Epoch [39/50] - Train Loss: 1.1511, Test Loss: 1.1918\n",
      "Epoch [40/50] - Train Loss: 1.1511, Test Loss: 1.1916\n",
      "Epoch [41/50] - Train Loss: 1.1510, Test Loss: 1.1913\n",
      "Epoch [42/50] - Train Loss: 1.1510, Test Loss: 1.1911\n",
      "Epoch [43/50] - Train Loss: 1.1510, Test Loss: 1.1909\n",
      "Epoch [44/50] - Train Loss: 1.1509, Test Loss: 1.1907\n",
      "Epoch [45/50] - Train Loss: 1.1509, Test Loss: 1.1905\n",
      "Epoch [46/50] - Train Loss: 1.1508, Test Loss: 1.1903\n",
      "Epoch [47/50] - Train Loss: 1.1508, Test Loss: 1.1900\n",
      "Epoch [48/50] - Train Loss: 1.1508, Test Loss: 1.1898\n",
      "Epoch [49/50] - Train Loss: 1.1507, Test Loss: 1.1896\n",
      "Epoch [50/50] - Train Loss: 1.1507, Test Loss: 1.1894\n",
      "Avg Test Loss: 1.1894\n",
      "Testing combination: (4, 1, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5221, Test Loss: 1.7791\n",
      "Epoch [2/50] - Train Loss: 1.5217, Test Loss: 1.7789\n",
      "Epoch [3/50] - Train Loss: 1.5213, Test Loss: 1.7786\n",
      "Epoch [4/50] - Train Loss: 1.5209, Test Loss: 1.7782\n",
      "Epoch [5/50] - Train Loss: 1.5205, Test Loss: 1.7779\n",
      "Epoch [6/50] - Train Loss: 1.5201, Test Loss: 1.7775\n",
      "Epoch [7/50] - Train Loss: 1.5197, Test Loss: 1.7771\n",
      "Epoch [8/50] - Train Loss: 1.5193, Test Loss: 1.7767\n",
      "Epoch [9/50] - Train Loss: 1.5189, Test Loss: 1.7764\n",
      "Epoch [10/50] - Train Loss: 1.5185, Test Loss: 1.7759\n",
      "Epoch [11/50] - Train Loss: 1.5181, Test Loss: 1.7755\n",
      "Epoch [12/50] - Train Loss: 1.5178, Test Loss: 1.7751\n",
      "Epoch [13/50] - Train Loss: 1.5174, Test Loss: 1.7746\n",
      "Epoch [14/50] - Train Loss: 1.5170, Test Loss: 1.7742\n",
      "Epoch [15/50] - Train Loss: 1.5167, Test Loss: 1.7738\n",
      "Epoch [16/50] - Train Loss: 1.5163, Test Loss: 1.7734\n",
      "Epoch [17/50] - Train Loss: 1.5160, Test Loss: 1.7730\n",
      "Epoch [18/50] - Train Loss: 1.5156, Test Loss: 1.7726\n",
      "Epoch [19/50] - Train Loss: 1.5153, Test Loss: 1.7722\n",
      "Epoch [20/50] - Train Loss: 1.5149, Test Loss: 1.7718\n",
      "Epoch [21/50] - Train Loss: 1.5146, Test Loss: 1.7714\n",
      "Epoch [22/50] - Train Loss: 1.5142, Test Loss: 1.7710\n",
      "Epoch [23/50] - Train Loss: 1.5139, Test Loss: 1.7706\n",
      "Epoch [24/50] - Train Loss: 1.5136, Test Loss: 1.7702\n",
      "Epoch [25/50] - Train Loss: 1.5132, Test Loss: 1.7699\n",
      "Epoch [26/50] - Train Loss: 1.5129, Test Loss: 1.7695\n",
      "Epoch [27/50] - Train Loss: 1.5126, Test Loss: 1.7691\n",
      "Epoch [28/50] - Train Loss: 1.5123, Test Loss: 1.7688\n",
      "Epoch [29/50] - Train Loss: 1.5120, Test Loss: 1.7684\n",
      "Epoch [30/50] - Train Loss: 1.5117, Test Loss: 1.7680\n",
      "Epoch [31/50] - Train Loss: 1.5114, Test Loss: 1.7677\n",
      "Epoch [32/50] - Train Loss: 1.5110, Test Loss: 1.7673\n",
      "Epoch [33/50] - Train Loss: 1.5108, Test Loss: 1.7669\n",
      "Epoch [34/50] - Train Loss: 1.5105, Test Loss: 1.7665\n",
      "Epoch [35/50] - Train Loss: 1.5102, Test Loss: 1.7662\n",
      "Epoch [36/50] - Train Loss: 1.5099, Test Loss: 1.7658\n",
      "Epoch [37/50] - Train Loss: 1.5096, Test Loss: 1.7654\n",
      "Epoch [38/50] - Train Loss: 1.5093, Test Loss: 1.7650\n",
      "Epoch [39/50] - Train Loss: 1.5090, Test Loss: 1.7647\n",
      "Epoch [40/50] - Train Loss: 1.5087, Test Loss: 1.7643\n",
      "Epoch [41/50] - Train Loss: 1.5085, Test Loss: 1.7640\n",
      "Epoch [42/50] - Train Loss: 1.5082, Test Loss: 1.7636\n",
      "Epoch [43/50] - Train Loss: 1.5079, Test Loss: 1.7633\n",
      "Epoch [44/50] - Train Loss: 1.5077, Test Loss: 1.7629\n",
      "Epoch [45/50] - Train Loss: 1.5074, Test Loss: 1.7626\n",
      "Epoch [46/50] - Train Loss: 1.5071, Test Loss: 1.7623\n",
      "Epoch [47/50] - Train Loss: 1.5069, Test Loss: 1.7619\n",
      "Epoch [48/50] - Train Loss: 1.5066, Test Loss: 1.7616\n",
      "Epoch [49/50] - Train Loss: 1.5064, Test Loss: 1.7613\n",
      "Epoch [50/50] - Train Loss: 1.5061, Test Loss: 1.7610\n",
      "Avg Test Loss: 1.7610\n",
      "Testing combination: (4, 2, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1601, Test Loss: 1.0852\n",
      "Epoch [2/50] - Train Loss: 1.1208, Test Loss: 1.0950\n",
      "Epoch [3/50] - Train Loss: 1.1177, Test Loss: 1.0934\n",
      "Epoch [4/50] - Train Loss: 1.1158, Test Loss: 1.0903\n",
      "Epoch [5/50] - Train Loss: 1.1153, Test Loss: 1.0895\n",
      "Epoch [6/50] - Train Loss: 1.1150, Test Loss: 1.0905\n",
      "Epoch [7/50] - Train Loss: 1.1141, Test Loss: 1.0925\n",
      "Epoch [8/50] - Train Loss: 1.1126, Test Loss: 1.0952\n",
      "Epoch [9/50] - Train Loss: 1.1102, Test Loss: 1.0982\n",
      "Epoch [10/50] - Train Loss: 1.1072, Test Loss: 1.1017\n",
      "Epoch [11/50] - Train Loss: 1.1037, Test Loss: 1.1058\n",
      "Epoch [12/50] - Train Loss: 1.1000, Test Loss: 1.1104\n",
      "Epoch [13/50] - Train Loss: 1.0961, Test Loss: 1.1155\n",
      "Epoch [14/50] - Train Loss: 1.0924, Test Loss: 1.1210\n",
      "Epoch [15/50] - Train Loss: 1.0891, Test Loss: 1.1268\n",
      "Epoch [16/50] - Train Loss: 1.0861, Test Loss: 1.1327\n",
      "Epoch [17/50] - Train Loss: 1.0826, Test Loss: 1.1381\n",
      "Epoch [18/50] - Train Loss: 1.0800, Test Loss: 1.1427\n",
      "Epoch [19/50] - Train Loss: 1.0784, Test Loss: 1.1469\n",
      "Epoch [20/50] - Train Loss: 1.0762, Test Loss: 1.1526\n",
      "Epoch [21/50] - Train Loss: 1.0738, Test Loss: 1.1605\n",
      "Epoch [22/50] - Train Loss: 1.0712, Test Loss: 1.1712\n",
      "Epoch [23/50] - Train Loss: 1.0690, Test Loss: 1.1831\n",
      "Epoch [24/50] - Train Loss: 1.0675, Test Loss: 1.1926\n",
      "Epoch [25/50] - Train Loss: 1.0650, Test Loss: 1.1982\n",
      "Epoch [26/50] - Train Loss: 1.1061, Test Loss: 1.0755\n",
      "Epoch [27/50] - Train Loss: 1.1048, Test Loss: 1.2090\n",
      "Epoch [28/50] - Train Loss: 1.0887, Test Loss: 1.1986\n",
      "Epoch [29/50] - Train Loss: 1.0663, Test Loss: 1.1992\n",
      "Epoch [30/50] - Train Loss: 1.0598, Test Loss: 1.2064\n",
      "Epoch [31/50] - Train Loss: 1.0588, Test Loss: 1.2093\n",
      "Epoch [32/50] - Train Loss: 1.0526, Test Loss: 1.2203\n",
      "Epoch [33/50] - Train Loss: 1.0440, Test Loss: 1.2589\n",
      "Epoch [34/50] - Train Loss: 1.0273, Test Loss: 1.2263\n",
      "Epoch [35/50] - Train Loss: 1.0629, Test Loss: 1.1689\n",
      "Epoch [36/50] - Train Loss: 1.0797, Test Loss: 1.0981\n",
      "Epoch [37/50] - Train Loss: 1.1144, Test Loss: 1.1013\n",
      "Epoch [38/50] - Train Loss: 1.0938, Test Loss: 1.1107\n",
      "Epoch [39/50] - Train Loss: 1.0837, Test Loss: 1.1177\n",
      "Epoch [40/50] - Train Loss: 1.0778, Test Loss: 1.1175\n",
      "Epoch [41/50] - Train Loss: 1.0739, Test Loss: 1.1184\n",
      "Epoch [42/50] - Train Loss: 1.0726, Test Loss: 1.1225\n",
      "Epoch [43/50] - Train Loss: 1.0702, Test Loss: 1.1290\n",
      "Epoch [44/50] - Train Loss: 1.0603, Test Loss: 1.1257\n",
      "Epoch [45/50] - Train Loss: 1.0580, Test Loss: 1.1531\n",
      "Epoch [46/50] - Train Loss: 1.1442, Test Loss: 1.1469\n",
      "Epoch [47/50] - Train Loss: 1.0921, Test Loss: 1.1303\n",
      "Epoch [48/50] - Train Loss: 1.1239, Test Loss: 1.1271\n",
      "Epoch [49/50] - Train Loss: 1.1180, Test Loss: 1.1357\n",
      "Epoch [50/50] - Train Loss: 1.1119, Test Loss: 1.1428\n",
      "Avg Test Loss: 1.1428\n",
      "Testing combination: (4, 2, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1721, Test Loss: 1.1916\n",
      "Epoch [2/50] - Train Loss: 1.1553, Test Loss: 1.1720\n",
      "Epoch [3/50] - Train Loss: 1.1521, Test Loss: 1.1639\n",
      "Epoch [4/50] - Train Loss: 1.1512, Test Loss: 1.1616\n",
      "Epoch [5/50] - Train Loss: 1.1504, Test Loss: 1.1624\n",
      "Epoch [6/50] - Train Loss: 1.1494, Test Loss: 1.1644\n",
      "Epoch [7/50] - Train Loss: 1.1481, Test Loss: 1.1665\n",
      "Epoch [8/50] - Train Loss: 1.1442, Test Loss: 1.1670\n",
      "Epoch [9/50] - Train Loss: 1.1339, Test Loss: 1.1680\n",
      "Epoch [10/50] - Train Loss: 1.1231, Test Loss: 1.1639\n",
      "Epoch [11/50] - Train Loss: 1.1104, Test Loss: 1.1591\n",
      "Epoch [12/50] - Train Loss: 1.1022, Test Loss: 1.1577\n",
      "Epoch [13/50] - Train Loss: 1.0963, Test Loss: 1.1591\n",
      "Epoch [14/50] - Train Loss: 1.0897, Test Loss: 1.1611\n",
      "Epoch [15/50] - Train Loss: 1.0833, Test Loss: 1.1626\n",
      "Epoch [16/50] - Train Loss: 1.0817, Test Loss: 1.1652\n",
      "Epoch [17/50] - Train Loss: 1.0778, Test Loss: 1.1688\n",
      "Epoch [18/50] - Train Loss: 1.0749, Test Loss: 1.1715\n",
      "Epoch [19/50] - Train Loss: 1.0722, Test Loss: 1.1734\n",
      "Epoch [20/50] - Train Loss: 1.0707, Test Loss: 1.1760\n",
      "Epoch [21/50] - Train Loss: 1.0688, Test Loss: 1.1791\n",
      "Epoch [22/50] - Train Loss: 1.0670, Test Loss: 1.1821\n",
      "Epoch [23/50] - Train Loss: 1.0652, Test Loss: 1.1850\n",
      "Epoch [24/50] - Train Loss: 1.0633, Test Loss: 1.1878\n",
      "Epoch [25/50] - Train Loss: 1.0613, Test Loss: 1.1908\n",
      "Epoch [26/50] - Train Loss: 1.0594, Test Loss: 1.1941\n",
      "Epoch [27/50] - Train Loss: 1.0575, Test Loss: 1.1977\n",
      "Epoch [28/50] - Train Loss: 1.0555, Test Loss: 1.2019\n",
      "Epoch [29/50] - Train Loss: 1.0534, Test Loss: 1.2066\n",
      "Epoch [30/50] - Train Loss: 1.0513, Test Loss: 1.2119\n",
      "Epoch [31/50] - Train Loss: 1.0492, Test Loss: 1.2173\n",
      "Epoch [32/50] - Train Loss: 1.0474, Test Loss: 1.2223\n",
      "Epoch [33/50] - Train Loss: 1.0459, Test Loss: 1.2266\n",
      "Epoch [34/50] - Train Loss: 1.0447, Test Loss: 1.2305\n",
      "Epoch [35/50] - Train Loss: 1.0436, Test Loss: 1.2341\n",
      "Epoch [36/50] - Train Loss: 1.0427, Test Loss: 1.2373\n",
      "Epoch [37/50] - Train Loss: 1.0419, Test Loss: 1.2402\n",
      "Epoch [38/50] - Train Loss: 1.0413, Test Loss: 1.2427\n",
      "Epoch [39/50] - Train Loss: 1.0407, Test Loss: 1.2449\n",
      "Epoch [40/50] - Train Loss: 1.0402, Test Loss: 1.2469\n",
      "Epoch [41/50] - Train Loss: 1.0398, Test Loss: 1.2485\n",
      "Epoch [42/50] - Train Loss: 1.0393, Test Loss: 1.2500\n",
      "Epoch [43/50] - Train Loss: 1.0389, Test Loss: 1.2512\n",
      "Epoch [44/50] - Train Loss: 1.0386, Test Loss: 1.2527\n",
      "Epoch [45/50] - Train Loss: 1.0388, Test Loss: 1.2562\n",
      "Epoch [46/50] - Train Loss: 1.0387, Test Loss: 1.2631\n",
      "Epoch [47/50] - Train Loss: 1.0356, Test Loss: 1.2757\n",
      "Epoch [48/50] - Train Loss: 1.0316, Test Loss: 1.2912\n",
      "Epoch [49/50] - Train Loss: 1.0226, Test Loss: 1.3049\n",
      "Epoch [50/50] - Train Loss: 1.0187, Test Loss: 1.3113\n",
      "Avg Test Loss: 1.3113\n",
      "Testing combination: (4, 2, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5254, Test Loss: 1.7449\n",
      "Epoch [2/50] - Train Loss: 1.4970, Test Loss: 1.7389\n",
      "Epoch [3/50] - Train Loss: 1.4913, Test Loss: 1.7397\n",
      "Epoch [4/50] - Train Loss: 1.4893, Test Loss: 1.7411\n",
      "Epoch [5/50] - Train Loss: 1.4881, Test Loss: 1.7417\n",
      "Epoch [6/50] - Train Loss: 1.4871, Test Loss: 1.7417\n",
      "Epoch [7/50] - Train Loss: 1.4864, Test Loss: 1.7418\n",
      "Epoch [8/50] - Train Loss: 1.4860, Test Loss: 1.7420\n",
      "Epoch [9/50] - Train Loss: 1.4859, Test Loss: 1.7425\n",
      "Epoch [10/50] - Train Loss: 1.4861, Test Loss: 1.7432\n",
      "Epoch [11/50] - Train Loss: 1.4863, Test Loss: 1.7440\n",
      "Epoch [12/50] - Train Loss: 1.4865, Test Loss: 1.7450\n",
      "Epoch [13/50] - Train Loss: 1.4866, Test Loss: 1.7460\n",
      "Epoch [14/50] - Train Loss: 1.4867, Test Loss: 1.7468\n",
      "Epoch [15/50] - Train Loss: 1.4866, Test Loss: 1.7474\n",
      "Epoch [16/50] - Train Loss: 1.4864, Test Loss: 1.7480\n",
      "Epoch [17/50] - Train Loss: 1.4860, Test Loss: 1.7487\n",
      "Epoch [18/50] - Train Loss: 1.4854, Test Loss: 1.7495\n",
      "Epoch [19/50] - Train Loss: 1.4846, Test Loss: 1.7505\n",
      "Epoch [20/50] - Train Loss: 1.4838, Test Loss: 1.7517\n",
      "Epoch [21/50] - Train Loss: 1.4828, Test Loss: 1.7533\n",
      "Epoch [22/50] - Train Loss: 1.4816, Test Loss: 1.7555\n",
      "Epoch [23/50] - Train Loss: 1.4802, Test Loss: 1.7588\n",
      "Epoch [24/50] - Train Loss: 1.4785, Test Loss: 1.7633\n",
      "Epoch [25/50] - Train Loss: 1.4765, Test Loss: 1.7688\n",
      "Epoch [26/50] - Train Loss: 1.4740, Test Loss: 1.7752\n",
      "Epoch [27/50] - Train Loss: 1.4712, Test Loss: 1.7827\n",
      "Epoch [28/50] - Train Loss: 1.4686, Test Loss: 1.7909\n",
      "Epoch [29/50] - Train Loss: 1.4643, Test Loss: 1.8005\n",
      "Epoch [30/50] - Train Loss: 1.4596, Test Loss: 1.8113\n",
      "Epoch [31/50] - Train Loss: 1.4545, Test Loss: 1.8229\n",
      "Epoch [32/50] - Train Loss: 1.4487, Test Loss: 1.8338\n",
      "Epoch [33/50] - Train Loss: 1.4398, Test Loss: 1.8429\n",
      "Epoch [34/50] - Train Loss: 1.4354, Test Loss: 1.8552\n",
      "Epoch [35/50] - Train Loss: 1.4284, Test Loss: 1.8700\n",
      "Epoch [36/50] - Train Loss: 1.4287, Test Loss: 1.8782\n",
      "Epoch [37/50] - Train Loss: 1.4287, Test Loss: 1.8831\n",
      "Epoch [38/50] - Train Loss: 1.4312, Test Loss: 1.8885\n",
      "Epoch [39/50] - Train Loss: 1.4292, Test Loss: 1.8915\n",
      "Epoch [40/50] - Train Loss: 1.4287, Test Loss: 1.8937\n",
      "Epoch [41/50] - Train Loss: 1.4289, Test Loss: 1.8947\n",
      "Epoch [42/50] - Train Loss: 1.4289, Test Loss: 1.8951\n",
      "Epoch [43/50] - Train Loss: 1.4287, Test Loss: 1.8956\n",
      "Epoch [44/50] - Train Loss: 1.4284, Test Loss: 1.8965\n",
      "Epoch [45/50] - Train Loss: 1.4279, Test Loss: 1.8976\n",
      "Epoch [46/50] - Train Loss: 1.4273, Test Loss: 1.8991\n",
      "Epoch [47/50] - Train Loss: 1.4269, Test Loss: 1.9009\n",
      "Epoch [48/50] - Train Loss: 1.4266, Test Loss: 1.9032\n",
      "Epoch [49/50] - Train Loss: 1.4263, Test Loss: 1.9057\n",
      "Epoch [50/50] - Train Loss: 1.4253, Test Loss: 1.9101\n",
      "Avg Test Loss: 1.9101\n",
      "Testing combination: (4, 2, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.2112, Test Loss: 1.2348\n",
      "Epoch [2/50] - Train Loss: 1.1959, Test Loss: 1.2155\n",
      "Epoch [3/50] - Train Loss: 1.1830, Test Loss: 1.1979\n",
      "Epoch [4/50] - Train Loss: 1.1715, Test Loss: 1.1818\n",
      "Epoch [5/50] - Train Loss: 1.1611, Test Loss: 1.1670\n",
      "Epoch [6/50] - Train Loss: 1.1520, Test Loss: 1.1537\n",
      "Epoch [7/50] - Train Loss: 1.1440, Test Loss: 1.1417\n",
      "Epoch [8/50] - Train Loss: 1.1373, Test Loss: 1.1313\n",
      "Epoch [9/50] - Train Loss: 1.1317, Test Loss: 1.1223\n",
      "Epoch [10/50] - Train Loss: 1.1273, Test Loss: 1.1148\n",
      "Epoch [11/50] - Train Loss: 1.1238, Test Loss: 1.1086\n",
      "Epoch [12/50] - Train Loss: 1.1213, Test Loss: 1.1036\n",
      "Epoch [13/50] - Train Loss: 1.1195, Test Loss: 1.0997\n",
      "Epoch [14/50] - Train Loss: 1.1183, Test Loss: 1.0968\n",
      "Epoch [15/50] - Train Loss: 1.1175, Test Loss: 1.0945\n",
      "Epoch [16/50] - Train Loss: 1.1170, Test Loss: 1.0927\n",
      "Epoch [17/50] - Train Loss: 1.1167, Test Loss: 1.0915\n",
      "Epoch [18/50] - Train Loss: 1.1165, Test Loss: 1.0905\n",
      "Epoch [19/50] - Train Loss: 1.1164, Test Loss: 1.0898\n",
      "Epoch [20/50] - Train Loss: 1.1164, Test Loss: 1.0892\n",
      "Epoch [21/50] - Train Loss: 1.1163, Test Loss: 1.0888\n",
      "Epoch [22/50] - Train Loss: 1.1163, Test Loss: 1.0885\n",
      "Epoch [23/50] - Train Loss: 1.1163, Test Loss: 1.0883\n",
      "Epoch [24/50] - Train Loss: 1.1163, Test Loss: 1.0881\n",
      "Epoch [25/50] - Train Loss: 1.1163, Test Loss: 1.0880\n",
      "Epoch [26/50] - Train Loss: 1.1163, Test Loss: 1.0879\n",
      "Epoch [27/50] - Train Loss: 1.1163, Test Loss: 1.0878\n",
      "Epoch [28/50] - Train Loss: 1.1163, Test Loss: 1.0877\n",
      "Epoch [29/50] - Train Loss: 1.1163, Test Loss: 1.0877\n",
      "Epoch [30/50] - Train Loss: 1.1163, Test Loss: 1.0876\n",
      "Epoch [31/50] - Train Loss: 1.1163, Test Loss: 1.0876\n",
      "Epoch [32/50] - Train Loss: 1.1163, Test Loss: 1.0876\n",
      "Epoch [33/50] - Train Loss: 1.1163, Test Loss: 1.0876\n",
      "Epoch [34/50] - Train Loss: 1.1163, Test Loss: 1.0876\n",
      "Epoch [35/50] - Train Loss: 1.1163, Test Loss: 1.0876\n",
      "Epoch [36/50] - Train Loss: 1.1163, Test Loss: 1.0876\n",
      "Epoch [37/50] - Train Loss: 1.1163, Test Loss: 1.0875\n",
      "Epoch [38/50] - Train Loss: 1.1163, Test Loss: 1.0875\n",
      "Epoch [39/50] - Train Loss: 1.1163, Test Loss: 1.0875\n",
      "Epoch [40/50] - Train Loss: 1.1163, Test Loss: 1.0875\n",
      "Epoch [41/50] - Train Loss: 1.1163, Test Loss: 1.0875\n",
      "Epoch [42/50] - Train Loss: 1.1163, Test Loss: 1.0875\n",
      "Epoch [43/50] - Train Loss: 1.1163, Test Loss: 1.0875\n",
      "Epoch [44/50] - Train Loss: 1.1163, Test Loss: 1.0875\n",
      "Epoch [45/50] - Train Loss: 1.1163, Test Loss: 1.0875\n",
      "Epoch [46/50] - Train Loss: 1.1163, Test Loss: 1.0875\n",
      "Epoch [47/50] - Train Loss: 1.1163, Test Loss: 1.0875\n",
      "Epoch [48/50] - Train Loss: 1.1163, Test Loss: 1.0875\n",
      "Epoch [49/50] - Train Loss: 1.1163, Test Loss: 1.0875\n",
      "Epoch [50/50] - Train Loss: 1.1163, Test Loss: 1.0875\n",
      "Avg Test Loss: 1.0875\n",
      "Testing combination: (4, 2, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.3181, Test Loss: 1.5242\n",
      "Epoch [2/50] - Train Loss: 1.2958, Test Loss: 1.4937\n",
      "Epoch [3/50] - Train Loss: 1.2781, Test Loss: 1.4659\n",
      "Epoch [4/50] - Train Loss: 1.2618, Test Loss: 1.4397\n",
      "Epoch [5/50] - Train Loss: 1.2461, Test Loss: 1.4145\n",
      "Epoch [6/50] - Train Loss: 1.2312, Test Loss: 1.3903\n",
      "Epoch [7/50] - Train Loss: 1.2167, Test Loss: 1.3663\n",
      "Epoch [8/50] - Train Loss: 1.2021, Test Loss: 1.3422\n",
      "Epoch [9/50] - Train Loss: 1.1875, Test Loss: 1.3182\n",
      "Epoch [10/50] - Train Loss: 1.1730, Test Loss: 1.2944\n",
      "Epoch [11/50] - Train Loss: 1.1587, Test Loss: 1.2715\n",
      "Epoch [12/50] - Train Loss: 1.1450, Test Loss: 1.2503\n",
      "Epoch [13/50] - Train Loss: 1.1327, Test Loss: 1.2316\n",
      "Epoch [14/50] - Train Loss: 1.1221, Test Loss: 1.2160\n",
      "Epoch [15/50] - Train Loss: 1.1136, Test Loss: 1.2039\n",
      "Epoch [16/50] - Train Loss: 1.1070, Test Loss: 1.1950\n",
      "Epoch [17/50] - Train Loss: 1.1021, Test Loss: 1.1887\n",
      "Epoch [18/50] - Train Loss: 1.0983, Test Loss: 1.1845\n",
      "Epoch [19/50] - Train Loss: 1.0954, Test Loss: 1.1818\n",
      "Epoch [20/50] - Train Loss: 1.0929, Test Loss: 1.1803\n",
      "Epoch [21/50] - Train Loss: 1.0906, Test Loss: 1.1794\n",
      "Epoch [22/50] - Train Loss: 1.0886, Test Loss: 1.1790\n",
      "Epoch [23/50] - Train Loss: 1.0868, Test Loss: 1.1789\n",
      "Epoch [24/50] - Train Loss: 1.0850, Test Loss: 1.1790\n",
      "Epoch [25/50] - Train Loss: 1.0834, Test Loss: 1.1793\n",
      "Epoch [26/50] - Train Loss: 1.0820, Test Loss: 1.1797\n",
      "Epoch [27/50] - Train Loss: 1.0806, Test Loss: 1.1803\n",
      "Epoch [28/50] - Train Loss: 1.0794, Test Loss: 1.1809\n",
      "Epoch [29/50] - Train Loss: 1.0785, Test Loss: 1.1819\n",
      "Epoch [30/50] - Train Loss: 1.0774, Test Loss: 1.1824\n",
      "Epoch [31/50] - Train Loss: 1.0765, Test Loss: 1.1829\n",
      "Epoch [32/50] - Train Loss: 1.0756, Test Loss: 1.1833\n",
      "Epoch [33/50] - Train Loss: 1.0748, Test Loss: 1.1838\n",
      "Epoch [34/50] - Train Loss: 1.0740, Test Loss: 1.1843\n",
      "Epoch [35/50] - Train Loss: 1.0732, Test Loss: 1.1849\n",
      "Epoch [36/50] - Train Loss: 1.0725, Test Loss: 1.1855\n",
      "Epoch [37/50] - Train Loss: 1.0718, Test Loss: 1.1861\n",
      "Epoch [38/50] - Train Loss: 1.0711, Test Loss: 1.1868\n",
      "Epoch [39/50] - Train Loss: 1.0704, Test Loss: 1.1876\n",
      "Epoch [40/50] - Train Loss: 1.0697, Test Loss: 1.1883\n",
      "Epoch [41/50] - Train Loss: 1.0691, Test Loss: 1.1891\n",
      "Epoch [42/50] - Train Loss: 1.0684, Test Loss: 1.1899\n",
      "Epoch [43/50] - Train Loss: 1.0678, Test Loss: 1.1906\n",
      "Epoch [44/50] - Train Loss: 1.0671, Test Loss: 1.1914\n",
      "Epoch [45/50] - Train Loss: 1.0665, Test Loss: 1.1922\n",
      "Epoch [46/50] - Train Loss: 1.0659, Test Loss: 1.1930\n",
      "Epoch [47/50] - Train Loss: 1.0653, Test Loss: 1.1937\n",
      "Epoch [48/50] - Train Loss: 1.0646, Test Loss: 1.1945\n",
      "Epoch [49/50] - Train Loss: 1.0640, Test Loss: 1.1954\n",
      "Epoch [50/50] - Train Loss: 1.0634, Test Loss: 1.1962\n",
      "Avg Test Loss: 1.1962\n",
      "Testing combination: (4, 2, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.6377, Test Loss: 1.9424\n",
      "Epoch [2/50] - Train Loss: 1.6305, Test Loss: 1.9324\n",
      "Epoch [3/50] - Train Loss: 1.6236, Test Loss: 1.9226\n",
      "Epoch [4/50] - Train Loss: 1.6169, Test Loss: 1.9131\n",
      "Epoch [5/50] - Train Loss: 1.6104, Test Loss: 1.9039\n",
      "Epoch [6/50] - Train Loss: 1.6041, Test Loss: 1.8950\n",
      "Epoch [7/50] - Train Loss: 1.5981, Test Loss: 1.8864\n",
      "Epoch [8/50] - Train Loss: 1.5922, Test Loss: 1.8782\n",
      "Epoch [9/50] - Train Loss: 1.5866, Test Loss: 1.8702\n",
      "Epoch [10/50] - Train Loss: 1.5811, Test Loss: 1.8624\n",
      "Epoch [11/50] - Train Loss: 1.5758, Test Loss: 1.8550\n",
      "Epoch [12/50] - Train Loss: 1.5707, Test Loss: 1.8478\n",
      "Epoch [13/50] - Train Loss: 1.5658, Test Loss: 1.8409\n",
      "Epoch [14/50] - Train Loss: 1.5611, Test Loss: 1.8343\n",
      "Epoch [15/50] - Train Loss: 1.5565, Test Loss: 1.8279\n",
      "Epoch [16/50] - Train Loss: 1.5521, Test Loss: 1.8218\n",
      "Epoch [17/50] - Train Loss: 1.5479, Test Loss: 1.8159\n",
      "Epoch [18/50] - Train Loss: 1.5439, Test Loss: 1.8103\n",
      "Epoch [19/50] - Train Loss: 1.5401, Test Loss: 1.8050\n",
      "Epoch [20/50] - Train Loss: 1.5364, Test Loss: 1.7999\n",
      "Epoch [21/50] - Train Loss: 1.5329, Test Loss: 1.7950\n",
      "Epoch [22/50] - Train Loss: 1.5295, Test Loss: 1.7904\n",
      "Epoch [23/50] - Train Loss: 1.5263, Test Loss: 1.7861\n",
      "Epoch [24/50] - Train Loss: 1.5233, Test Loss: 1.7819\n",
      "Epoch [25/50] - Train Loss: 1.5204, Test Loss: 1.7780\n",
      "Epoch [26/50] - Train Loss: 1.5177, Test Loss: 1.7743\n",
      "Epoch [27/50] - Train Loss: 1.5152, Test Loss: 1.7709\n",
      "Epoch [28/50] - Train Loss: 1.5127, Test Loss: 1.7676\n",
      "Epoch [29/50] - Train Loss: 1.5105, Test Loss: 1.7645\n",
      "Epoch [30/50] - Train Loss: 1.5083, Test Loss: 1.7617\n",
      "Epoch [31/50] - Train Loss: 1.5063, Test Loss: 1.7590\n",
      "Epoch [32/50] - Train Loss: 1.5045, Test Loss: 1.7566\n",
      "Epoch [33/50] - Train Loss: 1.5027, Test Loss: 1.7543\n",
      "Epoch [34/50] - Train Loss: 1.5011, Test Loss: 1.7521\n",
      "Epoch [35/50] - Train Loss: 1.4996, Test Loss: 1.7502\n",
      "Epoch [36/50] - Train Loss: 1.4982, Test Loss: 1.7484\n",
      "Epoch [37/50] - Train Loss: 1.4969, Test Loss: 1.7468\n",
      "Epoch [38/50] - Train Loss: 1.4958, Test Loss: 1.7453\n",
      "Epoch [39/50] - Train Loss: 1.4947, Test Loss: 1.7439\n",
      "Epoch [40/50] - Train Loss: 1.4937, Test Loss: 1.7427\n",
      "Epoch [41/50] - Train Loss: 1.4928, Test Loss: 1.7416\n",
      "Epoch [42/50] - Train Loss: 1.4920, Test Loss: 1.7406\n",
      "Epoch [43/50] - Train Loss: 1.4913, Test Loss: 1.7397\n",
      "Epoch [44/50] - Train Loss: 1.4906, Test Loss: 1.7388\n",
      "Epoch [45/50] - Train Loss: 1.4900, Test Loss: 1.7381\n",
      "Epoch [46/50] - Train Loss: 1.4895, Test Loss: 1.7375\n",
      "Epoch [47/50] - Train Loss: 1.4890, Test Loss: 1.7369\n",
      "Epoch [48/50] - Train Loss: 1.4886, Test Loss: 1.7364\n",
      "Epoch [49/50] - Train Loss: 1.4882, Test Loss: 1.7360\n",
      "Epoch [50/50] - Train Loss: 1.4878, Test Loss: 1.7356\n",
      "Avg Test Loss: 1.7356\n",
      "Testing combination: (4, 2, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1182, Test Loss: 1.0817\n",
      "Epoch [2/50] - Train Loss: 1.1181, Test Loss: 1.0817\n",
      "Epoch [3/50] - Train Loss: 1.1180, Test Loss: 1.0818\n",
      "Epoch [4/50] - Train Loss: 1.1180, Test Loss: 1.0818\n",
      "Epoch [5/50] - Train Loss: 1.1180, Test Loss: 1.0818\n",
      "Epoch [6/50] - Train Loss: 1.1179, Test Loss: 1.0819\n",
      "Epoch [7/50] - Train Loss: 1.1179, Test Loss: 1.0819\n",
      "Epoch [8/50] - Train Loss: 1.1179, Test Loss: 1.0819\n",
      "Epoch [9/50] - Train Loss: 1.1178, Test Loss: 1.0820\n",
      "Epoch [10/50] - Train Loss: 1.1178, Test Loss: 1.0820\n",
      "Epoch [11/50] - Train Loss: 1.1178, Test Loss: 1.0820\n",
      "Epoch [12/50] - Train Loss: 1.1177, Test Loss: 1.0820\n",
      "Epoch [13/50] - Train Loss: 1.1177, Test Loss: 1.0821\n",
      "Epoch [14/50] - Train Loss: 1.1177, Test Loss: 1.0821\n",
      "Epoch [15/50] - Train Loss: 1.1176, Test Loss: 1.0821\n",
      "Epoch [16/50] - Train Loss: 1.1176, Test Loss: 1.0821\n",
      "Epoch [17/50] - Train Loss: 1.1176, Test Loss: 1.0822\n",
      "Epoch [18/50] - Train Loss: 1.1175, Test Loss: 1.0822\n",
      "Epoch [19/50] - Train Loss: 1.1175, Test Loss: 1.0822\n",
      "Epoch [20/50] - Train Loss: 1.1175, Test Loss: 1.0822\n",
      "Epoch [21/50] - Train Loss: 1.1175, Test Loss: 1.0823\n",
      "Epoch [22/50] - Train Loss: 1.1174, Test Loss: 1.0823\n",
      "Epoch [23/50] - Train Loss: 1.1174, Test Loss: 1.0823\n",
      "Epoch [24/50] - Train Loss: 1.1174, Test Loss: 1.0823\n",
      "Epoch [25/50] - Train Loss: 1.1174, Test Loss: 1.0824\n",
      "Epoch [26/50] - Train Loss: 1.1173, Test Loss: 1.0824\n",
      "Epoch [27/50] - Train Loss: 1.1173, Test Loss: 1.0824\n",
      "Epoch [28/50] - Train Loss: 1.1173, Test Loss: 1.0824\n",
      "Epoch [29/50] - Train Loss: 1.1173, Test Loss: 1.0825\n",
      "Epoch [30/50] - Train Loss: 1.1172, Test Loss: 1.0825\n",
      "Epoch [31/50] - Train Loss: 1.1172, Test Loss: 1.0825\n",
      "Epoch [32/50] - Train Loss: 1.1172, Test Loss: 1.0825\n",
      "Epoch [33/50] - Train Loss: 1.1172, Test Loss: 1.0826\n",
      "Epoch [34/50] - Train Loss: 1.1172, Test Loss: 1.0826\n",
      "Epoch [35/50] - Train Loss: 1.1171, Test Loss: 1.0826\n",
      "Epoch [36/50] - Train Loss: 1.1171, Test Loss: 1.0826\n",
      "Epoch [37/50] - Train Loss: 1.1171, Test Loss: 1.0826\n",
      "Epoch [38/50] - Train Loss: 1.1171, Test Loss: 1.0827\n",
      "Epoch [39/50] - Train Loss: 1.1171, Test Loss: 1.0827\n",
      "Epoch [40/50] - Train Loss: 1.1170, Test Loss: 1.0827\n",
      "Epoch [41/50] - Train Loss: 1.1170, Test Loss: 1.0827\n",
      "Epoch [42/50] - Train Loss: 1.1170, Test Loss: 1.0828\n",
      "Epoch [43/50] - Train Loss: 1.1170, Test Loss: 1.0828\n",
      "Epoch [44/50] - Train Loss: 1.1170, Test Loss: 1.0828\n",
      "Epoch [45/50] - Train Loss: 1.1169, Test Loss: 1.0828\n",
      "Epoch [46/50] - Train Loss: 1.1169, Test Loss: 1.0829\n",
      "Epoch [47/50] - Train Loss: 1.1169, Test Loss: 1.0829\n",
      "Epoch [48/50] - Train Loss: 1.1169, Test Loss: 1.0829\n",
      "Epoch [49/50] - Train Loss: 1.1169, Test Loss: 1.0829\n",
      "Epoch [50/50] - Train Loss: 1.1169, Test Loss: 1.0830\n",
      "Avg Test Loss: 1.0830\n",
      "Testing combination: (4, 2, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1531, Test Loss: 1.1405\n",
      "Epoch [2/50] - Train Loss: 1.1530, Test Loss: 1.1405\n",
      "Epoch [3/50] - Train Loss: 1.1530, Test Loss: 1.1406\n",
      "Epoch [4/50] - Train Loss: 1.1529, Test Loss: 1.1407\n",
      "Epoch [5/50] - Train Loss: 1.1529, Test Loss: 1.1408\n",
      "Epoch [6/50] - Train Loss: 1.1528, Test Loss: 1.1409\n",
      "Epoch [7/50] - Train Loss: 1.1528, Test Loss: 1.1410\n",
      "Epoch [8/50] - Train Loss: 1.1528, Test Loss: 1.1411\n",
      "Epoch [9/50] - Train Loss: 1.1527, Test Loss: 1.1412\n",
      "Epoch [10/50] - Train Loss: 1.1527, Test Loss: 1.1413\n",
      "Epoch [11/50] - Train Loss: 1.1526, Test Loss: 1.1414\n",
      "Epoch [12/50] - Train Loss: 1.1526, Test Loss: 1.1414\n",
      "Epoch [13/50] - Train Loss: 1.1526, Test Loss: 1.1415\n",
      "Epoch [14/50] - Train Loss: 1.1525, Test Loss: 1.1416\n",
      "Epoch [15/50] - Train Loss: 1.1525, Test Loss: 1.1417\n",
      "Epoch [16/50] - Train Loss: 1.1524, Test Loss: 1.1418\n",
      "Epoch [17/50] - Train Loss: 1.1524, Test Loss: 1.1419\n",
      "Epoch [18/50] - Train Loss: 1.1524, Test Loss: 1.1420\n",
      "Epoch [19/50] - Train Loss: 1.1523, Test Loss: 1.1421\n",
      "Epoch [20/50] - Train Loss: 1.1523, Test Loss: 1.1421\n",
      "Epoch [21/50] - Train Loss: 1.1523, Test Loss: 1.1422\n",
      "Epoch [22/50] - Train Loss: 1.1522, Test Loss: 1.1423\n",
      "Epoch [23/50] - Train Loss: 1.1522, Test Loss: 1.1424\n",
      "Epoch [24/50] - Train Loss: 1.1521, Test Loss: 1.1425\n",
      "Epoch [25/50] - Train Loss: 1.1521, Test Loss: 1.1426\n",
      "Epoch [26/50] - Train Loss: 1.1521, Test Loss: 1.1427\n",
      "Epoch [27/50] - Train Loss: 1.1520, Test Loss: 1.1428\n",
      "Epoch [28/50] - Train Loss: 1.1520, Test Loss: 1.1428\n",
      "Epoch [29/50] - Train Loss: 1.1520, Test Loss: 1.1429\n",
      "Epoch [30/50] - Train Loss: 1.1519, Test Loss: 1.1430\n",
      "Epoch [31/50] - Train Loss: 1.1519, Test Loss: 1.1431\n",
      "Epoch [32/50] - Train Loss: 1.1519, Test Loss: 1.1432\n",
      "Epoch [33/50] - Train Loss: 1.1518, Test Loss: 1.1433\n",
      "Epoch [34/50] - Train Loss: 1.1518, Test Loss: 1.1434\n",
      "Epoch [35/50] - Train Loss: 1.1518, Test Loss: 1.1434\n",
      "Epoch [36/50] - Train Loss: 1.1517, Test Loss: 1.1435\n",
      "Epoch [37/50] - Train Loss: 1.1517, Test Loss: 1.1436\n",
      "Epoch [38/50] - Train Loss: 1.1517, Test Loss: 1.1437\n",
      "Epoch [39/50] - Train Loss: 1.1517, Test Loss: 1.1438\n",
      "Epoch [40/50] - Train Loss: 1.1516, Test Loss: 1.1439\n",
      "Epoch [41/50] - Train Loss: 1.1516, Test Loss: 1.1440\n",
      "Epoch [42/50] - Train Loss: 1.1516, Test Loss: 1.1440\n",
      "Epoch [43/50] - Train Loss: 1.1515, Test Loss: 1.1441\n",
      "Epoch [44/50] - Train Loss: 1.1515, Test Loss: 1.1442\n",
      "Epoch [45/50] - Train Loss: 1.1515, Test Loss: 1.1443\n",
      "Epoch [46/50] - Train Loss: 1.1514, Test Loss: 1.1444\n",
      "Epoch [47/50] - Train Loss: 1.1514, Test Loss: 1.1445\n",
      "Epoch [48/50] - Train Loss: 1.1514, Test Loss: 1.1445\n",
      "Epoch [49/50] - Train Loss: 1.1514, Test Loss: 1.1446\n",
      "Epoch [50/50] - Train Loss: 1.1513, Test Loss: 1.1447\n",
      "Avg Test Loss: 1.1447\n",
      "Testing combination: (4, 2, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.8334, Test Loss: 2.2332\n",
      "Epoch [2/50] - Train Loss: 1.8323, Test Loss: 2.2316\n",
      "Epoch [3/50] - Train Loss: 1.8311, Test Loss: 2.2299\n",
      "Epoch [4/50] - Train Loss: 1.8300, Test Loss: 2.2283\n",
      "Epoch [5/50] - Train Loss: 1.8289, Test Loss: 2.2267\n",
      "Epoch [6/50] - Train Loss: 1.8278, Test Loss: 2.2250\n",
      "Epoch [7/50] - Train Loss: 1.8267, Test Loss: 2.2234\n",
      "Epoch [8/50] - Train Loss: 1.8255, Test Loss: 2.2217\n",
      "Epoch [9/50] - Train Loss: 1.8244, Test Loss: 2.2201\n",
      "Epoch [10/50] - Train Loss: 1.8233, Test Loss: 2.2184\n",
      "Epoch [11/50] - Train Loss: 1.8222, Test Loss: 2.2168\n",
      "Epoch [12/50] - Train Loss: 1.8210, Test Loss: 2.2151\n",
      "Epoch [13/50] - Train Loss: 1.8199, Test Loss: 2.2135\n",
      "Epoch [14/50] - Train Loss: 1.8188, Test Loss: 2.2118\n",
      "Epoch [15/50] - Train Loss: 1.8177, Test Loss: 2.2101\n",
      "Epoch [16/50] - Train Loss: 1.8165, Test Loss: 2.2085\n",
      "Epoch [17/50] - Train Loss: 1.8154, Test Loss: 2.2068\n",
      "Epoch [18/50] - Train Loss: 1.8142, Test Loss: 2.2051\n",
      "Epoch [19/50] - Train Loss: 1.8131, Test Loss: 2.2034\n",
      "Epoch [20/50] - Train Loss: 1.8119, Test Loss: 2.2018\n",
      "Epoch [21/50] - Train Loss: 1.8108, Test Loss: 2.2001\n",
      "Epoch [22/50] - Train Loss: 1.8097, Test Loss: 2.1984\n",
      "Epoch [23/50] - Train Loss: 1.8085, Test Loss: 2.1967\n",
      "Epoch [24/50] - Train Loss: 1.8073, Test Loss: 2.1950\n",
      "Epoch [25/50] - Train Loss: 1.8062, Test Loss: 2.1933\n",
      "Epoch [26/50] - Train Loss: 1.8050, Test Loss: 2.1916\n",
      "Epoch [27/50] - Train Loss: 1.8039, Test Loss: 2.1899\n",
      "Epoch [28/50] - Train Loss: 1.8027, Test Loss: 2.1882\n",
      "Epoch [29/50] - Train Loss: 1.8015, Test Loss: 2.1865\n",
      "Epoch [30/50] - Train Loss: 1.8003, Test Loss: 2.1848\n",
      "Epoch [31/50] - Train Loss: 1.7992, Test Loss: 2.1830\n",
      "Epoch [32/50] - Train Loss: 1.7980, Test Loss: 2.1813\n",
      "Epoch [33/50] - Train Loss: 1.7968, Test Loss: 2.1796\n",
      "Epoch [34/50] - Train Loss: 1.7956, Test Loss: 2.1778\n",
      "Epoch [35/50] - Train Loss: 1.7944, Test Loss: 2.1761\n",
      "Epoch [36/50] - Train Loss: 1.7932, Test Loss: 2.1743\n",
      "Epoch [37/50] - Train Loss: 1.7920, Test Loss: 2.1726\n",
      "Epoch [38/50] - Train Loss: 1.7909, Test Loss: 2.1708\n",
      "Epoch [39/50] - Train Loss: 1.7896, Test Loss: 2.1690\n",
      "Epoch [40/50] - Train Loss: 1.7884, Test Loss: 2.1673\n",
      "Epoch [41/50] - Train Loss: 1.7872, Test Loss: 2.1655\n",
      "Epoch [42/50] - Train Loss: 1.7860, Test Loss: 2.1637\n",
      "Epoch [43/50] - Train Loss: 1.7848, Test Loss: 2.1619\n",
      "Epoch [44/50] - Train Loss: 1.7836, Test Loss: 2.1601\n",
      "Epoch [45/50] - Train Loss: 1.7824, Test Loss: 2.1583\n",
      "Epoch [46/50] - Train Loss: 1.7811, Test Loss: 2.1565\n",
      "Epoch [47/50] - Train Loss: 1.7799, Test Loss: 2.1547\n",
      "Epoch [48/50] - Train Loss: 1.7787, Test Loss: 2.1529\n",
      "Epoch [49/50] - Train Loss: 1.7774, Test Loss: 2.1511\n",
      "Epoch [50/50] - Train Loss: 1.7762, Test Loss: 2.1493\n",
      "Avg Test Loss: 2.1493\n",
      "Testing combination: (4, 3, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1455, Test Loss: 1.1102\n",
      "Epoch [2/50] - Train Loss: 1.1180, Test Loss: 1.0890\n",
      "Epoch [3/50] - Train Loss: 1.1170, Test Loss: 1.0848\n",
      "Epoch [4/50] - Train Loss: 1.1181, Test Loss: 1.0848\n",
      "Epoch [5/50] - Train Loss: 1.1181, Test Loss: 1.0859\n",
      "Epoch [6/50] - Train Loss: 1.1179, Test Loss: 1.0869\n",
      "Epoch [7/50] - Train Loss: 1.1177, Test Loss: 1.0873\n",
      "Epoch [8/50] - Train Loss: 1.1176, Test Loss: 1.0874\n",
      "Epoch [9/50] - Train Loss: 1.1175, Test Loss: 1.0873\n",
      "Epoch [10/50] - Train Loss: 1.1175, Test Loss: 1.0872\n",
      "Epoch [11/50] - Train Loss: 1.1175, Test Loss: 1.0871\n",
      "Epoch [12/50] - Train Loss: 1.1175, Test Loss: 1.0871\n",
      "Epoch [13/50] - Train Loss: 1.1175, Test Loss: 1.0871\n",
      "Epoch [14/50] - Train Loss: 1.1175, Test Loss: 1.0871\n",
      "Epoch [15/50] - Train Loss: 1.1175, Test Loss: 1.0871\n",
      "Epoch [16/50] - Train Loss: 1.1175, Test Loss: 1.0871\n",
      "Epoch [17/50] - Train Loss: 1.1175, Test Loss: 1.0871\n",
      "Epoch [18/50] - Train Loss: 1.1175, Test Loss: 1.0871\n",
      "Epoch [19/50] - Train Loss: 1.1174, Test Loss: 1.0871\n",
      "Epoch [20/50] - Train Loss: 1.1174, Test Loss: 1.0871\n",
      "Epoch [21/50] - Train Loss: 1.1174, Test Loss: 1.0871\n",
      "Epoch [22/50] - Train Loss: 1.1174, Test Loss: 1.0871\n",
      "Epoch [23/50] - Train Loss: 1.1174, Test Loss: 1.0871\n",
      "Epoch [24/50] - Train Loss: 1.1174, Test Loss: 1.0871\n",
      "Epoch [25/50] - Train Loss: 1.1174, Test Loss: 1.0871\n",
      "Epoch [26/50] - Train Loss: 1.1174, Test Loss: 1.0871\n",
      "Epoch [27/50] - Train Loss: 1.1173, Test Loss: 1.0871\n",
      "Epoch [28/50] - Train Loss: 1.1173, Test Loss: 1.0871\n",
      "Epoch [29/50] - Train Loss: 1.1173, Test Loss: 1.0871\n",
      "Epoch [30/50] - Train Loss: 1.1173, Test Loss: 1.0871\n",
      "Epoch [31/50] - Train Loss: 1.1173, Test Loss: 1.0871\n",
      "Epoch [32/50] - Train Loss: 1.1173, Test Loss: 1.0871\n",
      "Epoch [33/50] - Train Loss: 1.1173, Test Loss: 1.0871\n",
      "Epoch [34/50] - Train Loss: 1.1173, Test Loss: 1.0871\n",
      "Epoch [35/50] - Train Loss: 1.1173, Test Loss: 1.0871\n",
      "Epoch [36/50] - Train Loss: 1.1173, Test Loss: 1.0870\n",
      "Epoch [37/50] - Train Loss: 1.1173, Test Loss: 1.0870\n",
      "Epoch [38/50] - Train Loss: 1.1172, Test Loss: 1.0870\n",
      "Epoch [39/50] - Train Loss: 1.1172, Test Loss: 1.0870\n",
      "Epoch [40/50] - Train Loss: 1.1172, Test Loss: 1.0870\n",
      "Epoch [41/50] - Train Loss: 1.1172, Test Loss: 1.0870\n",
      "Epoch [42/50] - Train Loss: 1.1172, Test Loss: 1.0870\n",
      "Epoch [43/50] - Train Loss: 1.1172, Test Loss: 1.0870\n",
      "Epoch [44/50] - Train Loss: 1.1172, Test Loss: 1.0870\n",
      "Epoch [45/50] - Train Loss: 1.1172, Test Loss: 1.0870\n",
      "Epoch [46/50] - Train Loss: 1.1172, Test Loss: 1.0870\n",
      "Epoch [47/50] - Train Loss: 1.1172, Test Loss: 1.0870\n",
      "Epoch [48/50] - Train Loss: 1.1172, Test Loss: 1.0870\n",
      "Epoch [49/50] - Train Loss: 1.1172, Test Loss: 1.0870\n",
      "Epoch [50/50] - Train Loss: 1.1172, Test Loss: 1.0870\n",
      "Avg Test Loss: 1.0870\n",
      "Testing combination: (4, 3, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1759, Test Loss: 1.1989\n",
      "Epoch [2/50] - Train Loss: 1.1541, Test Loss: 1.1808\n",
      "Epoch [3/50] - Train Loss: 1.1510, Test Loss: 1.1725\n",
      "Epoch [4/50] - Train Loss: 1.1497, Test Loss: 1.1681\n",
      "Epoch [5/50] - Train Loss: 1.1482, Test Loss: 1.1657\n",
      "Epoch [6/50] - Train Loss: 1.1440, Test Loss: 1.1640\n",
      "Epoch [7/50] - Train Loss: 1.1335, Test Loss: 1.1618\n",
      "Epoch [8/50] - Train Loss: 1.1115, Test Loss: 1.1629\n",
      "Epoch [9/50] - Train Loss: 1.1222, Test Loss: 1.1674\n",
      "Epoch [10/50] - Train Loss: 1.0780, Test Loss: 1.1839\n",
      "Epoch [11/50] - Train Loss: 1.0565, Test Loss: 1.2173\n",
      "Epoch [12/50] - Train Loss: 1.0466, Test Loss: 1.2491\n",
      "Epoch [13/50] - Train Loss: 1.0466, Test Loss: 1.2637\n",
      "Epoch [14/50] - Train Loss: 1.0467, Test Loss: 1.2639\n",
      "Epoch [15/50] - Train Loss: 1.0437, Test Loss: 1.2606\n",
      "Epoch [16/50] - Train Loss: 1.0422, Test Loss: 1.2612\n",
      "Epoch [17/50] - Train Loss: 1.0415, Test Loss: 1.2651\n",
      "Epoch [18/50] - Train Loss: 1.0410, Test Loss: 1.2686\n",
      "Epoch [19/50] - Train Loss: 1.0405, Test Loss: 1.2703\n",
      "Epoch [20/50] - Train Loss: 1.0400, Test Loss: 1.2715\n",
      "Epoch [21/50] - Train Loss: 1.0396, Test Loss: 1.2747\n",
      "Epoch [22/50] - Train Loss: 1.0364, Test Loss: 1.2780\n",
      "Epoch [23/50] - Train Loss: 1.0396, Test Loss: 1.4756\n",
      "Epoch [24/50] - Train Loss: 1.1455, Test Loss: 1.1253\n",
      "Epoch [25/50] - Train Loss: 1.1626, Test Loss: 1.1321\n",
      "Epoch [26/50] - Train Loss: 1.1547, Test Loss: 1.1430\n",
      "Epoch [27/50] - Train Loss: 1.1509, Test Loss: 1.1529\n",
      "Epoch [28/50] - Train Loss: 1.1499, Test Loss: 1.1598\n",
      "Epoch [29/50] - Train Loss: 1.1499, Test Loss: 1.1638\n",
      "Epoch [30/50] - Train Loss: 1.1500, Test Loss: 1.1656\n",
      "Epoch [31/50] - Train Loss: 1.1501, Test Loss: 1.1661\n",
      "Epoch [32/50] - Train Loss: 1.1502, Test Loss: 1.1660\n",
      "Epoch [33/50] - Train Loss: 1.1502, Test Loss: 1.1656\n",
      "Epoch [34/50] - Train Loss: 1.1501, Test Loss: 1.1652\n",
      "Epoch [35/50] - Train Loss: 1.1501, Test Loss: 1.1649\n",
      "Epoch [36/50] - Train Loss: 1.1501, Test Loss: 1.1647\n",
      "Epoch [37/50] - Train Loss: 1.1501, Test Loss: 1.1645\n",
      "Epoch [38/50] - Train Loss: 1.1500, Test Loss: 1.1644\n",
      "Epoch [39/50] - Train Loss: 1.1500, Test Loss: 1.1644\n",
      "Epoch [40/50] - Train Loss: 1.1500, Test Loss: 1.1644\n",
      "Epoch [41/50] - Train Loss: 1.1500, Test Loss: 1.1644\n",
      "Epoch [42/50] - Train Loss: 1.1500, Test Loss: 1.1644\n",
      "Epoch [43/50] - Train Loss: 1.1500, Test Loss: 1.1645\n",
      "Epoch [44/50] - Train Loss: 1.1500, Test Loss: 1.1645\n",
      "Epoch [45/50] - Train Loss: 1.1499, Test Loss: 1.1645\n",
      "Epoch [46/50] - Train Loss: 1.1499, Test Loss: 1.1645\n",
      "Epoch [47/50] - Train Loss: 1.1499, Test Loss: 1.1645\n",
      "Epoch [48/50] - Train Loss: 1.1499, Test Loss: 1.1646\n",
      "Epoch [49/50] - Train Loss: 1.1499, Test Loss: 1.1646\n",
      "Epoch [50/50] - Train Loss: 1.1499, Test Loss: 1.1646\n",
      "Avg Test Loss: 1.1646\n",
      "Testing combination: (4, 3, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5663, Test Loss: 1.8136\n",
      "Epoch [2/50] - Train Loss: 1.5258, Test Loss: 1.7730\n",
      "Epoch [3/50] - Train Loss: 1.5036, Test Loss: 1.7504\n",
      "Epoch [4/50] - Train Loss: 1.4915, Test Loss: 1.7387\n",
      "Epoch [5/50] - Train Loss: 1.4856, Test Loss: 1.7338\n",
      "Epoch [6/50] - Train Loss: 1.4839, Test Loss: 1.7329\n",
      "Epoch [7/50] - Train Loss: 1.4843, Test Loss: 1.7337\n",
      "Epoch [8/50] - Train Loss: 1.4855, Test Loss: 1.7345\n",
      "Epoch [9/50] - Train Loss: 1.4866, Test Loss: 1.7349\n",
      "Epoch [10/50] - Train Loss: 1.4872, Test Loss: 1.7348\n",
      "Epoch [11/50] - Train Loss: 1.4874, Test Loss: 1.7344\n",
      "Epoch [12/50] - Train Loss: 1.4874, Test Loss: 1.7340\n",
      "Epoch [13/50] - Train Loss: 1.4872, Test Loss: 1.7336\n",
      "Epoch [14/50] - Train Loss: 1.4870, Test Loss: 1.7334\n",
      "Epoch [15/50] - Train Loss: 1.4869, Test Loss: 1.7332\n",
      "Epoch [16/50] - Train Loss: 1.4867, Test Loss: 1.7332\n",
      "Epoch [17/50] - Train Loss: 1.4866, Test Loss: 1.7332\n",
      "Epoch [18/50] - Train Loss: 1.4865, Test Loss: 1.7332\n",
      "Epoch [19/50] - Train Loss: 1.4864, Test Loss: 1.7332\n",
      "Epoch [20/50] - Train Loss: 1.4863, Test Loss: 1.7333\n",
      "Epoch [21/50] - Train Loss: 1.4863, Test Loss: 1.7333\n",
      "Epoch [22/50] - Train Loss: 1.4863, Test Loss: 1.7334\n",
      "Epoch [23/50] - Train Loss: 1.4862, Test Loss: 1.7336\n",
      "Epoch [24/50] - Train Loss: 1.4862, Test Loss: 1.7338\n",
      "Epoch [25/50] - Train Loss: 1.4862, Test Loss: 1.7340\n",
      "Epoch [26/50] - Train Loss: 1.4861, Test Loss: 1.7344\n",
      "Epoch [27/50] - Train Loss: 1.4860, Test Loss: 1.7350\n",
      "Epoch [28/50] - Train Loss: 1.4856, Test Loss: 1.7361\n",
      "Epoch [29/50] - Train Loss: 1.4850, Test Loss: 1.7378\n",
      "Epoch [30/50] - Train Loss: 1.4839, Test Loss: 1.7397\n",
      "Epoch [31/50] - Train Loss: 1.4821, Test Loss: 1.7416\n",
      "Epoch [32/50] - Train Loss: 1.4795, Test Loss: 1.7445\n",
      "Epoch [33/50] - Train Loss: 1.4748, Test Loss: 1.7492\n",
      "Epoch [34/50] - Train Loss: 1.4673, Test Loss: 1.7565\n",
      "Epoch [35/50] - Train Loss: 1.4568, Test Loss: 1.7664\n",
      "Epoch [36/50] - Train Loss: 1.4470, Test Loss: 1.7801\n",
      "Epoch [37/50] - Train Loss: 1.4400, Test Loss: 1.7953\n",
      "Epoch [38/50] - Train Loss: 1.4362, Test Loss: 1.8149\n",
      "Epoch [39/50] - Train Loss: 1.4347, Test Loss: 1.8527\n",
      "Epoch [40/50] - Train Loss: 1.4321, Test Loss: 1.8458\n",
      "Epoch [41/50] - Train Loss: 1.4274, Test Loss: 1.8559\n",
      "Epoch [42/50] - Train Loss: 1.4292, Test Loss: 1.8899\n",
      "Epoch [43/50] - Train Loss: 1.4279, Test Loss: 1.9061\n",
      "Epoch [44/50] - Train Loss: 1.4252, Test Loss: 1.8984\n",
      "Epoch [45/50] - Train Loss: 1.4235, Test Loss: 1.8962\n",
      "Epoch [46/50] - Train Loss: 1.4236, Test Loss: 1.9043\n",
      "Epoch [47/50] - Train Loss: 1.4234, Test Loss: 1.9170\n",
      "Epoch [48/50] - Train Loss: 1.4227, Test Loss: 1.9240\n",
      "Epoch [49/50] - Train Loss: 1.4213, Test Loss: 1.9226\n",
      "Epoch [50/50] - Train Loss: 1.4198, Test Loss: 1.9225\n",
      "Avg Test Loss: 1.9225\n",
      "Testing combination: (4, 3, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.4400, Test Loss: 1.5271\n",
      "Epoch [2/50] - Train Loss: 1.4101, Test Loss: 1.4921\n",
      "Epoch [3/50] - Train Loss: 1.3840, Test Loss: 1.4603\n",
      "Epoch [4/50] - Train Loss: 1.3602, Test Loss: 1.4306\n",
      "Epoch [5/50] - Train Loss: 1.3377, Test Loss: 1.4021\n",
      "Epoch [6/50] - Train Loss: 1.3160, Test Loss: 1.3739\n",
      "Epoch [7/50] - Train Loss: 1.2943, Test Loss: 1.3453\n",
      "Epoch [8/50] - Train Loss: 1.2723, Test Loss: 1.3159\n",
      "Epoch [9/50] - Train Loss: 1.2495, Test Loss: 1.2852\n",
      "Epoch [10/50] - Train Loss: 1.2259, Test Loss: 1.2532\n",
      "Epoch [11/50] - Train Loss: 1.2018, Test Loss: 1.2207\n",
      "Epoch [12/50] - Train Loss: 1.1780, Test Loss: 1.1890\n",
      "Epoch [13/50] - Train Loss: 1.1561, Test Loss: 1.1604\n",
      "Epoch [14/50] - Train Loss: 1.1378, Test Loss: 1.1373\n",
      "Epoch [15/50] - Train Loss: 1.1241, Test Loss: 1.1213\n",
      "Epoch [16/50] - Train Loss: 1.1147, Test Loss: 1.1118\n",
      "Epoch [17/50] - Train Loss: 1.1086, Test Loss: 1.1066\n",
      "Epoch [18/50] - Train Loss: 1.1050, Test Loss: 1.1038\n",
      "Epoch [19/50] - Train Loss: 1.1026, Test Loss: 1.1025\n",
      "Epoch [20/50] - Train Loss: 1.1008, Test Loss: 1.1021\n",
      "Epoch [21/50] - Train Loss: 1.0993, Test Loss: 1.1021\n",
      "Epoch [22/50] - Train Loss: 1.0979, Test Loss: 1.1024\n",
      "Epoch [23/50] - Train Loss: 1.0965, Test Loss: 1.1029\n",
      "Epoch [24/50] - Train Loss: 1.0950, Test Loss: 1.1036\n",
      "Epoch [25/50] - Train Loss: 1.0934, Test Loss: 1.1045\n",
      "Epoch [26/50] - Train Loss: 1.0919, Test Loss: 1.1057\n",
      "Epoch [27/50] - Train Loss: 1.0906, Test Loss: 1.1066\n",
      "Epoch [28/50] - Train Loss: 1.0892, Test Loss: 1.1070\n",
      "Epoch [29/50] - Train Loss: 1.0881, Test Loss: 1.1073\n",
      "Epoch [30/50] - Train Loss: 1.0869, Test Loss: 1.1076\n",
      "Epoch [31/50] - Train Loss: 1.0852, Test Loss: 1.1062\n",
      "Epoch [32/50] - Train Loss: 1.0812, Test Loss: 1.1078\n",
      "Epoch [33/50] - Train Loss: 1.0749, Test Loss: 1.1109\n",
      "Epoch [34/50] - Train Loss: 1.1336, Test Loss: 1.2766\n",
      "Epoch [35/50] - Train Loss: 1.2104, Test Loss: 1.1797\n",
      "Epoch [36/50] - Train Loss: 1.1130, Test Loss: 1.1213\n",
      "Epoch [37/50] - Train Loss: 1.0891, Test Loss: 1.1110\n",
      "Epoch [38/50] - Train Loss: 1.0896, Test Loss: 1.1082\n",
      "Epoch [39/50] - Train Loss: 1.0900, Test Loss: 1.1075\n",
      "Epoch [40/50] - Train Loss: 1.0892, Test Loss: 1.1077\n",
      "Epoch [41/50] - Train Loss: 1.0882, Test Loss: 1.1081\n",
      "Epoch [42/50] - Train Loss: 1.0872, Test Loss: 1.1088\n",
      "Epoch [43/50] - Train Loss: 1.0864, Test Loss: 1.1095\n",
      "Epoch [44/50] - Train Loss: 1.0857, Test Loss: 1.1102\n",
      "Epoch [45/50] - Train Loss: 1.0850, Test Loss: 1.1108\n",
      "Epoch [46/50] - Train Loss: 1.0844, Test Loss: 1.1114\n",
      "Epoch [47/50] - Train Loss: 1.0839, Test Loss: 1.1119\n",
      "Epoch [48/50] - Train Loss: 1.0833, Test Loss: 1.1125\n",
      "Epoch [49/50] - Train Loss: 1.0828, Test Loss: 1.1131\n",
      "Epoch [50/50] - Train Loss: 1.0823, Test Loss: 1.1136\n",
      "Avg Test Loss: 1.1136\n",
      "Testing combination: (4, 3, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1654, Test Loss: 1.1266\n",
      "Epoch [2/50] - Train Loss: 1.1631, Test Loss: 1.1277\n",
      "Epoch [3/50] - Train Loss: 1.1615, Test Loss: 1.1288\n",
      "Epoch [4/50] - Train Loss: 1.1600, Test Loss: 1.1299\n",
      "Epoch [5/50] - Train Loss: 1.1587, Test Loss: 1.1310\n",
      "Epoch [6/50] - Train Loss: 1.1574, Test Loss: 1.1322\n",
      "Epoch [7/50] - Train Loss: 1.1562, Test Loss: 1.1334\n",
      "Epoch [8/50] - Train Loss: 1.1550, Test Loss: 1.1347\n",
      "Epoch [9/50] - Train Loss: 1.1539, Test Loss: 1.1360\n",
      "Epoch [10/50] - Train Loss: 1.1528, Test Loss: 1.1373\n",
      "Epoch [11/50] - Train Loss: 1.1517, Test Loss: 1.1387\n",
      "Epoch [12/50] - Train Loss: 1.1507, Test Loss: 1.1401\n",
      "Epoch [13/50] - Train Loss: 1.1496, Test Loss: 1.1416\n",
      "Epoch [14/50] - Train Loss: 1.1485, Test Loss: 1.1430\n",
      "Epoch [15/50] - Train Loss: 1.1474, Test Loss: 1.1445\n",
      "Epoch [16/50] - Train Loss: 1.1462, Test Loss: 1.1460\n",
      "Epoch [17/50] - Train Loss: 1.1450, Test Loss: 1.1474\n",
      "Epoch [18/50] - Train Loss: 1.1437, Test Loss: 1.1489\n",
      "Epoch [19/50] - Train Loss: 1.1422, Test Loss: 1.1503\n",
      "Epoch [20/50] - Train Loss: 1.1407, Test Loss: 1.1517\n",
      "Epoch [21/50] - Train Loss: 1.1390, Test Loss: 1.1531\n",
      "Epoch [22/50] - Train Loss: 1.1372, Test Loss: 1.1543\n",
      "Epoch [23/50] - Train Loss: 1.1353, Test Loss: 1.1555\n",
      "Epoch [24/50] - Train Loss: 1.1332, Test Loss: 1.1566\n",
      "Epoch [25/50] - Train Loss: 1.1310, Test Loss: 1.1576\n",
      "Epoch [26/50] - Train Loss: 1.1288, Test Loss: 1.1586\n",
      "Epoch [27/50] - Train Loss: 1.1266, Test Loss: 1.1594\n",
      "Epoch [28/50] - Train Loss: 1.1243, Test Loss: 1.1602\n",
      "Epoch [29/50] - Train Loss: 1.1220, Test Loss: 1.1609\n",
      "Epoch [30/50] - Train Loss: 1.1198, Test Loss: 1.1616\n",
      "Epoch [31/50] - Train Loss: 1.1176, Test Loss: 1.1623\n",
      "Epoch [32/50] - Train Loss: 1.1154, Test Loss: 1.1629\n",
      "Epoch [33/50] - Train Loss: 1.1133, Test Loss: 1.1635\n",
      "Epoch [34/50] - Train Loss: 1.1112, Test Loss: 1.1641\n",
      "Epoch [35/50] - Train Loss: 1.1091, Test Loss: 1.1647\n",
      "Epoch [36/50] - Train Loss: 1.1071, Test Loss: 1.1652\n",
      "Epoch [37/50] - Train Loss: 1.1051, Test Loss: 1.1658\n",
      "Epoch [38/50] - Train Loss: 1.1031, Test Loss: 1.1664\n",
      "Epoch [39/50] - Train Loss: 1.1011, Test Loss: 1.1669\n",
      "Epoch [40/50] - Train Loss: 1.0990, Test Loss: 1.1675\n",
      "Epoch [41/50] - Train Loss: 1.0967, Test Loss: 1.1680\n",
      "Epoch [42/50] - Train Loss: 1.0943, Test Loss: 1.1685\n",
      "Epoch [43/50] - Train Loss: 1.0919, Test Loss: 1.1691\n",
      "Epoch [44/50] - Train Loss: 1.0899, Test Loss: 1.1695\n",
      "Epoch [45/50] - Train Loss: 1.0878, Test Loss: 1.1692\n",
      "Epoch [46/50] - Train Loss: 1.0858, Test Loss: 1.1690\n",
      "Epoch [47/50] - Train Loss: 1.0841, Test Loss: 1.1690\n",
      "Epoch [48/50] - Train Loss: 1.0824, Test Loss: 1.1689\n",
      "Epoch [49/50] - Train Loss: 1.0808, Test Loss: 1.1689\n",
      "Epoch [50/50] - Train Loss: 1.0791, Test Loss: 1.1689\n",
      "Avg Test Loss: 1.1689\n",
      "Testing combination: (4, 3, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.6439, Test Loss: 1.9515\n",
      "Epoch [2/50] - Train Loss: 1.6367, Test Loss: 1.9414\n",
      "Epoch [3/50] - Train Loss: 1.6298, Test Loss: 1.9316\n",
      "Epoch [4/50] - Train Loss: 1.6232, Test Loss: 1.9221\n",
      "Epoch [5/50] - Train Loss: 1.6168, Test Loss: 1.9131\n",
      "Epoch [6/50] - Train Loss: 1.6106, Test Loss: 1.9044\n",
      "Epoch [7/50] - Train Loss: 1.6047, Test Loss: 1.8962\n",
      "Epoch [8/50] - Train Loss: 1.5991, Test Loss: 1.8883\n",
      "Epoch [9/50] - Train Loss: 1.5937, Test Loss: 1.8807\n",
      "Epoch [10/50] - Train Loss: 1.5886, Test Loss: 1.8735\n",
      "Epoch [11/50] - Train Loss: 1.5836, Test Loss: 1.8666\n",
      "Epoch [12/50] - Train Loss: 1.5789, Test Loss: 1.8600\n",
      "Epoch [13/50] - Train Loss: 1.5743, Test Loss: 1.8536\n",
      "Epoch [14/50] - Train Loss: 1.5698, Test Loss: 1.8475\n",
      "Epoch [15/50] - Train Loss: 1.5656, Test Loss: 1.8417\n",
      "Epoch [16/50] - Train Loss: 1.5615, Test Loss: 1.8361\n",
      "Epoch [17/50] - Train Loss: 1.5575, Test Loss: 1.8308\n",
      "Epoch [18/50] - Train Loss: 1.5537, Test Loss: 1.8256\n",
      "Epoch [19/50] - Train Loss: 1.5500, Test Loss: 1.8207\n",
      "Epoch [20/50] - Train Loss: 1.5464, Test Loss: 1.8160\n",
      "Epoch [21/50] - Train Loss: 1.5429, Test Loss: 1.8114\n",
      "Epoch [22/50] - Train Loss: 1.5395, Test Loss: 1.8070\n",
      "Epoch [23/50] - Train Loss: 1.5363, Test Loss: 1.8028\n",
      "Epoch [24/50] - Train Loss: 1.5332, Test Loss: 1.7988\n",
      "Epoch [25/50] - Train Loss: 1.5302, Test Loss: 1.7949\n",
      "Epoch [26/50] - Train Loss: 1.5273, Test Loss: 1.7912\n",
      "Epoch [27/50] - Train Loss: 1.5245, Test Loss: 1.7877\n",
      "Epoch [28/50] - Train Loss: 1.5218, Test Loss: 1.7843\n",
      "Epoch [29/50] - Train Loss: 1.5192, Test Loss: 1.7811\n",
      "Epoch [30/50] - Train Loss: 1.5167, Test Loss: 1.7781\n",
      "Epoch [31/50] - Train Loss: 1.5144, Test Loss: 1.7753\n",
      "Epoch [32/50] - Train Loss: 1.5121, Test Loss: 1.7726\n",
      "Epoch [33/50] - Train Loss: 1.5100, Test Loss: 1.7700\n",
      "Epoch [34/50] - Train Loss: 1.5079, Test Loss: 1.7677\n",
      "Epoch [35/50] - Train Loss: 1.5059, Test Loss: 1.7655\n",
      "Epoch [36/50] - Train Loss: 1.5041, Test Loss: 1.7634\n",
      "Epoch [37/50] - Train Loss: 1.5023, Test Loss: 1.7615\n",
      "Epoch [38/50] - Train Loss: 1.5007, Test Loss: 1.7598\n",
      "Epoch [39/50] - Train Loss: 1.4991, Test Loss: 1.7581\n",
      "Epoch [40/50] - Train Loss: 1.4976, Test Loss: 1.7567\n",
      "Epoch [41/50] - Train Loss: 1.4962, Test Loss: 1.7553\n",
      "Epoch [42/50] - Train Loss: 1.4949, Test Loss: 1.7541\n",
      "Epoch [43/50] - Train Loss: 1.4936, Test Loss: 1.7531\n",
      "Epoch [44/50] - Train Loss: 1.4924, Test Loss: 1.7521\n",
      "Epoch [45/50] - Train Loss: 1.4913, Test Loss: 1.7513\n",
      "Epoch [46/50] - Train Loss: 1.4903, Test Loss: 1.7506\n",
      "Epoch [47/50] - Train Loss: 1.4893, Test Loss: 1.7500\n",
      "Epoch [48/50] - Train Loss: 1.4883, Test Loss: 1.7495\n",
      "Epoch [49/50] - Train Loss: 1.4874, Test Loss: 1.7491\n",
      "Epoch [50/50] - Train Loss: 1.4865, Test Loss: 1.7487\n",
      "Avg Test Loss: 1.7487\n",
      "Testing combination: (4, 3, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1165, Test Loss: 1.0844\n",
      "Epoch [2/50] - Train Loss: 1.1164, Test Loss: 1.0845\n",
      "Epoch [3/50] - Train Loss: 1.1163, Test Loss: 1.0845\n",
      "Epoch [4/50] - Train Loss: 1.1163, Test Loss: 1.0845\n",
      "Epoch [5/50] - Train Loss: 1.1163, Test Loss: 1.0845\n",
      "Epoch [6/50] - Train Loss: 1.1163, Test Loss: 1.0846\n",
      "Epoch [7/50] - Train Loss: 1.1163, Test Loss: 1.0846\n",
      "Epoch [8/50] - Train Loss: 1.1163, Test Loss: 1.0846\n",
      "Epoch [9/50] - Train Loss: 1.1163, Test Loss: 1.0847\n",
      "Epoch [10/50] - Train Loss: 1.1163, Test Loss: 1.0847\n",
      "Epoch [11/50] - Train Loss: 1.1163, Test Loss: 1.0847\n",
      "Epoch [12/50] - Train Loss: 1.1163, Test Loss: 1.0847\n",
      "Epoch [13/50] - Train Loss: 1.1163, Test Loss: 1.0848\n",
      "Epoch [14/50] - Train Loss: 1.1162, Test Loss: 1.0848\n",
      "Epoch [15/50] - Train Loss: 1.1162, Test Loss: 1.0848\n",
      "Epoch [16/50] - Train Loss: 1.1162, Test Loss: 1.0849\n",
      "Epoch [17/50] - Train Loss: 1.1162, Test Loss: 1.0849\n",
      "Epoch [18/50] - Train Loss: 1.1162, Test Loss: 1.0849\n",
      "Epoch [19/50] - Train Loss: 1.1162, Test Loss: 1.0849\n",
      "Epoch [20/50] - Train Loss: 1.1162, Test Loss: 1.0850\n",
      "Epoch [21/50] - Train Loss: 1.1162, Test Loss: 1.0850\n",
      "Epoch [22/50] - Train Loss: 1.1162, Test Loss: 1.0850\n",
      "Epoch [23/50] - Train Loss: 1.1162, Test Loss: 1.0850\n",
      "Epoch [24/50] - Train Loss: 1.1161, Test Loss: 1.0851\n",
      "Epoch [25/50] - Train Loss: 1.1161, Test Loss: 1.0851\n",
      "Epoch [26/50] - Train Loss: 1.1161, Test Loss: 1.0851\n",
      "Epoch [27/50] - Train Loss: 1.1161, Test Loss: 1.0851\n",
      "Epoch [28/50] - Train Loss: 1.1161, Test Loss: 1.0852\n",
      "Epoch [29/50] - Train Loss: 1.1161, Test Loss: 1.0852\n",
      "Epoch [30/50] - Train Loss: 1.1161, Test Loss: 1.0852\n",
      "Epoch [31/50] - Train Loss: 1.1161, Test Loss: 1.0852\n",
      "Epoch [32/50] - Train Loss: 1.1161, Test Loss: 1.0853\n",
      "Epoch [33/50] - Train Loss: 1.1161, Test Loss: 1.0853\n",
      "Epoch [34/50] - Train Loss: 1.1161, Test Loss: 1.0853\n",
      "Epoch [35/50] - Train Loss: 1.1160, Test Loss: 1.0853\n",
      "Epoch [36/50] - Train Loss: 1.1160, Test Loss: 1.0853\n",
      "Epoch [37/50] - Train Loss: 1.1160, Test Loss: 1.0854\n",
      "Epoch [38/50] - Train Loss: 1.1160, Test Loss: 1.0854\n",
      "Epoch [39/50] - Train Loss: 1.1160, Test Loss: 1.0854\n",
      "Epoch [40/50] - Train Loss: 1.1160, Test Loss: 1.0854\n",
      "Epoch [41/50] - Train Loss: 1.1160, Test Loss: 1.0854\n",
      "Epoch [42/50] - Train Loss: 1.1160, Test Loss: 1.0855\n",
      "Epoch [43/50] - Train Loss: 1.1160, Test Loss: 1.0855\n",
      "Epoch [44/50] - Train Loss: 1.1160, Test Loss: 1.0855\n",
      "Epoch [45/50] - Train Loss: 1.1160, Test Loss: 1.0855\n",
      "Epoch [46/50] - Train Loss: 1.1160, Test Loss: 1.0855\n",
      "Epoch [47/50] - Train Loss: 1.1159, Test Loss: 1.0856\n",
      "Epoch [48/50] - Train Loss: 1.1159, Test Loss: 1.0856\n",
      "Epoch [49/50] - Train Loss: 1.1159, Test Loss: 1.0856\n",
      "Epoch [50/50] - Train Loss: 1.1159, Test Loss: 1.0856\n",
      "Avg Test Loss: 1.0856\n",
      "Testing combination: (4, 3, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1617, Test Loss: 1.2319\n",
      "Epoch [2/50] - Train Loss: 1.1613, Test Loss: 1.2313\n",
      "Epoch [3/50] - Train Loss: 1.1612, Test Loss: 1.2307\n",
      "Epoch [4/50] - Train Loss: 1.1610, Test Loss: 1.2302\n",
      "Epoch [5/50] - Train Loss: 1.1608, Test Loss: 1.2297\n",
      "Epoch [6/50] - Train Loss: 1.1607, Test Loss: 1.2292\n",
      "Epoch [7/50] - Train Loss: 1.1605, Test Loss: 1.2287\n",
      "Epoch [8/50] - Train Loss: 1.1603, Test Loss: 1.2282\n",
      "Epoch [9/50] - Train Loss: 1.1602, Test Loss: 1.2277\n",
      "Epoch [10/50] - Train Loss: 1.1600, Test Loss: 1.2273\n",
      "Epoch [11/50] - Train Loss: 1.1599, Test Loss: 1.2268\n",
      "Epoch [12/50] - Train Loss: 1.1597, Test Loss: 1.2263\n",
      "Epoch [13/50] - Train Loss: 1.1596, Test Loss: 1.2258\n",
      "Epoch [14/50] - Train Loss: 1.1595, Test Loss: 1.2254\n",
      "Epoch [15/50] - Train Loss: 1.1593, Test Loss: 1.2249\n",
      "Epoch [16/50] - Train Loss: 1.1592, Test Loss: 1.2244\n",
      "Epoch [17/50] - Train Loss: 1.1590, Test Loss: 1.2240\n",
      "Epoch [18/50] - Train Loss: 1.1589, Test Loss: 1.2235\n",
      "Epoch [19/50] - Train Loss: 1.1588, Test Loss: 1.2231\n",
      "Epoch [20/50] - Train Loss: 1.1586, Test Loss: 1.2227\n",
      "Epoch [21/50] - Train Loss: 1.1585, Test Loss: 1.2222\n",
      "Epoch [22/50] - Train Loss: 1.1584, Test Loss: 1.2218\n",
      "Epoch [23/50] - Train Loss: 1.1583, Test Loss: 1.2213\n",
      "Epoch [24/50] - Train Loss: 1.1581, Test Loss: 1.2209\n",
      "Epoch [25/50] - Train Loss: 1.1580, Test Loss: 1.2205\n",
      "Epoch [26/50] - Train Loss: 1.1579, Test Loss: 1.2201\n",
      "Epoch [27/50] - Train Loss: 1.1578, Test Loss: 1.2197\n",
      "Epoch [28/50] - Train Loss: 1.1577, Test Loss: 1.2192\n",
      "Epoch [29/50] - Train Loss: 1.1575, Test Loss: 1.2188\n",
      "Epoch [30/50] - Train Loss: 1.1574, Test Loss: 1.2184\n",
      "Epoch [31/50] - Train Loss: 1.1573, Test Loss: 1.2180\n",
      "Epoch [32/50] - Train Loss: 1.1572, Test Loss: 1.2176\n",
      "Epoch [33/50] - Train Loss: 1.1571, Test Loss: 1.2172\n",
      "Epoch [34/50] - Train Loss: 1.1570, Test Loss: 1.2168\n",
      "Epoch [35/50] - Train Loss: 1.1569, Test Loss: 1.2164\n",
      "Epoch [36/50] - Train Loss: 1.1568, Test Loss: 1.2160\n",
      "Epoch [37/50] - Train Loss: 1.1566, Test Loss: 1.2157\n",
      "Epoch [38/50] - Train Loss: 1.1565, Test Loss: 1.2153\n",
      "Epoch [39/50] - Train Loss: 1.1564, Test Loss: 1.2149\n",
      "Epoch [40/50] - Train Loss: 1.1563, Test Loss: 1.2145\n",
      "Epoch [41/50] - Train Loss: 1.1562, Test Loss: 1.2141\n",
      "Epoch [42/50] - Train Loss: 1.1561, Test Loss: 1.2138\n",
      "Epoch [43/50] - Train Loss: 1.1560, Test Loss: 1.2134\n",
      "Epoch [44/50] - Train Loss: 1.1559, Test Loss: 1.2130\n",
      "Epoch [45/50] - Train Loss: 1.1558, Test Loss: 1.2127\n",
      "Epoch [46/50] - Train Loss: 1.1557, Test Loss: 1.2123\n",
      "Epoch [47/50] - Train Loss: 1.1556, Test Loss: 1.2120\n",
      "Epoch [48/50] - Train Loss: 1.1556, Test Loss: 1.2116\n",
      "Epoch [49/50] - Train Loss: 1.1555, Test Loss: 1.2113\n",
      "Epoch [50/50] - Train Loss: 1.1554, Test Loss: 1.2109\n",
      "Avg Test Loss: 1.2109\n",
      "Testing combination: (4, 3, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.4957, Test Loss: 1.7447\n",
      "Epoch [2/50] - Train Loss: 1.4955, Test Loss: 1.7446\n",
      "Epoch [3/50] - Train Loss: 1.4954, Test Loss: 1.7445\n",
      "Epoch [4/50] - Train Loss: 1.4953, Test Loss: 1.7444\n",
      "Epoch [5/50] - Train Loss: 1.4953, Test Loss: 1.7443\n",
      "Epoch [6/50] - Train Loss: 1.4952, Test Loss: 1.7442\n",
      "Epoch [7/50] - Train Loss: 1.4951, Test Loss: 1.7441\n",
      "Epoch [8/50] - Train Loss: 1.4950, Test Loss: 1.7440\n",
      "Epoch [9/50] - Train Loss: 1.4949, Test Loss: 1.7439\n",
      "Epoch [10/50] - Train Loss: 1.4948, Test Loss: 1.7437\n",
      "Epoch [11/50] - Train Loss: 1.4948, Test Loss: 1.7436\n",
      "Epoch [12/50] - Train Loss: 1.4947, Test Loss: 1.7435\n",
      "Epoch [13/50] - Train Loss: 1.4946, Test Loss: 1.7434\n",
      "Epoch [14/50] - Train Loss: 1.4945, Test Loss: 1.7433\n",
      "Epoch [15/50] - Train Loss: 1.4944, Test Loss: 1.7432\n",
      "Epoch [16/50] - Train Loss: 1.4944, Test Loss: 1.7431\n",
      "Epoch [17/50] - Train Loss: 1.4943, Test Loss: 1.7430\n",
      "Epoch [18/50] - Train Loss: 1.4942, Test Loss: 1.7429\n",
      "Epoch [19/50] - Train Loss: 1.4941, Test Loss: 1.7428\n",
      "Epoch [20/50] - Train Loss: 1.4941, Test Loss: 1.7427\n",
      "Epoch [21/50] - Train Loss: 1.4940, Test Loss: 1.7426\n",
      "Epoch [22/50] - Train Loss: 1.4939, Test Loss: 1.7425\n",
      "Epoch [23/50] - Train Loss: 1.4938, Test Loss: 1.7424\n",
      "Epoch [24/50] - Train Loss: 1.4938, Test Loss: 1.7423\n",
      "Epoch [25/50] - Train Loss: 1.4937, Test Loss: 1.7422\n",
      "Epoch [26/50] - Train Loss: 1.4936, Test Loss: 1.7422\n",
      "Epoch [27/50] - Train Loss: 1.4936, Test Loss: 1.7421\n",
      "Epoch [28/50] - Train Loss: 1.4935, Test Loss: 1.7420\n",
      "Epoch [29/50] - Train Loss: 1.4934, Test Loss: 1.7419\n",
      "Epoch [30/50] - Train Loss: 1.4933, Test Loss: 1.7418\n",
      "Epoch [31/50] - Train Loss: 1.4933, Test Loss: 1.7417\n",
      "Epoch [32/50] - Train Loss: 1.4932, Test Loss: 1.7416\n",
      "Epoch [33/50] - Train Loss: 1.4931, Test Loss: 1.7415\n",
      "Epoch [34/50] - Train Loss: 1.4931, Test Loss: 1.7415\n",
      "Epoch [35/50] - Train Loss: 1.4930, Test Loss: 1.7414\n",
      "Epoch [36/50] - Train Loss: 1.4929, Test Loss: 1.7413\n",
      "Epoch [37/50] - Train Loss: 1.4929, Test Loss: 1.7412\n",
      "Epoch [38/50] - Train Loss: 1.4928, Test Loss: 1.7411\n",
      "Epoch [39/50] - Train Loss: 1.4928, Test Loss: 1.7410\n",
      "Epoch [40/50] - Train Loss: 1.4927, Test Loss: 1.7410\n",
      "Epoch [41/50] - Train Loss: 1.4926, Test Loss: 1.7409\n",
      "Epoch [42/50] - Train Loss: 1.4926, Test Loss: 1.7408\n",
      "Epoch [43/50] - Train Loss: 1.4925, Test Loss: 1.7407\n",
      "Epoch [44/50] - Train Loss: 1.4925, Test Loss: 1.7406\n",
      "Epoch [45/50] - Train Loss: 1.4924, Test Loss: 1.7406\n",
      "Epoch [46/50] - Train Loss: 1.4923, Test Loss: 1.7405\n",
      "Epoch [47/50] - Train Loss: 1.4923, Test Loss: 1.7404\n",
      "Epoch [48/50] - Train Loss: 1.4922, Test Loss: 1.7404\n",
      "Epoch [49/50] - Train Loss: 1.4922, Test Loss: 1.7403\n",
      "Epoch [50/50] - Train Loss: 1.4921, Test Loss: 1.7402\n",
      "Avg Test Loss: 1.7402\n",
      "Testing combination: (4, 4, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.2202, Test Loss: 1.0828\n",
      "Epoch [2/50] - Train Loss: 1.1299, Test Loss: 1.0912\n",
      "Epoch [3/50] - Train Loss: 1.1214, Test Loss: 1.0950\n",
      "Epoch [4/50] - Train Loss: 1.1185, Test Loss: 1.0895\n",
      "Epoch [5/50] - Train Loss: 1.1176, Test Loss: 1.0863\n",
      "Epoch [6/50] - Train Loss: 1.1181, Test Loss: 1.0856\n",
      "Epoch [7/50] - Train Loss: 1.1184, Test Loss: 1.0861\n",
      "Epoch [8/50] - Train Loss: 1.1184, Test Loss: 1.0867\n",
      "Epoch [9/50] - Train Loss: 1.1182, Test Loss: 1.0870\n",
      "Epoch [10/50] - Train Loss: 1.1181, Test Loss: 1.0870\n",
      "Epoch [11/50] - Train Loss: 1.1179, Test Loss: 1.0869\n",
      "Epoch [12/50] - Train Loss: 1.1178, Test Loss: 1.0869\n",
      "Epoch [13/50] - Train Loss: 1.1177, Test Loss: 1.0869\n",
      "Epoch [14/50] - Train Loss: 1.1175, Test Loss: 1.0869\n",
      "Epoch [15/50] - Train Loss: 1.1173, Test Loss: 1.0870\n",
      "Epoch [16/50] - Train Loss: 1.1170, Test Loss: 1.0871\n",
      "Epoch [17/50] - Train Loss: 1.1166, Test Loss: 1.0873\n",
      "Epoch [18/50] - Train Loss: 1.1157, Test Loss: 1.0875\n",
      "Epoch [19/50] - Train Loss: 1.1137, Test Loss: 1.0880\n",
      "Epoch [20/50] - Train Loss: 1.1086, Test Loss: 1.0902\n",
      "Epoch [21/50] - Train Loss: 1.1001, Test Loss: 1.0941\n",
      "Epoch [22/50] - Train Loss: 1.0912, Test Loss: 1.0998\n",
      "Epoch [23/50] - Train Loss: 1.0868, Test Loss: 1.1101\n",
      "Epoch [24/50] - Train Loss: 1.0908, Test Loss: 1.1163\n",
      "Epoch [25/50] - Train Loss: 1.0931, Test Loss: 1.1203\n",
      "Epoch [26/50] - Train Loss: 1.0917, Test Loss: 1.1217\n",
      "Epoch [27/50] - Train Loss: 1.0876, Test Loss: 1.1275\n",
      "Epoch [28/50] - Train Loss: 1.0830, Test Loss: 1.1238\n",
      "Epoch [29/50] - Train Loss: 1.0825, Test Loss: 1.1208\n",
      "Epoch [30/50] - Train Loss: 1.0832, Test Loss: 1.1184\n",
      "Epoch [31/50] - Train Loss: 1.0836, Test Loss: 1.1167\n",
      "Epoch [32/50] - Train Loss: 1.0833, Test Loss: 1.1157\n",
      "Epoch [33/50] - Train Loss: 1.0826, Test Loss: 1.1150\n",
      "Epoch [34/50] - Train Loss: 1.0825, Test Loss: 1.1147\n",
      "Epoch [35/50] - Train Loss: 1.0825, Test Loss: 1.1147\n",
      "Epoch [36/50] - Train Loss: 1.0824, Test Loss: 1.1151\n",
      "Epoch [37/50] - Train Loss: 1.0822, Test Loss: 1.1159\n",
      "Epoch [38/50] - Train Loss: 1.0819, Test Loss: 1.1173\n",
      "Epoch [39/50] - Train Loss: 1.0814, Test Loss: 1.1179\n",
      "Epoch [40/50] - Train Loss: 1.0803, Test Loss: 1.1178\n",
      "Epoch [41/50] - Train Loss: 1.0796, Test Loss: 1.1146\n",
      "Epoch [42/50] - Train Loss: 1.0777, Test Loss: 1.1101\n",
      "Epoch [43/50] - Train Loss: 1.0724, Test Loss: 1.1256\n",
      "Epoch [44/50] - Train Loss: 1.0698, Test Loss: 1.1094\n",
      "Epoch [45/50] - Train Loss: 1.1141, Test Loss: 1.1320\n",
      "Epoch [46/50] - Train Loss: 1.1235, Test Loss: 1.1366\n",
      "Epoch [47/50] - Train Loss: 1.1207, Test Loss: 1.1384\n",
      "Epoch [48/50] - Train Loss: 1.1194, Test Loss: 1.1022\n",
      "Epoch [49/50] - Train Loss: 1.1186, Test Loss: 1.0978\n",
      "Epoch [50/50] - Train Loss: 1.1188, Test Loss: 1.1104\n",
      "Avg Test Loss: 1.1104\n",
      "Testing combination: (4, 4, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.2064, Test Loss: 1.1214\n",
      "Epoch [2/50] - Train Loss: 1.1716, Test Loss: 1.1275\n",
      "Epoch [3/50] - Train Loss: 1.1576, Test Loss: 1.1395\n",
      "Epoch [4/50] - Train Loss: 1.1517, Test Loss: 1.1523\n",
      "Epoch [5/50] - Train Loss: 1.1504, Test Loss: 1.1615\n",
      "Epoch [6/50] - Train Loss: 1.1506, Test Loss: 1.1658\n",
      "Epoch [7/50] - Train Loss: 1.1509, Test Loss: 1.1666\n",
      "Epoch [8/50] - Train Loss: 1.1509, Test Loss: 1.1658\n",
      "Epoch [9/50] - Train Loss: 1.1507, Test Loss: 1.1646\n",
      "Epoch [10/50] - Train Loss: 1.1506, Test Loss: 1.1638\n",
      "Epoch [11/50] - Train Loss: 1.1505, Test Loss: 1.1632\n",
      "Epoch [12/50] - Train Loss: 1.1505, Test Loss: 1.1630\n",
      "Epoch [13/50] - Train Loss: 1.1504, Test Loss: 1.1630\n",
      "Epoch [14/50] - Train Loss: 1.1504, Test Loss: 1.1631\n",
      "Epoch [15/50] - Train Loss: 1.1504, Test Loss: 1.1632\n",
      "Epoch [16/50] - Train Loss: 1.1503, Test Loss: 1.1633\n",
      "Epoch [17/50] - Train Loss: 1.1503, Test Loss: 1.1634\n",
      "Epoch [18/50] - Train Loss: 1.1503, Test Loss: 1.1634\n",
      "Epoch [19/50] - Train Loss: 1.1503, Test Loss: 1.1635\n",
      "Epoch [20/50] - Train Loss: 1.1503, Test Loss: 1.1635\n",
      "Epoch [21/50] - Train Loss: 1.1503, Test Loss: 1.1635\n",
      "Epoch [22/50] - Train Loss: 1.1503, Test Loss: 1.1636\n",
      "Epoch [23/50] - Train Loss: 1.1502, Test Loss: 1.1636\n",
      "Epoch [24/50] - Train Loss: 1.1502, Test Loss: 1.1636\n",
      "Epoch [25/50] - Train Loss: 1.1502, Test Loss: 1.1636\n",
      "Epoch [26/50] - Train Loss: 1.1502, Test Loss: 1.1636\n",
      "Epoch [27/50] - Train Loss: 1.1502, Test Loss: 1.1637\n",
      "Epoch [28/50] - Train Loss: 1.1502, Test Loss: 1.1637\n",
      "Epoch [29/50] - Train Loss: 1.1502, Test Loss: 1.1637\n",
      "Epoch [30/50] - Train Loss: 1.1501, Test Loss: 1.1637\n",
      "Epoch [31/50] - Train Loss: 1.1501, Test Loss: 1.1637\n",
      "Epoch [32/50] - Train Loss: 1.1501, Test Loss: 1.1637\n",
      "Epoch [33/50] - Train Loss: 1.1501, Test Loss: 1.1638\n",
      "Epoch [34/50] - Train Loss: 1.1501, Test Loss: 1.1638\n",
      "Epoch [35/50] - Train Loss: 1.1501, Test Loss: 1.1638\n",
      "Epoch [36/50] - Train Loss: 1.1500, Test Loss: 1.1638\n",
      "Epoch [37/50] - Train Loss: 1.1499, Test Loss: 1.1637\n",
      "Epoch [38/50] - Train Loss: 1.1497, Test Loss: 1.1635\n",
      "Epoch [39/50] - Train Loss: 1.1492, Test Loss: 1.1633\n",
      "Epoch [40/50] - Train Loss: 1.1502, Test Loss: 1.1626\n",
      "Epoch [41/50] - Train Loss: 1.1501, Test Loss: 1.1629\n",
      "Epoch [42/50] - Train Loss: 1.1501, Test Loss: 1.1632\n",
      "Epoch [43/50] - Train Loss: 1.1501, Test Loss: 1.1635\n",
      "Epoch [44/50] - Train Loss: 1.1501, Test Loss: 1.1637\n",
      "Epoch [45/50] - Train Loss: 1.1501, Test Loss: 1.1639\n",
      "Epoch [46/50] - Train Loss: 1.1500, Test Loss: 1.1645\n",
      "Epoch [47/50] - Train Loss: 1.1489, Test Loss: 1.1646\n",
      "Epoch [48/50] - Train Loss: 1.1479, Test Loss: 1.1646\n",
      "Epoch [49/50] - Train Loss: 1.1509, Test Loss: 1.1706\n",
      "Epoch [50/50] - Train Loss: 1.1507, Test Loss: 1.1689\n",
      "Avg Test Loss: 1.1689\n",
      "Testing combination: (4, 4, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5080, Test Loss: 1.7508\n",
      "Epoch [2/50] - Train Loss: 1.4967, Test Loss: 1.7434\n",
      "Epoch [3/50] - Train Loss: 1.4907, Test Loss: 1.7376\n",
      "Epoch [4/50] - Train Loss: 1.4870, Test Loss: 1.7343\n",
      "Epoch [5/50] - Train Loss: 1.4852, Test Loss: 1.7331\n",
      "Epoch [6/50] - Train Loss: 1.4849, Test Loss: 1.7330\n",
      "Epoch [7/50] - Train Loss: 1.4853, Test Loss: 1.7334\n",
      "Epoch [8/50] - Train Loss: 1.4860, Test Loss: 1.7338\n",
      "Epoch [9/50] - Train Loss: 1.4865, Test Loss: 1.7339\n",
      "Epoch [10/50] - Train Loss: 1.4868, Test Loss: 1.7339\n",
      "Epoch [11/50] - Train Loss: 1.4869, Test Loss: 1.7337\n",
      "Epoch [12/50] - Train Loss: 1.4869, Test Loss: 1.7335\n",
      "Epoch [13/50] - Train Loss: 1.4868, Test Loss: 1.7333\n",
      "Epoch [14/50] - Train Loss: 1.4866, Test Loss: 1.7330\n",
      "Epoch [15/50] - Train Loss: 1.4864, Test Loss: 1.7328\n",
      "Epoch [16/50] - Train Loss: 1.4862, Test Loss: 1.7327\n",
      "Epoch [17/50] - Train Loss: 1.4860, Test Loss: 1.7327\n",
      "Epoch [18/50] - Train Loss: 1.4857, Test Loss: 1.7330\n",
      "Epoch [19/50] - Train Loss: 1.4854, Test Loss: 1.7334\n",
      "Epoch [20/50] - Train Loss: 1.4849, Test Loss: 1.7341\n",
      "Epoch [21/50] - Train Loss: 1.4842, Test Loss: 1.7351\n",
      "Epoch [22/50] - Train Loss: 1.4831, Test Loss: 1.7370\n",
      "Epoch [23/50] - Train Loss: 1.4812, Test Loss: 1.7406\n",
      "Epoch [24/50] - Train Loss: 1.4789, Test Loss: 1.7449\n",
      "Epoch [25/50] - Train Loss: 1.4765, Test Loss: 1.7496\n",
      "Epoch [26/50] - Train Loss: 1.4736, Test Loss: 1.7550\n",
      "Epoch [27/50] - Train Loss: 1.4653, Test Loss: 1.7712\n",
      "Epoch [28/50] - Train Loss: 1.4688, Test Loss: 1.7641\n",
      "Epoch [29/50] - Train Loss: 1.4527, Test Loss: 1.7679\n",
      "Epoch [30/50] - Train Loss: 1.4500, Test Loss: 1.7798\n",
      "Epoch [31/50] - Train Loss: 1.4471, Test Loss: 1.7991\n",
      "Epoch [32/50] - Train Loss: 1.4417, Test Loss: 1.8000\n",
      "Epoch [33/50] - Train Loss: 1.4364, Test Loss: 1.8100\n",
      "Epoch [34/50] - Train Loss: 1.4347, Test Loss: 1.8346\n",
      "Epoch [35/50] - Train Loss: 1.4322, Test Loss: 1.8470\n",
      "Epoch [36/50] - Train Loss: 1.4280, Test Loss: 1.8529\n",
      "Epoch [37/50] - Train Loss: 1.4261, Test Loss: 1.8717\n",
      "Epoch [38/50] - Train Loss: 1.4244, Test Loss: 1.8857\n",
      "Epoch [39/50] - Train Loss: 1.4220, Test Loss: 1.8930\n",
      "Epoch [40/50] - Train Loss: 1.4203, Test Loss: 1.9079\n",
      "Epoch [41/50] - Train Loss: 1.4186, Test Loss: 1.9201\n",
      "Epoch [42/50] - Train Loss: 1.4159, Test Loss: 1.9266\n",
      "Epoch [43/50] - Train Loss: 1.4130, Test Loss: 1.9389\n",
      "Epoch [44/50] - Train Loss: 1.4090, Test Loss: 1.9399\n",
      "Epoch [45/50] - Train Loss: 1.4053, Test Loss: 1.9430\n",
      "Epoch [46/50] - Train Loss: 1.4017, Test Loss: 1.9412\n",
      "Epoch [47/50] - Train Loss: 1.4488, Test Loss: 1.7158\n",
      "Epoch [48/50] - Train Loss: 1.4988, Test Loss: 1.7484\n",
      "Epoch [49/50] - Train Loss: 1.4961, Test Loss: 1.7418\n",
      "Epoch [50/50] - Train Loss: 1.4927, Test Loss: 1.7370\n",
      "Avg Test Loss: 1.7370\n",
      "Testing combination: (4, 4, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1881, Test Loss: 1.2031\n",
      "Epoch [2/50] - Train Loss: 1.1749, Test Loss: 1.1862\n",
      "Epoch [3/50] - Train Loss: 1.1643, Test Loss: 1.1714\n",
      "Epoch [4/50] - Train Loss: 1.1552, Test Loss: 1.1586\n",
      "Epoch [5/50] - Train Loss: 1.1476, Test Loss: 1.1475\n",
      "Epoch [6/50] - Train Loss: 1.1413, Test Loss: 1.1380\n",
      "Epoch [7/50] - Train Loss: 1.1361, Test Loss: 1.1299\n",
      "Epoch [8/50] - Train Loss: 1.1318, Test Loss: 1.1229\n",
      "Epoch [9/50] - Train Loss: 1.1283, Test Loss: 1.1170\n",
      "Epoch [10/50] - Train Loss: 1.1255, Test Loss: 1.1120\n",
      "Epoch [11/50] - Train Loss: 1.1233, Test Loss: 1.1078\n",
      "Epoch [12/50] - Train Loss: 1.1216, Test Loss: 1.1043\n",
      "Epoch [13/50] - Train Loss: 1.1202, Test Loss: 1.1014\n",
      "Epoch [14/50] - Train Loss: 1.1192, Test Loss: 1.0990\n",
      "Epoch [15/50] - Train Loss: 1.1184, Test Loss: 1.0970\n",
      "Epoch [16/50] - Train Loss: 1.1179, Test Loss: 1.0953\n",
      "Epoch [17/50] - Train Loss: 1.1174, Test Loss: 1.0940\n",
      "Epoch [18/50] - Train Loss: 1.1171, Test Loss: 1.0928\n",
      "Epoch [19/50] - Train Loss: 1.1169, Test Loss: 1.0919\n",
      "Epoch [20/50] - Train Loss: 1.1167, Test Loss: 1.0911\n",
      "Epoch [21/50] - Train Loss: 1.1166, Test Loss: 1.0905\n",
      "Epoch [22/50] - Train Loss: 1.1165, Test Loss: 1.0899\n",
      "Epoch [23/50] - Train Loss: 1.1164, Test Loss: 1.0895\n",
      "Epoch [24/50] - Train Loss: 1.1164, Test Loss: 1.0891\n",
      "Epoch [25/50] - Train Loss: 1.1164, Test Loss: 1.0888\n",
      "Epoch [26/50] - Train Loss: 1.1163, Test Loss: 1.0885\n",
      "Epoch [27/50] - Train Loss: 1.1163, Test Loss: 1.0883\n",
      "Epoch [28/50] - Train Loss: 1.1163, Test Loss: 1.0881\n",
      "Epoch [29/50] - Train Loss: 1.1163, Test Loss: 1.0880\n",
      "Epoch [30/50] - Train Loss: 1.1163, Test Loss: 1.0878\n",
      "Epoch [31/50] - Train Loss: 1.1163, Test Loss: 1.0877\n",
      "Epoch [32/50] - Train Loss: 1.1163, Test Loss: 1.0876\n",
      "Epoch [33/50] - Train Loss: 1.1163, Test Loss: 1.0875\n",
      "Epoch [34/50] - Train Loss: 1.1163, Test Loss: 1.0875\n",
      "Epoch [35/50] - Train Loss: 1.1163, Test Loss: 1.0874\n",
      "Epoch [36/50] - Train Loss: 1.1163, Test Loss: 1.0874\n",
      "Epoch [37/50] - Train Loss: 1.1163, Test Loss: 1.0873\n",
      "Epoch [38/50] - Train Loss: 1.1163, Test Loss: 1.0873\n",
      "Epoch [39/50] - Train Loss: 1.1163, Test Loss: 1.0872\n",
      "Epoch [40/50] - Train Loss: 1.1163, Test Loss: 1.0872\n",
      "Epoch [41/50] - Train Loss: 1.1163, Test Loss: 1.0872\n",
      "Epoch [42/50] - Train Loss: 1.1163, Test Loss: 1.0872\n",
      "Epoch [43/50] - Train Loss: 1.1163, Test Loss: 1.0871\n",
      "Epoch [44/50] - Train Loss: 1.1163, Test Loss: 1.0871\n",
      "Epoch [45/50] - Train Loss: 1.1163, Test Loss: 1.0871\n",
      "Epoch [46/50] - Train Loss: 1.1163, Test Loss: 1.0871\n",
      "Epoch [47/50] - Train Loss: 1.1163, Test Loss: 1.0871\n",
      "Epoch [48/50] - Train Loss: 1.1163, Test Loss: 1.0871\n",
      "Epoch [49/50] - Train Loss: 1.1163, Test Loss: 1.0871\n",
      "Epoch [50/50] - Train Loss: 1.1163, Test Loss: 1.0871\n",
      "Avg Test Loss: 1.0871\n",
      "Testing combination: (4, 4, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.2527, Test Loss: 1.4175\n",
      "Epoch [2/50] - Train Loss: 1.2413, Test Loss: 1.3998\n",
      "Epoch [3/50] - Train Loss: 1.2323, Test Loss: 1.3833\n",
      "Epoch [4/50] - Train Loss: 1.2242, Test Loss: 1.3677\n",
      "Epoch [5/50] - Train Loss: 1.2166, Test Loss: 1.3528\n",
      "Epoch [6/50] - Train Loss: 1.2095, Test Loss: 1.3386\n",
      "Epoch [7/50] - Train Loss: 1.2029, Test Loss: 1.3251\n",
      "Epoch [8/50] - Train Loss: 1.1969, Test Loss: 1.3124\n",
      "Epoch [9/50] - Train Loss: 1.1914, Test Loss: 1.3005\n",
      "Epoch [10/50] - Train Loss: 1.1863, Test Loss: 1.2893\n",
      "Epoch [11/50] - Train Loss: 1.1818, Test Loss: 1.2790\n",
      "Epoch [12/50] - Train Loss: 1.1777, Test Loss: 1.2694\n",
      "Epoch [13/50] - Train Loss: 1.1741, Test Loss: 1.2605\n",
      "Epoch [14/50] - Train Loss: 1.1708, Test Loss: 1.2524\n",
      "Epoch [15/50] - Train Loss: 1.1679, Test Loss: 1.2449\n",
      "Epoch [16/50] - Train Loss: 1.1654, Test Loss: 1.2380\n",
      "Epoch [17/50] - Train Loss: 1.1632, Test Loss: 1.2316\n",
      "Epoch [18/50] - Train Loss: 1.1612, Test Loss: 1.2258\n",
      "Epoch [19/50] - Train Loss: 1.1595, Test Loss: 1.2205\n",
      "Epoch [20/50] - Train Loss: 1.1580, Test Loss: 1.2156\n",
      "Epoch [21/50] - Train Loss: 1.1567, Test Loss: 1.2112\n",
      "Epoch [22/50] - Train Loss: 1.1556, Test Loss: 1.2071\n",
      "Epoch [23/50] - Train Loss: 1.1546, Test Loss: 1.2034\n",
      "Epoch [24/50] - Train Loss: 1.1537, Test Loss: 1.2000\n",
      "Epoch [25/50] - Train Loss: 1.1530, Test Loss: 1.1969\n",
      "Epoch [26/50] - Train Loss: 1.1524, Test Loss: 1.1941\n",
      "Epoch [27/50] - Train Loss: 1.1518, Test Loss: 1.1915\n",
      "Epoch [28/50] - Train Loss: 1.1514, Test Loss: 1.1892\n",
      "Epoch [29/50] - Train Loss: 1.1510, Test Loss: 1.1870\n",
      "Epoch [30/50] - Train Loss: 1.1506, Test Loss: 1.1851\n",
      "Epoch [31/50] - Train Loss: 1.1503, Test Loss: 1.1833\n",
      "Epoch [32/50] - Train Loss: 1.1501, Test Loss: 1.1817\n",
      "Epoch [33/50] - Train Loss: 1.1499, Test Loss: 1.1802\n",
      "Epoch [34/50] - Train Loss: 1.1497, Test Loss: 1.1789\n",
      "Epoch [35/50] - Train Loss: 1.1495, Test Loss: 1.1777\n",
      "Epoch [36/50] - Train Loss: 1.1494, Test Loss: 1.1766\n",
      "Epoch [37/50] - Train Loss: 1.1493, Test Loss: 1.1755\n",
      "Epoch [38/50] - Train Loss: 1.1492, Test Loss: 1.1746\n",
      "Epoch [39/50] - Train Loss: 1.1491, Test Loss: 1.1738\n",
      "Epoch [40/50] - Train Loss: 1.1490, Test Loss: 1.1730\n",
      "Epoch [41/50] - Train Loss: 1.1490, Test Loss: 1.1723\n",
      "Epoch [42/50] - Train Loss: 1.1489, Test Loss: 1.1717\n",
      "Epoch [43/50] - Train Loss: 1.1489, Test Loss: 1.1711\n",
      "Epoch [44/50] - Train Loss: 1.1488, Test Loss: 1.1706\n",
      "Epoch [45/50] - Train Loss: 1.1488, Test Loss: 1.1701\n",
      "Epoch [46/50] - Train Loss: 1.1487, Test Loss: 1.1697\n",
      "Epoch [47/50] - Train Loss: 1.1487, Test Loss: 1.1693\n",
      "Epoch [48/50] - Train Loss: 1.1487, Test Loss: 1.1689\n",
      "Epoch [49/50] - Train Loss: 1.1487, Test Loss: 1.1686\n",
      "Epoch [50/50] - Train Loss: 1.1486, Test Loss: 1.1683\n",
      "Avg Test Loss: 1.1683\n",
      "Testing combination: (4, 4, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5260, Test Loss: 1.7960\n",
      "Epoch [2/50] - Train Loss: 1.5228, Test Loss: 1.7924\n",
      "Epoch [3/50] - Train Loss: 1.5205, Test Loss: 1.7891\n",
      "Epoch [4/50] - Train Loss: 1.5185, Test Loss: 1.7861\n",
      "Epoch [5/50] - Train Loss: 1.5166, Test Loss: 1.7833\n",
      "Epoch [6/50] - Train Loss: 1.5149, Test Loss: 1.7806\n",
      "Epoch [7/50] - Train Loss: 1.5132, Test Loss: 1.7780\n",
      "Epoch [8/50] - Train Loss: 1.5116, Test Loss: 1.7756\n",
      "Epoch [9/50] - Train Loss: 1.5102, Test Loss: 1.7733\n",
      "Epoch [10/50] - Train Loss: 1.5087, Test Loss: 1.7711\n",
      "Epoch [11/50] - Train Loss: 1.5074, Test Loss: 1.7690\n",
      "Epoch [12/50] - Train Loss: 1.5061, Test Loss: 1.7670\n",
      "Epoch [13/50] - Train Loss: 1.5049, Test Loss: 1.7651\n",
      "Epoch [14/50] - Train Loss: 1.5037, Test Loss: 1.7633\n",
      "Epoch [15/50] - Train Loss: 1.5026, Test Loss: 1.7616\n",
      "Epoch [16/50] - Train Loss: 1.5016, Test Loss: 1.7599\n",
      "Epoch [17/50] - Train Loss: 1.5006, Test Loss: 1.7584\n",
      "Epoch [18/50] - Train Loss: 1.4996, Test Loss: 1.7569\n",
      "Epoch [19/50] - Train Loss: 1.4987, Test Loss: 1.7555\n",
      "Epoch [20/50] - Train Loss: 1.4979, Test Loss: 1.7542\n",
      "Epoch [21/50] - Train Loss: 1.4971, Test Loss: 1.7529\n",
      "Epoch [22/50] - Train Loss: 1.4963, Test Loss: 1.7517\n",
      "Epoch [23/50] - Train Loss: 1.4956, Test Loss: 1.7506\n",
      "Epoch [24/50] - Train Loss: 1.4949, Test Loss: 1.7495\n",
      "Epoch [25/50] - Train Loss: 1.4943, Test Loss: 1.7485\n",
      "Epoch [26/50] - Train Loss: 1.4937, Test Loss: 1.7475\n",
      "Epoch [27/50] - Train Loss: 1.4931, Test Loss: 1.7466\n",
      "Epoch [28/50] - Train Loss: 1.4926, Test Loss: 1.7458\n",
      "Epoch [29/50] - Train Loss: 1.4921, Test Loss: 1.7450\n",
      "Epoch [30/50] - Train Loss: 1.4916, Test Loss: 1.7443\n",
      "Epoch [31/50] - Train Loss: 1.4911, Test Loss: 1.7435\n",
      "Epoch [32/50] - Train Loss: 1.4907, Test Loss: 1.7429\n",
      "Epoch [33/50] - Train Loss: 1.4903, Test Loss: 1.7423\n",
      "Epoch [34/50] - Train Loss: 1.4900, Test Loss: 1.7417\n",
      "Epoch [35/50] - Train Loss: 1.4896, Test Loss: 1.7411\n",
      "Epoch [36/50] - Train Loss: 1.4893, Test Loss: 1.7406\n",
      "Epoch [37/50] - Train Loss: 1.4890, Test Loss: 1.7401\n",
      "Epoch [38/50] - Train Loss: 1.4887, Test Loss: 1.7397\n",
      "Epoch [39/50] - Train Loss: 1.4885, Test Loss: 1.7393\n",
      "Epoch [40/50] - Train Loss: 1.4882, Test Loss: 1.7389\n",
      "Epoch [41/50] - Train Loss: 1.4880, Test Loss: 1.7385\n",
      "Epoch [42/50] - Train Loss: 1.4878, Test Loss: 1.7382\n",
      "Epoch [43/50] - Train Loss: 1.4876, Test Loss: 1.7379\n",
      "Epoch [44/50] - Train Loss: 1.4874, Test Loss: 1.7376\n",
      "Epoch [45/50] - Train Loss: 1.4873, Test Loss: 1.7373\n",
      "Epoch [46/50] - Train Loss: 1.4871, Test Loss: 1.7371\n",
      "Epoch [47/50] - Train Loss: 1.4869, Test Loss: 1.7369\n",
      "Epoch [48/50] - Train Loss: 1.4868, Test Loss: 1.7366\n",
      "Epoch [49/50] - Train Loss: 1.4867, Test Loss: 1.7364\n",
      "Epoch [50/50] - Train Loss: 1.4866, Test Loss: 1.7363\n",
      "Avg Test Loss: 1.7363\n",
      "Testing combination: (4, 4, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.2386, Test Loss: 1.1645\n",
      "Epoch [2/50] - Train Loss: 1.2369, Test Loss: 1.1632\n",
      "Epoch [3/50] - Train Loss: 1.2355, Test Loss: 1.1619\n",
      "Epoch [4/50] - Train Loss: 1.2340, Test Loss: 1.1607\n",
      "Epoch [5/50] - Train Loss: 1.2326, Test Loss: 1.1594\n",
      "Epoch [6/50] - Train Loss: 1.2313, Test Loss: 1.1583\n",
      "Epoch [7/50] - Train Loss: 1.2299, Test Loss: 1.1571\n",
      "Epoch [8/50] - Train Loss: 1.2286, Test Loss: 1.1559\n",
      "Epoch [9/50] - Train Loss: 1.2273, Test Loss: 1.1548\n",
      "Epoch [10/50] - Train Loss: 1.2260, Test Loss: 1.1537\n",
      "Epoch [11/50] - Train Loss: 1.2247, Test Loss: 1.1526\n",
      "Epoch [12/50] - Train Loss: 1.2234, Test Loss: 1.1515\n",
      "Epoch [13/50] - Train Loss: 1.2222, Test Loss: 1.1504\n",
      "Epoch [14/50] - Train Loss: 1.2209, Test Loss: 1.1493\n",
      "Epoch [15/50] - Train Loss: 1.2197, Test Loss: 1.1483\n",
      "Epoch [16/50] - Train Loss: 1.2185, Test Loss: 1.1472\n",
      "Epoch [17/50] - Train Loss: 1.2173, Test Loss: 1.1462\n",
      "Epoch [18/50] - Train Loss: 1.2161, Test Loss: 1.1452\n",
      "Epoch [19/50] - Train Loss: 1.2149, Test Loss: 1.1442\n",
      "Epoch [20/50] - Train Loss: 1.2137, Test Loss: 1.1432\n",
      "Epoch [21/50] - Train Loss: 1.2125, Test Loss: 1.1422\n",
      "Epoch [22/50] - Train Loss: 1.2114, Test Loss: 1.1412\n",
      "Epoch [23/50] - Train Loss: 1.2102, Test Loss: 1.1402\n",
      "Epoch [24/50] - Train Loss: 1.2091, Test Loss: 1.1393\n",
      "Epoch [25/50] - Train Loss: 1.2079, Test Loss: 1.1383\n",
      "Epoch [26/50] - Train Loss: 1.2068, Test Loss: 1.1373\n",
      "Epoch [27/50] - Train Loss: 1.2057, Test Loss: 1.1364\n",
      "Epoch [28/50] - Train Loss: 1.2045, Test Loss: 1.1355\n",
      "Epoch [29/50] - Train Loss: 1.2034, Test Loss: 1.1345\n",
      "Epoch [30/50] - Train Loss: 1.2023, Test Loss: 1.1336\n",
      "Epoch [31/50] - Train Loss: 1.2012, Test Loss: 1.1327\n",
      "Epoch [32/50] - Train Loss: 1.2001, Test Loss: 1.1318\n",
      "Epoch [33/50] - Train Loss: 1.1990, Test Loss: 1.1309\n",
      "Epoch [34/50] - Train Loss: 1.1979, Test Loss: 1.1300\n",
      "Epoch [35/50] - Train Loss: 1.1969, Test Loss: 1.1291\n",
      "Epoch [36/50] - Train Loss: 1.1958, Test Loss: 1.1282\n",
      "Epoch [37/50] - Train Loss: 1.1947, Test Loss: 1.1273\n",
      "Epoch [38/50] - Train Loss: 1.1936, Test Loss: 1.1265\n",
      "Epoch [39/50] - Train Loss: 1.1926, Test Loss: 1.1256\n",
      "Epoch [40/50] - Train Loss: 1.1915, Test Loss: 1.1248\n",
      "Epoch [41/50] - Train Loss: 1.1905, Test Loss: 1.1239\n",
      "Epoch [42/50] - Train Loss: 1.1895, Test Loss: 1.1231\n",
      "Epoch [43/50] - Train Loss: 1.1884, Test Loss: 1.1222\n",
      "Epoch [44/50] - Train Loss: 1.1874, Test Loss: 1.1214\n",
      "Epoch [45/50] - Train Loss: 1.1864, Test Loss: 1.1206\n",
      "Epoch [46/50] - Train Loss: 1.1853, Test Loss: 1.1198\n",
      "Epoch [47/50] - Train Loss: 1.1843, Test Loss: 1.1190\n",
      "Epoch [48/50] - Train Loss: 1.1833, Test Loss: 1.1182\n",
      "Epoch [49/50] - Train Loss: 1.1823, Test Loss: 1.1174\n",
      "Epoch [50/50] - Train Loss: 1.1813, Test Loss: 1.1166\n",
      "Avg Test Loss: 1.1166\n",
      "Testing combination: (4, 4, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.2762, Test Loss: 1.4749\n",
      "Epoch [2/50] - Train Loss: 1.2749, Test Loss: 1.4729\n",
      "Epoch [3/50] - Train Loss: 1.2738, Test Loss: 1.4710\n",
      "Epoch [4/50] - Train Loss: 1.2727, Test Loss: 1.4691\n",
      "Epoch [5/50] - Train Loss: 1.2717, Test Loss: 1.4672\n",
      "Epoch [6/50] - Train Loss: 1.2706, Test Loss: 1.4654\n",
      "Epoch [7/50] - Train Loss: 1.2696, Test Loss: 1.4635\n",
      "Epoch [8/50] - Train Loss: 1.2686, Test Loss: 1.4617\n",
      "Epoch [9/50] - Train Loss: 1.2676, Test Loss: 1.4599\n",
      "Epoch [10/50] - Train Loss: 1.2666, Test Loss: 1.4581\n",
      "Epoch [11/50] - Train Loss: 1.2656, Test Loss: 1.4563\n",
      "Epoch [12/50] - Train Loss: 1.2646, Test Loss: 1.4545\n",
      "Epoch [13/50] - Train Loss: 1.2636, Test Loss: 1.4527\n",
      "Epoch [14/50] - Train Loss: 1.2627, Test Loss: 1.4509\n",
      "Epoch [15/50] - Train Loss: 1.2617, Test Loss: 1.4491\n",
      "Epoch [16/50] - Train Loss: 1.2607, Test Loss: 1.4473\n",
      "Epoch [17/50] - Train Loss: 1.2598, Test Loss: 1.4456\n",
      "Epoch [18/50] - Train Loss: 1.2588, Test Loss: 1.4438\n",
      "Epoch [19/50] - Train Loss: 1.2579, Test Loss: 1.4420\n",
      "Epoch [20/50] - Train Loss: 1.2569, Test Loss: 1.4403\n",
      "Epoch [21/50] - Train Loss: 1.2560, Test Loss: 1.4385\n",
      "Epoch [22/50] - Train Loss: 1.2550, Test Loss: 1.4368\n",
      "Epoch [23/50] - Train Loss: 1.2541, Test Loss: 1.4351\n",
      "Epoch [24/50] - Train Loss: 1.2532, Test Loss: 1.4334\n",
      "Epoch [25/50] - Train Loss: 1.2523, Test Loss: 1.4316\n",
      "Epoch [26/50] - Train Loss: 1.2513, Test Loss: 1.4299\n",
      "Epoch [27/50] - Train Loss: 1.2504, Test Loss: 1.4282\n",
      "Epoch [28/50] - Train Loss: 1.2495, Test Loss: 1.4265\n",
      "Epoch [29/50] - Train Loss: 1.2486, Test Loss: 1.4248\n",
      "Epoch [30/50] - Train Loss: 1.2477, Test Loss: 1.4231\n",
      "Epoch [31/50] - Train Loss: 1.2468, Test Loss: 1.4214\n",
      "Epoch [32/50] - Train Loss: 1.2459, Test Loss: 1.4197\n",
      "Epoch [33/50] - Train Loss: 1.2450, Test Loss: 1.4181\n",
      "Epoch [34/50] - Train Loss: 1.2442, Test Loss: 1.4164\n",
      "Epoch [35/50] - Train Loss: 1.2433, Test Loss: 1.4147\n",
      "Epoch [36/50] - Train Loss: 1.2424, Test Loss: 1.4131\n",
      "Epoch [37/50] - Train Loss: 1.2415, Test Loss: 1.4114\n",
      "Epoch [38/50] - Train Loss: 1.2407, Test Loss: 1.4097\n",
      "Epoch [39/50] - Train Loss: 1.2398, Test Loss: 1.4081\n",
      "Epoch [40/50] - Train Loss: 1.2389, Test Loss: 1.4065\n",
      "Epoch [41/50] - Train Loss: 1.2381, Test Loss: 1.4048\n",
      "Epoch [42/50] - Train Loss: 1.2372, Test Loss: 1.4032\n",
      "Epoch [43/50] - Train Loss: 1.2364, Test Loss: 1.4015\n",
      "Epoch [44/50] - Train Loss: 1.2355, Test Loss: 1.3999\n",
      "Epoch [45/50] - Train Loss: 1.2347, Test Loss: 1.3983\n",
      "Epoch [46/50] - Train Loss: 1.2339, Test Loss: 1.3967\n",
      "Epoch [47/50] - Train Loss: 1.2330, Test Loss: 1.3950\n",
      "Epoch [48/50] - Train Loss: 1.2322, Test Loss: 1.3934\n",
      "Epoch [49/50] - Train Loss: 1.2314, Test Loss: 1.3918\n",
      "Epoch [50/50] - Train Loss: 1.2306, Test Loss: 1.3902\n",
      "Avg Test Loss: 1.3902\n",
      "Testing combination: (4, 4, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 2.0501, Test Loss: 2.5514\n",
      "Epoch [2/50] - Train Loss: 2.0475, Test Loss: 2.5475\n",
      "Epoch [3/50] - Train Loss: 2.0448, Test Loss: 2.5437\n",
      "Epoch [4/50] - Train Loss: 2.0422, Test Loss: 2.5398\n",
      "Epoch [5/50] - Train Loss: 2.0396, Test Loss: 2.5359\n",
      "Epoch [6/50] - Train Loss: 2.0370, Test Loss: 2.5321\n",
      "Epoch [7/50] - Train Loss: 2.0344, Test Loss: 2.5283\n",
      "Epoch [8/50] - Train Loss: 2.0318, Test Loss: 2.5245\n",
      "Epoch [9/50] - Train Loss: 2.0292, Test Loss: 2.5207\n",
      "Epoch [10/50] - Train Loss: 2.0267, Test Loss: 2.5169\n",
      "Epoch [11/50] - Train Loss: 2.0241, Test Loss: 2.5132\n",
      "Epoch [12/50] - Train Loss: 2.0216, Test Loss: 2.5094\n",
      "Epoch [13/50] - Train Loss: 2.0190, Test Loss: 2.5057\n",
      "Epoch [14/50] - Train Loss: 2.0165, Test Loss: 2.5020\n",
      "Epoch [15/50] - Train Loss: 2.0140, Test Loss: 2.4983\n",
      "Epoch [16/50] - Train Loss: 2.0115, Test Loss: 2.4947\n",
      "Epoch [17/50] - Train Loss: 2.0091, Test Loss: 2.4910\n",
      "Epoch [18/50] - Train Loss: 2.0066, Test Loss: 2.4874\n",
      "Epoch [19/50] - Train Loss: 2.0041, Test Loss: 2.4838\n",
      "Epoch [20/50] - Train Loss: 2.0017, Test Loss: 2.4802\n",
      "Epoch [21/50] - Train Loss: 1.9992, Test Loss: 2.4766\n",
      "Epoch [22/50] - Train Loss: 1.9968, Test Loss: 2.4730\n",
      "Epoch [23/50] - Train Loss: 1.9944, Test Loss: 2.4694\n",
      "Epoch [24/50] - Train Loss: 1.9920, Test Loss: 2.4659\n",
      "Epoch [25/50] - Train Loss: 1.9895, Test Loss: 2.4623\n",
      "Epoch [26/50] - Train Loss: 1.9871, Test Loss: 2.4588\n",
      "Epoch [27/50] - Train Loss: 1.9848, Test Loss: 2.4553\n",
      "Epoch [28/50] - Train Loss: 1.9824, Test Loss: 2.4518\n",
      "Epoch [29/50] - Train Loss: 1.9800, Test Loss: 2.4483\n",
      "Epoch [30/50] - Train Loss: 1.9776, Test Loss: 2.4448\n",
      "Epoch [31/50] - Train Loss: 1.9753, Test Loss: 2.4413\n",
      "Epoch [32/50] - Train Loss: 1.9729, Test Loss: 2.4378\n",
      "Epoch [33/50] - Train Loss: 1.9706, Test Loss: 2.4344\n",
      "Epoch [34/50] - Train Loss: 1.9682, Test Loss: 2.4310\n",
      "Epoch [35/50] - Train Loss: 1.9659, Test Loss: 2.4275\n",
      "Epoch [36/50] - Train Loss: 1.9636, Test Loss: 2.4241\n",
      "Epoch [37/50] - Train Loss: 1.9613, Test Loss: 2.4207\n",
      "Epoch [38/50] - Train Loss: 1.9589, Test Loss: 2.4173\n",
      "Epoch [39/50] - Train Loss: 1.9566, Test Loss: 2.4139\n",
      "Epoch [40/50] - Train Loss: 1.9543, Test Loss: 2.4105\n",
      "Epoch [41/50] - Train Loss: 1.9520, Test Loss: 2.4071\n",
      "Epoch [42/50] - Train Loss: 1.9497, Test Loss: 2.4038\n",
      "Epoch [43/50] - Train Loss: 1.9475, Test Loss: 2.4004\n",
      "Epoch [44/50] - Train Loss: 1.9452, Test Loss: 2.3971\n",
      "Epoch [45/50] - Train Loss: 1.9429, Test Loss: 2.3937\n",
      "Epoch [46/50] - Train Loss: 1.9407, Test Loss: 2.3904\n",
      "Epoch [47/50] - Train Loss: 1.9384, Test Loss: 2.3871\n",
      "Epoch [48/50] - Train Loss: 1.9361, Test Loss: 2.3837\n",
      "Epoch [49/50] - Train Loss: 1.9339, Test Loss: 2.3804\n",
      "Epoch [50/50] - Train Loss: 1.9316, Test Loss: 2.3771\n",
      "Avg Test Loss: 2.3771\n",
      "Testing combination: (8, 1, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1467, Test Loss: 1.0942\n",
      "Epoch [2/50] - Train Loss: 1.1166, Test Loss: 1.0822\n",
      "Epoch [3/50] - Train Loss: 1.1196, Test Loss: 1.0841\n",
      "Epoch [4/50] - Train Loss: 1.1195, Test Loss: 1.0865\n",
      "Epoch [5/50] - Train Loss: 1.1187, Test Loss: 1.0882\n",
      "Epoch [6/50] - Train Loss: 1.1183, Test Loss: 1.0886\n",
      "Epoch [7/50] - Train Loss: 1.1181, Test Loss: 1.0882\n",
      "Epoch [8/50] - Train Loss: 1.1180, Test Loss: 1.0875\n",
      "Epoch [9/50] - Train Loss: 1.1181, Test Loss: 1.0867\n",
      "Epoch [10/50] - Train Loss: 1.1181, Test Loss: 1.0863\n",
      "Epoch [11/50] - Train Loss: 1.1181, Test Loss: 1.0862\n",
      "Epoch [12/50] - Train Loss: 1.1181, Test Loss: 1.0862\n",
      "Epoch [13/50] - Train Loss: 1.1180, Test Loss: 1.0862\n",
      "Epoch [14/50] - Train Loss: 1.1180, Test Loss: 1.0862\n",
      "Epoch [15/50] - Train Loss: 1.1180, Test Loss: 1.0861\n",
      "Epoch [16/50] - Train Loss: 1.1180, Test Loss: 1.0861\n",
      "Epoch [17/50] - Train Loss: 1.1180, Test Loss: 1.0862\n",
      "Epoch [18/50] - Train Loss: 1.1180, Test Loss: 1.0862\n",
      "Epoch [19/50] - Train Loss: 1.1179, Test Loss: 1.0863\n",
      "Epoch [20/50] - Train Loss: 1.1179, Test Loss: 1.0865\n",
      "Epoch [21/50] - Train Loss: 1.1179, Test Loss: 1.0867\n",
      "Epoch [22/50] - Train Loss: 1.1179, Test Loss: 1.0870\n",
      "Epoch [23/50] - Train Loss: 1.1179, Test Loss: 1.0873\n",
      "Epoch [24/50] - Train Loss: 1.1178, Test Loss: 1.0876\n",
      "Epoch [25/50] - Train Loss: 1.1178, Test Loss: 1.0879\n",
      "Epoch [26/50] - Train Loss: 1.1178, Test Loss: 1.0883\n",
      "Epoch [27/50] - Train Loss: 1.1178, Test Loss: 1.0887\n",
      "Epoch [28/50] - Train Loss: 1.1178, Test Loss: 1.0891\n",
      "Epoch [29/50] - Train Loss: 1.1178, Test Loss: 1.0895\n",
      "Epoch [30/50] - Train Loss: 1.1177, Test Loss: 1.0898\n",
      "Epoch [31/50] - Train Loss: 1.1177, Test Loss: 1.0901\n",
      "Epoch [32/50] - Train Loss: 1.1177, Test Loss: 1.0905\n",
      "Epoch [33/50] - Train Loss: 1.1177, Test Loss: 1.0908\n",
      "Epoch [34/50] - Train Loss: 1.1177, Test Loss: 1.0913\n",
      "Epoch [35/50] - Train Loss: 1.1176, Test Loss: 1.0919\n",
      "Epoch [36/50] - Train Loss: 1.1176, Test Loss: 1.0930\n",
      "Epoch [37/50] - Train Loss: 1.1174, Test Loss: 1.0949\n",
      "Epoch [38/50] - Train Loss: 1.1159, Test Loss: 1.0975\n",
      "Epoch [39/50] - Train Loss: 1.1127, Test Loss: 1.1010\n",
      "Epoch [40/50] - Train Loss: 1.1023, Test Loss: 1.1085\n",
      "Epoch [41/50] - Train Loss: 1.0902, Test Loss: 1.1157\n",
      "Epoch [42/50] - Train Loss: 1.2155, Test Loss: 1.1044\n",
      "Epoch [43/50] - Train Loss: 1.1076, Test Loss: 1.1009\n",
      "Epoch [44/50] - Train Loss: 1.1047, Test Loss: 1.1037\n",
      "Epoch [45/50] - Train Loss: 1.0998, Test Loss: 1.1086\n",
      "Epoch [46/50] - Train Loss: 1.0949, Test Loss: 1.1144\n",
      "Epoch [47/50] - Train Loss: 1.0904, Test Loss: 1.1206\n",
      "Epoch [48/50] - Train Loss: 1.0861, Test Loss: 1.1267\n",
      "Epoch [49/50] - Train Loss: 1.0810, Test Loss: 1.1324\n",
      "Epoch [50/50] - Train Loss: 1.0753, Test Loss: 1.1372\n",
      "Avg Test Loss: 1.1372\n",
      "Testing combination: (8, 1, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.2498, Test Loss: 1.1320\n",
      "Epoch [2/50] - Train Loss: 1.1561, Test Loss: 1.1704\n",
      "Epoch [3/50] - Train Loss: 1.1436, Test Loss: 1.2067\n",
      "Epoch [4/50] - Train Loss: 1.1429, Test Loss: 1.2020\n",
      "Epoch [5/50] - Train Loss: 1.1306, Test Loss: 1.1868\n",
      "Epoch [6/50] - Train Loss: 1.1159, Test Loss: 1.1818\n",
      "Epoch [7/50] - Train Loss: 1.1090, Test Loss: 1.1826\n",
      "Epoch [8/50] - Train Loss: 1.0996, Test Loss: 1.1868\n",
      "Epoch [9/50] - Train Loss: 1.0897, Test Loss: 1.1945\n",
      "Epoch [10/50] - Train Loss: 1.0796, Test Loss: 1.2016\n",
      "Epoch [11/50] - Train Loss: 1.0689, Test Loss: 1.2078\n",
      "Epoch [12/50] - Train Loss: 1.0598, Test Loss: 1.2137\n",
      "Epoch [13/50] - Train Loss: 1.0540, Test Loss: 1.2191\n",
      "Epoch [14/50] - Train Loss: 1.0510, Test Loss: 1.2240\n",
      "Epoch [15/50] - Train Loss: 1.0496, Test Loss: 1.2290\n",
      "Epoch [16/50] - Train Loss: 1.0490, Test Loss: 1.2341\n",
      "Epoch [17/50] - Train Loss: 1.0487, Test Loss: 1.2376\n",
      "Epoch [18/50] - Train Loss: 1.0486, Test Loss: 1.2387\n",
      "Epoch [19/50] - Train Loss: 1.0484, Test Loss: 1.2375\n",
      "Epoch [20/50] - Train Loss: 1.0483, Test Loss: 1.2346\n",
      "Epoch [21/50] - Train Loss: 1.0482, Test Loss: 1.2315\n",
      "Epoch [22/50] - Train Loss: 1.0481, Test Loss: 1.2293\n",
      "Epoch [23/50] - Train Loss: 1.0479, Test Loss: 1.2278\n",
      "Epoch [24/50] - Train Loss: 1.0478, Test Loss: 1.2269\n",
      "Epoch [25/50] - Train Loss: 1.0477, Test Loss: 1.2263\n",
      "Epoch [26/50] - Train Loss: 1.0475, Test Loss: 1.2259\n",
      "Epoch [27/50] - Train Loss: 1.0472, Test Loss: 1.2257\n",
      "Epoch [28/50] - Train Loss: 1.0469, Test Loss: 1.2257\n",
      "Epoch [29/50] - Train Loss: 1.0461, Test Loss: 1.2262\n",
      "Epoch [30/50] - Train Loss: 1.0447, Test Loss: 1.2284\n",
      "Epoch [31/50] - Train Loss: 1.0429, Test Loss: 1.2351\n",
      "Epoch [32/50] - Train Loss: 1.0420, Test Loss: 1.2480\n",
      "Epoch [33/50] - Train Loss: 1.0407, Test Loss: 1.2585\n",
      "Epoch [34/50] - Train Loss: 1.0403, Test Loss: 1.2657\n",
      "Epoch [35/50] - Train Loss: 1.0401, Test Loss: 1.2721\n",
      "Epoch [36/50] - Train Loss: 1.0398, Test Loss: 1.2755\n",
      "Epoch [37/50] - Train Loss: 1.0395, Test Loss: 1.2775\n",
      "Epoch [38/50] - Train Loss: 1.0393, Test Loss: 1.2783\n",
      "Epoch [39/50] - Train Loss: 1.0391, Test Loss: 1.2793\n",
      "Epoch [40/50] - Train Loss: 1.0389, Test Loss: 1.2809\n",
      "Epoch [41/50] - Train Loss: 1.0387, Test Loss: 1.2821\n",
      "Epoch [42/50] - Train Loss: 1.0386, Test Loss: 1.2834\n",
      "Epoch [43/50] - Train Loss: 1.0384, Test Loss: 1.2847\n",
      "Epoch [44/50] - Train Loss: 1.0382, Test Loss: 1.2859\n",
      "Epoch [45/50] - Train Loss: 1.0381, Test Loss: 1.2867\n",
      "Epoch [46/50] - Train Loss: 1.0379, Test Loss: 1.2868\n",
      "Epoch [47/50] - Train Loss: 1.0377, Test Loss: 1.2862\n",
      "Epoch [48/50] - Train Loss: 1.0386, Test Loss: 1.2945\n",
      "Epoch [49/50] - Train Loss: 1.0431, Test Loss: 1.2734\n",
      "Epoch [50/50] - Train Loss: 1.0439, Test Loss: 1.2670\n",
      "Avg Test Loss: 1.2670\n",
      "Testing combination: (8, 1, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5932, Test Loss: 1.7968\n",
      "Epoch [2/50] - Train Loss: 1.5212, Test Loss: 1.7443\n",
      "Epoch [3/50] - Train Loss: 1.4987, Test Loss: 1.7273\n",
      "Epoch [4/50] - Train Loss: 1.4917, Test Loss: 1.7246\n",
      "Epoch [5/50] - Train Loss: 1.4882, Test Loss: 1.7234\n",
      "Epoch [6/50] - Train Loss: 1.4837, Test Loss: 1.7200\n",
      "Epoch [7/50] - Train Loss: 1.4780, Test Loss: 1.7178\n",
      "Epoch [8/50] - Train Loss: 1.4738, Test Loss: 1.7216\n",
      "Epoch [9/50] - Train Loss: 1.4708, Test Loss: 1.7320\n",
      "Epoch [10/50] - Train Loss: 1.4678, Test Loss: 1.7399\n",
      "Epoch [11/50] - Train Loss: 1.4645, Test Loss: 1.7482\n",
      "Epoch [12/50] - Train Loss: 1.4614, Test Loss: 1.7588\n",
      "Epoch [13/50] - Train Loss: 1.4581, Test Loss: 1.7715\n",
      "Epoch [14/50] - Train Loss: 1.4540, Test Loss: 1.7857\n",
      "Epoch [15/50] - Train Loss: 1.4488, Test Loss: 1.7996\n",
      "Epoch [16/50] - Train Loss: 1.4445, Test Loss: 1.8120\n",
      "Epoch [17/50] - Train Loss: 1.4414, Test Loss: 1.8221\n",
      "Epoch [18/50] - Train Loss: 1.4373, Test Loss: 1.8305\n",
      "Epoch [19/50] - Train Loss: 1.4323, Test Loss: 1.8380\n",
      "Epoch [20/50] - Train Loss: 1.4272, Test Loss: 1.8478\n",
      "Epoch [21/50] - Train Loss: 1.4231, Test Loss: 1.8627\n",
      "Epoch [22/50] - Train Loss: 1.4193, Test Loss: 1.8790\n",
      "Epoch [23/50] - Train Loss: 1.4155, Test Loss: 1.8903\n",
      "Epoch [24/50] - Train Loss: 1.4125, Test Loss: 1.8997\n",
      "Epoch [25/50] - Train Loss: 1.4112, Test Loss: 1.9117\n",
      "Epoch [26/50] - Train Loss: 1.4103, Test Loss: 1.9267\n",
      "Epoch [27/50] - Train Loss: 1.4090, Test Loss: 1.9396\n",
      "Epoch [28/50] - Train Loss: 1.4070, Test Loss: 1.9484\n",
      "Epoch [29/50] - Train Loss: 1.4056, Test Loss: 1.9580\n",
      "Epoch [30/50] - Train Loss: 1.4047, Test Loss: 1.9698\n",
      "Epoch [31/50] - Train Loss: 1.4036, Test Loss: 1.9800\n",
      "Epoch [32/50] - Train Loss: 1.4022, Test Loss: 1.9875\n",
      "Epoch [33/50] - Train Loss: 1.4009, Test Loss: 1.9951\n",
      "Epoch [34/50] - Train Loss: 1.3999, Test Loss: 2.0040\n",
      "Epoch [35/50] - Train Loss: 1.3986, Test Loss: 2.0123\n",
      "Epoch [36/50] - Train Loss: 1.3970, Test Loss: 2.0204\n",
      "Epoch [37/50] - Train Loss: 1.3954, Test Loss: 2.0309\n",
      "Epoch [38/50] - Train Loss: 1.3936, Test Loss: 2.0437\n",
      "Epoch [39/50] - Train Loss: 1.3914, Test Loss: 2.0588\n",
      "Epoch [40/50] - Train Loss: 1.3891, Test Loss: 2.0828\n",
      "Epoch [41/50] - Train Loss: 1.3859, Test Loss: 2.1076\n",
      "Epoch [42/50] - Train Loss: 1.3827, Test Loss: 2.1324\n",
      "Epoch [43/50] - Train Loss: 1.3760, Test Loss: 2.0991\n",
      "Epoch [44/50] - Train Loss: 1.3783, Test Loss: 2.1734\n",
      "Epoch [45/50] - Train Loss: 1.3547, Test Loss: 2.0685\n",
      "Epoch [46/50] - Train Loss: 1.4038, Test Loss: 2.1493\n",
      "Epoch [47/50] - Train Loss: 1.3620, Test Loss: 2.0939\n",
      "Epoch [48/50] - Train Loss: 1.3605, Test Loss: 2.2647\n",
      "Epoch [49/50] - Train Loss: 1.3517, Test Loss: 2.0667\n",
      "Epoch [50/50] - Train Loss: 1.4031, Test Loss: 2.0691\n",
      "Avg Test Loss: 2.0691\n",
      "Testing combination: (8, 1, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1177, Test Loss: 1.0905\n",
      "Epoch [2/50] - Train Loss: 1.1168, Test Loss: 1.0907\n",
      "Epoch [3/50] - Train Loss: 1.1166, Test Loss: 1.0912\n",
      "Epoch [4/50] - Train Loss: 1.1165, Test Loss: 1.0921\n",
      "Epoch [5/50] - Train Loss: 1.1164, Test Loss: 1.0934\n",
      "Epoch [6/50] - Train Loss: 1.1163, Test Loss: 1.0953\n",
      "Epoch [7/50] - Train Loss: 1.1162, Test Loss: 1.0971\n",
      "Epoch [8/50] - Train Loss: 1.1162, Test Loss: 1.0987\n",
      "Epoch [9/50] - Train Loss: 1.1161, Test Loss: 1.1003\n",
      "Epoch [10/50] - Train Loss: 1.1161, Test Loss: 1.1020\n",
      "Epoch [11/50] - Train Loss: 1.1160, Test Loss: 1.1039\n",
      "Epoch [12/50] - Train Loss: 1.1160, Test Loss: 1.1060\n",
      "Epoch [13/50] - Train Loss: 1.1159, Test Loss: 1.1083\n",
      "Epoch [14/50] - Train Loss: 1.1159, Test Loss: 1.1109\n",
      "Epoch [15/50] - Train Loss: 1.1158, Test Loss: 1.1137\n",
      "Epoch [16/50] - Train Loss: 1.1158, Test Loss: 1.1167\n",
      "Epoch [17/50] - Train Loss: 1.1157, Test Loss: 1.1198\n",
      "Epoch [18/50] - Train Loss: 1.1156, Test Loss: 1.1229\n",
      "Epoch [19/50] - Train Loss: 1.1156, Test Loss: 1.1259\n",
      "Epoch [20/50] - Train Loss: 1.1154, Test Loss: 1.1284\n",
      "Epoch [21/50] - Train Loss: 1.1153, Test Loss: 1.1306\n",
      "Epoch [22/50] - Train Loss: 1.1151, Test Loss: 1.1329\n",
      "Epoch [23/50] - Train Loss: 1.1149, Test Loss: 1.1353\n",
      "Epoch [24/50] - Train Loss: 1.1145, Test Loss: 1.1373\n",
      "Epoch [25/50] - Train Loss: 1.1141, Test Loss: 1.1388\n",
      "Epoch [26/50] - Train Loss: 1.1131, Test Loss: 1.1396\n",
      "Epoch [27/50] - Train Loss: 1.1116, Test Loss: 1.1391\n",
      "Epoch [28/50] - Train Loss: 1.1090, Test Loss: 1.1375\n",
      "Epoch [29/50] - Train Loss: 1.1053, Test Loss: 1.1346\n",
      "Epoch [30/50] - Train Loss: 1.1017, Test Loss: 1.1313\n",
      "Epoch [31/50] - Train Loss: 1.0994, Test Loss: 1.1286\n",
      "Epoch [32/50] - Train Loss: 1.0979, Test Loss: 1.1270\n",
      "Epoch [33/50] - Train Loss: 1.0965, Test Loss: 1.1259\n",
      "Epoch [34/50] - Train Loss: 1.0951, Test Loss: 1.1250\n",
      "Epoch [35/50] - Train Loss: 1.0932, Test Loss: 1.1238\n",
      "Epoch [36/50] - Train Loss: 1.0911, Test Loss: 1.1222\n",
      "Epoch [37/50] - Train Loss: 1.0891, Test Loss: 1.1204\n",
      "Epoch [38/50] - Train Loss: 1.0876, Test Loss: 1.1191\n",
      "Epoch [39/50] - Train Loss: 1.0864, Test Loss: 1.1174\n",
      "Epoch [40/50] - Train Loss: 1.0854, Test Loss: 1.1156\n",
      "Epoch [41/50] - Train Loss: 1.0847, Test Loss: 1.1140\n",
      "Epoch [42/50] - Train Loss: 1.0840, Test Loss: 1.1133\n",
      "Epoch [43/50] - Train Loss: 1.0834, Test Loss: 1.1127\n",
      "Epoch [44/50] - Train Loss: 1.0829, Test Loss: 1.1126\n",
      "Epoch [45/50] - Train Loss: 1.0824, Test Loss: 1.1127\n",
      "Epoch [46/50] - Train Loss: 1.0820, Test Loss: 1.1129\n",
      "Epoch [47/50] - Train Loss: 1.0815, Test Loss: 1.1131\n",
      "Epoch [48/50] - Train Loss: 1.0811, Test Loss: 1.1134\n",
      "Epoch [49/50] - Train Loss: 1.0807, Test Loss: 1.1137\n",
      "Epoch [50/50] - Train Loss: 1.0803, Test Loss: 1.1141\n",
      "Avg Test Loss: 1.1141\n",
      "Testing combination: (8, 1, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1534, Test Loss: 1.1936\n",
      "Epoch [2/50] - Train Loss: 1.1518, Test Loss: 1.1915\n",
      "Epoch [3/50] - Train Loss: 1.1512, Test Loss: 1.1895\n",
      "Epoch [4/50] - Train Loss: 1.1508, Test Loss: 1.1876\n",
      "Epoch [5/50] - Train Loss: 1.1505, Test Loss: 1.1857\n",
      "Epoch [6/50] - Train Loss: 1.1502, Test Loss: 1.1838\n",
      "Epoch [7/50] - Train Loss: 1.1499, Test Loss: 1.1820\n",
      "Epoch [8/50] - Train Loss: 1.1496, Test Loss: 1.1802\n",
      "Epoch [9/50] - Train Loss: 1.1494, Test Loss: 1.1784\n",
      "Epoch [10/50] - Train Loss: 1.1491, Test Loss: 1.1767\n",
      "Epoch [11/50] - Train Loss: 1.1488, Test Loss: 1.1750\n",
      "Epoch [12/50] - Train Loss: 1.1484, Test Loss: 1.1733\n",
      "Epoch [13/50] - Train Loss: 1.1480, Test Loss: 1.1717\n",
      "Epoch [14/50] - Train Loss: 1.1475, Test Loss: 1.1701\n",
      "Epoch [15/50] - Train Loss: 1.1469, Test Loss: 1.1686\n",
      "Epoch [16/50] - Train Loss: 1.1462, Test Loss: 1.1673\n",
      "Epoch [17/50] - Train Loss: 1.1451, Test Loss: 1.1660\n",
      "Epoch [18/50] - Train Loss: 1.1438, Test Loss: 1.1649\n",
      "Epoch [19/50] - Train Loss: 1.1421, Test Loss: 1.1640\n",
      "Epoch [20/50] - Train Loss: 1.1401, Test Loss: 1.1633\n",
      "Epoch [21/50] - Train Loss: 1.1380, Test Loss: 1.1628\n",
      "Epoch [22/50] - Train Loss: 1.1357, Test Loss: 1.1625\n",
      "Epoch [23/50] - Train Loss: 1.1332, Test Loss: 1.1625\n",
      "Epoch [24/50] - Train Loss: 1.1305, Test Loss: 1.1627\n",
      "Epoch [25/50] - Train Loss: 1.1276, Test Loss: 1.1630\n",
      "Epoch [26/50] - Train Loss: 1.1243, Test Loss: 1.1634\n",
      "Epoch [27/50] - Train Loss: 1.1209, Test Loss: 1.1637\n",
      "Epoch [28/50] - Train Loss: 1.1173, Test Loss: 1.1640\n",
      "Epoch [29/50] - Train Loss: 1.1138, Test Loss: 1.1643\n",
      "Epoch [30/50] - Train Loss: 1.1105, Test Loss: 1.1645\n",
      "Epoch [31/50] - Train Loss: 1.1075, Test Loss: 1.1643\n",
      "Epoch [32/50] - Train Loss: 1.1046, Test Loss: 1.1640\n",
      "Epoch [33/50] - Train Loss: 1.1021, Test Loss: 1.1636\n",
      "Epoch [34/50] - Train Loss: 1.1000, Test Loss: 1.1632\n",
      "Epoch [35/50] - Train Loss: 1.0979, Test Loss: 1.1628\n",
      "Epoch [36/50] - Train Loss: 1.0959, Test Loss: 1.1626\n",
      "Epoch [37/50] - Train Loss: 1.0941, Test Loss: 1.1625\n",
      "Epoch [38/50] - Train Loss: 1.0923, Test Loss: 1.1626\n",
      "Epoch [39/50] - Train Loss: 1.0905, Test Loss: 1.1627\n",
      "Epoch [40/50] - Train Loss: 1.0887, Test Loss: 1.1630\n",
      "Epoch [41/50] - Train Loss: 1.0870, Test Loss: 1.1634\n",
      "Epoch [42/50] - Train Loss: 1.0852, Test Loss: 1.1639\n",
      "Epoch [43/50] - Train Loss: 1.0834, Test Loss: 1.1644\n",
      "Epoch [44/50] - Train Loss: 1.0814, Test Loss: 1.1651\n",
      "Epoch [45/50] - Train Loss: 1.0793, Test Loss: 1.1657\n",
      "Epoch [46/50] - Train Loss: 1.0772, Test Loss: 1.1663\n",
      "Epoch [47/50] - Train Loss: 1.0753, Test Loss: 1.1668\n",
      "Epoch [48/50] - Train Loss: 1.0737, Test Loss: 1.1677\n",
      "Epoch [49/50] - Train Loss: 1.0722, Test Loss: 1.1692\n",
      "Epoch [50/50] - Train Loss: 1.0708, Test Loss: 1.1711\n",
      "Avg Test Loss: 1.1711\n",
      "Testing combination: (8, 1, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.6466, Test Loss: 1.9717\n",
      "Epoch [2/50] - Train Loss: 1.6299, Test Loss: 1.9521\n",
      "Epoch [3/50] - Train Loss: 1.6162, Test Loss: 1.9354\n",
      "Epoch [4/50] - Train Loss: 1.6039, Test Loss: 1.9211\n",
      "Epoch [5/50] - Train Loss: 1.5928, Test Loss: 1.9089\n",
      "Epoch [6/50] - Train Loss: 1.5827, Test Loss: 1.8986\n",
      "Epoch [7/50] - Train Loss: 1.5735, Test Loss: 1.8897\n",
      "Epoch [8/50] - Train Loss: 1.5651, Test Loss: 1.8819\n",
      "Epoch [9/50] - Train Loss: 1.5574, Test Loss: 1.8751\n",
      "Epoch [10/50] - Train Loss: 1.5501, Test Loss: 1.8688\n",
      "Epoch [11/50] - Train Loss: 1.5434, Test Loss: 1.8630\n",
      "Epoch [12/50] - Train Loss: 1.5371, Test Loss: 1.8573\n",
      "Epoch [13/50] - Train Loss: 1.5311, Test Loss: 1.8519\n",
      "Epoch [14/50] - Train Loss: 1.5254, Test Loss: 1.8473\n",
      "Epoch [15/50] - Train Loss: 1.5198, Test Loss: 1.8431\n",
      "Epoch [16/50] - Train Loss: 1.5145, Test Loss: 1.8392\n",
      "Epoch [17/50] - Train Loss: 1.5094, Test Loss: 1.8347\n",
      "Epoch [18/50] - Train Loss: 1.5041, Test Loss: 1.8307\n",
      "Epoch [19/50] - Train Loss: 1.4992, Test Loss: 1.8269\n",
      "Epoch [20/50] - Train Loss: 1.4950, Test Loss: 1.8237\n",
      "Epoch [21/50] - Train Loss: 1.4913, Test Loss: 1.8208\n",
      "Epoch [22/50] - Train Loss: 1.4883, Test Loss: 1.8185\n",
      "Epoch [23/50] - Train Loss: 1.4857, Test Loss: 1.8167\n",
      "Epoch [24/50] - Train Loss: 1.4835, Test Loss: 1.8154\n",
      "Epoch [25/50] - Train Loss: 1.4817, Test Loss: 1.8144\n",
      "Epoch [26/50] - Train Loss: 1.4801, Test Loss: 1.8139\n",
      "Epoch [27/50] - Train Loss: 1.4787, Test Loss: 1.8136\n",
      "Epoch [28/50] - Train Loss: 1.4775, Test Loss: 1.8137\n",
      "Epoch [29/50] - Train Loss: 1.4764, Test Loss: 1.8139\n",
      "Epoch [30/50] - Train Loss: 1.4755, Test Loss: 1.8143\n",
      "Epoch [31/50] - Train Loss: 1.4746, Test Loss: 1.8149\n",
      "Epoch [32/50] - Train Loss: 1.4738, Test Loss: 1.8157\n",
      "Epoch [33/50] - Train Loss: 1.4730, Test Loss: 1.8166\n",
      "Epoch [34/50] - Train Loss: 1.4723, Test Loss: 1.8175\n",
      "Epoch [35/50] - Train Loss: 1.4716, Test Loss: 1.8186\n",
      "Epoch [36/50] - Train Loss: 1.4708, Test Loss: 1.8198\n",
      "Epoch [37/50] - Train Loss: 1.4701, Test Loss: 1.8211\n",
      "Epoch [38/50] - Train Loss: 1.4693, Test Loss: 1.8226\n",
      "Epoch [39/50] - Train Loss: 1.4685, Test Loss: 1.8241\n",
      "Epoch [40/50] - Train Loss: 1.4678, Test Loss: 1.8257\n",
      "Epoch [41/50] - Train Loss: 1.4671, Test Loss: 1.8274\n",
      "Epoch [42/50] - Train Loss: 1.4664, Test Loss: 1.8293\n",
      "Epoch [43/50] - Train Loss: 1.4659, Test Loss: 1.8312\n",
      "Epoch [44/50] - Train Loss: 1.4653, Test Loss: 1.8332\n",
      "Epoch [45/50] - Train Loss: 1.4648, Test Loss: 1.8352\n",
      "Epoch [46/50] - Train Loss: 1.4643, Test Loss: 1.8373\n",
      "Epoch [47/50] - Train Loss: 1.4638, Test Loss: 1.8394\n",
      "Epoch [48/50] - Train Loss: 1.4634, Test Loss: 1.8415\n",
      "Epoch [49/50] - Train Loss: 1.4629, Test Loss: 1.8436\n",
      "Epoch [50/50] - Train Loss: 1.4625, Test Loss: 1.8458\n",
      "Avg Test Loss: 1.8458\n",
      "Testing combination: (8, 1, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.2487, Test Loss: 1.1726\n",
      "Epoch [2/50] - Train Loss: 1.2462, Test Loss: 1.1706\n",
      "Epoch [3/50] - Train Loss: 1.2439, Test Loss: 1.1687\n",
      "Epoch [4/50] - Train Loss: 1.2418, Test Loss: 1.1668\n",
      "Epoch [5/50] - Train Loss: 1.2397, Test Loss: 1.1650\n",
      "Epoch [6/50] - Train Loss: 1.2376, Test Loss: 1.1632\n",
      "Epoch [7/50] - Train Loss: 1.2355, Test Loss: 1.1615\n",
      "Epoch [8/50] - Train Loss: 1.2335, Test Loss: 1.1599\n",
      "Epoch [9/50] - Train Loss: 1.2316, Test Loss: 1.1583\n",
      "Epoch [10/50] - Train Loss: 1.2297, Test Loss: 1.1567\n",
      "Epoch [11/50] - Train Loss: 1.2278, Test Loss: 1.1551\n",
      "Epoch [12/50] - Train Loss: 1.2259, Test Loss: 1.1536\n",
      "Epoch [13/50] - Train Loss: 1.2240, Test Loss: 1.1521\n",
      "Epoch [14/50] - Train Loss: 1.2222, Test Loss: 1.1506\n",
      "Epoch [15/50] - Train Loss: 1.2204, Test Loss: 1.1491\n",
      "Epoch [16/50] - Train Loss: 1.2187, Test Loss: 1.1477\n",
      "Epoch [17/50] - Train Loss: 1.2169, Test Loss: 1.1462\n",
      "Epoch [18/50] - Train Loss: 1.2152, Test Loss: 1.1449\n",
      "Epoch [19/50] - Train Loss: 1.2135, Test Loss: 1.1435\n",
      "Epoch [20/50] - Train Loss: 1.2118, Test Loss: 1.1421\n",
      "Epoch [21/50] - Train Loss: 1.2102, Test Loss: 1.1408\n",
      "Epoch [22/50] - Train Loss: 1.2085, Test Loss: 1.1395\n",
      "Epoch [23/50] - Train Loss: 1.2069, Test Loss: 1.1382\n",
      "Epoch [24/50] - Train Loss: 1.2053, Test Loss: 1.1370\n",
      "Epoch [25/50] - Train Loss: 1.2038, Test Loss: 1.1357\n",
      "Epoch [26/50] - Train Loss: 1.2022, Test Loss: 1.1345\n",
      "Epoch [27/50] - Train Loss: 1.2007, Test Loss: 1.1333\n",
      "Epoch [28/50] - Train Loss: 1.1992, Test Loss: 1.1321\n",
      "Epoch [29/50] - Train Loss: 1.1977, Test Loss: 1.1310\n",
      "Epoch [30/50] - Train Loss: 1.1962, Test Loss: 1.1298\n",
      "Epoch [31/50] - Train Loss: 1.1948, Test Loss: 1.1287\n",
      "Epoch [32/50] - Train Loss: 1.1933, Test Loss: 1.1276\n",
      "Epoch [33/50] - Train Loss: 1.1919, Test Loss: 1.1265\n",
      "Epoch [34/50] - Train Loss: 1.1905, Test Loss: 1.1255\n",
      "Epoch [35/50] - Train Loss: 1.1891, Test Loss: 1.1244\n",
      "Epoch [36/50] - Train Loss: 1.1878, Test Loss: 1.1234\n",
      "Epoch [37/50] - Train Loss: 1.1864, Test Loss: 1.1224\n",
      "Epoch [38/50] - Train Loss: 1.1851, Test Loss: 1.1214\n",
      "Epoch [39/50] - Train Loss: 1.1838, Test Loss: 1.1204\n",
      "Epoch [40/50] - Train Loss: 1.1825, Test Loss: 1.1195\n",
      "Epoch [41/50] - Train Loss: 1.1812, Test Loss: 1.1185\n",
      "Epoch [42/50] - Train Loss: 1.1799, Test Loss: 1.1176\n",
      "Epoch [43/50] - Train Loss: 1.1787, Test Loss: 1.1167\n",
      "Epoch [44/50] - Train Loss: 1.1775, Test Loss: 1.1158\n",
      "Epoch [45/50] - Train Loss: 1.1762, Test Loss: 1.1150\n",
      "Epoch [46/50] - Train Loss: 1.1750, Test Loss: 1.1141\n",
      "Epoch [47/50] - Train Loss: 1.1739, Test Loss: 1.1133\n",
      "Epoch [48/50] - Train Loss: 1.1727, Test Loss: 1.1124\n",
      "Epoch [49/50] - Train Loss: 1.1715, Test Loss: 1.1116\n",
      "Epoch [50/50] - Train Loss: 1.1704, Test Loss: 1.1108\n",
      "Avg Test Loss: 1.1108\n",
      "Testing combination: (8, 1, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1517, Test Loss: 1.1945\n",
      "Epoch [2/50] - Train Loss: 1.1515, Test Loss: 1.1943\n",
      "Epoch [3/50] - Train Loss: 1.1514, Test Loss: 1.1941\n",
      "Epoch [4/50] - Train Loss: 1.1513, Test Loss: 1.1939\n",
      "Epoch [5/50] - Train Loss: 1.1513, Test Loss: 1.1937\n",
      "Epoch [6/50] - Train Loss: 1.1512, Test Loss: 1.1935\n",
      "Epoch [7/50] - Train Loss: 1.1512, Test Loss: 1.1934\n",
      "Epoch [8/50] - Train Loss: 1.1511, Test Loss: 1.1932\n",
      "Epoch [9/50] - Train Loss: 1.1511, Test Loss: 1.1930\n",
      "Epoch [10/50] - Train Loss: 1.1511, Test Loss: 1.1929\n",
      "Epoch [11/50] - Train Loss: 1.1510, Test Loss: 1.1927\n",
      "Epoch [12/50] - Train Loss: 1.1510, Test Loss: 1.1926\n",
      "Epoch [13/50] - Train Loss: 1.1509, Test Loss: 1.1924\n",
      "Epoch [14/50] - Train Loss: 1.1509, Test Loss: 1.1923\n",
      "Epoch [15/50] - Train Loss: 1.1508, Test Loss: 1.1921\n",
      "Epoch [16/50] - Train Loss: 1.1508, Test Loss: 1.1920\n",
      "Epoch [17/50] - Train Loss: 1.1507, Test Loss: 1.1918\n",
      "Epoch [18/50] - Train Loss: 1.1507, Test Loss: 1.1917\n",
      "Epoch [19/50] - Train Loss: 1.1507, Test Loss: 1.1916\n",
      "Epoch [20/50] - Train Loss: 1.1506, Test Loss: 1.1914\n",
      "Epoch [21/50] - Train Loss: 1.1506, Test Loss: 1.1913\n",
      "Epoch [22/50] - Train Loss: 1.1505, Test Loss: 1.1912\n",
      "Epoch [23/50] - Train Loss: 1.1505, Test Loss: 1.1910\n",
      "Epoch [24/50] - Train Loss: 1.1505, Test Loss: 1.1909\n",
      "Epoch [25/50] - Train Loss: 1.1504, Test Loss: 1.1908\n",
      "Epoch [26/50] - Train Loss: 1.1504, Test Loss: 1.1907\n",
      "Epoch [27/50] - Train Loss: 1.1503, Test Loss: 1.1906\n",
      "Epoch [28/50] - Train Loss: 1.1503, Test Loss: 1.1904\n",
      "Epoch [29/50] - Train Loss: 1.1503, Test Loss: 1.1903\n",
      "Epoch [30/50] - Train Loss: 1.1502, Test Loss: 1.1902\n",
      "Epoch [31/50] - Train Loss: 1.1502, Test Loss: 1.1901\n",
      "Epoch [32/50] - Train Loss: 1.1501, Test Loss: 1.1900\n",
      "Epoch [33/50] - Train Loss: 1.1501, Test Loss: 1.1899\n",
      "Epoch [34/50] - Train Loss: 1.1501, Test Loss: 1.1898\n",
      "Epoch [35/50] - Train Loss: 1.1500, Test Loss: 1.1897\n",
      "Epoch [36/50] - Train Loss: 1.1500, Test Loss: 1.1896\n",
      "Epoch [37/50] - Train Loss: 1.1499, Test Loss: 1.1895\n",
      "Epoch [38/50] - Train Loss: 1.1499, Test Loss: 1.1894\n",
      "Epoch [39/50] - Train Loss: 1.1499, Test Loss: 1.1893\n",
      "Epoch [40/50] - Train Loss: 1.1498, Test Loss: 1.1892\n",
      "Epoch [41/50] - Train Loss: 1.1498, Test Loss: 1.1891\n",
      "Epoch [42/50] - Train Loss: 1.1498, Test Loss: 1.1890\n",
      "Epoch [43/50] - Train Loss: 1.1497, Test Loss: 1.1889\n",
      "Epoch [44/50] - Train Loss: 1.1497, Test Loss: 1.1888\n",
      "Epoch [45/50] - Train Loss: 1.1497, Test Loss: 1.1888\n",
      "Epoch [46/50] - Train Loss: 1.1496, Test Loss: 1.1887\n",
      "Epoch [47/50] - Train Loss: 1.1496, Test Loss: 1.1886\n",
      "Epoch [48/50] - Train Loss: 1.1495, Test Loss: 1.1885\n",
      "Epoch [49/50] - Train Loss: 1.1495, Test Loss: 1.1884\n",
      "Epoch [50/50] - Train Loss: 1.1495, Test Loss: 1.1884\n",
      "Avg Test Loss: 1.1884\n",
      "Testing combination: (8, 1, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5972, Test Loss: 1.9117\n",
      "Epoch [2/50] - Train Loss: 1.5960, Test Loss: 1.9102\n",
      "Epoch [3/50] - Train Loss: 1.5951, Test Loss: 1.9087\n",
      "Epoch [4/50] - Train Loss: 1.5941, Test Loss: 1.9073\n",
      "Epoch [5/50] - Train Loss: 1.5932, Test Loss: 1.9059\n",
      "Epoch [6/50] - Train Loss: 1.5923, Test Loss: 1.9045\n",
      "Epoch [7/50] - Train Loss: 1.5914, Test Loss: 1.9031\n",
      "Epoch [8/50] - Train Loss: 1.5905, Test Loss: 1.9017\n",
      "Epoch [9/50] - Train Loss: 1.5896, Test Loss: 1.9004\n",
      "Epoch [10/50] - Train Loss: 1.5887, Test Loss: 1.8990\n",
      "Epoch [11/50] - Train Loss: 1.5878, Test Loss: 1.8977\n",
      "Epoch [12/50] - Train Loss: 1.5869, Test Loss: 1.8963\n",
      "Epoch [13/50] - Train Loss: 1.5861, Test Loss: 1.8950\n",
      "Epoch [14/50] - Train Loss: 1.5852, Test Loss: 1.8936\n",
      "Epoch [15/50] - Train Loss: 1.5843, Test Loss: 1.8923\n",
      "Epoch [16/50] - Train Loss: 1.5835, Test Loss: 1.8910\n",
      "Epoch [17/50] - Train Loss: 1.5826, Test Loss: 1.8897\n",
      "Epoch [18/50] - Train Loss: 1.5818, Test Loss: 1.8884\n",
      "Epoch [19/50] - Train Loss: 1.5809, Test Loss: 1.8871\n",
      "Epoch [20/50] - Train Loss: 1.5801, Test Loss: 1.8859\n",
      "Epoch [21/50] - Train Loss: 1.5792, Test Loss: 1.8846\n",
      "Epoch [22/50] - Train Loss: 1.5784, Test Loss: 1.8834\n",
      "Epoch [23/50] - Train Loss: 1.5776, Test Loss: 1.8821\n",
      "Epoch [24/50] - Train Loss: 1.5767, Test Loss: 1.8809\n",
      "Epoch [25/50] - Train Loss: 1.5759, Test Loss: 1.8797\n",
      "Epoch [26/50] - Train Loss: 1.5751, Test Loss: 1.8784\n",
      "Epoch [27/50] - Train Loss: 1.5743, Test Loss: 1.8772\n",
      "Epoch [28/50] - Train Loss: 1.5735, Test Loss: 1.8760\n",
      "Epoch [29/50] - Train Loss: 1.5727, Test Loss: 1.8748\n",
      "Epoch [30/50] - Train Loss: 1.5719, Test Loss: 1.8736\n",
      "Epoch [31/50] - Train Loss: 1.5711, Test Loss: 1.8724\n",
      "Epoch [32/50] - Train Loss: 1.5703, Test Loss: 1.8712\n",
      "Epoch [33/50] - Train Loss: 1.5695, Test Loss: 1.8701\n",
      "Epoch [34/50] - Train Loss: 1.5687, Test Loss: 1.8689\n",
      "Epoch [35/50] - Train Loss: 1.5679, Test Loss: 1.8677\n",
      "Epoch [36/50] - Train Loss: 1.5671, Test Loss: 1.8666\n",
      "Epoch [37/50] - Train Loss: 1.5664, Test Loss: 1.8654\n",
      "Epoch [38/50] - Train Loss: 1.5656, Test Loss: 1.8643\n",
      "Epoch [39/50] - Train Loss: 1.5648, Test Loss: 1.8632\n",
      "Epoch [40/50] - Train Loss: 1.5641, Test Loss: 1.8620\n",
      "Epoch [41/50] - Train Loss: 1.5633, Test Loss: 1.8609\n",
      "Epoch [42/50] - Train Loss: 1.5625, Test Loss: 1.8598\n",
      "Epoch [43/50] - Train Loss: 1.5618, Test Loss: 1.8587\n",
      "Epoch [44/50] - Train Loss: 1.5611, Test Loss: 1.8576\n",
      "Epoch [45/50] - Train Loss: 1.5603, Test Loss: 1.8565\n",
      "Epoch [46/50] - Train Loss: 1.5596, Test Loss: 1.8554\n",
      "Epoch [47/50] - Train Loss: 1.5588, Test Loss: 1.8544\n",
      "Epoch [48/50] - Train Loss: 1.5581, Test Loss: 1.8533\n",
      "Epoch [49/50] - Train Loss: 1.5574, Test Loss: 1.8523\n",
      "Epoch [50/50] - Train Loss: 1.5567, Test Loss: 1.8512\n",
      "Avg Test Loss: 1.8512\n",
      "Testing combination: (8, 2, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1360, Test Loss: 1.0912\n",
      "Epoch [2/50] - Train Loss: 1.1182, Test Loss: 1.0829\n",
      "Epoch [3/50] - Train Loss: 1.1191, Test Loss: 1.0856\n",
      "Epoch [4/50] - Train Loss: 1.1164, Test Loss: 1.0908\n",
      "Epoch [5/50] - Train Loss: 1.1096, Test Loss: 1.0971\n",
      "Epoch [6/50] - Train Loss: 1.0974, Test Loss: 1.1039\n",
      "Epoch [7/50] - Train Loss: 1.0846, Test Loss: 1.1416\n",
      "Epoch [8/50] - Train Loss: 1.3157, Test Loss: 1.1526\n",
      "Epoch [9/50] - Train Loss: 1.1189, Test Loss: 1.0800\n",
      "Epoch [10/50] - Train Loss: 1.1258, Test Loss: 1.0808\n",
      "Epoch [11/50] - Train Loss: 1.1215, Test Loss: 1.0863\n",
      "Epoch [12/50] - Train Loss: 1.1191, Test Loss: 1.0890\n",
      "Epoch [13/50] - Train Loss: 1.1183, Test Loss: 1.0883\n",
      "Epoch [14/50] - Train Loss: 1.1179, Test Loss: 1.0870\n",
      "Epoch [15/50] - Train Loss: 1.1180, Test Loss: 1.0864\n",
      "Epoch [16/50] - Train Loss: 1.1180, Test Loss: 1.0864\n",
      "Epoch [17/50] - Train Loss: 1.1180, Test Loss: 1.0866\n",
      "Epoch [18/50] - Train Loss: 1.1178, Test Loss: 1.0869\n",
      "Epoch [19/50] - Train Loss: 1.1176, Test Loss: 1.0871\n",
      "Epoch [20/50] - Train Loss: 1.1172, Test Loss: 1.0873\n",
      "Epoch [21/50] - Train Loss: 1.1166, Test Loss: 1.0875\n",
      "Epoch [22/50] - Train Loss: 1.1157, Test Loss: 1.0878\n",
      "Epoch [23/50] - Train Loss: 1.1146, Test Loss: 1.0883\n",
      "Epoch [24/50] - Train Loss: 1.1133, Test Loss: 1.0890\n",
      "Epoch [25/50] - Train Loss: 1.1118, Test Loss: 1.0900\n",
      "Epoch [26/50] - Train Loss: 1.1101, Test Loss: 1.0913\n",
      "Epoch [27/50] - Train Loss: 1.1082, Test Loss: 1.0927\n",
      "Epoch [28/50] - Train Loss: 1.1063, Test Loss: 1.0945\n",
      "Epoch [29/50] - Train Loss: 1.1041, Test Loss: 1.0965\n",
      "Epoch [30/50] - Train Loss: 1.1017, Test Loss: 1.0991\n",
      "Epoch [31/50] - Train Loss: 1.0993, Test Loss: 1.1021\n",
      "Epoch [32/50] - Train Loss: 1.0967, Test Loss: 1.1058\n",
      "Epoch [33/50] - Train Loss: 1.0939, Test Loss: 1.1100\n",
      "Epoch [34/50] - Train Loss: 1.0907, Test Loss: 1.1153\n",
      "Epoch [35/50] - Train Loss: 1.0873, Test Loss: 1.1229\n",
      "Epoch [36/50] - Train Loss: 1.0840, Test Loss: 1.1352\n",
      "Epoch [37/50] - Train Loss: 1.0811, Test Loss: 1.1484\n",
      "Epoch [38/50] - Train Loss: 1.0789, Test Loss: 1.1595\n",
      "Epoch [39/50] - Train Loss: 1.0773, Test Loss: 1.1703\n",
      "Epoch [40/50] - Train Loss: 1.0761, Test Loss: 1.1803\n",
      "Epoch [41/50] - Train Loss: 1.0753, Test Loss: 1.1887\n",
      "Epoch [42/50] - Train Loss: 1.0749, Test Loss: 1.1948\n",
      "Epoch [43/50] - Train Loss: 1.0746, Test Loss: 1.1991\n",
      "Epoch [44/50] - Train Loss: 1.0745, Test Loss: 1.2021\n",
      "Epoch [45/50] - Train Loss: 1.0743, Test Loss: 1.2042\n",
      "Epoch [46/50] - Train Loss: 1.0742, Test Loss: 1.2056\n",
      "Epoch [47/50] - Train Loss: 1.0741, Test Loss: 1.2065\n",
      "Epoch [48/50] - Train Loss: 1.0741, Test Loss: 1.2071\n",
      "Epoch [49/50] - Train Loss: 1.0740, Test Loss: 1.2075\n",
      "Epoch [50/50] - Train Loss: 1.0740, Test Loss: 1.2077\n",
      "Avg Test Loss: 1.2077\n",
      "Testing combination: (8, 2, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1708, Test Loss: 1.1377\n",
      "Epoch [2/50] - Train Loss: 1.1513, Test Loss: 1.1524\n",
      "Epoch [3/50] - Train Loss: 1.1434, Test Loss: 1.1642\n",
      "Epoch [4/50] - Train Loss: 1.1358, Test Loss: 1.1727\n",
      "Epoch [5/50] - Train Loss: 1.1228, Test Loss: 1.1753\n",
      "Epoch [6/50] - Train Loss: 1.0981, Test Loss: 1.1778\n",
      "Epoch [7/50] - Train Loss: 1.0657, Test Loss: 1.1928\n",
      "Epoch [8/50] - Train Loss: 1.0954, Test Loss: 1.2046\n",
      "Epoch [9/50] - Train Loss: 1.0651, Test Loss: 1.2190\n",
      "Epoch [10/50] - Train Loss: 1.0551, Test Loss: 1.2466\n",
      "Epoch [11/50] - Train Loss: 1.0488, Test Loss: 1.2751\n",
      "Epoch [12/50] - Train Loss: 1.0486, Test Loss: 1.2905\n",
      "Epoch [13/50] - Train Loss: 1.0485, Test Loss: 1.2915\n",
      "Epoch [14/50] - Train Loss: 1.0480, Test Loss: 1.2861\n",
      "Epoch [15/50] - Train Loss: 1.0478, Test Loss: 1.2815\n",
      "Epoch [16/50] - Train Loss: 1.0476, Test Loss: 1.2807\n",
      "Epoch [17/50] - Train Loss: 1.0476, Test Loss: 1.2809\n",
      "Epoch [18/50] - Train Loss: 1.0476, Test Loss: 1.2811\n",
      "Epoch [19/50] - Train Loss: 1.0476, Test Loss: 1.2810\n",
      "Epoch [20/50] - Train Loss: 1.0476, Test Loss: 1.2811\n",
      "Epoch [21/50] - Train Loss: 1.0475, Test Loss: 1.2813\n",
      "Epoch [22/50] - Train Loss: 1.0475, Test Loss: 1.2816\n",
      "Epoch [23/50] - Train Loss: 1.0475, Test Loss: 1.2819\n",
      "Epoch [24/50] - Train Loss: 1.0475, Test Loss: 1.2821\n",
      "Epoch [25/50] - Train Loss: 1.0474, Test Loss: 1.2822\n",
      "Epoch [26/50] - Train Loss: 1.0474, Test Loss: 1.2823\n",
      "Epoch [27/50] - Train Loss: 1.0474, Test Loss: 1.2824\n",
      "Epoch [28/50] - Train Loss: 1.0474, Test Loss: 1.2824\n",
      "Epoch [29/50] - Train Loss: 1.0474, Test Loss: 1.2824\n",
      "Epoch [30/50] - Train Loss: 1.0474, Test Loss: 1.2824\n",
      "Epoch [31/50] - Train Loss: 1.0473, Test Loss: 1.2824\n",
      "Epoch [32/50] - Train Loss: 1.0473, Test Loss: 1.2824\n",
      "Epoch [33/50] - Train Loss: 1.0473, Test Loss: 1.2823\n",
      "Epoch [34/50] - Train Loss: 1.0473, Test Loss: 1.2823\n",
      "Epoch [35/50] - Train Loss: 1.0473, Test Loss: 1.2822\n",
      "Epoch [36/50] - Train Loss: 1.0472, Test Loss: 1.2822\n",
      "Epoch [37/50] - Train Loss: 1.0472, Test Loss: 1.2821\n",
      "Epoch [38/50] - Train Loss: 1.0472, Test Loss: 1.2820\n",
      "Epoch [39/50] - Train Loss: 1.0472, Test Loss: 1.2819\n",
      "Epoch [40/50] - Train Loss: 1.0472, Test Loss: 1.2819\n",
      "Epoch [41/50] - Train Loss: 1.0472, Test Loss: 1.2818\n",
      "Epoch [42/50] - Train Loss: 1.0471, Test Loss: 1.2817\n",
      "Epoch [43/50] - Train Loss: 1.0471, Test Loss: 1.2816\n",
      "Epoch [44/50] - Train Loss: 1.0471, Test Loss: 1.2815\n",
      "Epoch [45/50] - Train Loss: 1.0471, Test Loss: 1.2814\n",
      "Epoch [46/50] - Train Loss: 1.0471, Test Loss: 1.2812\n",
      "Epoch [47/50] - Train Loss: 1.0471, Test Loss: 1.2809\n",
      "Epoch [48/50] - Train Loss: 1.0470, Test Loss: 1.2806\n",
      "Epoch [49/50] - Train Loss: 1.0470, Test Loss: 1.2804\n",
      "Epoch [50/50] - Train Loss: 1.0470, Test Loss: 1.2802\n",
      "Avg Test Loss: 1.2802\n",
      "Testing combination: (8, 2, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.6195, Test Loss: 1.8184\n",
      "Epoch [2/50] - Train Loss: 1.4966, Test Loss: 1.7555\n",
      "Epoch [3/50] - Train Loss: 1.4703, Test Loss: 1.7649\n",
      "Epoch [4/50] - Train Loss: 1.4758, Test Loss: 1.7815\n",
      "Epoch [5/50] - Train Loss: 1.4801, Test Loss: 1.7885\n",
      "Epoch [6/50] - Train Loss: 1.4751, Test Loss: 1.7909\n",
      "Epoch [7/50] - Train Loss: 1.4671, Test Loss: 1.7947\n",
      "Epoch [8/50] - Train Loss: 1.4580, Test Loss: 1.8010\n",
      "Epoch [9/50] - Train Loss: 1.4468, Test Loss: 1.8105\n",
      "Epoch [10/50] - Train Loss: 1.4379, Test Loss: 1.8284\n",
      "Epoch [11/50] - Train Loss: 1.4321, Test Loss: 1.8461\n",
      "Epoch [12/50] - Train Loss: 1.4288, Test Loss: 1.8619\n",
      "Epoch [13/50] - Train Loss: 1.4297, Test Loss: 1.8755\n",
      "Epoch [14/50] - Train Loss: 1.4306, Test Loss: 1.8874\n",
      "Epoch [15/50] - Train Loss: 1.4304, Test Loss: 1.8984\n",
      "Epoch [16/50] - Train Loss: 1.4290, Test Loss: 1.9078\n",
      "Epoch [17/50] - Train Loss: 1.4269, Test Loss: 1.9175\n",
      "Epoch [18/50] - Train Loss: 1.4251, Test Loss: 1.9294\n",
      "Epoch [19/50] - Train Loss: 1.4235, Test Loss: 1.9411\n",
      "Epoch [20/50] - Train Loss: 1.4217, Test Loss: 1.9520\n",
      "Epoch [21/50] - Train Loss: 1.4197, Test Loss: 1.9634\n",
      "Epoch [22/50] - Train Loss: 1.4177, Test Loss: 1.9761\n",
      "Epoch [23/50] - Train Loss: 1.4159, Test Loss: 1.9903\n",
      "Epoch [24/50] - Train Loss: 1.4142, Test Loss: 2.0042\n",
      "Epoch [25/50] - Train Loss: 1.4123, Test Loss: 2.0175\n",
      "Epoch [26/50] - Train Loss: 1.4105, Test Loss: 2.0311\n",
      "Epoch [27/50] - Train Loss: 1.4085, Test Loss: 2.0448\n",
      "Epoch [28/50] - Train Loss: 1.4063, Test Loss: 2.0570\n",
      "Epoch [29/50] - Train Loss: 1.4037, Test Loss: 2.0673\n",
      "Epoch [30/50] - Train Loss: 1.4006, Test Loss: 2.0758\n",
      "Epoch [31/50] - Train Loss: 1.3960, Test Loss: 2.0679\n",
      "Epoch [32/50] - Train Loss: 1.3956, Test Loss: 2.1297\n",
      "Epoch [33/50] - Train Loss: 1.3893, Test Loss: 2.1302\n",
      "Epoch [34/50] - Train Loss: 1.3842, Test Loss: 2.1069\n",
      "Epoch [35/50] - Train Loss: 1.3810, Test Loss: 2.1202\n",
      "Epoch [36/50] - Train Loss: 1.3811, Test Loss: 2.1700\n",
      "Epoch [37/50] - Train Loss: 1.3707, Test Loss: 2.1548\n",
      "Epoch [38/50] - Train Loss: 1.3692, Test Loss: 2.1486\n",
      "Epoch [39/50] - Train Loss: 1.3685, Test Loss: 2.1530\n",
      "Epoch [40/50] - Train Loss: 1.3659, Test Loss: 2.1427\n",
      "Epoch [41/50] - Train Loss: 1.3658, Test Loss: 2.1260\n",
      "Epoch [42/50] - Train Loss: 1.3649, Test Loss: 2.1326\n",
      "Epoch [43/50] - Train Loss: 1.3649, Test Loss: 2.2648\n",
      "Epoch [44/50] - Train Loss: 1.4883, Test Loss: 2.0426\n",
      "Epoch [45/50] - Train Loss: 1.4656, Test Loss: 1.8642\n",
      "Epoch [46/50] - Train Loss: 1.4819, Test Loss: 1.8363\n",
      "Epoch [47/50] - Train Loss: 1.4812, Test Loss: 1.8264\n",
      "Epoch [48/50] - Train Loss: 1.4748, Test Loss: 1.8232\n",
      "Epoch [49/50] - Train Loss: 1.4659, Test Loss: 1.8250\n",
      "Epoch [50/50] - Train Loss: 1.4594, Test Loss: 1.8296\n",
      "Avg Test Loss: 1.8296\n",
      "Testing combination: (8, 2, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1180, Test Loss: 1.0931\n",
      "Epoch [2/50] - Train Loss: 1.1167, Test Loss: 1.0936\n",
      "Epoch [3/50] - Train Loss: 1.1163, Test Loss: 1.0940\n",
      "Epoch [4/50] - Train Loss: 1.1161, Test Loss: 1.0942\n",
      "Epoch [5/50] - Train Loss: 1.1158, Test Loss: 1.0945\n",
      "Epoch [6/50] - Train Loss: 1.1156, Test Loss: 1.0949\n",
      "Epoch [7/50] - Train Loss: 1.1154, Test Loss: 1.0953\n",
      "Epoch [8/50] - Train Loss: 1.1151, Test Loss: 1.0958\n",
      "Epoch [9/50] - Train Loss: 1.1147, Test Loss: 1.0962\n",
      "Epoch [10/50] - Train Loss: 1.1142, Test Loss: 1.0968\n",
      "Epoch [11/50] - Train Loss: 1.1137, Test Loss: 1.0976\n",
      "Epoch [12/50] - Train Loss: 1.1129, Test Loss: 1.0988\n",
      "Epoch [13/50] - Train Loss: 1.1118, Test Loss: 1.1005\n",
      "Epoch [14/50] - Train Loss: 1.1103, Test Loss: 1.1027\n",
      "Epoch [15/50] - Train Loss: 1.1081, Test Loss: 1.1052\n",
      "Epoch [16/50] - Train Loss: 1.1052, Test Loss: 1.1082\n",
      "Epoch [17/50] - Train Loss: 1.1016, Test Loss: 1.1118\n",
      "Epoch [18/50] - Train Loss: 1.0975, Test Loss: 1.1159\n",
      "Epoch [19/50] - Train Loss: 1.0934, Test Loss: 1.1206\n",
      "Epoch [20/50] - Train Loss: 1.0896, Test Loss: 1.1257\n",
      "Epoch [21/50] - Train Loss: 1.0860, Test Loss: 1.1310\n",
      "Epoch [22/50] - Train Loss: 1.0825, Test Loss: 1.1363\n",
      "Epoch [23/50] - Train Loss: 1.0791, Test Loss: 1.1415\n",
      "Epoch [24/50] - Train Loss: 1.0759, Test Loss: 1.1465\n",
      "Epoch [25/50] - Train Loss: 1.0739, Test Loss: 1.1512\n",
      "Epoch [26/50] - Train Loss: 1.0728, Test Loss: 1.1545\n",
      "Epoch [27/50] - Train Loss: 1.0719, Test Loss: 1.1571\n",
      "Epoch [28/50] - Train Loss: 1.0714, Test Loss: 1.1595\n",
      "Epoch [29/50] - Train Loss: 1.0712, Test Loss: 1.1619\n",
      "Epoch [30/50] - Train Loss: 1.0709, Test Loss: 1.1640\n",
      "Epoch [31/50] - Train Loss: 1.0706, Test Loss: 1.1660\n",
      "Epoch [32/50] - Train Loss: 1.0703, Test Loss: 1.1678\n",
      "Epoch [33/50] - Train Loss: 1.0700, Test Loss: 1.1695\n",
      "Epoch [34/50] - Train Loss: 1.0697, Test Loss: 1.1712\n",
      "Epoch [35/50] - Train Loss: 1.0693, Test Loss: 1.1727\n",
      "Epoch [36/50] - Train Loss: 1.0690, Test Loss: 1.1743\n",
      "Epoch [37/50] - Train Loss: 1.0687, Test Loss: 1.1758\n",
      "Epoch [38/50] - Train Loss: 1.0683, Test Loss: 1.1773\n",
      "Epoch [39/50] - Train Loss: 1.0679, Test Loss: 1.1788\n",
      "Epoch [40/50] - Train Loss: 1.0675, Test Loss: 1.1803\n",
      "Epoch [41/50] - Train Loss: 1.0671, Test Loss: 1.1818\n",
      "Epoch [42/50] - Train Loss: 1.0667, Test Loss: 1.1833\n",
      "Epoch [43/50] - Train Loss: 1.0663, Test Loss: 1.1848\n",
      "Epoch [44/50] - Train Loss: 1.0658, Test Loss: 1.1863\n",
      "Epoch [45/50] - Train Loss: 1.0652, Test Loss: 1.1879\n",
      "Epoch [46/50] - Train Loss: 1.0646, Test Loss: 1.1895\n",
      "Epoch [47/50] - Train Loss: 1.0638, Test Loss: 1.1913\n",
      "Epoch [48/50] - Train Loss: 1.0629, Test Loss: 1.1934\n",
      "Epoch [49/50] - Train Loss: 1.0620, Test Loss: 1.1955\n",
      "Epoch [50/50] - Train Loss: 1.0607, Test Loss: 1.1976\n",
      "Avg Test Loss: 1.1976\n",
      "Testing combination: (8, 2, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1841, Test Loss: 1.2794\n",
      "Epoch [2/50] - Train Loss: 1.1775, Test Loss: 1.2692\n",
      "Epoch [3/50] - Train Loss: 1.1733, Test Loss: 1.2606\n",
      "Epoch [4/50] - Train Loss: 1.1698, Test Loss: 1.2531\n",
      "Epoch [5/50] - Train Loss: 1.1666, Test Loss: 1.2465\n",
      "Epoch [6/50] - Train Loss: 1.1636, Test Loss: 1.2404\n",
      "Epoch [7/50] - Train Loss: 1.1605, Test Loss: 1.2347\n",
      "Epoch [8/50] - Train Loss: 1.1572, Test Loss: 1.2291\n",
      "Epoch [9/50] - Train Loss: 1.1538, Test Loss: 1.2235\n",
      "Epoch [10/50] - Train Loss: 1.1500, Test Loss: 1.2179\n",
      "Epoch [11/50] - Train Loss: 1.1458, Test Loss: 1.2121\n",
      "Epoch [12/50] - Train Loss: 1.1410, Test Loss: 1.2063\n",
      "Epoch [13/50] - Train Loss: 1.1356, Test Loss: 1.2003\n",
      "Epoch [14/50] - Train Loss: 1.1296, Test Loss: 1.1944\n",
      "Epoch [15/50] - Train Loss: 1.1234, Test Loss: 1.1890\n",
      "Epoch [16/50] - Train Loss: 1.1172, Test Loss: 1.1843\n",
      "Epoch [17/50] - Train Loss: 1.1111, Test Loss: 1.1806\n",
      "Epoch [18/50] - Train Loss: 1.1052, Test Loss: 1.1783\n",
      "Epoch [19/50] - Train Loss: 1.0994, Test Loss: 1.1774\n",
      "Epoch [20/50] - Train Loss: 1.0936, Test Loss: 1.1780\n",
      "Epoch [21/50] - Train Loss: 1.0879, Test Loss: 1.1796\n",
      "Epoch [22/50] - Train Loss: 1.0824, Test Loss: 1.1821\n",
      "Epoch [23/50] - Train Loss: 1.0776, Test Loss: 1.1851\n",
      "Epoch [24/50] - Train Loss: 1.0736, Test Loss: 1.1884\n",
      "Epoch [25/50] - Train Loss: 1.0704, Test Loss: 1.1914\n",
      "Epoch [26/50] - Train Loss: 1.0678, Test Loss: 1.1940\n",
      "Epoch [27/50] - Train Loss: 1.0656, Test Loss: 1.1964\n",
      "Epoch [28/50] - Train Loss: 1.0637, Test Loss: 1.1986\n",
      "Epoch [29/50] - Train Loss: 1.0620, Test Loss: 1.2007\n",
      "Epoch [30/50] - Train Loss: 1.0604, Test Loss: 1.2028\n",
      "Epoch [31/50] - Train Loss: 1.0590, Test Loss: 1.2049\n",
      "Epoch [32/50] - Train Loss: 1.0577, Test Loss: 1.2070\n",
      "Epoch [33/50] - Train Loss: 1.0565, Test Loss: 1.2092\n",
      "Epoch [34/50] - Train Loss: 1.0553, Test Loss: 1.2113\n",
      "Epoch [35/50] - Train Loss: 1.0542, Test Loss: 1.2134\n",
      "Epoch [36/50] - Train Loss: 1.0533, Test Loss: 1.2155\n",
      "Epoch [37/50] - Train Loss: 1.0523, Test Loss: 1.2176\n",
      "Epoch [38/50] - Train Loss: 1.0514, Test Loss: 1.2197\n",
      "Epoch [39/50] - Train Loss: 1.0505, Test Loss: 1.2218\n",
      "Epoch [40/50] - Train Loss: 1.0497, Test Loss: 1.2238\n",
      "Epoch [41/50] - Train Loss: 1.0489, Test Loss: 1.2259\n",
      "Epoch [42/50] - Train Loss: 1.0481, Test Loss: 1.2278\n",
      "Epoch [43/50] - Train Loss: 1.0473, Test Loss: 1.2298\n",
      "Epoch [44/50] - Train Loss: 1.0465, Test Loss: 1.2317\n",
      "Epoch [45/50] - Train Loss: 1.0458, Test Loss: 1.2335\n",
      "Epoch [46/50] - Train Loss: 1.0450, Test Loss: 1.2354\n",
      "Epoch [47/50] - Train Loss: 1.0442, Test Loss: 1.2372\n",
      "Epoch [48/50] - Train Loss: 1.0433, Test Loss: 1.2390\n",
      "Epoch [49/50] - Train Loss: 1.0426, Test Loss: 1.2406\n",
      "Epoch [50/50] - Train Loss: 1.0416, Test Loss: 1.2423\n",
      "Avg Test Loss: 1.2423\n",
      "Testing combination: (8, 2, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5473, Test Loss: 1.8193\n",
      "Epoch [2/50] - Train Loss: 1.5365, Test Loss: 1.8069\n",
      "Epoch [3/50] - Train Loss: 1.5286, Test Loss: 1.7963\n",
      "Epoch [4/50] - Train Loss: 1.5219, Test Loss: 1.7872\n",
      "Epoch [5/50] - Train Loss: 1.5159, Test Loss: 1.7792\n",
      "Epoch [6/50] - Train Loss: 1.5107, Test Loss: 1.7722\n",
      "Epoch [7/50] - Train Loss: 1.5060, Test Loss: 1.7662\n",
      "Epoch [8/50] - Train Loss: 1.5020, Test Loss: 1.7610\n",
      "Epoch [9/50] - Train Loss: 1.4986, Test Loss: 1.7566\n",
      "Epoch [10/50] - Train Loss: 1.4956, Test Loss: 1.7529\n",
      "Epoch [11/50] - Train Loss: 1.4931, Test Loss: 1.7498\n",
      "Epoch [12/50] - Train Loss: 1.4910, Test Loss: 1.7473\n",
      "Epoch [13/50] - Train Loss: 1.4893, Test Loss: 1.7453\n",
      "Epoch [14/50] - Train Loss: 1.4878, Test Loss: 1.7436\n",
      "Epoch [15/50] - Train Loss: 1.4867, Test Loss: 1.7423\n",
      "Epoch [16/50] - Train Loss: 1.4857, Test Loss: 1.7413\n",
      "Epoch [17/50] - Train Loss: 1.4850, Test Loss: 1.7405\n",
      "Epoch [18/50] - Train Loss: 1.4844, Test Loss: 1.7399\n",
      "Epoch [19/50] - Train Loss: 1.4839, Test Loss: 1.7394\n",
      "Epoch [20/50] - Train Loss: 1.4835, Test Loss: 1.7391\n",
      "Epoch [21/50] - Train Loss: 1.4831, Test Loss: 1.7388\n",
      "Epoch [22/50] - Train Loss: 1.4828, Test Loss: 1.7387\n",
      "Epoch [23/50] - Train Loss: 1.4826, Test Loss: 1.7385\n",
      "Epoch [24/50] - Train Loss: 1.4824, Test Loss: 1.7385\n",
      "Epoch [25/50] - Train Loss: 1.4822, Test Loss: 1.7384\n",
      "Epoch [26/50] - Train Loss: 1.4820, Test Loss: 1.7384\n",
      "Epoch [27/50] - Train Loss: 1.4818, Test Loss: 1.7384\n",
      "Epoch [28/50] - Train Loss: 1.4816, Test Loss: 1.7385\n",
      "Epoch [29/50] - Train Loss: 1.4815, Test Loss: 1.7385\n",
      "Epoch [30/50] - Train Loss: 1.4813, Test Loss: 1.7387\n",
      "Epoch [31/50] - Train Loss: 1.4811, Test Loss: 1.7388\n",
      "Epoch [32/50] - Train Loss: 1.4811, Test Loss: 1.7390\n",
      "Epoch [33/50] - Train Loss: 1.4809, Test Loss: 1.7392\n",
      "Epoch [34/50] - Train Loss: 1.4807, Test Loss: 1.7393\n",
      "Epoch [35/50] - Train Loss: 1.4805, Test Loss: 1.7395\n",
      "Epoch [36/50] - Train Loss: 1.4803, Test Loss: 1.7398\n",
      "Epoch [37/50] - Train Loss: 1.4801, Test Loss: 1.7400\n",
      "Epoch [38/50] - Train Loss: 1.4799, Test Loss: 1.7402\n",
      "Epoch [39/50] - Train Loss: 1.4796, Test Loss: 1.7404\n",
      "Epoch [40/50] - Train Loss: 1.4794, Test Loss: 1.7407\n",
      "Epoch [41/50] - Train Loss: 1.4792, Test Loss: 1.7409\n",
      "Epoch [42/50] - Train Loss: 1.4790, Test Loss: 1.7411\n",
      "Epoch [43/50] - Train Loss: 1.4788, Test Loss: 1.7414\n",
      "Epoch [44/50] - Train Loss: 1.4785, Test Loss: 1.7416\n",
      "Epoch [45/50] - Train Loss: 1.4783, Test Loss: 1.7418\n",
      "Epoch [46/50] - Train Loss: 1.4780, Test Loss: 1.7421\n",
      "Epoch [47/50] - Train Loss: 1.4778, Test Loss: 1.7423\n",
      "Epoch [48/50] - Train Loss: 1.4775, Test Loss: 1.7426\n",
      "Epoch [49/50] - Train Loss: 1.4773, Test Loss: 1.7429\n",
      "Epoch [50/50] - Train Loss: 1.4770, Test Loss: 1.7432\n",
      "Avg Test Loss: 1.7432\n",
      "Testing combination: (8, 2, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1926, Test Loss: 1.2180\n",
      "Epoch [2/50] - Train Loss: 1.1906, Test Loss: 1.2154\n",
      "Epoch [3/50] - Train Loss: 1.1888, Test Loss: 1.2129\n",
      "Epoch [4/50] - Train Loss: 1.1871, Test Loss: 1.2105\n",
      "Epoch [5/50] - Train Loss: 1.1854, Test Loss: 1.2081\n",
      "Epoch [6/50] - Train Loss: 1.1838, Test Loss: 1.2059\n",
      "Epoch [7/50] - Train Loss: 1.1822, Test Loss: 1.2037\n",
      "Epoch [8/50] - Train Loss: 1.1807, Test Loss: 1.2015\n",
      "Epoch [9/50] - Train Loss: 1.1792, Test Loss: 1.1994\n",
      "Epoch [10/50] - Train Loss: 1.1778, Test Loss: 1.1974\n",
      "Epoch [11/50] - Train Loss: 1.1764, Test Loss: 1.1954\n",
      "Epoch [12/50] - Train Loss: 1.1750, Test Loss: 1.1935\n",
      "Epoch [13/50] - Train Loss: 1.1737, Test Loss: 1.1916\n",
      "Epoch [14/50] - Train Loss: 1.1725, Test Loss: 1.1898\n",
      "Epoch [15/50] - Train Loss: 1.1712, Test Loss: 1.1880\n",
      "Epoch [16/50] - Train Loss: 1.1700, Test Loss: 1.1862\n",
      "Epoch [17/50] - Train Loss: 1.1688, Test Loss: 1.1845\n",
      "Epoch [18/50] - Train Loss: 1.1677, Test Loss: 1.1828\n",
      "Epoch [19/50] - Train Loss: 1.1665, Test Loss: 1.1812\n",
      "Epoch [20/50] - Train Loss: 1.1654, Test Loss: 1.1795\n",
      "Epoch [21/50] - Train Loss: 1.1643, Test Loss: 1.1780\n",
      "Epoch [22/50] - Train Loss: 1.1633, Test Loss: 1.1764\n",
      "Epoch [23/50] - Train Loss: 1.1622, Test Loss: 1.1749\n",
      "Epoch [24/50] - Train Loss: 1.1612, Test Loss: 1.1734\n",
      "Epoch [25/50] - Train Loss: 1.1602, Test Loss: 1.1719\n",
      "Epoch [26/50] - Train Loss: 1.1593, Test Loss: 1.1705\n",
      "Epoch [27/50] - Train Loss: 1.1583, Test Loss: 1.1691\n",
      "Epoch [28/50] - Train Loss: 1.1574, Test Loss: 1.1677\n",
      "Epoch [29/50] - Train Loss: 1.1564, Test Loss: 1.1663\n",
      "Epoch [30/50] - Train Loss: 1.1555, Test Loss: 1.1650\n",
      "Epoch [31/50] - Train Loss: 1.1546, Test Loss: 1.1637\n",
      "Epoch [32/50] - Train Loss: 1.1538, Test Loss: 1.1624\n",
      "Epoch [33/50] - Train Loss: 1.1529, Test Loss: 1.1611\n",
      "Epoch [34/50] - Train Loss: 1.1520, Test Loss: 1.1598\n",
      "Epoch [35/50] - Train Loss: 1.1512, Test Loss: 1.1586\n",
      "Epoch [36/50] - Train Loss: 1.1504, Test Loss: 1.1574\n",
      "Epoch [37/50] - Train Loss: 1.1496, Test Loss: 1.1562\n",
      "Epoch [38/50] - Train Loss: 1.1488, Test Loss: 1.1550\n",
      "Epoch [39/50] - Train Loss: 1.1480, Test Loss: 1.1538\n",
      "Epoch [40/50] - Train Loss: 1.1472, Test Loss: 1.1527\n",
      "Epoch [41/50] - Train Loss: 1.1464, Test Loss: 1.1515\n",
      "Epoch [42/50] - Train Loss: 1.1457, Test Loss: 1.1504\n",
      "Epoch [43/50] - Train Loss: 1.1449, Test Loss: 1.1493\n",
      "Epoch [44/50] - Train Loss: 1.1442, Test Loss: 1.1482\n",
      "Epoch [45/50] - Train Loss: 1.1435, Test Loss: 1.1472\n",
      "Epoch [46/50] - Train Loss: 1.1428, Test Loss: 1.1461\n",
      "Epoch [47/50] - Train Loss: 1.1421, Test Loss: 1.1451\n",
      "Epoch [48/50] - Train Loss: 1.1414, Test Loss: 1.1441\n",
      "Epoch [49/50] - Train Loss: 1.1407, Test Loss: 1.1431\n",
      "Epoch [50/50] - Train Loss: 1.1400, Test Loss: 1.1421\n",
      "Avg Test Loss: 1.1421\n",
      "Testing combination: (8, 2, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1535, Test Loss: 1.1399\n",
      "Epoch [2/50] - Train Loss: 1.1533, Test Loss: 1.1401\n",
      "Epoch [3/50] - Train Loss: 1.1532, Test Loss: 1.1404\n",
      "Epoch [4/50] - Train Loss: 1.1531, Test Loss: 1.1406\n",
      "Epoch [5/50] - Train Loss: 1.1529, Test Loss: 1.1408\n",
      "Epoch [6/50] - Train Loss: 1.1528, Test Loss: 1.1410\n",
      "Epoch [7/50] - Train Loss: 1.1527, Test Loss: 1.1412\n",
      "Epoch [8/50] - Train Loss: 1.1526, Test Loss: 1.1414\n",
      "Epoch [9/50] - Train Loss: 1.1526, Test Loss: 1.1416\n",
      "Epoch [10/50] - Train Loss: 1.1525, Test Loss: 1.1418\n",
      "Epoch [11/50] - Train Loss: 1.1524, Test Loss: 1.1420\n",
      "Epoch [12/50] - Train Loss: 1.1523, Test Loss: 1.1423\n",
      "Epoch [13/50] - Train Loss: 1.1522, Test Loss: 1.1425\n",
      "Epoch [14/50] - Train Loss: 1.1521, Test Loss: 1.1427\n",
      "Epoch [15/50] - Train Loss: 1.1520, Test Loss: 1.1429\n",
      "Epoch [16/50] - Train Loss: 1.1519, Test Loss: 1.1430\n",
      "Epoch [17/50] - Train Loss: 1.1519, Test Loss: 1.1432\n",
      "Epoch [18/50] - Train Loss: 1.1518, Test Loss: 1.1434\n",
      "Epoch [19/50] - Train Loss: 1.1517, Test Loss: 1.1436\n",
      "Epoch [20/50] - Train Loss: 1.1516, Test Loss: 1.1438\n",
      "Epoch [21/50] - Train Loss: 1.1515, Test Loss: 1.1440\n",
      "Epoch [22/50] - Train Loss: 1.1515, Test Loss: 1.1442\n",
      "Epoch [23/50] - Train Loss: 1.1514, Test Loss: 1.1444\n",
      "Epoch [24/50] - Train Loss: 1.1513, Test Loss: 1.1446\n",
      "Epoch [25/50] - Train Loss: 1.1513, Test Loss: 1.1448\n",
      "Epoch [26/50] - Train Loss: 1.1512, Test Loss: 1.1449\n",
      "Epoch [27/50] - Train Loss: 1.1511, Test Loss: 1.1451\n",
      "Epoch [28/50] - Train Loss: 1.1511, Test Loss: 1.1453\n",
      "Epoch [29/50] - Train Loss: 1.1510, Test Loss: 1.1455\n",
      "Epoch [30/50] - Train Loss: 1.1509, Test Loss: 1.1457\n",
      "Epoch [31/50] - Train Loss: 1.1509, Test Loss: 1.1458\n",
      "Epoch [32/50] - Train Loss: 1.1508, Test Loss: 1.1460\n",
      "Epoch [33/50] - Train Loss: 1.1507, Test Loss: 1.1462\n",
      "Epoch [34/50] - Train Loss: 1.1507, Test Loss: 1.1464\n",
      "Epoch [35/50] - Train Loss: 1.1506, Test Loss: 1.1466\n",
      "Epoch [36/50] - Train Loss: 1.1505, Test Loss: 1.1468\n",
      "Epoch [37/50] - Train Loss: 1.1505, Test Loss: 1.1469\n",
      "Epoch [38/50] - Train Loss: 1.1504, Test Loss: 1.1471\n",
      "Epoch [39/50] - Train Loss: 1.1504, Test Loss: 1.1473\n",
      "Epoch [40/50] - Train Loss: 1.1503, Test Loss: 1.1475\n",
      "Epoch [41/50] - Train Loss: 1.1502, Test Loss: 1.1477\n",
      "Epoch [42/50] - Train Loss: 1.1502, Test Loss: 1.1479\n",
      "Epoch [43/50] - Train Loss: 1.1501, Test Loss: 1.1481\n",
      "Epoch [44/50] - Train Loss: 1.1501, Test Loss: 1.1483\n",
      "Epoch [45/50] - Train Loss: 1.1500, Test Loss: 1.1485\n",
      "Epoch [46/50] - Train Loss: 1.1500, Test Loss: 1.1487\n",
      "Epoch [47/50] - Train Loss: 1.1499, Test Loss: 1.1489\n",
      "Epoch [48/50] - Train Loss: 1.1499, Test Loss: 1.1490\n",
      "Epoch [49/50] - Train Loss: 1.1498, Test Loss: 1.1492\n",
      "Epoch [50/50] - Train Loss: 1.1498, Test Loss: 1.1494\n",
      "Avg Test Loss: 1.1494\n",
      "Testing combination: (8, 2, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.4899, Test Loss: 1.7357\n",
      "Epoch [2/50] - Train Loss: 1.4897, Test Loss: 1.7357\n",
      "Epoch [3/50] - Train Loss: 1.4896, Test Loss: 1.7357\n",
      "Epoch [4/50] - Train Loss: 1.4895, Test Loss: 1.7357\n",
      "Epoch [5/50] - Train Loss: 1.4895, Test Loss: 1.7357\n",
      "Epoch [6/50] - Train Loss: 1.4894, Test Loss: 1.7357\n",
      "Epoch [7/50] - Train Loss: 1.4893, Test Loss: 1.7357\n",
      "Epoch [8/50] - Train Loss: 1.4893, Test Loss: 1.7357\n",
      "Epoch [9/50] - Train Loss: 1.4892, Test Loss: 1.7357\n",
      "Epoch [10/50] - Train Loss: 1.4891, Test Loss: 1.7357\n",
      "Epoch [11/50] - Train Loss: 1.4891, Test Loss: 1.7357\n",
      "Epoch [12/50] - Train Loss: 1.4890, Test Loss: 1.7357\n",
      "Epoch [13/50] - Train Loss: 1.4889, Test Loss: 1.7357\n",
      "Epoch [14/50] - Train Loss: 1.4889, Test Loss: 1.7357\n",
      "Epoch [15/50] - Train Loss: 1.4888, Test Loss: 1.7357\n",
      "Epoch [16/50] - Train Loss: 1.4888, Test Loss: 1.7357\n",
      "Epoch [17/50] - Train Loss: 1.4887, Test Loss: 1.7358\n",
      "Epoch [18/50] - Train Loss: 1.4887, Test Loss: 1.7358\n",
      "Epoch [19/50] - Train Loss: 1.4886, Test Loss: 1.7359\n",
      "Epoch [20/50] - Train Loss: 1.4885, Test Loss: 1.7359\n",
      "Epoch [21/50] - Train Loss: 1.4885, Test Loss: 1.7360\n",
      "Epoch [22/50] - Train Loss: 1.4884, Test Loss: 1.7361\n",
      "Epoch [23/50] - Train Loss: 1.4884, Test Loss: 1.7362\n",
      "Epoch [24/50] - Train Loss: 1.4883, Test Loss: 1.7362\n",
      "Epoch [25/50] - Train Loss: 1.4883, Test Loss: 1.7363\n",
      "Epoch [26/50] - Train Loss: 1.4882, Test Loss: 1.7364\n",
      "Epoch [27/50] - Train Loss: 1.4882, Test Loss: 1.7364\n",
      "Epoch [28/50] - Train Loss: 1.4881, Test Loss: 1.7365\n",
      "Epoch [29/50] - Train Loss: 1.4881, Test Loss: 1.7365\n",
      "Epoch [30/50] - Train Loss: 1.4880, Test Loss: 1.7366\n",
      "Epoch [31/50] - Train Loss: 1.4880, Test Loss: 1.7367\n",
      "Epoch [32/50] - Train Loss: 1.4879, Test Loss: 1.7367\n",
      "Epoch [33/50] - Train Loss: 1.4879, Test Loss: 1.7368\n",
      "Epoch [34/50] - Train Loss: 1.4878, Test Loss: 1.7368\n",
      "Epoch [35/50] - Train Loss: 1.4878, Test Loss: 1.7369\n",
      "Epoch [36/50] - Train Loss: 1.4877, Test Loss: 1.7369\n",
      "Epoch [37/50] - Train Loss: 1.4877, Test Loss: 1.7370\n",
      "Epoch [38/50] - Train Loss: 1.4876, Test Loss: 1.7370\n",
      "Epoch [39/50] - Train Loss: 1.4876, Test Loss: 1.7371\n",
      "Epoch [40/50] - Train Loss: 1.4875, Test Loss: 1.7372\n",
      "Epoch [41/50] - Train Loss: 1.4875, Test Loss: 1.7372\n",
      "Epoch [42/50] - Train Loss: 1.4874, Test Loss: 1.7373\n",
      "Epoch [43/50] - Train Loss: 1.4874, Test Loss: 1.7374\n",
      "Epoch [44/50] - Train Loss: 1.4874, Test Loss: 1.7374\n",
      "Epoch [45/50] - Train Loss: 1.4873, Test Loss: 1.7375\n",
      "Epoch [46/50] - Train Loss: 1.4873, Test Loss: 1.7376\n",
      "Epoch [47/50] - Train Loss: 1.4872, Test Loss: 1.7377\n",
      "Epoch [48/50] - Train Loss: 1.4872, Test Loss: 1.7378\n",
      "Epoch [49/50] - Train Loss: 1.4872, Test Loss: 1.7378\n",
      "Epoch [50/50] - Train Loss: 1.4871, Test Loss: 1.7379\n",
      "Avg Test Loss: 1.7379\n",
      "Testing combination: (8, 3, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1435, Test Loss: 1.1015\n",
      "Epoch [2/50] - Train Loss: 1.1169, Test Loss: 1.0866\n",
      "Epoch [3/50] - Train Loss: 1.1176, Test Loss: 1.0846\n",
      "Epoch [4/50] - Train Loss: 1.1183, Test Loss: 1.0855\n",
      "Epoch [5/50] - Train Loss: 1.1181, Test Loss: 1.0869\n",
      "Epoch [6/50] - Train Loss: 1.1177, Test Loss: 1.0880\n",
      "Epoch [7/50] - Train Loss: 1.1170, Test Loss: 1.0890\n",
      "Epoch [8/50] - Train Loss: 1.1147, Test Loss: 1.0917\n",
      "Epoch [9/50] - Train Loss: 1.1056, Test Loss: 1.0989\n",
      "Epoch [10/50] - Train Loss: 1.1022, Test Loss: 1.1071\n",
      "Epoch [11/50] - Train Loss: 1.0876, Test Loss: 1.1287\n",
      "Epoch [12/50] - Train Loss: 1.0825, Test Loss: 1.1540\n",
      "Epoch [13/50] - Train Loss: 1.0799, Test Loss: 1.1690\n",
      "Epoch [14/50] - Train Loss: 1.0767, Test Loss: 1.1726\n",
      "Epoch [15/50] - Train Loss: 1.0718, Test Loss: 1.1754\n",
      "Epoch [16/50] - Train Loss: 1.0674, Test Loss: 1.1833\n",
      "Epoch [17/50] - Train Loss: 1.0673, Test Loss: 1.1913\n",
      "Epoch [18/50] - Train Loss: 1.0647, Test Loss: 1.1975\n",
      "Epoch [19/50] - Train Loss: 1.0649, Test Loss: 1.2008\n",
      "Epoch [20/50] - Train Loss: 1.0628, Test Loss: 1.2016\n",
      "Epoch [21/50] - Train Loss: 1.1135, Test Loss: 1.1587\n",
      "Epoch [22/50] - Train Loss: 1.1223, Test Loss: 1.0808\n",
      "Epoch [23/50] - Train Loss: 1.1201, Test Loss: 1.0843\n",
      "Epoch [24/50] - Train Loss: 1.1185, Test Loss: 1.0871\n",
      "Epoch [25/50] - Train Loss: 1.1179, Test Loss: 1.0879\n",
      "Epoch [26/50] - Train Loss: 1.1176, Test Loss: 1.0876\n",
      "Epoch [27/50] - Train Loss: 1.1175, Test Loss: 1.0871\n",
      "Epoch [28/50] - Train Loss: 1.1175, Test Loss: 1.0868\n",
      "Epoch [29/50] - Train Loss: 1.1175, Test Loss: 1.0867\n",
      "Epoch [30/50] - Train Loss: 1.1175, Test Loss: 1.0868\n",
      "Epoch [31/50] - Train Loss: 1.1175, Test Loss: 1.0870\n",
      "Epoch [32/50] - Train Loss: 1.1174, Test Loss: 1.0872\n",
      "Epoch [33/50] - Train Loss: 1.1172, Test Loss: 1.0875\n",
      "Epoch [34/50] - Train Loss: 1.1169, Test Loss: 1.0879\n",
      "Epoch [35/50] - Train Loss: 1.1163, Test Loss: 1.0890\n",
      "Epoch [36/50] - Train Loss: 1.1145, Test Loss: 1.0945\n",
      "Epoch [37/50] - Train Loss: 1.0965, Test Loss: 1.1294\n",
      "Epoch [38/50] - Train Loss: 1.0657, Test Loss: 1.2054\n",
      "Epoch [39/50] - Train Loss: 1.1969, Test Loss: 1.1280\n",
      "Epoch [40/50] - Train Loss: 1.0828, Test Loss: 1.1236\n",
      "Epoch [41/50] - Train Loss: 1.0684, Test Loss: 1.1740\n",
      "Epoch [42/50] - Train Loss: 1.0589, Test Loss: 1.1540\n",
      "Epoch [43/50] - Train Loss: 1.0541, Test Loss: 1.1662\n",
      "Epoch [44/50] - Train Loss: 1.0550, Test Loss: 1.1802\n",
      "Epoch [45/50] - Train Loss: 1.0496, Test Loss: 1.2220\n",
      "Epoch [46/50] - Train Loss: 1.0501, Test Loss: 1.1910\n",
      "Epoch [47/50] - Train Loss: 1.1118, Test Loss: 1.0803\n",
      "Epoch [48/50] - Train Loss: 1.1195, Test Loss: 1.1052\n",
      "Epoch [49/50] - Train Loss: 1.0629, Test Loss: 1.2436\n",
      "Epoch [50/50] - Train Loss: 1.0516, Test Loss: 1.1948\n",
      "Avg Test Loss: 1.1948\n",
      "Testing combination: (8, 3, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.2337, Test Loss: 1.1247\n",
      "Epoch [2/50] - Train Loss: 1.1550, Test Loss: 1.1607\n",
      "Epoch [3/50] - Train Loss: 1.1520, Test Loss: 1.1796\n",
      "Epoch [4/50] - Train Loss: 1.1533, Test Loss: 1.1774\n",
      "Epoch [5/50] - Train Loss: 1.1520, Test Loss: 1.1699\n",
      "Epoch [6/50] - Train Loss: 1.1499, Test Loss: 1.1637\n",
      "Epoch [7/50] - Train Loss: 1.1473, Test Loss: 1.1589\n",
      "Epoch [8/50] - Train Loss: 1.1431, Test Loss: 1.1549\n",
      "Epoch [9/50] - Train Loss: 1.1348, Test Loss: 1.1520\n",
      "Epoch [10/50] - Train Loss: 1.1269, Test Loss: 1.1547\n",
      "Epoch [11/50] - Train Loss: 1.1023, Test Loss: 1.1656\n",
      "Epoch [12/50] - Train Loss: 1.0799, Test Loss: 1.1749\n",
      "Epoch [13/50] - Train Loss: 1.0705, Test Loss: 1.1845\n",
      "Epoch [14/50] - Train Loss: 1.0613, Test Loss: 1.2010\n",
      "Epoch [15/50] - Train Loss: 1.0584, Test Loss: 1.2171\n",
      "Epoch [16/50] - Train Loss: 1.0523, Test Loss: 1.2306\n",
      "Epoch [17/50] - Train Loss: 1.0462, Test Loss: 1.2426\n",
      "Epoch [18/50] - Train Loss: 1.0461, Test Loss: 1.2498\n",
      "Epoch [19/50] - Train Loss: 1.0447, Test Loss: 1.2588\n",
      "Epoch [20/50] - Train Loss: 1.0447, Test Loss: 1.2568\n",
      "Epoch [21/50] - Train Loss: 1.0410, Test Loss: 1.2532\n",
      "Epoch [22/50] - Train Loss: 1.0410, Test Loss: 1.2512\n",
      "Epoch [23/50] - Train Loss: 1.0410, Test Loss: 1.2554\n",
      "Epoch [24/50] - Train Loss: 1.0400, Test Loss: 1.2491\n",
      "Epoch [25/50] - Train Loss: 1.0349, Test Loss: 1.2560\n",
      "Epoch [26/50] - Train Loss: 1.1439, Test Loss: 1.2850\n",
      "Epoch [27/50] - Train Loss: 1.0546, Test Loss: 1.2498\n",
      "Epoch [28/50] - Train Loss: 1.0367, Test Loss: 1.3289\n",
      "Epoch [29/50] - Train Loss: 1.0545, Test Loss: 1.2443\n",
      "Epoch [30/50] - Train Loss: 1.0417, Test Loss: 1.2403\n",
      "Epoch [31/50] - Train Loss: 1.0410, Test Loss: 1.2430\n",
      "Epoch [32/50] - Train Loss: 1.0375, Test Loss: 1.2450\n",
      "Epoch [33/50] - Train Loss: 1.0362, Test Loss: 1.2484\n",
      "Epoch [34/50] - Train Loss: 1.0321, Test Loss: 1.2602\n",
      "Epoch [35/50] - Train Loss: 1.0234, Test Loss: 1.3207\n",
      "Epoch [36/50] - Train Loss: 1.0234, Test Loss: 1.2415\n",
      "Epoch [37/50] - Train Loss: 1.0189, Test Loss: 1.3635\n",
      "Epoch [38/50] - Train Loss: 1.0354, Test Loss: 1.2766\n",
      "Epoch [39/50] - Train Loss: 1.0266, Test Loss: 1.2259\n",
      "Epoch [40/50] - Train Loss: 1.0317, Test Loss: 1.2968\n",
      "Epoch [41/50] - Train Loss: 1.0286, Test Loss: 1.3329\n",
      "Epoch [42/50] - Train Loss: 1.0109, Test Loss: 1.2800\n",
      "Epoch [43/50] - Train Loss: 1.0164, Test Loss: 1.3247\n",
      "Epoch [44/50] - Train Loss: 1.0115, Test Loss: 1.3460\n",
      "Epoch [45/50] - Train Loss: 1.0084, Test Loss: 1.3394\n",
      "Epoch [46/50] - Train Loss: 1.0072, Test Loss: 1.3509\n",
      "Epoch [47/50] - Train Loss: 1.0061, Test Loss: 1.3739\n",
      "Epoch [48/50] - Train Loss: 1.0047, Test Loss: 1.3962\n",
      "Epoch [49/50] - Train Loss: 1.0022, Test Loss: 1.4024\n",
      "Epoch [50/50] - Train Loss: 0.9928, Test Loss: 1.3719\n",
      "Avg Test Loss: 1.3719\n",
      "Testing combination: (8, 3, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5334, Test Loss: 1.7674\n",
      "Epoch [2/50] - Train Loss: 1.4987, Test Loss: 1.7433\n",
      "Epoch [3/50] - Train Loss: 1.4869, Test Loss: 1.7345\n",
      "Epoch [4/50] - Train Loss: 1.4839, Test Loss: 1.7333\n",
      "Epoch [5/50] - Train Loss: 1.4849, Test Loss: 1.7347\n",
      "Epoch [6/50] - Train Loss: 1.4868, Test Loss: 1.7360\n",
      "Epoch [7/50] - Train Loss: 1.4879, Test Loss: 1.7366\n",
      "Epoch [8/50] - Train Loss: 1.4881, Test Loss: 1.7369\n",
      "Epoch [9/50] - Train Loss: 1.4878, Test Loss: 1.7371\n",
      "Epoch [10/50] - Train Loss: 1.4874, Test Loss: 1.7373\n",
      "Epoch [11/50] - Train Loss: 1.4870, Test Loss: 1.7377\n",
      "Epoch [12/50] - Train Loss: 1.4867, Test Loss: 1.7385\n",
      "Epoch [13/50] - Train Loss: 1.4863, Test Loss: 1.7393\n",
      "Epoch [14/50] - Train Loss: 1.4860, Test Loss: 1.7403\n",
      "Epoch [15/50] - Train Loss: 1.4856, Test Loss: 1.7414\n",
      "Epoch [16/50] - Train Loss: 1.4850, Test Loss: 1.7428\n",
      "Epoch [17/50] - Train Loss: 1.4840, Test Loss: 1.7445\n",
      "Epoch [18/50] - Train Loss: 1.4823, Test Loss: 1.7465\n",
      "Epoch [19/50] - Train Loss: 1.4799, Test Loss: 1.7493\n",
      "Epoch [20/50] - Train Loss: 1.4764, Test Loss: 1.7540\n",
      "Epoch [21/50] - Train Loss: 1.4712, Test Loss: 1.7622\n",
      "Epoch [22/50] - Train Loss: 1.4630, Test Loss: 1.7798\n",
      "Epoch [23/50] - Train Loss: 1.4527, Test Loss: 1.8023\n",
      "Epoch [24/50] - Train Loss: 1.4376, Test Loss: 1.8217\n",
      "Epoch [25/50] - Train Loss: 1.4302, Test Loss: 1.8528\n",
      "Epoch [26/50] - Train Loss: 1.4314, Test Loss: 1.8770\n",
      "Epoch [27/50] - Train Loss: 1.4326, Test Loss: 1.8826\n",
      "Epoch [28/50] - Train Loss: 1.4322, Test Loss: 1.8806\n",
      "Epoch [29/50] - Train Loss: 1.4313, Test Loss: 1.8844\n",
      "Epoch [30/50] - Train Loss: 1.4295, Test Loss: 1.8926\n",
      "Epoch [31/50] - Train Loss: 1.4271, Test Loss: 1.8909\n",
      "Epoch [32/50] - Train Loss: 1.4247, Test Loss: 1.8875\n",
      "Epoch [33/50] - Train Loss: 1.4235, Test Loss: 1.8920\n",
      "Epoch [34/50] - Train Loss: 1.4228, Test Loss: 1.9035\n",
      "Epoch [35/50] - Train Loss: 1.4215, Test Loss: 1.9141\n",
      "Epoch [36/50] - Train Loss: 1.4194, Test Loss: 1.9177\n",
      "Epoch [37/50] - Train Loss: 1.4166, Test Loss: 1.9209\n",
      "Epoch [38/50] - Train Loss: 1.4131, Test Loss: 1.9314\n",
      "Epoch [39/50] - Train Loss: 1.4076, Test Loss: 1.9456\n",
      "Epoch [40/50] - Train Loss: 1.3978, Test Loss: 1.9629\n",
      "Epoch [41/50] - Train Loss: 1.3854, Test Loss: 1.9982\n",
      "Epoch [42/50] - Train Loss: 1.3774, Test Loss: 2.0174\n",
      "Epoch [43/50] - Train Loss: 1.3731, Test Loss: 2.0021\n",
      "Epoch [44/50] - Train Loss: 1.3693, Test Loss: 1.9377\n",
      "Epoch [45/50] - Train Loss: 1.3666, Test Loss: 1.9799\n",
      "Epoch [46/50] - Train Loss: 1.3530, Test Loss: 1.9822\n",
      "Epoch [47/50] - Train Loss: 1.3563, Test Loss: 1.8081\n",
      "Epoch [48/50] - Train Loss: 1.3249, Test Loss: 2.4571\n",
      "Epoch [49/50] - Train Loss: 1.7958, Test Loss: 2.0101\n",
      "Epoch [50/50] - Train Loss: 1.5207, Test Loss: 1.7990\n",
      "Avg Test Loss: 1.7990\n",
      "Testing combination: (8, 3, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1268, Test Loss: 1.0808\n",
      "Epoch [2/50] - Train Loss: 1.1230, Test Loss: 1.0808\n",
      "Epoch [3/50] - Train Loss: 1.1213, Test Loss: 1.0810\n",
      "Epoch [4/50] - Train Loss: 1.1201, Test Loss: 1.0814\n",
      "Epoch [5/50] - Train Loss: 1.1192, Test Loss: 1.0819\n",
      "Epoch [6/50] - Train Loss: 1.1184, Test Loss: 1.0824\n",
      "Epoch [7/50] - Train Loss: 1.1178, Test Loss: 1.0830\n",
      "Epoch [8/50] - Train Loss: 1.1173, Test Loss: 1.0836\n",
      "Epoch [9/50] - Train Loss: 1.1169, Test Loss: 1.0842\n",
      "Epoch [10/50] - Train Loss: 1.1166, Test Loss: 1.0848\n",
      "Epoch [11/50] - Train Loss: 1.1163, Test Loss: 1.0853\n",
      "Epoch [12/50] - Train Loss: 1.1160, Test Loss: 1.0858\n",
      "Epoch [13/50] - Train Loss: 1.1157, Test Loss: 1.0863\n",
      "Epoch [14/50] - Train Loss: 1.1154, Test Loss: 1.0868\n",
      "Epoch [15/50] - Train Loss: 1.1151, Test Loss: 1.0873\n",
      "Epoch [16/50] - Train Loss: 1.1148, Test Loss: 1.0877\n",
      "Epoch [17/50] - Train Loss: 1.1145, Test Loss: 1.0882\n",
      "Epoch [18/50] - Train Loss: 1.1141, Test Loss: 1.0887\n",
      "Epoch [19/50] - Train Loss: 1.1136, Test Loss: 1.0891\n",
      "Epoch [20/50] - Train Loss: 1.1131, Test Loss: 1.0897\n",
      "Epoch [21/50] - Train Loss: 1.1125, Test Loss: 1.0903\n",
      "Epoch [22/50] - Train Loss: 1.1116, Test Loss: 1.0910\n",
      "Epoch [23/50] - Train Loss: 1.1105, Test Loss: 1.0918\n",
      "Epoch [24/50] - Train Loss: 1.1088, Test Loss: 1.0929\n",
      "Epoch [25/50] - Train Loss: 1.1064, Test Loss: 1.0944\n",
      "Epoch [26/50] - Train Loss: 1.1033, Test Loss: 1.0966\n",
      "Epoch [27/50] - Train Loss: 1.0999, Test Loss: 1.0979\n",
      "Epoch [28/50] - Train Loss: 1.0960, Test Loss: 1.0995\n",
      "Epoch [29/50] - Train Loss: 1.0921, Test Loss: 1.1020\n",
      "Epoch [30/50] - Train Loss: 1.0884, Test Loss: 1.1049\n",
      "Epoch [31/50] - Train Loss: 1.0848, Test Loss: 1.1079\n",
      "Epoch [32/50] - Train Loss: 1.0818, Test Loss: 1.1111\n",
      "Epoch [33/50] - Train Loss: 1.0792, Test Loss: 1.1146\n",
      "Epoch [34/50] - Train Loss: 1.0771, Test Loss: 1.1181\n",
      "Epoch [35/50] - Train Loss: 1.0751, Test Loss: 1.1215\n",
      "Epoch [36/50] - Train Loss: 1.0730, Test Loss: 1.1246\n",
      "Epoch [37/50] - Train Loss: 1.0707, Test Loss: 1.1275\n",
      "Epoch [38/50] - Train Loss: 1.0680, Test Loss: 1.1305\n",
      "Epoch [39/50] - Train Loss: 1.0649, Test Loss: 1.1344\n",
      "Epoch [40/50] - Train Loss: 1.0614, Test Loss: 1.1408\n",
      "Epoch [41/50] - Train Loss: 1.0568, Test Loss: 1.1498\n",
      "Epoch [42/50] - Train Loss: 1.0511, Test Loss: 1.1624\n",
      "Epoch [43/50] - Train Loss: 1.0448, Test Loss: 1.1712\n",
      "Epoch [44/50] - Train Loss: 1.0409, Test Loss: 1.1810\n",
      "Epoch [45/50] - Train Loss: 1.0513, Test Loss: 1.1675\n",
      "Epoch [46/50] - Train Loss: 1.0623, Test Loss: 1.1266\n",
      "Epoch [47/50] - Train Loss: 1.0509, Test Loss: 1.2147\n",
      "Epoch [48/50] - Train Loss: 1.0528, Test Loss: 1.1935\n",
      "Epoch [49/50] - Train Loss: 1.0365, Test Loss: 1.1400\n",
      "Epoch [50/50] - Train Loss: 1.0396, Test Loss: 1.1550\n",
      "Avg Test Loss: 1.1550\n",
      "Testing combination: (8, 3, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1797, Test Loss: 1.1224\n",
      "Epoch [2/50] - Train Loss: 1.1727, Test Loss: 1.1239\n",
      "Epoch [3/50] - Train Loss: 1.1680, Test Loss: 1.1259\n",
      "Epoch [4/50] - Train Loss: 1.1640, Test Loss: 1.1283\n",
      "Epoch [5/50] - Train Loss: 1.1607, Test Loss: 1.1310\n",
      "Epoch [6/50] - Train Loss: 1.1579, Test Loss: 1.1338\n",
      "Epoch [7/50] - Train Loss: 1.1555, Test Loss: 1.1369\n",
      "Epoch [8/50] - Train Loss: 1.1535, Test Loss: 1.1401\n",
      "Epoch [9/50] - Train Loss: 1.1517, Test Loss: 1.1434\n",
      "Epoch [10/50] - Train Loss: 1.1501, Test Loss: 1.1468\n",
      "Epoch [11/50] - Train Loss: 1.1488, Test Loss: 1.1501\n",
      "Epoch [12/50] - Train Loss: 1.1475, Test Loss: 1.1532\n",
      "Epoch [13/50] - Train Loss: 1.1463, Test Loss: 1.1562\n",
      "Epoch [14/50] - Train Loss: 1.1453, Test Loss: 1.1590\n",
      "Epoch [15/50] - Train Loss: 1.1442, Test Loss: 1.1615\n",
      "Epoch [16/50] - Train Loss: 1.1431, Test Loss: 1.1639\n",
      "Epoch [17/50] - Train Loss: 1.1420, Test Loss: 1.1660\n",
      "Epoch [18/50] - Train Loss: 1.1407, Test Loss: 1.1679\n",
      "Epoch [19/50] - Train Loss: 1.1393, Test Loss: 1.1696\n",
      "Epoch [20/50] - Train Loss: 1.1378, Test Loss: 1.1712\n",
      "Epoch [21/50] - Train Loss: 1.1361, Test Loss: 1.1727\n",
      "Epoch [22/50] - Train Loss: 1.1341, Test Loss: 1.1742\n",
      "Epoch [23/50] - Train Loss: 1.1318, Test Loss: 1.1756\n",
      "Epoch [24/50] - Train Loss: 1.1291, Test Loss: 1.1770\n",
      "Epoch [25/50] - Train Loss: 1.1258, Test Loss: 1.1786\n",
      "Epoch [26/50] - Train Loss: 1.1219, Test Loss: 1.1803\n",
      "Epoch [27/50] - Train Loss: 1.1173, Test Loss: 1.1822\n",
      "Epoch [28/50] - Train Loss: 1.1118, Test Loss: 1.1842\n",
      "Epoch [29/50] - Train Loss: 1.1055, Test Loss: 1.1865\n",
      "Epoch [30/50] - Train Loss: 1.0985, Test Loss: 1.1889\n",
      "Epoch [31/50] - Train Loss: 1.0910, Test Loss: 1.1916\n",
      "Epoch [32/50] - Train Loss: 1.0835, Test Loss: 1.1945\n",
      "Epoch [33/50] - Train Loss: 1.0764, Test Loss: 1.1977\n",
      "Epoch [34/50] - Train Loss: 1.0701, Test Loss: 1.2010\n",
      "Epoch [35/50] - Train Loss: 1.0649, Test Loss: 1.2044\n",
      "Epoch [36/50] - Train Loss: 1.0610, Test Loss: 1.2078\n",
      "Epoch [37/50] - Train Loss: 1.0581, Test Loss: 1.2110\n",
      "Epoch [38/50] - Train Loss: 1.0561, Test Loss: 1.2140\n",
      "Epoch [39/50] - Train Loss: 1.0547, Test Loss: 1.2168\n",
      "Epoch [40/50] - Train Loss: 1.0537, Test Loss: 1.2193\n",
      "Epoch [41/50] - Train Loss: 1.0530, Test Loss: 1.2215\n",
      "Epoch [42/50] - Train Loss: 1.0524, Test Loss: 1.2235\n",
      "Epoch [43/50] - Train Loss: 1.0519, Test Loss: 1.2254\n",
      "Epoch [44/50] - Train Loss: 1.0515, Test Loss: 1.2271\n",
      "Epoch [45/50] - Train Loss: 1.0511, Test Loss: 1.2287\n",
      "Epoch [46/50] - Train Loss: 1.0507, Test Loss: 1.2303\n",
      "Epoch [47/50] - Train Loss: 1.0502, Test Loss: 1.2318\n",
      "Epoch [48/50] - Train Loss: 1.0498, Test Loss: 1.2333\n",
      "Epoch [49/50] - Train Loss: 1.0492, Test Loss: 1.2348\n",
      "Epoch [50/50] - Train Loss: 1.0487, Test Loss: 1.2363\n",
      "Avg Test Loss: 1.2363\n",
      "Testing combination: (8, 3, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.4883, Test Loss: 1.7340\n",
      "Epoch [2/50] - Train Loss: 1.4871, Test Loss: 1.7340\n",
      "Epoch [3/50] - Train Loss: 1.4869, Test Loss: 1.7340\n",
      "Epoch [4/50] - Train Loss: 1.4867, Test Loss: 1.7340\n",
      "Epoch [5/50] - Train Loss: 1.4865, Test Loss: 1.7339\n",
      "Epoch [6/50] - Train Loss: 1.4864, Test Loss: 1.7339\n",
      "Epoch [7/50] - Train Loss: 1.4863, Test Loss: 1.7339\n",
      "Epoch [8/50] - Train Loss: 1.4862, Test Loss: 1.7339\n",
      "Epoch [9/50] - Train Loss: 1.4860, Test Loss: 1.7339\n",
      "Epoch [10/50] - Train Loss: 1.4859, Test Loss: 1.7340\n",
      "Epoch [11/50] - Train Loss: 1.4858, Test Loss: 1.7340\n",
      "Epoch [12/50] - Train Loss: 1.4857, Test Loss: 1.7341\n",
      "Epoch [13/50] - Train Loss: 1.4856, Test Loss: 1.7341\n",
      "Epoch [14/50] - Train Loss: 1.4855, Test Loss: 1.7342\n",
      "Epoch [15/50] - Train Loss: 1.4854, Test Loss: 1.7343\n",
      "Epoch [16/50] - Train Loss: 1.4853, Test Loss: 1.7344\n",
      "Epoch [17/50] - Train Loss: 1.4851, Test Loss: 1.7345\n",
      "Epoch [18/50] - Train Loss: 1.4850, Test Loss: 1.7346\n",
      "Epoch [19/50] - Train Loss: 1.4849, Test Loss: 1.7348\n",
      "Epoch [20/50] - Train Loss: 1.4847, Test Loss: 1.7350\n",
      "Epoch [21/50] - Train Loss: 1.4845, Test Loss: 1.7353\n",
      "Epoch [22/50] - Train Loss: 1.4843, Test Loss: 1.7356\n",
      "Epoch [23/50] - Train Loss: 1.4841, Test Loss: 1.7360\n",
      "Epoch [24/50] - Train Loss: 1.4838, Test Loss: 1.7364\n",
      "Epoch [25/50] - Train Loss: 1.4836, Test Loss: 1.7370\n",
      "Epoch [26/50] - Train Loss: 1.4832, Test Loss: 1.7376\n",
      "Epoch [27/50] - Train Loss: 1.4828, Test Loss: 1.7383\n",
      "Epoch [28/50] - Train Loss: 1.4823, Test Loss: 1.7392\n",
      "Epoch [29/50] - Train Loss: 1.4817, Test Loss: 1.7401\n",
      "Epoch [30/50] - Train Loss: 1.4809, Test Loss: 1.7412\n",
      "Epoch [31/50] - Train Loss: 1.4800, Test Loss: 1.7425\n",
      "Epoch [32/50] - Train Loss: 1.4787, Test Loss: 1.7440\n",
      "Epoch [33/50] - Train Loss: 1.4772, Test Loss: 1.7458\n",
      "Epoch [34/50] - Train Loss: 1.4755, Test Loss: 1.7482\n",
      "Epoch [35/50] - Train Loss: 1.4736, Test Loss: 1.7510\n",
      "Epoch [36/50] - Train Loss: 1.4715, Test Loss: 1.7539\n",
      "Epoch [37/50] - Train Loss: 1.4689, Test Loss: 1.7566\n",
      "Epoch [38/50] - Train Loss: 1.4663, Test Loss: 1.7595\n",
      "Epoch [39/50] - Train Loss: 1.4636, Test Loss: 1.7628\n",
      "Epoch [40/50] - Train Loss: 1.4608, Test Loss: 1.7666\n",
      "Epoch [41/50] - Train Loss: 1.4580, Test Loss: 1.7708\n",
      "Epoch [42/50] - Train Loss: 1.4551, Test Loss: 1.7755\n",
      "Epoch [43/50] - Train Loss: 1.4523, Test Loss: 1.7805\n",
      "Epoch [44/50] - Train Loss: 1.4495, Test Loss: 1.7858\n",
      "Epoch [45/50] - Train Loss: 1.4468, Test Loss: 1.7911\n",
      "Epoch [46/50] - Train Loss: 1.4442, Test Loss: 1.7967\n",
      "Epoch [47/50] - Train Loss: 1.4418, Test Loss: 1.8026\n",
      "Epoch [48/50] - Train Loss: 1.4395, Test Loss: 1.8087\n",
      "Epoch [49/50] - Train Loss: 1.4373, Test Loss: 1.8149\n",
      "Epoch [50/50] - Train Loss: 1.4352, Test Loss: 1.8212\n",
      "Avg Test Loss: 1.8212\n",
      "Testing combination: (8, 3, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1202, Test Loss: 1.0807\n",
      "Epoch [2/50] - Train Loss: 1.1199, Test Loss: 1.0808\n",
      "Epoch [3/50] - Train Loss: 1.1197, Test Loss: 1.0808\n",
      "Epoch [4/50] - Train Loss: 1.1196, Test Loss: 1.0809\n",
      "Epoch [5/50] - Train Loss: 1.1195, Test Loss: 1.0809\n",
      "Epoch [6/50] - Train Loss: 1.1194, Test Loss: 1.0810\n",
      "Epoch [7/50] - Train Loss: 1.1193, Test Loss: 1.0810\n",
      "Epoch [8/50] - Train Loss: 1.1191, Test Loss: 1.0811\n",
      "Epoch [9/50] - Train Loss: 1.1190, Test Loss: 1.0812\n",
      "Epoch [10/50] - Train Loss: 1.1189, Test Loss: 1.0812\n",
      "Epoch [11/50] - Train Loss: 1.1188, Test Loss: 1.0813\n",
      "Epoch [12/50] - Train Loss: 1.1187, Test Loss: 1.0813\n",
      "Epoch [13/50] - Train Loss: 1.1186, Test Loss: 1.0814\n",
      "Epoch [14/50] - Train Loss: 1.1186, Test Loss: 1.0814\n",
      "Epoch [15/50] - Train Loss: 1.1185, Test Loss: 1.0815\n",
      "Epoch [16/50] - Train Loss: 1.1184, Test Loss: 1.0816\n",
      "Epoch [17/50] - Train Loss: 1.1183, Test Loss: 1.0816\n",
      "Epoch [18/50] - Train Loss: 1.1182, Test Loss: 1.0817\n",
      "Epoch [19/50] - Train Loss: 1.1181, Test Loss: 1.0817\n",
      "Epoch [20/50] - Train Loss: 1.1181, Test Loss: 1.0818\n",
      "Epoch [21/50] - Train Loss: 1.1180, Test Loss: 1.0819\n",
      "Epoch [22/50] - Train Loss: 1.1179, Test Loss: 1.0819\n",
      "Epoch [23/50] - Train Loss: 1.1178, Test Loss: 1.0820\n",
      "Epoch [24/50] - Train Loss: 1.1178, Test Loss: 1.0821\n",
      "Epoch [25/50] - Train Loss: 1.1177, Test Loss: 1.0822\n",
      "Epoch [26/50] - Train Loss: 1.1176, Test Loss: 1.0822\n",
      "Epoch [27/50] - Train Loss: 1.1175, Test Loss: 1.0823\n",
      "Epoch [28/50] - Train Loss: 1.1175, Test Loss: 1.0824\n",
      "Epoch [29/50] - Train Loss: 1.1174, Test Loss: 1.0825\n",
      "Epoch [30/50] - Train Loss: 1.1173, Test Loss: 1.0826\n",
      "Epoch [31/50] - Train Loss: 1.1173, Test Loss: 1.0826\n",
      "Epoch [32/50] - Train Loss: 1.1172, Test Loss: 1.0827\n",
      "Epoch [33/50] - Train Loss: 1.1171, Test Loss: 1.0828\n",
      "Epoch [34/50] - Train Loss: 1.1171, Test Loss: 1.0829\n",
      "Epoch [35/50] - Train Loss: 1.1170, Test Loss: 1.0829\n",
      "Epoch [36/50] - Train Loss: 1.1170, Test Loss: 1.0830\n",
      "Epoch [37/50] - Train Loss: 1.1169, Test Loss: 1.0831\n",
      "Epoch [38/50] - Train Loss: 1.1169, Test Loss: 1.0832\n",
      "Epoch [39/50] - Train Loss: 1.1168, Test Loss: 1.0832\n",
      "Epoch [40/50] - Train Loss: 1.1168, Test Loss: 1.0833\n",
      "Epoch [41/50] - Train Loss: 1.1167, Test Loss: 1.0834\n",
      "Epoch [42/50] - Train Loss: 1.1167, Test Loss: 1.0835\n",
      "Epoch [43/50] - Train Loss: 1.1166, Test Loss: 1.0835\n",
      "Epoch [44/50] - Train Loss: 1.1166, Test Loss: 1.0836\n",
      "Epoch [45/50] - Train Loss: 1.1165, Test Loss: 1.0837\n",
      "Epoch [46/50] - Train Loss: 1.1165, Test Loss: 1.0838\n",
      "Epoch [47/50] - Train Loss: 1.1164, Test Loss: 1.0838\n",
      "Epoch [48/50] - Train Loss: 1.1164, Test Loss: 1.0839\n",
      "Epoch [49/50] - Train Loss: 1.1163, Test Loss: 1.0840\n",
      "Epoch [50/50] - Train Loss: 1.1163, Test Loss: 1.0841\n",
      "Avg Test Loss: 1.0841\n",
      "Testing combination: (8, 3, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1506, Test Loss: 1.1476\n",
      "Epoch [2/50] - Train Loss: 1.1504, Test Loss: 1.1477\n",
      "Epoch [3/50] - Train Loss: 1.1504, Test Loss: 1.1478\n",
      "Epoch [4/50] - Train Loss: 1.1504, Test Loss: 1.1479\n",
      "Epoch [5/50] - Train Loss: 1.1503, Test Loss: 1.1480\n",
      "Epoch [6/50] - Train Loss: 1.1503, Test Loss: 1.1481\n",
      "Epoch [7/50] - Train Loss: 1.1503, Test Loss: 1.1482\n",
      "Epoch [8/50] - Train Loss: 1.1502, Test Loss: 1.1483\n",
      "Epoch [9/50] - Train Loss: 1.1502, Test Loss: 1.1484\n",
      "Epoch [10/50] - Train Loss: 1.1502, Test Loss: 1.1485\n",
      "Epoch [11/50] - Train Loss: 1.1502, Test Loss: 1.1487\n",
      "Epoch [12/50] - Train Loss: 1.1501, Test Loss: 1.1488\n",
      "Epoch [13/50] - Train Loss: 1.1501, Test Loss: 1.1489\n",
      "Epoch [14/50] - Train Loss: 1.1501, Test Loss: 1.1490\n",
      "Epoch [15/50] - Train Loss: 1.1500, Test Loss: 1.1491\n",
      "Epoch [16/50] - Train Loss: 1.1500, Test Loss: 1.1492\n",
      "Epoch [17/50] - Train Loss: 1.1500, Test Loss: 1.1493\n",
      "Epoch [18/50] - Train Loss: 1.1500, Test Loss: 1.1494\n",
      "Epoch [19/50] - Train Loss: 1.1499, Test Loss: 1.1495\n",
      "Epoch [20/50] - Train Loss: 1.1499, Test Loss: 1.1496\n",
      "Epoch [21/50] - Train Loss: 1.1499, Test Loss: 1.1497\n",
      "Epoch [22/50] - Train Loss: 1.1498, Test Loss: 1.1498\n",
      "Epoch [23/50] - Train Loss: 1.1498, Test Loss: 1.1499\n",
      "Epoch [24/50] - Train Loss: 1.1498, Test Loss: 1.1500\n",
      "Epoch [25/50] - Train Loss: 1.1498, Test Loss: 1.1501\n",
      "Epoch [26/50] - Train Loss: 1.1497, Test Loss: 1.1502\n",
      "Epoch [27/50] - Train Loss: 1.1497, Test Loss: 1.1503\n",
      "Epoch [28/50] - Train Loss: 1.1497, Test Loss: 1.1504\n",
      "Epoch [29/50] - Train Loss: 1.1497, Test Loss: 1.1505\n",
      "Epoch [30/50] - Train Loss: 1.1496, Test Loss: 1.1506\n",
      "Epoch [31/50] - Train Loss: 1.1496, Test Loss: 1.1507\n",
      "Epoch [32/50] - Train Loss: 1.1496, Test Loss: 1.1508\n",
      "Epoch [33/50] - Train Loss: 1.1495, Test Loss: 1.1509\n",
      "Epoch [34/50] - Train Loss: 1.1495, Test Loss: 1.1510\n",
      "Epoch [35/50] - Train Loss: 1.1495, Test Loss: 1.1511\n",
      "Epoch [36/50] - Train Loss: 1.1495, Test Loss: 1.1512\n",
      "Epoch [37/50] - Train Loss: 1.1494, Test Loss: 1.1513\n",
      "Epoch [38/50] - Train Loss: 1.1494, Test Loss: 1.1514\n",
      "Epoch [39/50] - Train Loss: 1.1494, Test Loss: 1.1515\n",
      "Epoch [40/50] - Train Loss: 1.1494, Test Loss: 1.1516\n",
      "Epoch [41/50] - Train Loss: 1.1493, Test Loss: 1.1516\n",
      "Epoch [42/50] - Train Loss: 1.1493, Test Loss: 1.1517\n",
      "Epoch [43/50] - Train Loss: 1.1493, Test Loss: 1.1518\n",
      "Epoch [44/50] - Train Loss: 1.1493, Test Loss: 1.1519\n",
      "Epoch [45/50] - Train Loss: 1.1492, Test Loss: 1.1520\n",
      "Epoch [46/50] - Train Loss: 1.1492, Test Loss: 1.1521\n",
      "Epoch [47/50] - Train Loss: 1.1492, Test Loss: 1.1522\n",
      "Epoch [48/50] - Train Loss: 1.1491, Test Loss: 1.1523\n",
      "Epoch [49/50] - Train Loss: 1.1491, Test Loss: 1.1524\n",
      "Epoch [50/50] - Train Loss: 1.1491, Test Loss: 1.1525\n",
      "Avg Test Loss: 1.1525\n",
      "Testing combination: (8, 3, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.6605, Test Loss: 1.9799\n",
      "Epoch [2/50] - Train Loss: 1.6593, Test Loss: 1.9782\n",
      "Epoch [3/50] - Train Loss: 1.6581, Test Loss: 1.9764\n",
      "Epoch [4/50] - Train Loss: 1.6569, Test Loss: 1.9747\n",
      "Epoch [5/50] - Train Loss: 1.6557, Test Loss: 1.9730\n",
      "Epoch [6/50] - Train Loss: 1.6545, Test Loss: 1.9713\n",
      "Epoch [7/50] - Train Loss: 1.6533, Test Loss: 1.9696\n",
      "Epoch [8/50] - Train Loss: 1.6522, Test Loss: 1.9679\n",
      "Epoch [9/50] - Train Loss: 1.6510, Test Loss: 1.9663\n",
      "Epoch [10/50] - Train Loss: 1.6499, Test Loss: 1.9646\n",
      "Epoch [11/50] - Train Loss: 1.6488, Test Loss: 1.9630\n",
      "Epoch [12/50] - Train Loss: 1.6477, Test Loss: 1.9614\n",
      "Epoch [13/50] - Train Loss: 1.6466, Test Loss: 1.9598\n",
      "Epoch [14/50] - Train Loss: 1.6455, Test Loss: 1.9583\n",
      "Epoch [15/50] - Train Loss: 1.6444, Test Loss: 1.9567\n",
      "Epoch [16/50] - Train Loss: 1.6433, Test Loss: 1.9552\n",
      "Epoch [17/50] - Train Loss: 1.6422, Test Loss: 1.9537\n",
      "Epoch [18/50] - Train Loss: 1.6412, Test Loss: 1.9521\n",
      "Epoch [19/50] - Train Loss: 1.6401, Test Loss: 1.9506\n",
      "Epoch [20/50] - Train Loss: 1.6391, Test Loss: 1.9492\n",
      "Epoch [21/50] - Train Loss: 1.6381, Test Loss: 1.9477\n",
      "Epoch [22/50] - Train Loss: 1.6370, Test Loss: 1.9462\n",
      "Epoch [23/50] - Train Loss: 1.6360, Test Loss: 1.9447\n",
      "Epoch [24/50] - Train Loss: 1.6350, Test Loss: 1.9433\n",
      "Epoch [25/50] - Train Loss: 1.6339, Test Loss: 1.9418\n",
      "Epoch [26/50] - Train Loss: 1.6329, Test Loss: 1.9404\n",
      "Epoch [27/50] - Train Loss: 1.6319, Test Loss: 1.9390\n",
      "Epoch [28/50] - Train Loss: 1.6309, Test Loss: 1.9375\n",
      "Epoch [29/50] - Train Loss: 1.6299, Test Loss: 1.9361\n",
      "Epoch [30/50] - Train Loss: 1.6289, Test Loss: 1.9347\n",
      "Epoch [31/50] - Train Loss: 1.6279, Test Loss: 1.9333\n",
      "Epoch [32/50] - Train Loss: 1.6269, Test Loss: 1.9319\n",
      "Epoch [33/50] - Train Loss: 1.6259, Test Loss: 1.9305\n",
      "Epoch [34/50] - Train Loss: 1.6249, Test Loss: 1.9291\n",
      "Epoch [35/50] - Train Loss: 1.6239, Test Loss: 1.9277\n",
      "Epoch [36/50] - Train Loss: 1.6228, Test Loss: 1.9263\n",
      "Epoch [37/50] - Train Loss: 1.6218, Test Loss: 1.9249\n",
      "Epoch [38/50] - Train Loss: 1.6208, Test Loss: 1.9236\n",
      "Epoch [39/50] - Train Loss: 1.6198, Test Loss: 1.9222\n",
      "Epoch [40/50] - Train Loss: 1.6188, Test Loss: 1.9208\n",
      "Epoch [41/50] - Train Loss: 1.6177, Test Loss: 1.9194\n",
      "Epoch [42/50] - Train Loss: 1.6167, Test Loss: 1.9180\n",
      "Epoch [43/50] - Train Loss: 1.6157, Test Loss: 1.9166\n",
      "Epoch [44/50] - Train Loss: 1.6146, Test Loss: 1.9152\n",
      "Epoch [45/50] - Train Loss: 1.6136, Test Loss: 1.9138\n",
      "Epoch [46/50] - Train Loss: 1.6125, Test Loss: 1.9124\n",
      "Epoch [47/50] - Train Loss: 1.6115, Test Loss: 1.9110\n",
      "Epoch [48/50] - Train Loss: 1.6104, Test Loss: 1.9096\n",
      "Epoch [49/50] - Train Loss: 1.6094, Test Loss: 1.9082\n",
      "Epoch [50/50] - Train Loss: 1.6083, Test Loss: 1.9068\n",
      "Avg Test Loss: 1.9068\n",
      "Testing combination: (8, 4, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1378, Test Loss: 1.0884\n",
      "Epoch [2/50] - Train Loss: 1.1201, Test Loss: 1.0843\n",
      "Epoch [3/50] - Train Loss: 1.1204, Test Loss: 1.0868\n",
      "Epoch [4/50] - Train Loss: 1.1193, Test Loss: 1.0884\n",
      "Epoch [5/50] - Train Loss: 1.1186, Test Loss: 1.0884\n",
      "Epoch [6/50] - Train Loss: 1.1180, Test Loss: 1.0882\n",
      "Epoch [7/50] - Train Loss: 1.1171, Test Loss: 1.0889\n",
      "Epoch [8/50] - Train Loss: 1.1146, Test Loss: 1.0910\n",
      "Epoch [9/50] - Train Loss: 1.1080, Test Loss: 1.0999\n",
      "Epoch [10/50] - Train Loss: 1.1474, Test Loss: 1.1073\n",
      "Epoch [11/50] - Train Loss: 1.1183, Test Loss: 1.0852\n",
      "Epoch [12/50] - Train Loss: 1.1195, Test Loss: 1.0840\n",
      "Epoch [13/50] - Train Loss: 1.1197, Test Loss: 1.0863\n",
      "Epoch [14/50] - Train Loss: 1.1189, Test Loss: 1.0878\n",
      "Epoch [15/50] - Train Loss: 1.1184, Test Loss: 1.0880\n",
      "Epoch [16/50] - Train Loss: 1.1182, Test Loss: 1.0875\n",
      "Epoch [17/50] - Train Loss: 1.1182, Test Loss: 1.0872\n",
      "Epoch [18/50] - Train Loss: 1.1182, Test Loss: 1.0871\n",
      "Epoch [19/50] - Train Loss: 1.1181, Test Loss: 1.0871\n",
      "Epoch [20/50] - Train Loss: 1.1181, Test Loss: 1.0872\n",
      "Epoch [21/50] - Train Loss: 1.1180, Test Loss: 1.0872\n",
      "Epoch [22/50] - Train Loss: 1.1179, Test Loss: 1.0872\n",
      "Epoch [23/50] - Train Loss: 1.1178, Test Loss: 1.0872\n",
      "Epoch [24/50] - Train Loss: 1.1177, Test Loss: 1.0871\n",
      "Epoch [25/50] - Train Loss: 1.1174, Test Loss: 1.0870\n",
      "Epoch [26/50] - Train Loss: 1.1171, Test Loss: 1.0869\n",
      "Epoch [27/50] - Train Loss: 1.1166, Test Loss: 1.0867\n",
      "Epoch [28/50] - Train Loss: 1.1155, Test Loss: 1.0865\n",
      "Epoch [29/50] - Train Loss: 1.1137, Test Loss: 1.0864\n",
      "Epoch [30/50] - Train Loss: 1.1105, Test Loss: 1.0862\n",
      "Epoch [31/50] - Train Loss: 1.1077, Test Loss: 1.0896\n",
      "Epoch [32/50] - Train Loss: 1.1077, Test Loss: 1.0930\n",
      "Epoch [33/50] - Train Loss: 1.0942, Test Loss: 1.0942\n",
      "Epoch [34/50] - Train Loss: 1.0915, Test Loss: 1.1082\n",
      "Epoch [35/50] - Train Loss: 1.1173, Test Loss: 1.0962\n",
      "Epoch [36/50] - Train Loss: 1.0930, Test Loss: 1.1180\n",
      "Epoch [37/50] - Train Loss: 1.0838, Test Loss: 1.1168\n",
      "Epoch [38/50] - Train Loss: 1.0845, Test Loss: 1.1256\n",
      "Epoch [39/50] - Train Loss: 1.0804, Test Loss: 1.1337\n",
      "Epoch [40/50] - Train Loss: 1.0764, Test Loss: 1.1381\n",
      "Epoch [41/50] - Train Loss: 1.0732, Test Loss: 1.1401\n",
      "Epoch [42/50] - Train Loss: 1.0708, Test Loss: 1.1429\n",
      "Epoch [43/50] - Train Loss: 1.0691, Test Loss: 1.1500\n",
      "Epoch [44/50] - Train Loss: 1.0685, Test Loss: 1.1614\n",
      "Epoch [45/50] - Train Loss: 1.0647, Test Loss: 1.1794\n",
      "Epoch [46/50] - Train Loss: 1.0594, Test Loss: 1.2127\n",
      "Epoch [47/50] - Train Loss: 1.0574, Test Loss: 1.2178\n",
      "Epoch [48/50] - Train Loss: 1.0563, Test Loss: 1.2277\n",
      "Epoch [49/50] - Train Loss: 1.0561, Test Loss: 1.2139\n",
      "Epoch [50/50] - Train Loss: 1.0577, Test Loss: 1.2486\n",
      "Avg Test Loss: 1.2486\n",
      "Testing combination: (8, 4, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1743, Test Loss: 1.1319\n",
      "Epoch [2/50] - Train Loss: 1.1554, Test Loss: 1.1450\n",
      "Epoch [3/50] - Train Loss: 1.1515, Test Loss: 1.1568\n",
      "Epoch [4/50] - Train Loss: 1.1511, Test Loss: 1.1637\n",
      "Epoch [5/50] - Train Loss: 1.1513, Test Loss: 1.1657\n",
      "Epoch [6/50] - Train Loss: 1.1513, Test Loss: 1.1653\n",
      "Epoch [7/50] - Train Loss: 1.1512, Test Loss: 1.1642\n",
      "Epoch [8/50] - Train Loss: 1.1510, Test Loss: 1.1632\n",
      "Epoch [9/50] - Train Loss: 1.1509, Test Loss: 1.1627\n",
      "Epoch [10/50] - Train Loss: 1.1508, Test Loss: 1.1625\n",
      "Epoch [11/50] - Train Loss: 1.1507, Test Loss: 1.1626\n",
      "Epoch [12/50] - Train Loss: 1.1507, Test Loss: 1.1627\n",
      "Epoch [13/50] - Train Loss: 1.1507, Test Loss: 1.1629\n",
      "Epoch [14/50] - Train Loss: 1.1506, Test Loss: 1.1630\n",
      "Epoch [15/50] - Train Loss: 1.1506, Test Loss: 1.1631\n",
      "Epoch [16/50] - Train Loss: 1.1506, Test Loss: 1.1632\n",
      "Epoch [17/50] - Train Loss: 1.1506, Test Loss: 1.1632\n",
      "Epoch [18/50] - Train Loss: 1.1505, Test Loss: 1.1632\n",
      "Epoch [19/50] - Train Loss: 1.1505, Test Loss: 1.1633\n",
      "Epoch [20/50] - Train Loss: 1.1505, Test Loss: 1.1633\n",
      "Epoch [21/50] - Train Loss: 1.1505, Test Loss: 1.1633\n",
      "Epoch [22/50] - Train Loss: 1.1505, Test Loss: 1.1633\n",
      "Epoch [23/50] - Train Loss: 1.1504, Test Loss: 1.1634\n",
      "Epoch [24/50] - Train Loss: 1.1504, Test Loss: 1.1634\n",
      "Epoch [25/50] - Train Loss: 1.1504, Test Loss: 1.1634\n",
      "Epoch [26/50] - Train Loss: 1.1504, Test Loss: 1.1634\n",
      "Epoch [27/50] - Train Loss: 1.1503, Test Loss: 1.1634\n",
      "Epoch [28/50] - Train Loss: 1.1503, Test Loss: 1.1634\n",
      "Epoch [29/50] - Train Loss: 1.1502, Test Loss: 1.1633\n",
      "Epoch [30/50] - Train Loss: 1.1509, Test Loss: 1.1643\n",
      "Epoch [31/50] - Train Loss: 1.1507, Test Loss: 1.1639\n",
      "Epoch [32/50] - Train Loss: 1.1505, Test Loss: 1.1637\n",
      "Epoch [33/50] - Train Loss: 1.1504, Test Loss: 1.1635\n",
      "Epoch [34/50] - Train Loss: 1.1503, Test Loss: 1.1634\n",
      "Epoch [35/50] - Train Loss: 1.1503, Test Loss: 1.1634\n",
      "Epoch [36/50] - Train Loss: 1.1503, Test Loss: 1.1635\n",
      "Epoch [37/50] - Train Loss: 1.1502, Test Loss: 1.1635\n",
      "Epoch [38/50] - Train Loss: 1.1502, Test Loss: 1.1636\n",
      "Epoch [39/50] - Train Loss: 1.1502, Test Loss: 1.1636\n",
      "Epoch [40/50] - Train Loss: 1.1502, Test Loss: 1.1637\n",
      "Epoch [41/50] - Train Loss: 1.1502, Test Loss: 1.1637\n",
      "Epoch [42/50] - Train Loss: 1.1502, Test Loss: 1.1637\n",
      "Epoch [43/50] - Train Loss: 1.1502, Test Loss: 1.1637\n",
      "Epoch [44/50] - Train Loss: 1.1501, Test Loss: 1.1637\n",
      "Epoch [45/50] - Train Loss: 1.1501, Test Loss: 1.1637\n",
      "Epoch [46/50] - Train Loss: 1.1501, Test Loss: 1.1638\n",
      "Epoch [47/50] - Train Loss: 1.1500, Test Loss: 1.1638\n",
      "Epoch [48/50] - Train Loss: 1.1499, Test Loss: 1.1637\n",
      "Epoch [49/50] - Train Loss: 1.1496, Test Loss: 1.1636\n",
      "Epoch [50/50] - Train Loss: 1.1515, Test Loss: 1.1644\n",
      "Avg Test Loss: 1.1644\n",
      "Testing combination: (8, 4, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5133, Test Loss: 1.7390\n",
      "Epoch [2/50] - Train Loss: 1.4927, Test Loss: 1.7345\n",
      "Epoch [3/50] - Train Loss: 1.4890, Test Loss: 1.7334\n",
      "Epoch [4/50] - Train Loss: 1.4876, Test Loss: 1.7332\n",
      "Epoch [5/50] - Train Loss: 1.4870, Test Loss: 1.7333\n",
      "Epoch [6/50] - Train Loss: 1.4865, Test Loss: 1.7333\n",
      "Epoch [7/50] - Train Loss: 1.4862, Test Loss: 1.7334\n",
      "Epoch [8/50] - Train Loss: 1.4859, Test Loss: 1.7335\n",
      "Epoch [9/50] - Train Loss: 1.4857, Test Loss: 1.7336\n",
      "Epoch [10/50] - Train Loss: 1.4855, Test Loss: 1.7338\n",
      "Epoch [11/50] - Train Loss: 1.4853, Test Loss: 1.7342\n",
      "Epoch [12/50] - Train Loss: 1.4850, Test Loss: 1.7347\n",
      "Epoch [13/50] - Train Loss: 1.4845, Test Loss: 1.7354\n",
      "Epoch [14/50] - Train Loss: 1.4837, Test Loss: 1.7364\n",
      "Epoch [15/50] - Train Loss: 1.4819, Test Loss: 1.7377\n",
      "Epoch [16/50] - Train Loss: 1.4787, Test Loss: 1.7408\n",
      "Epoch [17/50] - Train Loss: 1.4736, Test Loss: 1.7446\n",
      "Epoch [18/50] - Train Loss: 1.4641, Test Loss: 1.7534\n",
      "Epoch [19/50] - Train Loss: 1.4528, Test Loss: 1.7716\n",
      "Epoch [20/50] - Train Loss: 1.4415, Test Loss: 1.7941\n",
      "Epoch [21/50] - Train Loss: 1.4331, Test Loss: 1.8306\n",
      "Epoch [22/50] - Train Loss: 1.4330, Test Loss: 1.8548\n",
      "Epoch [23/50] - Train Loss: 1.4286, Test Loss: 1.8995\n",
      "Epoch [24/50] - Train Loss: 1.4283, Test Loss: 1.8770\n",
      "Epoch [25/50] - Train Loss: 1.4245, Test Loss: 1.8942\n",
      "Epoch [26/50] - Train Loss: 1.4237, Test Loss: 1.9325\n",
      "Epoch [27/50] - Train Loss: 1.4213, Test Loss: 1.8621\n",
      "Epoch [28/50] - Train Loss: 1.4186, Test Loss: 1.8757\n",
      "Epoch [29/50] - Train Loss: 1.4124, Test Loss: 1.9877\n",
      "Epoch [30/50] - Train Loss: 1.4155, Test Loss: 1.8108\n",
      "Epoch [31/50] - Train Loss: 1.4408, Test Loss: 1.8726\n",
      "Epoch [32/50] - Train Loss: 1.4576, Test Loss: 1.8840\n",
      "Epoch [33/50] - Train Loss: 1.4368, Test Loss: 1.8828\n",
      "Epoch [34/50] - Train Loss: 1.4328, Test Loss: 1.8790\n",
      "Epoch [35/50] - Train Loss: 1.4327, Test Loss: 1.8821\n",
      "Epoch [36/50] - Train Loss: 1.4319, Test Loss: 1.8879\n",
      "Epoch [37/50] - Train Loss: 1.4309, Test Loss: 1.8939\n",
      "Epoch [38/50] - Train Loss: 1.4299, Test Loss: 1.8994\n",
      "Epoch [39/50] - Train Loss: 1.4289, Test Loss: 1.9049\n",
      "Epoch [40/50] - Train Loss: 1.4278, Test Loss: 1.9111\n",
      "Epoch [41/50] - Train Loss: 1.4264, Test Loss: 1.9183\n",
      "Epoch [42/50] - Train Loss: 1.4249, Test Loss: 1.9269\n",
      "Epoch [43/50] - Train Loss: 1.4232, Test Loss: 1.9373\n",
      "Epoch [44/50] - Train Loss: 1.4213, Test Loss: 1.9491\n",
      "Epoch [45/50] - Train Loss: 1.4196, Test Loss: 1.9614\n",
      "Epoch [46/50] - Train Loss: 1.4182, Test Loss: 1.9739\n",
      "Epoch [47/50] - Train Loss: 1.4170, Test Loss: 1.9857\n",
      "Epoch [48/50] - Train Loss: 1.4159, Test Loss: 1.9957\n",
      "Epoch [49/50] - Train Loss: 1.4149, Test Loss: 2.0028\n",
      "Epoch [50/50] - Train Loss: 1.4139, Test Loss: 2.0070\n",
      "Avg Test Loss: 2.0070\n",
      "Testing combination: (8, 4, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1199, Test Loss: 1.0980\n",
      "Epoch [2/50] - Train Loss: 1.1183, Test Loss: 1.0963\n",
      "Epoch [3/50] - Train Loss: 1.1177, Test Loss: 1.0948\n",
      "Epoch [4/50] - Train Loss: 1.1173, Test Loss: 1.0935\n",
      "Epoch [5/50] - Train Loss: 1.1169, Test Loss: 1.0925\n",
      "Epoch [6/50] - Train Loss: 1.1167, Test Loss: 1.0916\n",
      "Epoch [7/50] - Train Loss: 1.1165, Test Loss: 1.0909\n",
      "Epoch [8/50] - Train Loss: 1.1163, Test Loss: 1.0904\n",
      "Epoch [9/50] - Train Loss: 1.1162, Test Loss: 1.0899\n",
      "Epoch [10/50] - Train Loss: 1.1160, Test Loss: 1.0896\n",
      "Epoch [11/50] - Train Loss: 1.1159, Test Loss: 1.0893\n",
      "Epoch [12/50] - Train Loss: 1.1157, Test Loss: 1.0891\n",
      "Epoch [13/50] - Train Loss: 1.1155, Test Loss: 1.0890\n",
      "Epoch [14/50] - Train Loss: 1.1153, Test Loss: 1.0890\n",
      "Epoch [15/50] - Train Loss: 1.1149, Test Loss: 1.0891\n",
      "Epoch [16/50] - Train Loss: 1.1143, Test Loss: 1.0892\n",
      "Epoch [17/50] - Train Loss: 1.1136, Test Loss: 1.0895\n",
      "Epoch [18/50] - Train Loss: 1.1126, Test Loss: 1.0898\n",
      "Epoch [19/50] - Train Loss: 1.1112, Test Loss: 1.0903\n",
      "Epoch [20/50] - Train Loss: 1.1093, Test Loss: 1.0912\n",
      "Epoch [21/50] - Train Loss: 1.1070, Test Loss: 1.0922\n",
      "Epoch [22/50] - Train Loss: 1.1040, Test Loss: 1.0932\n",
      "Epoch [23/50] - Train Loss: 1.1003, Test Loss: 1.0946\n",
      "Epoch [24/50] - Train Loss: 1.0962, Test Loss: 1.0963\n",
      "Epoch [25/50] - Train Loss: 1.0918, Test Loss: 1.0979\n",
      "Epoch [26/50] - Train Loss: 1.0874, Test Loss: 1.1000\n",
      "Epoch [27/50] - Train Loss: 1.0827, Test Loss: 1.1029\n",
      "Epoch [28/50] - Train Loss: 1.0765, Test Loss: 1.1045\n",
      "Epoch [29/50] - Train Loss: 1.0682, Test Loss: 1.1039\n",
      "Epoch [30/50] - Train Loss: 1.0531, Test Loss: 1.1487\n",
      "Epoch [31/50] - Train Loss: 1.0489, Test Loss: 1.0835\n",
      "Epoch [32/50] - Train Loss: 1.0543, Test Loss: 1.1269\n",
      "Epoch [33/50] - Train Loss: 1.0555, Test Loss: 1.1085\n",
      "Epoch [34/50] - Train Loss: 1.0780, Test Loss: 1.0963\n",
      "Epoch [35/50] - Train Loss: 1.0869, Test Loss: 1.1081\n",
      "Epoch [36/50] - Train Loss: 1.0661, Test Loss: 1.1232\n",
      "Epoch [37/50] - Train Loss: 1.0428, Test Loss: 1.2047\n",
      "Epoch [38/50] - Train Loss: 1.0348, Test Loss: 1.1518\n",
      "Epoch [39/50] - Train Loss: 1.0263, Test Loss: 1.1251\n",
      "Epoch [40/50] - Train Loss: 1.0377, Test Loss: 1.2343\n",
      "Epoch [41/50] - Train Loss: 0.9905, Test Loss: 1.1403\n",
      "Epoch [42/50] - Train Loss: 0.9976, Test Loss: 1.3426\n",
      "Epoch [43/50] - Train Loss: 1.0086, Test Loss: 1.2788\n",
      "Epoch [44/50] - Train Loss: 0.8992, Test Loss: 1.3001\n",
      "Epoch [45/50] - Train Loss: 0.9520, Test Loss: 1.1263\n",
      "Epoch [46/50] - Train Loss: 1.0913, Test Loss: 1.1224\n",
      "Epoch [47/50] - Train Loss: 1.0720, Test Loss: 1.1183\n",
      "Epoch [48/50] - Train Loss: 1.0884, Test Loss: 1.2486\n",
      "Epoch [49/50] - Train Loss: 0.9418, Test Loss: 1.1252\n",
      "Epoch [50/50] - Train Loss: 0.9822, Test Loss: 1.1002\n",
      "Avg Test Loss: 1.1002\n",
      "Testing combination: (8, 4, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1805, Test Loss: 1.1222\n",
      "Epoch [2/50] - Train Loss: 1.1742, Test Loss: 1.1233\n",
      "Epoch [3/50] - Train Loss: 1.1697, Test Loss: 1.1249\n",
      "Epoch [4/50] - Train Loss: 1.1660, Test Loss: 1.1267\n",
      "Epoch [5/50] - Train Loss: 1.1628, Test Loss: 1.1288\n",
      "Epoch [6/50] - Train Loss: 1.1601, Test Loss: 1.1310\n",
      "Epoch [7/50] - Train Loss: 1.1578, Test Loss: 1.1334\n",
      "Epoch [8/50] - Train Loss: 1.1558, Test Loss: 1.1358\n",
      "Epoch [9/50] - Train Loss: 1.1542, Test Loss: 1.1383\n",
      "Epoch [10/50] - Train Loss: 1.1527, Test Loss: 1.1408\n",
      "Epoch [11/50] - Train Loss: 1.1515, Test Loss: 1.1432\n",
      "Epoch [12/50] - Train Loss: 1.1505, Test Loss: 1.1456\n",
      "Epoch [13/50] - Train Loss: 1.1497, Test Loss: 1.1478\n",
      "Epoch [14/50] - Train Loss: 1.1490, Test Loss: 1.1499\n",
      "Epoch [15/50] - Train Loss: 1.1483, Test Loss: 1.1519\n",
      "Epoch [16/50] - Train Loss: 1.1478, Test Loss: 1.1537\n",
      "Epoch [17/50] - Train Loss: 1.1472, Test Loss: 1.1554\n",
      "Epoch [18/50] - Train Loss: 1.1468, Test Loss: 1.1569\n",
      "Epoch [19/50] - Train Loss: 1.1463, Test Loss: 1.1583\n",
      "Epoch [20/50] - Train Loss: 1.1458, Test Loss: 1.1595\n",
      "Epoch [21/50] - Train Loss: 1.1453, Test Loss: 1.1605\n",
      "Epoch [22/50] - Train Loss: 1.1448, Test Loss: 1.1614\n",
      "Epoch [23/50] - Train Loss: 1.1442, Test Loss: 1.1622\n",
      "Epoch [24/50] - Train Loss: 1.1435, Test Loss: 1.1628\n",
      "Epoch [25/50] - Train Loss: 1.1428, Test Loss: 1.1633\n",
      "Epoch [26/50] - Train Loss: 1.1420, Test Loss: 1.1637\n",
      "Epoch [27/50] - Train Loss: 1.1411, Test Loss: 1.1640\n",
      "Epoch [28/50] - Train Loss: 1.1400, Test Loss: 1.1642\n",
      "Epoch [29/50] - Train Loss: 1.1387, Test Loss: 1.1643\n",
      "Epoch [30/50] - Train Loss: 1.1372, Test Loss: 1.1644\n",
      "Epoch [31/50] - Train Loss: 1.1354, Test Loss: 1.1644\n",
      "Epoch [32/50] - Train Loss: 1.1332, Test Loss: 1.1643\n",
      "Epoch [33/50] - Train Loss: 1.1305, Test Loss: 1.1641\n",
      "Epoch [34/50] - Train Loss: 1.1272, Test Loss: 1.1640\n",
      "Epoch [35/50] - Train Loss: 1.1230, Test Loss: 1.1638\n",
      "Epoch [36/50] - Train Loss: 1.1177, Test Loss: 1.1639\n",
      "Epoch [37/50] - Train Loss: 1.1110, Test Loss: 1.1644\n",
      "Epoch [38/50] - Train Loss: 1.1029, Test Loss: 1.1654\n",
      "Epoch [39/50] - Train Loss: 1.0936, Test Loss: 1.1673\n",
      "Epoch [40/50] - Train Loss: 1.0846, Test Loss: 1.1705\n",
      "Epoch [41/50] - Train Loss: 1.0773, Test Loss: 1.1743\n",
      "Epoch [42/50] - Train Loss: 1.0718, Test Loss: 1.1775\n",
      "Epoch [43/50] - Train Loss: 1.0674, Test Loss: 1.1779\n",
      "Epoch [44/50] - Train Loss: 1.0643, Test Loss: 1.1829\n",
      "Epoch [45/50] - Train Loss: 1.0622, Test Loss: 1.1837\n",
      "Epoch [46/50] - Train Loss: 1.0578, Test Loss: 1.1870\n",
      "Epoch [47/50] - Train Loss: 1.0566, Test Loss: 1.1899\n",
      "Epoch [48/50] - Train Loss: 1.0509, Test Loss: 1.1924\n",
      "Epoch [49/50] - Train Loss: 1.1197, Test Loss: 1.1830\n",
      "Epoch [50/50] - Train Loss: 1.0925, Test Loss: 1.1698\n",
      "Avg Test Loss: 1.1698\n",
      "Testing combination: (8, 4, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5125, Test Loss: 1.7657\n",
      "Epoch [2/50] - Train Loss: 1.5097, Test Loss: 1.7629\n",
      "Epoch [3/50] - Train Loss: 1.5074, Test Loss: 1.7600\n",
      "Epoch [4/50] - Train Loss: 1.5053, Test Loss: 1.7572\n",
      "Epoch [5/50] - Train Loss: 1.5032, Test Loss: 1.7546\n",
      "Epoch [6/50] - Train Loss: 1.5013, Test Loss: 1.7521\n",
      "Epoch [7/50] - Train Loss: 1.4994, Test Loss: 1.7498\n",
      "Epoch [8/50] - Train Loss: 1.4977, Test Loss: 1.7478\n",
      "Epoch [9/50] - Train Loss: 1.4962, Test Loss: 1.7459\n",
      "Epoch [10/50] - Train Loss: 1.4947, Test Loss: 1.7442\n",
      "Epoch [11/50] - Train Loss: 1.4934, Test Loss: 1.7427\n",
      "Epoch [12/50] - Train Loss: 1.4922, Test Loss: 1.7413\n",
      "Epoch [13/50] - Train Loss: 1.4910, Test Loss: 1.7402\n",
      "Epoch [14/50] - Train Loss: 1.4900, Test Loss: 1.7392\n",
      "Epoch [15/50] - Train Loss: 1.4891, Test Loss: 1.7383\n",
      "Epoch [16/50] - Train Loss: 1.4883, Test Loss: 1.7377\n",
      "Epoch [17/50] - Train Loss: 1.4875, Test Loss: 1.7371\n",
      "Epoch [18/50] - Train Loss: 1.4869, Test Loss: 1.7368\n",
      "Epoch [19/50] - Train Loss: 1.4863, Test Loss: 1.7365\n",
      "Epoch [20/50] - Train Loss: 1.4857, Test Loss: 1.7364\n",
      "Epoch [21/50] - Train Loss: 1.4852, Test Loss: 1.7363\n",
      "Epoch [22/50] - Train Loss: 1.4848, Test Loss: 1.7363\n",
      "Epoch [23/50] - Train Loss: 1.4843, Test Loss: 1.7364\n",
      "Epoch [24/50] - Train Loss: 1.4840, Test Loss: 1.7366\n",
      "Epoch [25/50] - Train Loss: 1.4836, Test Loss: 1.7368\n",
      "Epoch [26/50] - Train Loss: 1.4833, Test Loss: 1.7371\n",
      "Epoch [27/50] - Train Loss: 1.4830, Test Loss: 1.7374\n",
      "Epoch [28/50] - Train Loss: 1.4826, Test Loss: 1.7377\n",
      "Epoch [29/50] - Train Loss: 1.4823, Test Loss: 1.7380\n",
      "Epoch [30/50] - Train Loss: 1.4820, Test Loss: 1.7384\n",
      "Epoch [31/50] - Train Loss: 1.4817, Test Loss: 1.7388\n",
      "Epoch [32/50] - Train Loss: 1.4814, Test Loss: 1.7392\n",
      "Epoch [33/50] - Train Loss: 1.4811, Test Loss: 1.7396\n",
      "Epoch [34/50] - Train Loss: 1.4808, Test Loss: 1.7400\n",
      "Epoch [35/50] - Train Loss: 1.4804, Test Loss: 1.7404\n",
      "Epoch [36/50] - Train Loss: 1.4801, Test Loss: 1.7409\n",
      "Epoch [37/50] - Train Loss: 1.4798, Test Loss: 1.7414\n",
      "Epoch [38/50] - Train Loss: 1.4794, Test Loss: 1.7418\n",
      "Epoch [39/50] - Train Loss: 1.4790, Test Loss: 1.7423\n",
      "Epoch [40/50] - Train Loss: 1.4785, Test Loss: 1.7429\n",
      "Epoch [41/50] - Train Loss: 1.4780, Test Loss: 1.7434\n",
      "Epoch [42/50] - Train Loss: 1.4775, Test Loss: 1.7440\n",
      "Epoch [43/50] - Train Loss: 1.4769, Test Loss: 1.7447\n",
      "Epoch [44/50] - Train Loss: 1.4762, Test Loss: 1.7455\n",
      "Epoch [45/50] - Train Loss: 1.4755, Test Loss: 1.7464\n",
      "Epoch [46/50] - Train Loss: 1.4749, Test Loss: 1.7474\n",
      "Epoch [47/50] - Train Loss: 1.4742, Test Loss: 1.7485\n",
      "Epoch [48/50] - Train Loss: 1.4736, Test Loss: 1.7495\n",
      "Epoch [49/50] - Train Loss: 1.4729, Test Loss: 1.7506\n",
      "Epoch [50/50] - Train Loss: 1.4723, Test Loss: 1.7516\n",
      "Avg Test Loss: 1.7516\n",
      "Testing combination: (8, 4, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.2022, Test Loss: 1.2326\n",
      "Epoch [2/50] - Train Loss: 1.2006, Test Loss: 1.2305\n",
      "Epoch [3/50] - Train Loss: 1.1992, Test Loss: 1.2285\n",
      "Epoch [4/50] - Train Loss: 1.1978, Test Loss: 1.2266\n",
      "Epoch [5/50] - Train Loss: 1.1965, Test Loss: 1.2247\n",
      "Epoch [6/50] - Train Loss: 1.1952, Test Loss: 1.2229\n",
      "Epoch [7/50] - Train Loss: 1.1939, Test Loss: 1.2211\n",
      "Epoch [8/50] - Train Loss: 1.1927, Test Loss: 1.2193\n",
      "Epoch [9/50] - Train Loss: 1.1914, Test Loss: 1.2176\n",
      "Epoch [10/50] - Train Loss: 1.1903, Test Loss: 1.2159\n",
      "Epoch [11/50] - Train Loss: 1.1891, Test Loss: 1.2143\n",
      "Epoch [12/50] - Train Loss: 1.1880, Test Loss: 1.2127\n",
      "Epoch [13/50] - Train Loss: 1.1869, Test Loss: 1.2111\n",
      "Epoch [14/50] - Train Loss: 1.1858, Test Loss: 1.2095\n",
      "Epoch [15/50] - Train Loss: 1.1847, Test Loss: 1.2080\n",
      "Epoch [16/50] - Train Loss: 1.1837, Test Loss: 1.2065\n",
      "Epoch [17/50] - Train Loss: 1.1826, Test Loss: 1.2050\n",
      "Epoch [18/50] - Train Loss: 1.1816, Test Loss: 1.2036\n",
      "Epoch [19/50] - Train Loss: 1.1806, Test Loss: 1.2022\n",
      "Epoch [20/50] - Train Loss: 1.1797, Test Loss: 1.2008\n",
      "Epoch [21/50] - Train Loss: 1.1787, Test Loss: 1.1994\n",
      "Epoch [22/50] - Train Loss: 1.1778, Test Loss: 1.1980\n",
      "Epoch [23/50] - Train Loss: 1.1769, Test Loss: 1.1967\n",
      "Epoch [24/50] - Train Loss: 1.1760, Test Loss: 1.1954\n",
      "Epoch [25/50] - Train Loss: 1.1751, Test Loss: 1.1941\n",
      "Epoch [26/50] - Train Loss: 1.1742, Test Loss: 1.1928\n",
      "Epoch [27/50] - Train Loss: 1.1733, Test Loss: 1.1915\n",
      "Epoch [28/50] - Train Loss: 1.1725, Test Loss: 1.1903\n",
      "Epoch [29/50] - Train Loss: 1.1716, Test Loss: 1.1890\n",
      "Epoch [30/50] - Train Loss: 1.1708, Test Loss: 1.1878\n",
      "Epoch [31/50] - Train Loss: 1.1700, Test Loss: 1.1866\n",
      "Epoch [32/50] - Train Loss: 1.1692, Test Loss: 1.1854\n",
      "Epoch [33/50] - Train Loss: 1.1684, Test Loss: 1.1842\n",
      "Epoch [34/50] - Train Loss: 1.1676, Test Loss: 1.1831\n",
      "Epoch [35/50] - Train Loss: 1.1668, Test Loss: 1.1819\n",
      "Epoch [36/50] - Train Loss: 1.1661, Test Loss: 1.1808\n",
      "Epoch [37/50] - Train Loss: 1.1653, Test Loss: 1.1796\n",
      "Epoch [38/50] - Train Loss: 1.1646, Test Loss: 1.1785\n",
      "Epoch [39/50] - Train Loss: 1.1638, Test Loss: 1.1774\n",
      "Epoch [40/50] - Train Loss: 1.1631, Test Loss: 1.1763\n",
      "Epoch [41/50] - Train Loss: 1.1624, Test Loss: 1.1752\n",
      "Epoch [42/50] - Train Loss: 1.1617, Test Loss: 1.1742\n",
      "Epoch [43/50] - Train Loss: 1.1610, Test Loss: 1.1731\n",
      "Epoch [44/50] - Train Loss: 1.1603, Test Loss: 1.1720\n",
      "Epoch [45/50] - Train Loss: 1.1596, Test Loss: 1.1710\n",
      "Epoch [46/50] - Train Loss: 1.1589, Test Loss: 1.1700\n",
      "Epoch [47/50] - Train Loss: 1.1582, Test Loss: 1.1689\n",
      "Epoch [48/50] - Train Loss: 1.1576, Test Loss: 1.1679\n",
      "Epoch [49/50] - Train Loss: 1.1569, Test Loss: 1.1669\n",
      "Epoch [50/50] - Train Loss: 1.1563, Test Loss: 1.1659\n",
      "Avg Test Loss: 1.1659\n",
      "Testing combination: (8, 4, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.2049, Test Loss: 1.1234\n",
      "Epoch [2/50] - Train Loss: 1.2039, Test Loss: 1.1232\n",
      "Epoch [3/50] - Train Loss: 1.2031, Test Loss: 1.1230\n",
      "Epoch [4/50] - Train Loss: 1.2022, Test Loss: 1.1229\n",
      "Epoch [5/50] - Train Loss: 1.2014, Test Loss: 1.1227\n",
      "Epoch [6/50] - Train Loss: 1.2006, Test Loss: 1.1226\n",
      "Epoch [7/50] - Train Loss: 1.1999, Test Loss: 1.1225\n",
      "Epoch [8/50] - Train Loss: 1.1991, Test Loss: 1.1224\n",
      "Epoch [9/50] - Train Loss: 1.1983, Test Loss: 1.1222\n",
      "Epoch [10/50] - Train Loss: 1.1976, Test Loss: 1.1221\n",
      "Epoch [11/50] - Train Loss: 1.1968, Test Loss: 1.1220\n",
      "Epoch [12/50] - Train Loss: 1.1961, Test Loss: 1.1219\n",
      "Epoch [13/50] - Train Loss: 1.1954, Test Loss: 1.1219\n",
      "Epoch [14/50] - Train Loss: 1.1947, Test Loss: 1.1218\n",
      "Epoch [15/50] - Train Loss: 1.1940, Test Loss: 1.1217\n",
      "Epoch [16/50] - Train Loss: 1.1933, Test Loss: 1.1217\n",
      "Epoch [17/50] - Train Loss: 1.1926, Test Loss: 1.1216\n",
      "Epoch [18/50] - Train Loss: 1.1919, Test Loss: 1.1215\n",
      "Epoch [19/50] - Train Loss: 1.1912, Test Loss: 1.1215\n",
      "Epoch [20/50] - Train Loss: 1.1906, Test Loss: 1.1215\n",
      "Epoch [21/50] - Train Loss: 1.1899, Test Loss: 1.1214\n",
      "Epoch [22/50] - Train Loss: 1.1893, Test Loss: 1.1214\n",
      "Epoch [23/50] - Train Loss: 1.1886, Test Loss: 1.1214\n",
      "Epoch [24/50] - Train Loss: 1.1880, Test Loss: 1.1214\n",
      "Epoch [25/50] - Train Loss: 1.1873, Test Loss: 1.1214\n",
      "Epoch [26/50] - Train Loss: 1.1867, Test Loss: 1.1214\n",
      "Epoch [27/50] - Train Loss: 1.1860, Test Loss: 1.1214\n",
      "Epoch [28/50] - Train Loss: 1.1854, Test Loss: 1.1214\n",
      "Epoch [29/50] - Train Loss: 1.1848, Test Loss: 1.1214\n",
      "Epoch [30/50] - Train Loss: 1.1842, Test Loss: 1.1214\n",
      "Epoch [31/50] - Train Loss: 1.1835, Test Loss: 1.1214\n",
      "Epoch [32/50] - Train Loss: 1.1829, Test Loss: 1.1215\n",
      "Epoch [33/50] - Train Loss: 1.1823, Test Loss: 1.1215\n",
      "Epoch [34/50] - Train Loss: 1.1817, Test Loss: 1.1216\n",
      "Epoch [35/50] - Train Loss: 1.1811, Test Loss: 1.1216\n",
      "Epoch [36/50] - Train Loss: 1.1805, Test Loss: 1.1217\n",
      "Epoch [37/50] - Train Loss: 1.1799, Test Loss: 1.1217\n",
      "Epoch [38/50] - Train Loss: 1.1793, Test Loss: 1.1218\n",
      "Epoch [39/50] - Train Loss: 1.1787, Test Loss: 1.1219\n",
      "Epoch [40/50] - Train Loss: 1.1782, Test Loss: 1.1220\n",
      "Epoch [41/50] - Train Loss: 1.1776, Test Loss: 1.1221\n",
      "Epoch [42/50] - Train Loss: 1.1770, Test Loss: 1.1222\n",
      "Epoch [43/50] - Train Loss: 1.1764, Test Loss: 1.1223\n",
      "Epoch [44/50] - Train Loss: 1.1759, Test Loss: 1.1224\n",
      "Epoch [45/50] - Train Loss: 1.1753, Test Loss: 1.1225\n",
      "Epoch [46/50] - Train Loss: 1.1747, Test Loss: 1.1226\n",
      "Epoch [47/50] - Train Loss: 1.1742, Test Loss: 1.1228\n",
      "Epoch [48/50] - Train Loss: 1.1736, Test Loss: 1.1229\n",
      "Epoch [49/50] - Train Loss: 1.1731, Test Loss: 1.1231\n",
      "Epoch [50/50] - Train Loss: 1.1725, Test Loss: 1.1232\n",
      "Avg Test Loss: 1.1232\n",
      "Testing combination: (8, 4, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.4879, Test Loss: 1.7348\n",
      "Epoch [2/50] - Train Loss: 1.4877, Test Loss: 1.7348\n",
      "Epoch [3/50] - Train Loss: 1.4877, Test Loss: 1.7348\n",
      "Epoch [4/50] - Train Loss: 1.4877, Test Loss: 1.7347\n",
      "Epoch [5/50] - Train Loss: 1.4876, Test Loss: 1.7347\n",
      "Epoch [6/50] - Train Loss: 1.4876, Test Loss: 1.7347\n",
      "Epoch [7/50] - Train Loss: 1.4876, Test Loss: 1.7347\n",
      "Epoch [8/50] - Train Loss: 1.4876, Test Loss: 1.7346\n",
      "Epoch [9/50] - Train Loss: 1.4875, Test Loss: 1.7346\n",
      "Epoch [10/50] - Train Loss: 1.4875, Test Loss: 1.7346\n",
      "Epoch [11/50] - Train Loss: 1.4875, Test Loss: 1.7346\n",
      "Epoch [12/50] - Train Loss: 1.4875, Test Loss: 1.7345\n",
      "Epoch [13/50] - Train Loss: 1.4874, Test Loss: 1.7345\n",
      "Epoch [14/50] - Train Loss: 1.4874, Test Loss: 1.7345\n",
      "Epoch [15/50] - Train Loss: 1.4874, Test Loss: 1.7345\n",
      "Epoch [16/50] - Train Loss: 1.4874, Test Loss: 1.7344\n",
      "Epoch [17/50] - Train Loss: 1.4874, Test Loss: 1.7344\n",
      "Epoch [18/50] - Train Loss: 1.4873, Test Loss: 1.7344\n",
      "Epoch [19/50] - Train Loss: 1.4873, Test Loss: 1.7344\n",
      "Epoch [20/50] - Train Loss: 1.4873, Test Loss: 1.7344\n",
      "Epoch [21/50] - Train Loss: 1.4873, Test Loss: 1.7343\n",
      "Epoch [22/50] - Train Loss: 1.4873, Test Loss: 1.7343\n",
      "Epoch [23/50] - Train Loss: 1.4872, Test Loss: 1.7343\n",
      "Epoch [24/50] - Train Loss: 1.4872, Test Loss: 1.7343\n",
      "Epoch [25/50] - Train Loss: 1.4872, Test Loss: 1.7342\n",
      "Epoch [26/50] - Train Loss: 1.4872, Test Loss: 1.7342\n",
      "Epoch [27/50] - Train Loss: 1.4872, Test Loss: 1.7342\n",
      "Epoch [28/50] - Train Loss: 1.4871, Test Loss: 1.7342\n",
      "Epoch [29/50] - Train Loss: 1.4871, Test Loss: 1.7342\n",
      "Epoch [30/50] - Train Loss: 1.4871, Test Loss: 1.7341\n",
      "Epoch [31/50] - Train Loss: 1.4871, Test Loss: 1.7341\n",
      "Epoch [32/50] - Train Loss: 1.4871, Test Loss: 1.7341\n",
      "Epoch [33/50] - Train Loss: 1.4870, Test Loss: 1.7341\n",
      "Epoch [34/50] - Train Loss: 1.4870, Test Loss: 1.7341\n",
      "Epoch [35/50] - Train Loss: 1.4870, Test Loss: 1.7341\n",
      "Epoch [36/50] - Train Loss: 1.4870, Test Loss: 1.7340\n",
      "Epoch [37/50] - Train Loss: 1.4870, Test Loss: 1.7340\n",
      "Epoch [38/50] - Train Loss: 1.4869, Test Loss: 1.7340\n",
      "Epoch [39/50] - Train Loss: 1.4869, Test Loss: 1.7340\n",
      "Epoch [40/50] - Train Loss: 1.4869, Test Loss: 1.7340\n",
      "Epoch [41/50] - Train Loss: 1.4869, Test Loss: 1.7340\n",
      "Epoch [42/50] - Train Loss: 1.4869, Test Loss: 1.7339\n",
      "Epoch [43/50] - Train Loss: 1.4869, Test Loss: 1.7339\n",
      "Epoch [44/50] - Train Loss: 1.4868, Test Loss: 1.7339\n",
      "Epoch [45/50] - Train Loss: 1.4868, Test Loss: 1.7339\n",
      "Epoch [46/50] - Train Loss: 1.4868, Test Loss: 1.7339\n",
      "Epoch [47/50] - Train Loss: 1.4868, Test Loss: 1.7339\n",
      "Epoch [48/50] - Train Loss: 1.4868, Test Loss: 1.7338\n",
      "Epoch [49/50] - Train Loss: 1.4868, Test Loss: 1.7338\n",
      "Epoch [50/50] - Train Loss: 1.4868, Test Loss: 1.7338\n",
      "Avg Test Loss: 1.7338\n",
      "Testing combination: (16, 1, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1373, Test Loss: 1.0934\n",
      "Epoch [2/50] - Train Loss: 1.1170, Test Loss: 1.0829\n",
      "Epoch [3/50] - Train Loss: 1.1178, Test Loss: 1.0799\n",
      "Epoch [4/50] - Train Loss: 1.1180, Test Loss: 1.0787\n",
      "Epoch [5/50] - Train Loss: 1.1173, Test Loss: 1.0765\n",
      "Epoch [6/50] - Train Loss: 1.1138, Test Loss: 1.0733\n",
      "Epoch [7/50] - Train Loss: 1.1108, Test Loss: 1.0734\n",
      "Epoch [8/50] - Train Loss: 1.1054, Test Loss: 1.0745\n",
      "Epoch [9/50] - Train Loss: 1.0939, Test Loss: 1.0752\n",
      "Epoch [10/50] - Train Loss: 1.0909, Test Loss: 1.0711\n",
      "Epoch [11/50] - Train Loss: 1.0788, Test Loss: 1.0761\n",
      "Epoch [12/50] - Train Loss: 1.0754, Test Loss: 1.0836\n",
      "Epoch [13/50] - Train Loss: 1.0753, Test Loss: 1.0842\n",
      "Epoch [14/50] - Train Loss: 1.0747, Test Loss: 1.0842\n",
      "Epoch [15/50] - Train Loss: 1.0742, Test Loss: 1.0841\n",
      "Epoch [16/50] - Train Loss: 1.0741, Test Loss: 1.0839\n",
      "Epoch [17/50] - Train Loss: 1.0740, Test Loss: 1.0839\n",
      "Epoch [18/50] - Train Loss: 1.0739, Test Loss: 1.0836\n",
      "Epoch [19/50] - Train Loss: 1.0738, Test Loss: 1.0836\n",
      "Epoch [20/50] - Train Loss: 1.0737, Test Loss: 1.0834\n",
      "Epoch [21/50] - Train Loss: 1.0736, Test Loss: 1.0833\n",
      "Epoch [22/50] - Train Loss: 1.0735, Test Loss: 1.0833\n",
      "Epoch [23/50] - Train Loss: 1.0735, Test Loss: 1.0832\n",
      "Epoch [24/50] - Train Loss: 1.0734, Test Loss: 1.0832\n",
      "Epoch [25/50] - Train Loss: 1.0734, Test Loss: 1.0832\n",
      "Epoch [26/50] - Train Loss: 1.0734, Test Loss: 1.0832\n",
      "Epoch [27/50] - Train Loss: 1.0733, Test Loss: 1.0832\n",
      "Epoch [28/50] - Train Loss: 1.0733, Test Loss: 1.0832\n",
      "Epoch [29/50] - Train Loss: 1.0732, Test Loss: 1.0832\n",
      "Epoch [30/50] - Train Loss: 1.0732, Test Loss: 1.0832\n",
      "Epoch [31/50] - Train Loss: 1.0732, Test Loss: 1.0832\n",
      "Epoch [32/50] - Train Loss: 1.0732, Test Loss: 1.0832\n",
      "Epoch [33/50] - Train Loss: 1.0731, Test Loss: 1.0832\n",
      "Epoch [34/50] - Train Loss: 1.0731, Test Loss: 1.0832\n",
      "Epoch [35/50] - Train Loss: 1.0731, Test Loss: 1.0832\n",
      "Epoch [36/50] - Train Loss: 1.0731, Test Loss: 1.0832\n",
      "Epoch [37/50] - Train Loss: 1.0730, Test Loss: 1.0832\n",
      "Epoch [38/50] - Train Loss: 1.0730, Test Loss: 1.0832\n",
      "Epoch [39/50] - Train Loss: 1.0730, Test Loss: 1.0833\n",
      "Epoch [40/50] - Train Loss: 1.0729, Test Loss: 1.0833\n",
      "Epoch [41/50] - Train Loss: 1.0729, Test Loss: 1.0833\n",
      "Epoch [42/50] - Train Loss: 1.0729, Test Loss: 1.0834\n",
      "Epoch [43/50] - Train Loss: 1.0728, Test Loss: 1.0834\n",
      "Epoch [44/50] - Train Loss: 1.0725, Test Loss: 1.0834\n",
      "Epoch [45/50] - Train Loss: 1.0714, Test Loss: 1.0825\n",
      "Epoch [46/50] - Train Loss: 1.0757, Test Loss: 1.0837\n",
      "Epoch [47/50] - Train Loss: 1.0736, Test Loss: 1.0843\n",
      "Epoch [48/50] - Train Loss: 1.0733, Test Loss: 1.0845\n",
      "Epoch [49/50] - Train Loss: 1.0731, Test Loss: 1.0846\n",
      "Epoch [50/50] - Train Loss: 1.0730, Test Loss: 1.0847\n",
      "Avg Test Loss: 1.0847\n",
      "Testing combination: (16, 1, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1702, Test Loss: 1.1557\n",
      "Epoch [2/50] - Train Loss: 1.1520, Test Loss: 1.1634\n",
      "Epoch [3/50] - Train Loss: 1.1485, Test Loss: 1.1694\n",
      "Epoch [4/50] - Train Loss: 1.1386, Test Loss: 1.1769\n",
      "Epoch [5/50] - Train Loss: 1.1294, Test Loss: 1.1783\n",
      "Epoch [6/50] - Train Loss: 1.1049, Test Loss: 1.1782\n",
      "Epoch [7/50] - Train Loss: 1.0680, Test Loss: 1.1851\n",
      "Epoch [8/50] - Train Loss: 1.0496, Test Loss: 1.2002\n",
      "Epoch [9/50] - Train Loss: 1.0518, Test Loss: 1.2109\n",
      "Epoch [10/50] - Train Loss: 1.0495, Test Loss: 1.2129\n",
      "Epoch [11/50] - Train Loss: 1.0491, Test Loss: 1.2141\n",
      "Epoch [12/50] - Train Loss: 1.0485, Test Loss: 1.2148\n",
      "Epoch [13/50] - Train Loss: 1.0483, Test Loss: 1.2147\n",
      "Epoch [14/50] - Train Loss: 1.0481, Test Loss: 1.2140\n",
      "Epoch [15/50] - Train Loss: 1.0479, Test Loss: 1.2133\n",
      "Epoch [16/50] - Train Loss: 1.0479, Test Loss: 1.2130\n",
      "Epoch [17/50] - Train Loss: 1.0478, Test Loss: 1.2129\n",
      "Epoch [18/50] - Train Loss: 1.0477, Test Loss: 1.2128\n",
      "Epoch [19/50] - Train Loss: 1.0476, Test Loss: 1.2127\n",
      "Epoch [20/50] - Train Loss: 1.0476, Test Loss: 1.2126\n",
      "Epoch [21/50] - Train Loss: 1.0475, Test Loss: 1.2123\n",
      "Epoch [22/50] - Train Loss: 1.0475, Test Loss: 1.2120\n",
      "Epoch [23/50] - Train Loss: 1.0474, Test Loss: 1.2116\n",
      "Epoch [24/50] - Train Loss: 1.0474, Test Loss: 1.2113\n",
      "Epoch [25/50] - Train Loss: 1.0473, Test Loss: 1.2112\n",
      "Epoch [26/50] - Train Loss: 1.0470, Test Loss: 1.2114\n",
      "Epoch [27/50] - Train Loss: 1.0465, Test Loss: 1.2124\n",
      "Epoch [28/50] - Train Loss: 1.0458, Test Loss: 1.2114\n",
      "Epoch [29/50] - Train Loss: 1.0427, Test Loss: 1.2211\n",
      "Epoch [30/50] - Train Loss: 1.2313, Test Loss: 1.2094\n",
      "Epoch [31/50] - Train Loss: 1.0656, Test Loss: 1.1849\n",
      "Epoch [32/50] - Train Loss: 1.0577, Test Loss: 1.1902\n",
      "Epoch [33/50] - Train Loss: 1.0515, Test Loss: 1.2032\n",
      "Epoch [34/50] - Train Loss: 1.0500, Test Loss: 1.2026\n",
      "Epoch [35/50] - Train Loss: 1.0483, Test Loss: 1.1974\n",
      "Epoch [36/50] - Train Loss: 1.0478, Test Loss: 1.1952\n",
      "Epoch [37/50] - Train Loss: 1.0476, Test Loss: 1.1960\n",
      "Epoch [38/50] - Train Loss: 1.0475, Test Loss: 1.1975\n",
      "Epoch [39/50] - Train Loss: 1.0474, Test Loss: 1.1983\n",
      "Epoch [40/50] - Train Loss: 1.0473, Test Loss: 1.1982\n",
      "Epoch [41/50] - Train Loss: 1.0471, Test Loss: 1.1980\n",
      "Epoch [42/50] - Train Loss: 1.0470, Test Loss: 1.1980\n",
      "Epoch [43/50] - Train Loss: 1.0469, Test Loss: 1.1981\n",
      "Epoch [44/50] - Train Loss: 1.0469, Test Loss: 1.1982\n",
      "Epoch [45/50] - Train Loss: 1.0468, Test Loss: 1.1981\n",
      "Epoch [46/50] - Train Loss: 1.0468, Test Loss: 1.1980\n",
      "Epoch [47/50] - Train Loss: 1.0467, Test Loss: 1.1979\n",
      "Epoch [48/50] - Train Loss: 1.0467, Test Loss: 1.1978\n",
      "Epoch [49/50] - Train Loss: 1.0466, Test Loss: 1.1977\n",
      "Epoch [50/50] - Train Loss: 1.0466, Test Loss: 1.1975\n",
      "Avg Test Loss: 1.1975\n",
      "Testing combination: (16, 1, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5288, Test Loss: 1.7435\n",
      "Epoch [2/50] - Train Loss: 1.4954, Test Loss: 1.7409\n",
      "Epoch [3/50] - Train Loss: 1.4887, Test Loss: 1.7423\n",
      "Epoch [4/50] - Train Loss: 1.4835, Test Loss: 1.7413\n",
      "Epoch [5/50] - Train Loss: 1.4781, Test Loss: 1.7397\n",
      "Epoch [6/50] - Train Loss: 1.4700, Test Loss: 1.7441\n",
      "Epoch [7/50] - Train Loss: 1.4610, Test Loss: 1.7516\n",
      "Epoch [8/50] - Train Loss: 1.4534, Test Loss: 1.7586\n",
      "Epoch [9/50] - Train Loss: 1.4470, Test Loss: 1.7686\n",
      "Epoch [10/50] - Train Loss: 1.4412, Test Loss: 1.7773\n",
      "Epoch [11/50] - Train Loss: 1.4351, Test Loss: 1.7818\n",
      "Epoch [12/50] - Train Loss: 1.4301, Test Loss: 1.7885\n",
      "Epoch [13/50] - Train Loss: 1.4266, Test Loss: 1.7964\n",
      "Epoch [14/50] - Train Loss: 1.4245, Test Loss: 1.8031\n",
      "Epoch [15/50] - Train Loss: 1.4209, Test Loss: 1.8085\n",
      "Epoch [16/50] - Train Loss: 1.4161, Test Loss: 1.8145\n",
      "Epoch [17/50] - Train Loss: 1.4151, Test Loss: 1.8238\n",
      "Epoch [18/50] - Train Loss: 1.4109, Test Loss: 1.8256\n",
      "Epoch [19/50] - Train Loss: 1.4097, Test Loss: 1.8284\n",
      "Epoch [20/50] - Train Loss: 1.4102, Test Loss: 1.8326\n",
      "Epoch [21/50] - Train Loss: 1.4107, Test Loss: 1.8370\n",
      "Epoch [22/50] - Train Loss: 1.4102, Test Loss: 1.8377\n",
      "Epoch [23/50] - Train Loss: 1.4090, Test Loss: 1.8360\n",
      "Epoch [24/50] - Train Loss: 1.4083, Test Loss: 1.8352\n",
      "Epoch [25/50] - Train Loss: 1.4079, Test Loss: 1.8356\n",
      "Epoch [26/50] - Train Loss: 1.4071, Test Loss: 1.8352\n",
      "Epoch [27/50] - Train Loss: 1.4058, Test Loss: 1.8339\n",
      "Epoch [28/50] - Train Loss: 1.4046, Test Loss: 1.8340\n",
      "Epoch [29/50] - Train Loss: 1.4035, Test Loss: 1.8337\n",
      "Epoch [30/50] - Train Loss: 1.4019, Test Loss: 1.8281\n",
      "Epoch [31/50] - Train Loss: 1.3997, Test Loss: 1.8215\n",
      "Epoch [32/50] - Train Loss: 1.3948, Test Loss: 1.8727\n",
      "Epoch [33/50] - Train Loss: 1.4018, Test Loss: 2.0140\n",
      "Epoch [34/50] - Train Loss: 1.4246, Test Loss: 1.8167\n",
      "Epoch [35/50] - Train Loss: 1.5099, Test Loss: 1.7585\n",
      "Epoch [36/50] - Train Loss: 1.4696, Test Loss: 1.7481\n",
      "Epoch [37/50] - Train Loss: 1.4493, Test Loss: 1.7394\n",
      "Epoch [38/50] - Train Loss: 1.4380, Test Loss: 1.7874\n",
      "Epoch [39/50] - Train Loss: 1.4329, Test Loss: 1.8034\n",
      "Epoch [40/50] - Train Loss: 1.4314, Test Loss: 1.8118\n",
      "Epoch [41/50] - Train Loss: 1.4300, Test Loss: 1.8141\n",
      "Epoch [42/50] - Train Loss: 1.4281, Test Loss: 1.8125\n",
      "Epoch [43/50] - Train Loss: 1.4277, Test Loss: 1.8147\n",
      "Epoch [44/50] - Train Loss: 1.4274, Test Loss: 1.8203\n",
      "Epoch [45/50] - Train Loss: 1.4274, Test Loss: 1.8213\n",
      "Epoch [46/50] - Train Loss: 1.4274, Test Loss: 1.8202\n",
      "Epoch [47/50] - Train Loss: 1.4276, Test Loss: 1.8204\n",
      "Epoch [48/50] - Train Loss: 1.4276, Test Loss: 1.8219\n",
      "Epoch [49/50] - Train Loss: 1.4275, Test Loss: 1.8225\n",
      "Epoch [50/50] - Train Loss: 1.4272, Test Loss: 1.8221\n",
      "Avg Test Loss: 1.8221\n",
      "Testing combination: (16, 1, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1729, Test Loss: 1.1733\n",
      "Epoch [2/50] - Train Loss: 1.1542, Test Loss: 1.1511\n",
      "Epoch [3/50] - Train Loss: 1.1414, Test Loss: 1.1349\n",
      "Epoch [4/50] - Train Loss: 1.1323, Test Loss: 1.1224\n",
      "Epoch [5/50] - Train Loss: 1.1258, Test Loss: 1.1127\n",
      "Epoch [6/50] - Train Loss: 1.1215, Test Loss: 1.1059\n",
      "Epoch [7/50] - Train Loss: 1.1186, Test Loss: 1.1015\n",
      "Epoch [8/50] - Train Loss: 1.1168, Test Loss: 1.0992\n",
      "Epoch [9/50] - Train Loss: 1.1157, Test Loss: 1.0987\n",
      "Epoch [10/50] - Train Loss: 1.1148, Test Loss: 1.0991\n",
      "Epoch [11/50] - Train Loss: 1.1141, Test Loss: 1.0994\n",
      "Epoch [12/50] - Train Loss: 1.1132, Test Loss: 1.0990\n",
      "Epoch [13/50] - Train Loss: 1.1121, Test Loss: 1.0979\n",
      "Epoch [14/50] - Train Loss: 1.1101, Test Loss: 1.0966\n",
      "Epoch [15/50] - Train Loss: 1.1068, Test Loss: 1.0960\n",
      "Epoch [16/50] - Train Loss: 1.1018, Test Loss: 1.0958\n",
      "Epoch [17/50] - Train Loss: 1.0968, Test Loss: 1.0961\n",
      "Epoch [18/50] - Train Loss: 1.0923, Test Loss: 1.0975\n",
      "Epoch [19/50] - Train Loss: 1.0875, Test Loss: 1.0998\n",
      "Epoch [20/50] - Train Loss: 1.0840, Test Loss: 1.1020\n",
      "Epoch [21/50] - Train Loss: 1.0820, Test Loss: 1.1039\n",
      "Epoch [22/50] - Train Loss: 1.0807, Test Loss: 1.1058\n",
      "Epoch [23/50] - Train Loss: 1.0797, Test Loss: 1.1080\n",
      "Epoch [24/50] - Train Loss: 1.0789, Test Loss: 1.1106\n",
      "Epoch [25/50] - Train Loss: 1.0781, Test Loss: 1.1135\n",
      "Epoch [26/50] - Train Loss: 1.0774, Test Loss: 1.1165\n",
      "Epoch [27/50] - Train Loss: 1.0768, Test Loss: 1.1196\n",
      "Epoch [28/50] - Train Loss: 1.0762, Test Loss: 1.1227\n",
      "Epoch [29/50] - Train Loss: 1.0756, Test Loss: 1.1258\n",
      "Epoch [30/50] - Train Loss: 1.0750, Test Loss: 1.1291\n",
      "Epoch [31/50] - Train Loss: 1.0745, Test Loss: 1.1324\n",
      "Epoch [32/50] - Train Loss: 1.0740, Test Loss: 1.1361\n",
      "Epoch [33/50] - Train Loss: 1.0736, Test Loss: 1.1402\n",
      "Epoch [34/50] - Train Loss: 1.0733, Test Loss: 1.1449\n",
      "Epoch [35/50] - Train Loss: 1.0730, Test Loss: 1.1499\n",
      "Epoch [36/50] - Train Loss: 1.0727, Test Loss: 1.1551\n",
      "Epoch [37/50] - Train Loss: 1.0725, Test Loss: 1.1601\n",
      "Epoch [38/50] - Train Loss: 1.0723, Test Loss: 1.1646\n",
      "Epoch [39/50] - Train Loss: 1.0722, Test Loss: 1.1686\n",
      "Epoch [40/50] - Train Loss: 1.0720, Test Loss: 1.1719\n",
      "Epoch [41/50] - Train Loss: 1.0720, Test Loss: 1.1746\n",
      "Epoch [42/50] - Train Loss: 1.0719, Test Loss: 1.1766\n",
      "Epoch [43/50] - Train Loss: 1.0719, Test Loss: 1.1782\n",
      "Epoch [44/50] - Train Loss: 1.0718, Test Loss: 1.1794\n",
      "Epoch [45/50] - Train Loss: 1.0718, Test Loss: 1.1803\n",
      "Epoch [46/50] - Train Loss: 1.0717, Test Loss: 1.1810\n",
      "Epoch [47/50] - Train Loss: 1.0717, Test Loss: 1.1815\n",
      "Epoch [48/50] - Train Loss: 1.0717, Test Loss: 1.1820\n",
      "Epoch [49/50] - Train Loss: 1.0716, Test Loss: 1.1824\n",
      "Epoch [50/50] - Train Loss: 1.0716, Test Loss: 1.1828\n",
      "Avg Test Loss: 1.1828\n",
      "Testing combination: (16, 1, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1567, Test Loss: 1.1984\n",
      "Epoch [2/50] - Train Loss: 1.1528, Test Loss: 1.1948\n",
      "Epoch [3/50] - Train Loss: 1.1513, Test Loss: 1.1918\n",
      "Epoch [4/50] - Train Loss: 1.1500, Test Loss: 1.1897\n",
      "Epoch [5/50] - Train Loss: 1.1487, Test Loss: 1.1885\n",
      "Epoch [6/50] - Train Loss: 1.1472, Test Loss: 1.1881\n",
      "Epoch [7/50] - Train Loss: 1.1454, Test Loss: 1.1887\n",
      "Epoch [8/50] - Train Loss: 1.1431, Test Loss: 1.1909\n",
      "Epoch [9/50] - Train Loss: 1.1401, Test Loss: 1.1945\n",
      "Epoch [10/50] - Train Loss: 1.1361, Test Loss: 1.1992\n",
      "Epoch [11/50] - Train Loss: 1.1308, Test Loss: 1.2042\n",
      "Epoch [12/50] - Train Loss: 1.1240, Test Loss: 1.2091\n",
      "Epoch [13/50] - Train Loss: 1.1155, Test Loss: 1.2137\n",
      "Epoch [14/50] - Train Loss: 1.1053, Test Loss: 1.2180\n",
      "Epoch [15/50] - Train Loss: 1.0941, Test Loss: 1.2228\n",
      "Epoch [16/50] - Train Loss: 1.0833, Test Loss: 1.2282\n",
      "Epoch [17/50] - Train Loss: 1.0736, Test Loss: 1.2347\n",
      "Epoch [18/50] - Train Loss: 1.0654, Test Loss: 1.2431\n",
      "Epoch [19/50] - Train Loss: 1.0592, Test Loss: 1.2527\n",
      "Epoch [20/50] - Train Loss: 1.0551, Test Loss: 1.2623\n",
      "Epoch [21/50] - Train Loss: 1.0525, Test Loss: 1.2703\n",
      "Epoch [22/50] - Train Loss: 1.0506, Test Loss: 1.2766\n",
      "Epoch [23/50] - Train Loss: 1.0492, Test Loss: 1.2815\n",
      "Epoch [24/50] - Train Loss: 1.0480, Test Loss: 1.2857\n",
      "Epoch [25/50] - Train Loss: 1.0471, Test Loss: 1.2898\n",
      "Epoch [26/50] - Train Loss: 1.0464, Test Loss: 1.2937\n",
      "Epoch [27/50] - Train Loss: 1.0458, Test Loss: 1.2972\n",
      "Epoch [28/50] - Train Loss: 1.0452, Test Loss: 1.3003\n",
      "Epoch [29/50] - Train Loss: 1.0448, Test Loss: 1.3032\n",
      "Epoch [30/50] - Train Loss: 1.0444, Test Loss: 1.3057\n",
      "Epoch [31/50] - Train Loss: 1.0441, Test Loss: 1.3080\n",
      "Epoch [32/50] - Train Loss: 1.0437, Test Loss: 1.3100\n",
      "Epoch [33/50] - Train Loss: 1.0434, Test Loss: 1.3119\n",
      "Epoch [34/50] - Train Loss: 1.0431, Test Loss: 1.3135\n",
      "Epoch [35/50] - Train Loss: 1.0428, Test Loss: 1.3145\n",
      "Epoch [36/50] - Train Loss: 1.0424, Test Loss: 1.3144\n",
      "Epoch [37/50] - Train Loss: 1.0420, Test Loss: 1.3120\n",
      "Epoch [38/50] - Train Loss: 1.0415, Test Loss: 1.3083\n",
      "Epoch [39/50] - Train Loss: 1.0408, Test Loss: 1.3112\n",
      "Epoch [40/50] - Train Loss: 1.0397, Test Loss: 1.3250\n",
      "Epoch [41/50] - Train Loss: 1.0383, Test Loss: 1.3294\n",
      "Epoch [42/50] - Train Loss: 1.0363, Test Loss: 1.3336\n",
      "Epoch [43/50] - Train Loss: 1.0340, Test Loss: 1.3361\n",
      "Epoch [44/50] - Train Loss: 1.0312, Test Loss: 1.3352\n",
      "Epoch [45/50] - Train Loss: 1.0283, Test Loss: 1.3356\n",
      "Epoch [46/50] - Train Loss: 1.0438, Test Loss: 1.3349\n",
      "Epoch [47/50] - Train Loss: 1.0407, Test Loss: 1.2588\n",
      "Epoch [48/50] - Train Loss: 1.0556, Test Loss: 1.2655\n",
      "Epoch [49/50] - Train Loss: 1.0442, Test Loss: 1.2759\n",
      "Epoch [50/50] - Train Loss: 1.0338, Test Loss: 1.2910\n",
      "Avg Test Loss: 1.2910\n",
      "Testing combination: (16, 1, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5289, Test Loss: 1.7925\n",
      "Epoch [2/50] - Train Loss: 1.5229, Test Loss: 1.7884\n",
      "Epoch [3/50] - Train Loss: 1.5178, Test Loss: 1.7850\n",
      "Epoch [4/50] - Train Loss: 1.5131, Test Loss: 1.7822\n",
      "Epoch [5/50] - Train Loss: 1.5089, Test Loss: 1.7802\n",
      "Epoch [6/50] - Train Loss: 1.5051, Test Loss: 1.7791\n",
      "Epoch [7/50] - Train Loss: 1.5017, Test Loss: 1.7789\n",
      "Epoch [8/50] - Train Loss: 1.4986, Test Loss: 1.7795\n",
      "Epoch [9/50] - Train Loss: 1.4960, Test Loss: 1.7806\n",
      "Epoch [10/50] - Train Loss: 1.4934, Test Loss: 1.7822\n",
      "Epoch [11/50] - Train Loss: 1.4912, Test Loss: 1.7846\n",
      "Epoch [12/50] - Train Loss: 1.4891, Test Loss: 1.7878\n",
      "Epoch [13/50] - Train Loss: 1.4872, Test Loss: 1.7916\n",
      "Epoch [14/50] - Train Loss: 1.4855, Test Loss: 1.7960\n",
      "Epoch [15/50] - Train Loss: 1.4838, Test Loss: 1.8008\n",
      "Epoch [16/50] - Train Loss: 1.4821, Test Loss: 1.8058\n",
      "Epoch [17/50] - Train Loss: 1.4805, Test Loss: 1.8107\n",
      "Epoch [18/50] - Train Loss: 1.4786, Test Loss: 1.8150\n",
      "Epoch [19/50] - Train Loss: 1.4765, Test Loss: 1.8182\n",
      "Epoch [20/50] - Train Loss: 1.4740, Test Loss: 1.8200\n",
      "Epoch [21/50] - Train Loss: 1.4712, Test Loss: 1.8200\n",
      "Epoch [22/50] - Train Loss: 1.4679, Test Loss: 1.8183\n",
      "Epoch [23/50] - Train Loss: 1.4641, Test Loss: 1.8152\n",
      "Epoch [24/50] - Train Loss: 1.4598, Test Loss: 1.8112\n",
      "Epoch [25/50] - Train Loss: 1.4555, Test Loss: 1.8075\n",
      "Epoch [26/50] - Train Loss: 1.4513, Test Loss: 1.8052\n",
      "Epoch [27/50] - Train Loss: 1.4476, Test Loss: 1.8046\n",
      "Epoch [28/50] - Train Loss: 1.4444, Test Loss: 1.8056\n",
      "Epoch [29/50] - Train Loss: 1.4418, Test Loss: 1.8077\n",
      "Epoch [30/50] - Train Loss: 1.4391, Test Loss: 1.8109\n",
      "Epoch [31/50] - Train Loss: 1.4368, Test Loss: 1.8149\n",
      "Epoch [32/50] - Train Loss: 1.4346, Test Loss: 1.8196\n",
      "Epoch [33/50] - Train Loss: 1.4326, Test Loss: 1.8247\n",
      "Epoch [34/50] - Train Loss: 1.4308, Test Loss: 1.8301\n",
      "Epoch [35/50] - Train Loss: 1.4293, Test Loss: 1.8356\n",
      "Epoch [36/50] - Train Loss: 1.4280, Test Loss: 1.8410\n",
      "Epoch [37/50] - Train Loss: 1.4269, Test Loss: 1.8462\n",
      "Epoch [38/50] - Train Loss: 1.4260, Test Loss: 1.8510\n",
      "Epoch [39/50] - Train Loss: 1.4253, Test Loss: 1.8555\n",
      "Epoch [40/50] - Train Loss: 1.4247, Test Loss: 1.8595\n",
      "Epoch [41/50] - Train Loss: 1.4241, Test Loss: 1.8631\n",
      "Epoch [42/50] - Train Loss: 1.4235, Test Loss: 1.8664\n",
      "Epoch [43/50] - Train Loss: 1.4230, Test Loss: 1.8694\n",
      "Epoch [44/50] - Train Loss: 1.4225, Test Loss: 1.8721\n",
      "Epoch [45/50] - Train Loss: 1.4219, Test Loss: 1.8748\n",
      "Epoch [46/50] - Train Loss: 1.4214, Test Loss: 1.8779\n",
      "Epoch [47/50] - Train Loss: 1.4208, Test Loss: 1.8808\n",
      "Epoch [48/50] - Train Loss: 1.4202, Test Loss: 1.8836\n",
      "Epoch [49/50] - Train Loss: 1.4196, Test Loss: 1.8865\n",
      "Epoch [50/50] - Train Loss: 1.4191, Test Loss: 1.8894\n",
      "Avg Test Loss: 1.8894\n",
      "Testing combination: (16, 1, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1199, Test Loss: 1.1023\n",
      "Epoch [2/50] - Train Loss: 1.1197, Test Loss: 1.1024\n",
      "Epoch [3/50] - Train Loss: 1.1195, Test Loss: 1.1024\n",
      "Epoch [4/50] - Train Loss: 1.1193, Test Loss: 1.1025\n",
      "Epoch [5/50] - Train Loss: 1.1192, Test Loss: 1.1025\n",
      "Epoch [6/50] - Train Loss: 1.1190, Test Loss: 1.1026\n",
      "Epoch [7/50] - Train Loss: 1.1189, Test Loss: 1.1026\n",
      "Epoch [8/50] - Train Loss: 1.1188, Test Loss: 1.1027\n",
      "Epoch [9/50] - Train Loss: 1.1186, Test Loss: 1.1028\n",
      "Epoch [10/50] - Train Loss: 1.1185, Test Loss: 1.1029\n",
      "Epoch [11/50] - Train Loss: 1.1184, Test Loss: 1.1030\n",
      "Epoch [12/50] - Train Loss: 1.1183, Test Loss: 1.1031\n",
      "Epoch [13/50] - Train Loss: 1.1181, Test Loss: 1.1033\n",
      "Epoch [14/50] - Train Loss: 1.1180, Test Loss: 1.1034\n",
      "Epoch [15/50] - Train Loss: 1.1179, Test Loss: 1.1036\n",
      "Epoch [16/50] - Train Loss: 1.1178, Test Loss: 1.1038\n",
      "Epoch [17/50] - Train Loss: 1.1177, Test Loss: 1.1039\n",
      "Epoch [18/50] - Train Loss: 1.1176, Test Loss: 1.1041\n",
      "Epoch [19/50] - Train Loss: 1.1175, Test Loss: 1.1043\n",
      "Epoch [20/50] - Train Loss: 1.1174, Test Loss: 1.1045\n",
      "Epoch [21/50] - Train Loss: 1.1173, Test Loss: 1.1047\n",
      "Epoch [22/50] - Train Loss: 1.1172, Test Loss: 1.1049\n",
      "Epoch [23/50] - Train Loss: 1.1171, Test Loss: 1.1052\n",
      "Epoch [24/50] - Train Loss: 1.1170, Test Loss: 1.1054\n",
      "Epoch [25/50] - Train Loss: 1.1169, Test Loss: 1.1057\n",
      "Epoch [26/50] - Train Loss: 1.1168, Test Loss: 1.1060\n",
      "Epoch [27/50] - Train Loss: 1.1167, Test Loss: 1.1063\n",
      "Epoch [28/50] - Train Loss: 1.1166, Test Loss: 1.1066\n",
      "Epoch [29/50] - Train Loss: 1.1165, Test Loss: 1.1068\n",
      "Epoch [30/50] - Train Loss: 1.1164, Test Loss: 1.1071\n",
      "Epoch [31/50] - Train Loss: 1.1163, Test Loss: 1.1074\n",
      "Epoch [32/50] - Train Loss: 1.1163, Test Loss: 1.1077\n",
      "Epoch [33/50] - Train Loss: 1.1162, Test Loss: 1.1081\n",
      "Epoch [34/50] - Train Loss: 1.1161, Test Loss: 1.1084\n",
      "Epoch [35/50] - Train Loss: 1.1160, Test Loss: 1.1087\n",
      "Epoch [36/50] - Train Loss: 1.1159, Test Loss: 1.1091\n",
      "Epoch [37/50] - Train Loss: 1.1159, Test Loss: 1.1094\n",
      "Epoch [38/50] - Train Loss: 1.1158, Test Loss: 1.1097\n",
      "Epoch [39/50] - Train Loss: 1.1157, Test Loss: 1.1101\n",
      "Epoch [40/50] - Train Loss: 1.1156, Test Loss: 1.1105\n",
      "Epoch [41/50] - Train Loss: 1.1155, Test Loss: 1.1109\n",
      "Epoch [42/50] - Train Loss: 1.1155, Test Loss: 1.1113\n",
      "Epoch [43/50] - Train Loss: 1.1154, Test Loss: 1.1117\n",
      "Epoch [44/50] - Train Loss: 1.1153, Test Loss: 1.1121\n",
      "Epoch [45/50] - Train Loss: 1.1152, Test Loss: 1.1126\n",
      "Epoch [46/50] - Train Loss: 1.1152, Test Loss: 1.1131\n",
      "Epoch [47/50] - Train Loss: 1.1151, Test Loss: 1.1135\n",
      "Epoch [48/50] - Train Loss: 1.1150, Test Loss: 1.1140\n",
      "Epoch [49/50] - Train Loss: 1.1149, Test Loss: 1.1145\n",
      "Epoch [50/50] - Train Loss: 1.1149, Test Loss: 1.1150\n",
      "Avg Test Loss: 1.1150\n",
      "Testing combination: (16, 1, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1510, Test Loss: 1.1924\n",
      "Epoch [2/50] - Train Loss: 1.1508, Test Loss: 1.1922\n",
      "Epoch [3/50] - Train Loss: 1.1507, Test Loss: 1.1921\n",
      "Epoch [4/50] - Train Loss: 1.1506, Test Loss: 1.1920\n",
      "Epoch [5/50] - Train Loss: 1.1505, Test Loss: 1.1919\n",
      "Epoch [6/50] - Train Loss: 1.1504, Test Loss: 1.1918\n",
      "Epoch [7/50] - Train Loss: 1.1503, Test Loss: 1.1917\n",
      "Epoch [8/50] - Train Loss: 1.1503, Test Loss: 1.1917\n",
      "Epoch [9/50] - Train Loss: 1.1502, Test Loss: 1.1916\n",
      "Epoch [10/50] - Train Loss: 1.1501, Test Loss: 1.1915\n",
      "Epoch [11/50] - Train Loss: 1.1500, Test Loss: 1.1914\n",
      "Epoch [12/50] - Train Loss: 1.1499, Test Loss: 1.1913\n",
      "Epoch [13/50] - Train Loss: 1.1498, Test Loss: 1.1913\n",
      "Epoch [14/50] - Train Loss: 1.1497, Test Loss: 1.1912\n",
      "Epoch [15/50] - Train Loss: 1.1496, Test Loss: 1.1912\n",
      "Epoch [16/50] - Train Loss: 1.1495, Test Loss: 1.1912\n",
      "Epoch [17/50] - Train Loss: 1.1494, Test Loss: 1.1912\n",
      "Epoch [18/50] - Train Loss: 1.1493, Test Loss: 1.1912\n",
      "Epoch [19/50] - Train Loss: 1.1492, Test Loss: 1.1912\n",
      "Epoch [20/50] - Train Loss: 1.1491, Test Loss: 1.1912\n",
      "Epoch [21/50] - Train Loss: 1.1490, Test Loss: 1.1913\n",
      "Epoch [22/50] - Train Loss: 1.1489, Test Loss: 1.1913\n",
      "Epoch [23/50] - Train Loss: 1.1488, Test Loss: 1.1913\n",
      "Epoch [24/50] - Train Loss: 1.1487, Test Loss: 1.1913\n",
      "Epoch [25/50] - Train Loss: 1.1486, Test Loss: 1.1913\n",
      "Epoch [26/50] - Train Loss: 1.1485, Test Loss: 1.1914\n",
      "Epoch [27/50] - Train Loss: 1.1484, Test Loss: 1.1914\n",
      "Epoch [28/50] - Train Loss: 1.1483, Test Loss: 1.1914\n",
      "Epoch [29/50] - Train Loss: 1.1481, Test Loss: 1.1915\n",
      "Epoch [30/50] - Train Loss: 1.1480, Test Loss: 1.1915\n",
      "Epoch [31/50] - Train Loss: 1.1479, Test Loss: 1.1916\n",
      "Epoch [32/50] - Train Loss: 1.1478, Test Loss: 1.1917\n",
      "Epoch [33/50] - Train Loss: 1.1476, Test Loss: 1.1917\n",
      "Epoch [34/50] - Train Loss: 1.1475, Test Loss: 1.1918\n",
      "Epoch [35/50] - Train Loss: 1.1473, Test Loss: 1.1919\n",
      "Epoch [36/50] - Train Loss: 1.1472, Test Loss: 1.1920\n",
      "Epoch [37/50] - Train Loss: 1.1470, Test Loss: 1.1922\n",
      "Epoch [38/50] - Train Loss: 1.1468, Test Loss: 1.1923\n",
      "Epoch [39/50] - Train Loss: 1.1466, Test Loss: 1.1924\n",
      "Epoch [40/50] - Train Loss: 1.1465, Test Loss: 1.1925\n",
      "Epoch [41/50] - Train Loss: 1.1463, Test Loss: 1.1927\n",
      "Epoch [42/50] - Train Loss: 1.1461, Test Loss: 1.1928\n",
      "Epoch [43/50] - Train Loss: 1.1458, Test Loss: 1.1930\n",
      "Epoch [44/50] - Train Loss: 1.1456, Test Loss: 1.1931\n",
      "Epoch [45/50] - Train Loss: 1.1454, Test Loss: 1.1933\n",
      "Epoch [46/50] - Train Loss: 1.1451, Test Loss: 1.1935\n",
      "Epoch [47/50] - Train Loss: 1.1449, Test Loss: 1.1937\n",
      "Epoch [48/50] - Train Loss: 1.1446, Test Loss: 1.1939\n",
      "Epoch [49/50] - Train Loss: 1.1443, Test Loss: 1.1941\n",
      "Epoch [50/50] - Train Loss: 1.1440, Test Loss: 1.1943\n",
      "Avg Test Loss: 1.1943\n",
      "Testing combination: (16, 1, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.4869, Test Loss: 1.7335\n",
      "Epoch [2/50] - Train Loss: 1.4866, Test Loss: 1.7336\n",
      "Epoch [3/50] - Train Loss: 1.4865, Test Loss: 1.7337\n",
      "Epoch [4/50] - Train Loss: 1.4865, Test Loss: 1.7338\n",
      "Epoch [5/50] - Train Loss: 1.4864, Test Loss: 1.7339\n",
      "Epoch [6/50] - Train Loss: 1.4864, Test Loss: 1.7340\n",
      "Epoch [7/50] - Train Loss: 1.4864, Test Loss: 1.7341\n",
      "Epoch [8/50] - Train Loss: 1.4864, Test Loss: 1.7342\n",
      "Epoch [9/50] - Train Loss: 1.4863, Test Loss: 1.7344\n",
      "Epoch [10/50] - Train Loss: 1.4863, Test Loss: 1.7345\n",
      "Epoch [11/50] - Train Loss: 1.4863, Test Loss: 1.7346\n",
      "Epoch [12/50] - Train Loss: 1.4863, Test Loss: 1.7346\n",
      "Epoch [13/50] - Train Loss: 1.4862, Test Loss: 1.7347\n",
      "Epoch [14/50] - Train Loss: 1.4862, Test Loss: 1.7348\n",
      "Epoch [15/50] - Train Loss: 1.4862, Test Loss: 1.7349\n",
      "Epoch [16/50] - Train Loss: 1.4862, Test Loss: 1.7350\n",
      "Epoch [17/50] - Train Loss: 1.4862, Test Loss: 1.7351\n",
      "Epoch [18/50] - Train Loss: 1.4861, Test Loss: 1.7352\n",
      "Epoch [19/50] - Train Loss: 1.4861, Test Loss: 1.7353\n",
      "Epoch [20/50] - Train Loss: 1.4861, Test Loss: 1.7353\n",
      "Epoch [21/50] - Train Loss: 1.4861, Test Loss: 1.7354\n",
      "Epoch [22/50] - Train Loss: 1.4861, Test Loss: 1.7355\n",
      "Epoch [23/50] - Train Loss: 1.4860, Test Loss: 1.7356\n",
      "Epoch [24/50] - Train Loss: 1.4860, Test Loss: 1.7357\n",
      "Epoch [25/50] - Train Loss: 1.4860, Test Loss: 1.7358\n",
      "Epoch [26/50] - Train Loss: 1.4860, Test Loss: 1.7358\n",
      "Epoch [27/50] - Train Loss: 1.4860, Test Loss: 1.7359\n",
      "Epoch [28/50] - Train Loss: 1.4859, Test Loss: 1.7360\n",
      "Epoch [29/50] - Train Loss: 1.4859, Test Loss: 1.7361\n",
      "Epoch [30/50] - Train Loss: 1.4859, Test Loss: 1.7361\n",
      "Epoch [31/50] - Train Loss: 1.4859, Test Loss: 1.7362\n",
      "Epoch [32/50] - Train Loss: 1.4859, Test Loss: 1.7362\n",
      "Epoch [33/50] - Train Loss: 1.4859, Test Loss: 1.7363\n",
      "Epoch [34/50] - Train Loss: 1.4858, Test Loss: 1.7364\n",
      "Epoch [35/50] - Train Loss: 1.4858, Test Loss: 1.7365\n",
      "Epoch [36/50] - Train Loss: 1.4858, Test Loss: 1.7365\n",
      "Epoch [37/50] - Train Loss: 1.4858, Test Loss: 1.7366\n",
      "Epoch [38/50] - Train Loss: 1.4858, Test Loss: 1.7367\n",
      "Epoch [39/50] - Train Loss: 1.4858, Test Loss: 1.7368\n",
      "Epoch [40/50] - Train Loss: 1.4857, Test Loss: 1.7369\n",
      "Epoch [41/50] - Train Loss: 1.4857, Test Loss: 1.7369\n",
      "Epoch [42/50] - Train Loss: 1.4857, Test Loss: 1.7370\n",
      "Epoch [43/50] - Train Loss: 1.4857, Test Loss: 1.7371\n",
      "Epoch [44/50] - Train Loss: 1.4857, Test Loss: 1.7373\n",
      "Epoch [45/50] - Train Loss: 1.4857, Test Loss: 1.7375\n",
      "Epoch [46/50] - Train Loss: 1.4856, Test Loss: 1.7377\n",
      "Epoch [47/50] - Train Loss: 1.4856, Test Loss: 1.7379\n",
      "Epoch [48/50] - Train Loss: 1.4856, Test Loss: 1.7381\n",
      "Epoch [49/50] - Train Loss: 1.4856, Test Loss: 1.7383\n",
      "Epoch [50/50] - Train Loss: 1.4855, Test Loss: 1.7386\n",
      "Avg Test Loss: 1.7386\n",
      "Testing combination: (16, 2, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1494, Test Loss: 1.0859\n",
      "Epoch [2/50] - Train Loss: 1.1201, Test Loss: 1.0852\n",
      "Epoch [3/50] - Train Loss: 1.1198, Test Loss: 1.0853\n",
      "Epoch [4/50] - Train Loss: 1.1194, Test Loss: 1.0867\n",
      "Epoch [5/50] - Train Loss: 1.1182, Test Loss: 1.0878\n",
      "Epoch [6/50] - Train Loss: 1.1154, Test Loss: 1.0918\n",
      "Epoch [7/50] - Train Loss: 1.1040, Test Loss: 1.1068\n",
      "Epoch [8/50] - Train Loss: 1.0881, Test Loss: 1.1367\n",
      "Epoch [9/50] - Train Loss: 1.0835, Test Loss: 1.1711\n",
      "Epoch [10/50] - Train Loss: 1.0702, Test Loss: 1.2092\n",
      "Epoch [11/50] - Train Loss: 1.0736, Test Loss: 1.2033\n",
      "Epoch [12/50] - Train Loss: 1.0714, Test Loss: 1.2059\n",
      "Epoch [13/50] - Train Loss: 1.0685, Test Loss: 1.1884\n",
      "Epoch [14/50] - Train Loss: 1.0668, Test Loss: 1.1843\n",
      "Epoch [15/50] - Train Loss: 1.0643, Test Loss: 1.1948\n",
      "Epoch [16/50] - Train Loss: 1.0649, Test Loss: 1.1936\n",
      "Epoch [17/50] - Train Loss: 1.0646, Test Loss: 1.1973\n",
      "Epoch [18/50] - Train Loss: 1.0641, Test Loss: 1.1988\n",
      "Epoch [19/50] - Train Loss: 1.0642, Test Loss: 1.1986\n",
      "Epoch [20/50] - Train Loss: 1.0639, Test Loss: 1.2011\n",
      "Epoch [21/50] - Train Loss: 1.0648, Test Loss: 1.1906\n",
      "Epoch [22/50] - Train Loss: 1.0638, Test Loss: 1.2431\n",
      "Epoch [23/50] - Train Loss: 1.0681, Test Loss: 1.2335\n",
      "Epoch [24/50] - Train Loss: 1.0692, Test Loss: 1.1652\n",
      "Epoch [25/50] - Train Loss: 1.0571, Test Loss: 1.2077\n",
      "Epoch [26/50] - Train Loss: 1.0508, Test Loss: 1.2211\n",
      "Epoch [27/50] - Train Loss: 1.0487, Test Loss: 1.2100\n",
      "Epoch [28/50] - Train Loss: 1.0490, Test Loss: 1.2138\n",
      "Epoch [29/50] - Train Loss: 1.0463, Test Loss: 1.2044\n",
      "Epoch [30/50] - Train Loss: 1.0919, Test Loss: 1.2037\n",
      "Epoch [31/50] - Train Loss: 1.0876, Test Loss: 1.1964\n",
      "Epoch [32/50] - Train Loss: 1.0830, Test Loss: 1.1711\n",
      "Epoch [33/50] - Train Loss: 1.0802, Test Loss: 1.1854\n",
      "Epoch [34/50] - Train Loss: 1.0735, Test Loss: 1.2053\n",
      "Epoch [35/50] - Train Loss: 1.0683, Test Loss: 1.2053\n",
      "Epoch [36/50] - Train Loss: 1.0641, Test Loss: 1.1994\n",
      "Epoch [37/50] - Train Loss: 1.0615, Test Loss: 1.2053\n",
      "Epoch [38/50] - Train Loss: 1.0555, Test Loss: 1.2223\n",
      "Epoch [39/50] - Train Loss: 1.0520, Test Loss: 1.2177\n",
      "Epoch [40/50] - Train Loss: 1.0455, Test Loss: 1.2594\n",
      "Epoch [41/50] - Train Loss: 1.0321, Test Loss: 1.2626\n",
      "Epoch [42/50] - Train Loss: 1.0229, Test Loss: 1.2009\n",
      "Epoch [43/50] - Train Loss: 1.0445, Test Loss: 1.2024\n",
      "Epoch [44/50] - Train Loss: 1.0928, Test Loss: 1.1919\n",
      "Epoch [45/50] - Train Loss: 1.0920, Test Loss: 1.1935\n",
      "Epoch [46/50] - Train Loss: 1.0825, Test Loss: 1.2174\n",
      "Epoch [47/50] - Train Loss: 1.0743, Test Loss: 1.2115\n",
      "Epoch [48/50] - Train Loss: 1.0716, Test Loss: 1.2048\n",
      "Epoch [49/50] - Train Loss: 1.0695, Test Loss: 1.2065\n",
      "Epoch [50/50] - Train Loss: 1.0683, Test Loss: 1.2088\n",
      "Avg Test Loss: 1.2088\n",
      "Testing combination: (16, 2, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.2139, Test Loss: 1.1653\n",
      "Epoch [2/50] - Train Loss: 1.1547, Test Loss: 1.1503\n",
      "Epoch [3/50] - Train Loss: 1.1524, Test Loss: 1.1523\n",
      "Epoch [4/50] - Train Loss: 1.1510, Test Loss: 1.1576\n",
      "Epoch [5/50] - Train Loss: 1.1501, Test Loss: 1.1623\n",
      "Epoch [6/50] - Train Loss: 1.1488, Test Loss: 1.1656\n",
      "Epoch [7/50] - Train Loss: 1.1430, Test Loss: 1.1692\n",
      "Epoch [8/50] - Train Loss: 1.1171, Test Loss: 1.1777\n",
      "Epoch [9/50] - Train Loss: 1.0595, Test Loss: 1.2270\n",
      "Epoch [10/50] - Train Loss: 1.6746, Test Loss: 1.1571\n",
      "Epoch [11/50] - Train Loss: 1.1298, Test Loss: 1.1472\n",
      "Epoch [12/50] - Train Loss: 1.1298, Test Loss: 1.1475\n",
      "Epoch [13/50] - Train Loss: 1.1234, Test Loss: 1.1500\n",
      "Epoch [14/50] - Train Loss: 1.1136, Test Loss: 1.1542\n",
      "Epoch [15/50] - Train Loss: 1.0981, Test Loss: 1.1625\n",
      "Epoch [16/50] - Train Loss: 1.0767, Test Loss: 1.1787\n",
      "Epoch [17/50] - Train Loss: 1.0609, Test Loss: 1.1953\n",
      "Epoch [18/50] - Train Loss: 1.0547, Test Loss: 1.2092\n",
      "Epoch [19/50] - Train Loss: 1.0533, Test Loss: 1.2189\n",
      "Epoch [20/50] - Train Loss: 1.0486, Test Loss: 1.2268\n",
      "Epoch [21/50] - Train Loss: 1.0451, Test Loss: 1.2351\n",
      "Epoch [22/50] - Train Loss: 1.0436, Test Loss: 1.2431\n",
      "Epoch [23/50] - Train Loss: 1.0426, Test Loss: 1.2470\n",
      "Epoch [24/50] - Train Loss: 1.0419, Test Loss: 1.2479\n",
      "Epoch [25/50] - Train Loss: 1.0416, Test Loss: 1.2483\n",
      "Epoch [26/50] - Train Loss: 1.0413, Test Loss: 1.2488\n",
      "Epoch [27/50] - Train Loss: 1.0409, Test Loss: 1.2492\n",
      "Epoch [28/50] - Train Loss: 1.0407, Test Loss: 1.2494\n",
      "Epoch [29/50] - Train Loss: 1.0405, Test Loss: 1.2496\n",
      "Epoch [30/50] - Train Loss: 1.0403, Test Loss: 1.2498\n",
      "Epoch [31/50] - Train Loss: 1.0400, Test Loss: 1.2501\n",
      "Epoch [32/50] - Train Loss: 1.0398, Test Loss: 1.2505\n",
      "Epoch [33/50] - Train Loss: 1.0395, Test Loss: 1.2510\n",
      "Epoch [34/50] - Train Loss: 1.0391, Test Loss: 1.2516\n",
      "Epoch [35/50] - Train Loss: 1.0385, Test Loss: 1.2525\n",
      "Epoch [36/50] - Train Loss: 1.0378, Test Loss: 1.2541\n",
      "Epoch [37/50] - Train Loss: 1.0367, Test Loss: 1.2563\n",
      "Epoch [38/50] - Train Loss: 1.0348, Test Loss: 1.2594\n",
      "Epoch [39/50] - Train Loss: 1.0321, Test Loss: 1.2673\n",
      "Epoch [40/50] - Train Loss: 1.0411, Test Loss: 1.2794\n",
      "Epoch [41/50] - Train Loss: 1.0854, Test Loss: 1.2698\n",
      "Epoch [42/50] - Train Loss: 1.0505, Test Loss: 1.2565\n",
      "Epoch [43/50] - Train Loss: 1.0495, Test Loss: 1.2574\n",
      "Epoch [44/50] - Train Loss: 1.0480, Test Loss: 1.2638\n",
      "Epoch [45/50] - Train Loss: 1.0476, Test Loss: 1.2686\n",
      "Epoch [46/50] - Train Loss: 1.0475, Test Loss: 1.2702\n",
      "Epoch [47/50] - Train Loss: 1.0473, Test Loss: 1.2697\n",
      "Epoch [48/50] - Train Loss: 1.0472, Test Loss: 1.2685\n",
      "Epoch [49/50] - Train Loss: 1.0472, Test Loss: 1.2675\n",
      "Epoch [50/50] - Train Loss: 1.0471, Test Loss: 1.2670\n",
      "Avg Test Loss: 1.2670\n",
      "Testing combination: (16, 2, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5390, Test Loss: 1.7601\n",
      "Epoch [2/50] - Train Loss: 1.4920, Test Loss: 1.7367\n",
      "Epoch [3/50] - Train Loss: 1.4827, Test Loss: 1.7333\n",
      "Epoch [4/50] - Train Loss: 1.4846, Test Loss: 1.7362\n",
      "Epoch [5/50] - Train Loss: 1.4877, Test Loss: 1.7399\n",
      "Epoch [6/50] - Train Loss: 1.4885, Test Loss: 1.7430\n",
      "Epoch [7/50] - Train Loss: 1.4867, Test Loss: 1.7462\n",
      "Epoch [8/50] - Train Loss: 1.4822, Test Loss: 1.7516\n",
      "Epoch [9/50] - Train Loss: 1.4740, Test Loss: 1.7584\n",
      "Epoch [10/50] - Train Loss: 1.4614, Test Loss: 1.7740\n",
      "Epoch [11/50] - Train Loss: 1.4443, Test Loss: 1.8197\n",
      "Epoch [12/50] - Train Loss: 1.4294, Test Loss: 1.8997\n",
      "Epoch [13/50] - Train Loss: 1.4251, Test Loss: 1.9974\n",
      "Epoch [14/50] - Train Loss: 1.4240, Test Loss: 2.0793\n",
      "Epoch [15/50] - Train Loss: 1.4222, Test Loss: 2.1187\n",
      "Epoch [16/50] - Train Loss: 1.4201, Test Loss: 2.1239\n",
      "Epoch [17/50] - Train Loss: 1.4174, Test Loss: 2.1304\n",
      "Epoch [18/50] - Train Loss: 1.4155, Test Loss: 2.1615\n",
      "Epoch [19/50] - Train Loss: 1.4134, Test Loss: 2.1695\n",
      "Epoch [20/50] - Train Loss: 1.4087, Test Loss: 2.1651\n",
      "Epoch [21/50] - Train Loss: 1.4082, Test Loss: 2.1808\n",
      "Epoch [22/50] - Train Loss: 1.4079, Test Loss: 2.1935\n",
      "Epoch [23/50] - Train Loss: 1.4070, Test Loss: 2.1862\n",
      "Epoch [24/50] - Train Loss: 1.4057, Test Loss: 2.2030\n",
      "Epoch [25/50] - Train Loss: 1.4048, Test Loss: 2.2279\n",
      "Epoch [26/50] - Train Loss: 1.4027, Test Loss: 2.2516\n",
      "Epoch [27/50] - Train Loss: 1.3967, Test Loss: 1.9808\n",
      "Epoch [28/50] - Train Loss: 1.4579, Test Loss: 1.9681\n",
      "Epoch [29/50] - Train Loss: 1.4122, Test Loss: 2.2449\n",
      "Epoch [30/50] - Train Loss: 1.6685, Test Loss: 2.2575\n",
      "Epoch [31/50] - Train Loss: 1.4040, Test Loss: 2.0011\n",
      "Epoch [32/50] - Train Loss: 1.4466, Test Loss: 1.9217\n",
      "Epoch [33/50] - Train Loss: 1.4531, Test Loss: 1.8871\n",
      "Epoch [34/50] - Train Loss: 1.4434, Test Loss: 1.9026\n",
      "Epoch [35/50] - Train Loss: 1.4248, Test Loss: 1.9609\n",
      "Epoch [36/50] - Train Loss: 1.4025, Test Loss: 2.0046\n",
      "Epoch [37/50] - Train Loss: 1.3836, Test Loss: 2.0563\n",
      "Epoch [38/50] - Train Loss: 1.3784, Test Loss: 2.1125\n",
      "Epoch [39/50] - Train Loss: 1.3765, Test Loss: 2.1542\n",
      "Epoch [40/50] - Train Loss: 1.3750, Test Loss: 2.1789\n",
      "Epoch [41/50] - Train Loss: 1.3711, Test Loss: 2.0336\n",
      "Epoch [42/50] - Train Loss: 1.3725, Test Loss: 2.2115\n",
      "Epoch [43/50] - Train Loss: 1.3670, Test Loss: 2.1101\n",
      "Epoch [44/50] - Train Loss: 1.5305, Test Loss: 2.1274\n",
      "Epoch [45/50] - Train Loss: 1.4084, Test Loss: 1.7822\n",
      "Epoch [46/50] - Train Loss: 1.5076, Test Loss: 1.7694\n",
      "Epoch [47/50] - Train Loss: 1.5018, Test Loss: 1.7567\n",
      "Epoch [48/50] - Train Loss: 1.4955, Test Loss: 1.7482\n",
      "Epoch [49/50] - Train Loss: 1.4910, Test Loss: 1.7437\n",
      "Epoch [50/50] - Train Loss: 1.4882, Test Loss: 1.7420\n",
      "Avg Test Loss: 1.7420\n",
      "Testing combination: (16, 2, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1629, Test Loss: 1.1587\n",
      "Epoch [2/50] - Train Loss: 1.1431, Test Loss: 1.1349\n",
      "Epoch [3/50] - Train Loss: 1.1310, Test Loss: 1.1181\n",
      "Epoch [4/50] - Train Loss: 1.1234, Test Loss: 1.1065\n",
      "Epoch [5/50] - Train Loss: 1.1190, Test Loss: 1.0991\n",
      "Epoch [6/50] - Train Loss: 1.1168, Test Loss: 1.0950\n",
      "Epoch [7/50] - Train Loss: 1.1159, Test Loss: 1.0932\n",
      "Epoch [8/50] - Train Loss: 1.1155, Test Loss: 1.0929\n",
      "Epoch [9/50] - Train Loss: 1.1153, Test Loss: 1.0934\n",
      "Epoch [10/50] - Train Loss: 1.1150, Test Loss: 1.0943\n",
      "Epoch [11/50] - Train Loss: 1.1147, Test Loss: 1.0954\n",
      "Epoch [12/50] - Train Loss: 1.1143, Test Loss: 1.0966\n",
      "Epoch [13/50] - Train Loss: 1.1138, Test Loss: 1.0976\n",
      "Epoch [14/50] - Train Loss: 1.1131, Test Loss: 1.0986\n",
      "Epoch [15/50] - Train Loss: 1.1123, Test Loss: 1.0994\n",
      "Epoch [16/50] - Train Loss: 1.1112, Test Loss: 1.1002\n",
      "Epoch [17/50] - Train Loss: 1.1097, Test Loss: 1.1010\n",
      "Epoch [18/50] - Train Loss: 1.1074, Test Loss: 1.1018\n",
      "Epoch [19/50] - Train Loss: 1.1045, Test Loss: 1.1025\n",
      "Epoch [20/50] - Train Loss: 1.1013, Test Loss: 1.1033\n",
      "Epoch [21/50] - Train Loss: 1.0986, Test Loss: 1.1050\n",
      "Epoch [22/50] - Train Loss: 1.0961, Test Loss: 1.1076\n",
      "Epoch [23/50] - Train Loss: 1.0936, Test Loss: 1.1107\n",
      "Epoch [24/50] - Train Loss: 1.0911, Test Loss: 1.1144\n",
      "Epoch [25/50] - Train Loss: 1.0885, Test Loss: 1.1187\n",
      "Epoch [26/50] - Train Loss: 1.0858, Test Loss: 1.1240\n",
      "Epoch [27/50] - Train Loss: 1.0830, Test Loss: 1.1303\n",
      "Epoch [28/50] - Train Loss: 1.0803, Test Loss: 1.1379\n",
      "Epoch [29/50] - Train Loss: 1.0776, Test Loss: 1.1479\n",
      "Epoch [30/50] - Train Loss: 1.0751, Test Loss: 1.1591\n",
      "Epoch [31/50] - Train Loss: 1.0733, Test Loss: 1.1698\n",
      "Epoch [32/50] - Train Loss: 1.0720, Test Loss: 1.1787\n",
      "Epoch [33/50] - Train Loss: 1.0712, Test Loss: 1.1854\n",
      "Epoch [34/50] - Train Loss: 1.0708, Test Loss: 1.1901\n",
      "Epoch [35/50] - Train Loss: 1.0705, Test Loss: 1.1939\n",
      "Epoch [36/50] - Train Loss: 1.0702, Test Loss: 1.1969\n",
      "Epoch [37/50] - Train Loss: 1.0699, Test Loss: 1.1996\n",
      "Epoch [38/50] - Train Loss: 1.0695, Test Loss: 1.2020\n",
      "Epoch [39/50] - Train Loss: 1.0692, Test Loss: 1.2045\n",
      "Epoch [40/50] - Train Loss: 1.0688, Test Loss: 1.2069\n",
      "Epoch [41/50] - Train Loss: 1.0685, Test Loss: 1.2094\n",
      "Epoch [42/50] - Train Loss: 1.0681, Test Loss: 1.2119\n",
      "Epoch [43/50] - Train Loss: 1.0678, Test Loss: 1.2143\n",
      "Epoch [44/50] - Train Loss: 1.0675, Test Loss: 1.2168\n",
      "Epoch [45/50] - Train Loss: 1.0672, Test Loss: 1.2192\n",
      "Epoch [46/50] - Train Loss: 1.0669, Test Loss: 1.2217\n",
      "Epoch [47/50] - Train Loss: 1.0666, Test Loss: 1.2243\n",
      "Epoch [48/50] - Train Loss: 1.0663, Test Loss: 1.2268\n",
      "Epoch [49/50] - Train Loss: 1.0660, Test Loss: 1.2291\n",
      "Epoch [50/50] - Train Loss: 1.0656, Test Loss: 1.2314\n",
      "Avg Test Loss: 1.2314\n",
      "Testing combination: (16, 2, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1528, Test Loss: 1.1490\n",
      "Epoch [2/50] - Train Loss: 1.1506, Test Loss: 1.1507\n",
      "Epoch [3/50] - Train Loss: 1.1500, Test Loss: 1.1525\n",
      "Epoch [4/50] - Train Loss: 1.1496, Test Loss: 1.1543\n",
      "Epoch [5/50] - Train Loss: 1.1492, Test Loss: 1.1561\n",
      "Epoch [6/50] - Train Loss: 1.1489, Test Loss: 1.1580\n",
      "Epoch [7/50] - Train Loss: 1.1484, Test Loss: 1.1600\n",
      "Epoch [8/50] - Train Loss: 1.1479, Test Loss: 1.1623\n",
      "Epoch [9/50] - Train Loss: 1.1471, Test Loss: 1.1647\n",
      "Epoch [10/50] - Train Loss: 1.1458, Test Loss: 1.1672\n",
      "Epoch [11/50] - Train Loss: 1.1438, Test Loss: 1.1699\n",
      "Epoch [12/50] - Train Loss: 1.1407, Test Loss: 1.1730\n",
      "Epoch [13/50] - Train Loss: 1.1355, Test Loss: 1.1771\n",
      "Epoch [14/50] - Train Loss: 1.1278, Test Loss: 1.1824\n",
      "Epoch [15/50] - Train Loss: 1.1174, Test Loss: 1.1888\n",
      "Epoch [16/50] - Train Loss: 1.1054, Test Loss: 1.1952\n",
      "Epoch [17/50] - Train Loss: 1.0934, Test Loss: 1.2009\n",
      "Epoch [18/50] - Train Loss: 1.0821, Test Loss: 1.2059\n",
      "Epoch [19/50] - Train Loss: 1.0721, Test Loss: 1.2113\n",
      "Epoch [20/50] - Train Loss: 1.0642, Test Loss: 1.2172\n",
      "Epoch [21/50] - Train Loss: 1.0582, Test Loss: 1.2234\n",
      "Epoch [22/50] - Train Loss: 1.0542, Test Loss: 1.2295\n",
      "Epoch [23/50] - Train Loss: 1.0516, Test Loss: 1.2351\n",
      "Epoch [24/50] - Train Loss: 1.0501, Test Loss: 1.2400\n",
      "Epoch [25/50] - Train Loss: 1.0490, Test Loss: 1.2443\n",
      "Epoch [26/50] - Train Loss: 1.0482, Test Loss: 1.2480\n",
      "Epoch [27/50] - Train Loss: 1.0474, Test Loss: 1.2515\n",
      "Epoch [28/50] - Train Loss: 1.0467, Test Loss: 1.2548\n",
      "Epoch [29/50] - Train Loss: 1.0459, Test Loss: 1.2580\n",
      "Epoch [30/50] - Train Loss: 1.0452, Test Loss: 1.2610\n",
      "Epoch [31/50] - Train Loss: 1.0445, Test Loss: 1.2641\n",
      "Epoch [32/50] - Train Loss: 1.0437, Test Loss: 1.2668\n",
      "Epoch [33/50] - Train Loss: 1.0429, Test Loss: 1.2690\n",
      "Epoch [34/50] - Train Loss: 1.0421, Test Loss: 1.2709\n",
      "Epoch [35/50] - Train Loss: 1.0413, Test Loss: 1.2727\n",
      "Epoch [36/50] - Train Loss: 1.0405, Test Loss: 1.2743\n",
      "Epoch [37/50] - Train Loss: 1.0399, Test Loss: 1.2757\n",
      "Epoch [38/50] - Train Loss: 1.0384, Test Loss: 1.2714\n",
      "Epoch [39/50] - Train Loss: 1.0389, Test Loss: 1.2793\n",
      "Epoch [40/50] - Train Loss: 1.0382, Test Loss: 1.2770\n",
      "Epoch [41/50] - Train Loss: 1.0349, Test Loss: 1.2727\n",
      "Epoch [42/50] - Train Loss: 1.0347, Test Loss: 1.2737\n",
      "Epoch [43/50] - Train Loss: 1.0326, Test Loss: 1.2764\n",
      "Epoch [44/50] - Train Loss: 1.0323, Test Loss: 1.2264\n",
      "Epoch [45/50] - Train Loss: 1.0396, Test Loss: 1.2591\n",
      "Epoch [46/50] - Train Loss: 1.0505, Test Loss: 1.2635\n",
      "Epoch [47/50] - Train Loss: 1.0253, Test Loss: 1.2456\n",
      "Epoch [48/50] - Train Loss: 1.0285, Test Loss: 1.2492\n",
      "Epoch [49/50] - Train Loss: 1.0259, Test Loss: 1.2482\n",
      "Epoch [50/50] - Train Loss: 1.0307, Test Loss: 1.2908\n",
      "Avg Test Loss: 1.2908\n",
      "Testing combination: (16, 2, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5077, Test Loss: 1.7529\n",
      "Epoch [2/50] - Train Loss: 1.5011, Test Loss: 1.7488\n",
      "Epoch [3/50] - Train Loss: 1.4969, Test Loss: 1.7454\n",
      "Epoch [4/50] - Train Loss: 1.4935, Test Loss: 1.7428\n",
      "Epoch [5/50] - Train Loss: 1.4909, Test Loss: 1.7411\n",
      "Epoch [6/50] - Train Loss: 1.4889, Test Loss: 1.7402\n",
      "Epoch [7/50] - Train Loss: 1.4873, Test Loss: 1.7399\n",
      "Epoch [8/50] - Train Loss: 1.4860, Test Loss: 1.7401\n",
      "Epoch [9/50] - Train Loss: 1.4849, Test Loss: 1.7406\n",
      "Epoch [10/50] - Train Loss: 1.4840, Test Loss: 1.7412\n",
      "Epoch [11/50] - Train Loss: 1.4831, Test Loss: 1.7419\n",
      "Epoch [12/50] - Train Loss: 1.4823, Test Loss: 1.7426\n",
      "Epoch [13/50] - Train Loss: 1.4814, Test Loss: 1.7434\n",
      "Epoch [14/50] - Train Loss: 1.4804, Test Loss: 1.7443\n",
      "Epoch [15/50] - Train Loss: 1.4792, Test Loss: 1.7453\n",
      "Epoch [16/50] - Train Loss: 1.4780, Test Loss: 1.7466\n",
      "Epoch [17/50] - Train Loss: 1.4766, Test Loss: 1.7482\n",
      "Epoch [18/50] - Train Loss: 1.4750, Test Loss: 1.7502\n",
      "Epoch [19/50] - Train Loss: 1.4733, Test Loss: 1.7525\n",
      "Epoch [20/50] - Train Loss: 1.4715, Test Loss: 1.7551\n",
      "Epoch [21/50] - Train Loss: 1.4696, Test Loss: 1.7583\n",
      "Epoch [22/50] - Train Loss: 1.4676, Test Loss: 1.7618\n",
      "Epoch [23/50] - Train Loss: 1.4656, Test Loss: 1.7658\n",
      "Epoch [24/50] - Train Loss: 1.4635, Test Loss: 1.7703\n",
      "Epoch [25/50] - Train Loss: 1.4614, Test Loss: 1.7753\n",
      "Epoch [26/50] - Train Loss: 1.4590, Test Loss: 1.7809\n",
      "Epoch [27/50] - Train Loss: 1.4564, Test Loss: 1.7872\n",
      "Epoch [28/50] - Train Loss: 1.4536, Test Loss: 1.7940\n",
      "Epoch [29/50] - Train Loss: 1.4503, Test Loss: 1.8015\n",
      "Epoch [30/50] - Train Loss: 1.4465, Test Loss: 1.8099\n",
      "Epoch [31/50] - Train Loss: 1.4424, Test Loss: 1.8191\n",
      "Epoch [32/50] - Train Loss: 1.4381, Test Loss: 1.8293\n",
      "Epoch [33/50] - Train Loss: 1.4337, Test Loss: 1.8407\n",
      "Epoch [34/50] - Train Loss: 1.4295, Test Loss: 1.8538\n",
      "Epoch [35/50] - Train Loss: 1.4259, Test Loss: 1.8692\n",
      "Epoch [36/50] - Train Loss: 1.4228, Test Loss: 1.8865\n",
      "Epoch [37/50] - Train Loss: 1.4204, Test Loss: 1.9046\n",
      "Epoch [38/50] - Train Loss: 1.4186, Test Loss: 1.9218\n",
      "Epoch [39/50] - Train Loss: 1.4172, Test Loss: 1.9371\n",
      "Epoch [40/50] - Train Loss: 1.4163, Test Loss: 1.9503\n",
      "Epoch [41/50] - Train Loss: 1.4157, Test Loss: 1.9612\n",
      "Epoch [42/50] - Train Loss: 1.4153, Test Loss: 1.9704\n",
      "Epoch [43/50] - Train Loss: 1.4151, Test Loss: 1.9779\n",
      "Epoch [44/50] - Train Loss: 1.4148, Test Loss: 1.9843\n",
      "Epoch [45/50] - Train Loss: 1.4145, Test Loss: 1.9897\n",
      "Epoch [46/50] - Train Loss: 1.4142, Test Loss: 1.9944\n",
      "Epoch [47/50] - Train Loss: 1.4139, Test Loss: 1.9987\n",
      "Epoch [48/50] - Train Loss: 1.4135, Test Loss: 2.0026\n",
      "Epoch [49/50] - Train Loss: 1.4131, Test Loss: 2.0063\n",
      "Epoch [50/50] - Train Loss: 1.4127, Test Loss: 2.0099\n",
      "Avg Test Loss: 2.0099\n",
      "Testing combination: (16, 2, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1776, Test Loss: 1.1111\n",
      "Epoch [2/50] - Train Loss: 1.1739, Test Loss: 1.1088\n",
      "Epoch [3/50] - Train Loss: 1.1709, Test Loss: 1.1067\n",
      "Epoch [4/50] - Train Loss: 1.1681, Test Loss: 1.1047\n",
      "Epoch [5/50] - Train Loss: 1.1654, Test Loss: 1.1029\n",
      "Epoch [6/50] - Train Loss: 1.1629, Test Loss: 1.1012\n",
      "Epoch [7/50] - Train Loss: 1.1605, Test Loss: 1.0995\n",
      "Epoch [8/50] - Train Loss: 1.1582, Test Loss: 1.0980\n",
      "Epoch [9/50] - Train Loss: 1.1560, Test Loss: 1.0965\n",
      "Epoch [10/50] - Train Loss: 1.1539, Test Loss: 1.0952\n",
      "Epoch [11/50] - Train Loss: 1.1519, Test Loss: 1.0939\n",
      "Epoch [12/50] - Train Loss: 1.1499, Test Loss: 1.0927\n",
      "Epoch [13/50] - Train Loss: 1.1481, Test Loss: 1.0915\n",
      "Epoch [14/50] - Train Loss: 1.1463, Test Loss: 1.0905\n",
      "Epoch [15/50] - Train Loss: 1.1446, Test Loss: 1.0895\n",
      "Epoch [16/50] - Train Loss: 1.1430, Test Loss: 1.0886\n",
      "Epoch [17/50] - Train Loss: 1.1414, Test Loss: 1.0877\n",
      "Epoch [18/50] - Train Loss: 1.1400, Test Loss: 1.0869\n",
      "Epoch [19/50] - Train Loss: 1.1385, Test Loss: 1.0862\n",
      "Epoch [20/50] - Train Loss: 1.1372, Test Loss: 1.0855\n",
      "Epoch [21/50] - Train Loss: 1.1359, Test Loss: 1.0849\n",
      "Epoch [22/50] - Train Loss: 1.1347, Test Loss: 1.0843\n",
      "Epoch [23/50] - Train Loss: 1.1335, Test Loss: 1.0838\n",
      "Epoch [24/50] - Train Loss: 1.1324, Test Loss: 1.0833\n",
      "Epoch [25/50] - Train Loss: 1.1313, Test Loss: 1.0829\n",
      "Epoch [26/50] - Train Loss: 1.1303, Test Loss: 1.0825\n",
      "Epoch [27/50] - Train Loss: 1.1294, Test Loss: 1.0822\n",
      "Epoch [28/50] - Train Loss: 1.1285, Test Loss: 1.0819\n",
      "Epoch [29/50] - Train Loss: 1.1276, Test Loss: 1.0816\n",
      "Epoch [30/50] - Train Loss: 1.1268, Test Loss: 1.0814\n",
      "Epoch [31/50] - Train Loss: 1.1261, Test Loss: 1.0812\n",
      "Epoch [32/50] - Train Loss: 1.1253, Test Loss: 1.0811\n",
      "Epoch [33/50] - Train Loss: 1.1247, Test Loss: 1.0810\n",
      "Epoch [34/50] - Train Loss: 1.1240, Test Loss: 1.0809\n",
      "Epoch [35/50] - Train Loss: 1.1234, Test Loss: 1.0808\n",
      "Epoch [36/50] - Train Loss: 1.1228, Test Loss: 1.0808\n",
      "Epoch [37/50] - Train Loss: 1.1223, Test Loss: 1.0808\n",
      "Epoch [38/50] - Train Loss: 1.1218, Test Loss: 1.0808\n",
      "Epoch [39/50] - Train Loss: 1.1213, Test Loss: 1.0808\n",
      "Epoch [40/50] - Train Loss: 1.1209, Test Loss: 1.0809\n",
      "Epoch [41/50] - Train Loss: 1.1205, Test Loss: 1.0810\n",
      "Epoch [42/50] - Train Loss: 1.1201, Test Loss: 1.0811\n",
      "Epoch [43/50] - Train Loss: 1.1198, Test Loss: 1.0812\n",
      "Epoch [44/50] - Train Loss: 1.1194, Test Loss: 1.0813\n",
      "Epoch [45/50] - Train Loss: 1.1191, Test Loss: 1.0814\n",
      "Epoch [46/50] - Train Loss: 1.1188, Test Loss: 1.0816\n",
      "Epoch [47/50] - Train Loss: 1.1185, Test Loss: 1.0817\n",
      "Epoch [48/50] - Train Loss: 1.1183, Test Loss: 1.0819\n",
      "Epoch [49/50] - Train Loss: 1.1181, Test Loss: 1.0820\n",
      "Epoch [50/50] - Train Loss: 1.1178, Test Loss: 1.0822\n",
      "Avg Test Loss: 1.0822\n",
      "Testing combination: (16, 2, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1664, Test Loss: 1.1259\n",
      "Epoch [2/50] - Train Loss: 1.1657, Test Loss: 1.1262\n",
      "Epoch [3/50] - Train Loss: 1.1652, Test Loss: 1.1265\n",
      "Epoch [4/50] - Train Loss: 1.1647, Test Loss: 1.1268\n",
      "Epoch [5/50] - Train Loss: 1.1643, Test Loss: 1.1272\n",
      "Epoch [6/50] - Train Loss: 1.1638, Test Loss: 1.1275\n",
      "Epoch [7/50] - Train Loss: 1.1634, Test Loss: 1.1279\n",
      "Epoch [8/50] - Train Loss: 1.1630, Test Loss: 1.1282\n",
      "Epoch [9/50] - Train Loss: 1.1626, Test Loss: 1.1285\n",
      "Epoch [10/50] - Train Loss: 1.1622, Test Loss: 1.1289\n",
      "Epoch [11/50] - Train Loss: 1.1618, Test Loss: 1.1292\n",
      "Epoch [12/50] - Train Loss: 1.1614, Test Loss: 1.1296\n",
      "Epoch [13/50] - Train Loss: 1.1610, Test Loss: 1.1300\n",
      "Epoch [14/50] - Train Loss: 1.1607, Test Loss: 1.1303\n",
      "Epoch [15/50] - Train Loss: 1.1603, Test Loss: 1.1307\n",
      "Epoch [16/50] - Train Loss: 1.1600, Test Loss: 1.1311\n",
      "Epoch [17/50] - Train Loss: 1.1596, Test Loss: 1.1314\n",
      "Epoch [18/50] - Train Loss: 1.1593, Test Loss: 1.1318\n",
      "Epoch [19/50] - Train Loss: 1.1590, Test Loss: 1.1322\n",
      "Epoch [20/50] - Train Loss: 1.1587, Test Loss: 1.1325\n",
      "Epoch [21/50] - Train Loss: 1.1583, Test Loss: 1.1329\n",
      "Epoch [22/50] - Train Loss: 1.1580, Test Loss: 1.1333\n",
      "Epoch [23/50] - Train Loss: 1.1577, Test Loss: 1.1337\n",
      "Epoch [24/50] - Train Loss: 1.1575, Test Loss: 1.1340\n",
      "Epoch [25/50] - Train Loss: 1.1572, Test Loss: 1.1344\n",
      "Epoch [26/50] - Train Loss: 1.1569, Test Loss: 1.1348\n",
      "Epoch [27/50] - Train Loss: 1.1566, Test Loss: 1.1352\n",
      "Epoch [28/50] - Train Loss: 1.1564, Test Loss: 1.1356\n",
      "Epoch [29/50] - Train Loss: 1.1561, Test Loss: 1.1359\n",
      "Epoch [30/50] - Train Loss: 1.1559, Test Loss: 1.1363\n",
      "Epoch [31/50] - Train Loss: 1.1556, Test Loss: 1.1367\n",
      "Epoch [32/50] - Train Loss: 1.1554, Test Loss: 1.1371\n",
      "Epoch [33/50] - Train Loss: 1.1551, Test Loss: 1.1375\n",
      "Epoch [34/50] - Train Loss: 1.1549, Test Loss: 1.1379\n",
      "Epoch [35/50] - Train Loss: 1.1547, Test Loss: 1.1383\n",
      "Epoch [36/50] - Train Loss: 1.1544, Test Loss: 1.1387\n",
      "Epoch [37/50] - Train Loss: 1.1542, Test Loss: 1.1391\n",
      "Epoch [38/50] - Train Loss: 1.1540, Test Loss: 1.1396\n",
      "Epoch [39/50] - Train Loss: 1.1538, Test Loss: 1.1400\n",
      "Epoch [40/50] - Train Loss: 1.1535, Test Loss: 1.1404\n",
      "Epoch [41/50] - Train Loss: 1.1533, Test Loss: 1.1408\n",
      "Epoch [42/50] - Train Loss: 1.1531, Test Loss: 1.1413\n",
      "Epoch [43/50] - Train Loss: 1.1529, Test Loss: 1.1417\n",
      "Epoch [44/50] - Train Loss: 1.1527, Test Loss: 1.1422\n",
      "Epoch [45/50] - Train Loss: 1.1525, Test Loss: 1.1426\n",
      "Epoch [46/50] - Train Loss: 1.1522, Test Loss: 1.1431\n",
      "Epoch [47/50] - Train Loss: 1.1520, Test Loss: 1.1436\n",
      "Epoch [48/50] - Train Loss: 1.1518, Test Loss: 1.1441\n",
      "Epoch [49/50] - Train Loss: 1.1516, Test Loss: 1.1446\n",
      "Epoch [50/50] - Train Loss: 1.1514, Test Loss: 1.1451\n",
      "Avg Test Loss: 1.1451\n",
      "Testing combination: (16, 2, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.4914, Test Loss: 1.7433\n",
      "Epoch [2/50] - Train Loss: 1.4909, Test Loss: 1.7431\n",
      "Epoch [3/50] - Train Loss: 1.4907, Test Loss: 1.7429\n",
      "Epoch [4/50] - Train Loss: 1.4906, Test Loss: 1.7427\n",
      "Epoch [5/50] - Train Loss: 1.4905, Test Loss: 1.7425\n",
      "Epoch [6/50] - Train Loss: 1.4903, Test Loss: 1.7423\n",
      "Epoch [7/50] - Train Loss: 1.4902, Test Loss: 1.7422\n",
      "Epoch [8/50] - Train Loss: 1.4901, Test Loss: 1.7420\n",
      "Epoch [9/50] - Train Loss: 1.4900, Test Loss: 1.7418\n",
      "Epoch [10/50] - Train Loss: 1.4899, Test Loss: 1.7417\n",
      "Epoch [11/50] - Train Loss: 1.4898, Test Loss: 1.7416\n",
      "Epoch [12/50] - Train Loss: 1.4896, Test Loss: 1.7414\n",
      "Epoch [13/50] - Train Loss: 1.4895, Test Loss: 1.7413\n",
      "Epoch [14/50] - Train Loss: 1.4894, Test Loss: 1.7411\n",
      "Epoch [15/50] - Train Loss: 1.4893, Test Loss: 1.7410\n",
      "Epoch [16/50] - Train Loss: 1.4892, Test Loss: 1.7409\n",
      "Epoch [17/50] - Train Loss: 1.4891, Test Loss: 1.7408\n",
      "Epoch [18/50] - Train Loss: 1.4890, Test Loss: 1.7406\n",
      "Epoch [19/50] - Train Loss: 1.4889, Test Loss: 1.7405\n",
      "Epoch [20/50] - Train Loss: 1.4888, Test Loss: 1.7404\n",
      "Epoch [21/50] - Train Loss: 1.4888, Test Loss: 1.7403\n",
      "Epoch [22/50] - Train Loss: 1.4887, Test Loss: 1.7402\n",
      "Epoch [23/50] - Train Loss: 1.4886, Test Loss: 1.7401\n",
      "Epoch [24/50] - Train Loss: 1.4885, Test Loss: 1.7400\n",
      "Epoch [25/50] - Train Loss: 1.4884, Test Loss: 1.7399\n",
      "Epoch [26/50] - Train Loss: 1.4883, Test Loss: 1.7398\n",
      "Epoch [27/50] - Train Loss: 1.4882, Test Loss: 1.7397\n",
      "Epoch [28/50] - Train Loss: 1.4881, Test Loss: 1.7396\n",
      "Epoch [29/50] - Train Loss: 1.4881, Test Loss: 1.7395\n",
      "Epoch [30/50] - Train Loss: 1.4880, Test Loss: 1.7394\n",
      "Epoch [31/50] - Train Loss: 1.4879, Test Loss: 1.7393\n",
      "Epoch [32/50] - Train Loss: 1.4878, Test Loss: 1.7392\n",
      "Epoch [33/50] - Train Loss: 1.4877, Test Loss: 1.7391\n",
      "Epoch [34/50] - Train Loss: 1.4877, Test Loss: 1.7390\n",
      "Epoch [35/50] - Train Loss: 1.4876, Test Loss: 1.7390\n",
      "Epoch [36/50] - Train Loss: 1.4875, Test Loss: 1.7389\n",
      "Epoch [37/50] - Train Loss: 1.4874, Test Loss: 1.7388\n",
      "Epoch [38/50] - Train Loss: 1.4874, Test Loss: 1.7387\n",
      "Epoch [39/50] - Train Loss: 1.4873, Test Loss: 1.7387\n",
      "Epoch [40/50] - Train Loss: 1.4872, Test Loss: 1.7386\n",
      "Epoch [41/50] - Train Loss: 1.4872, Test Loss: 1.7385\n",
      "Epoch [42/50] - Train Loss: 1.4871, Test Loss: 1.7385\n",
      "Epoch [43/50] - Train Loss: 1.4870, Test Loss: 1.7384\n",
      "Epoch [44/50] - Train Loss: 1.4869, Test Loss: 1.7383\n",
      "Epoch [45/50] - Train Loss: 1.4869, Test Loss: 1.7383\n",
      "Epoch [46/50] - Train Loss: 1.4868, Test Loss: 1.7382\n",
      "Epoch [47/50] - Train Loss: 1.4867, Test Loss: 1.7382\n",
      "Epoch [48/50] - Train Loss: 1.4867, Test Loss: 1.7381\n",
      "Epoch [49/50] - Train Loss: 1.4866, Test Loss: 1.7381\n",
      "Epoch [50/50] - Train Loss: 1.4865, Test Loss: 1.7380\n",
      "Avg Test Loss: 1.7380\n",
      "Testing combination: (16, 3, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1412, Test Loss: 1.0890\n",
      "Epoch [2/50] - Train Loss: 1.1186, Test Loss: 1.0865\n",
      "Epoch [3/50] - Train Loss: 1.1182, Test Loss: 1.0862\n",
      "Epoch [4/50] - Train Loss: 1.1180, Test Loss: 1.0870\n",
      "Epoch [5/50] - Train Loss: 1.1167, Test Loss: 1.0892\n",
      "Epoch [6/50] - Train Loss: 1.1105, Test Loss: 1.0949\n",
      "Epoch [7/50] - Train Loss: 1.1035, Test Loss: 1.1047\n",
      "Epoch [8/50] - Train Loss: 1.0885, Test Loss: 1.1300\n",
      "Epoch [9/50] - Train Loss: 1.0831, Test Loss: 1.1602\n",
      "Epoch [10/50] - Train Loss: 1.0771, Test Loss: 1.1957\n",
      "Epoch [11/50] - Train Loss: 1.0740, Test Loss: 1.2218\n",
      "Epoch [12/50] - Train Loss: 1.0798, Test Loss: 1.1933\n",
      "Epoch [13/50] - Train Loss: 1.0672, Test Loss: 1.2073\n",
      "Epoch [14/50] - Train Loss: 1.0660, Test Loss: 1.2139\n",
      "Epoch [15/50] - Train Loss: 1.0657, Test Loss: 1.2151\n",
      "Epoch [16/50] - Train Loss: 1.0659, Test Loss: 1.2119\n",
      "Epoch [17/50] - Train Loss: 1.0647, Test Loss: 1.2080\n",
      "Epoch [18/50] - Train Loss: 1.0636, Test Loss: 1.2072\n",
      "Epoch [19/50] - Train Loss: 1.0646, Test Loss: 1.2077\n",
      "Epoch [20/50] - Train Loss: 1.0632, Test Loss: 1.2075\n",
      "Epoch [21/50] - Train Loss: 1.0641, Test Loss: 1.2068\n",
      "Epoch [22/50] - Train Loss: 1.0627, Test Loss: 1.2066\n",
      "Epoch [23/50] - Train Loss: 1.0644, Test Loss: 1.2064\n",
      "Epoch [24/50] - Train Loss: 1.0622, Test Loss: 1.2058\n",
      "Epoch [25/50] - Train Loss: 1.0645, Test Loss: 1.2054\n",
      "Epoch [26/50] - Train Loss: 1.0627, Test Loss: 1.2053\n",
      "Epoch [27/50] - Train Loss: 1.0650, Test Loss: 1.2068\n",
      "Epoch [28/50] - Train Loss: 1.0615, Test Loss: 1.2043\n",
      "Epoch [29/50] - Train Loss: 1.0626, Test Loss: 1.2009\n",
      "Epoch [30/50] - Train Loss: 1.0609, Test Loss: 1.2005\n",
      "Epoch [31/50] - Train Loss: 1.0775, Test Loss: 1.2059\n",
      "Epoch [32/50] - Train Loss: 1.1019, Test Loss: 1.2125\n",
      "Epoch [33/50] - Train Loss: 1.0712, Test Loss: 1.2259\n",
      "Epoch [34/50] - Train Loss: 1.0669, Test Loss: 1.2117\n",
      "Epoch [35/50] - Train Loss: 1.0654, Test Loss: 1.1953\n",
      "Epoch [36/50] - Train Loss: 1.0613, Test Loss: 1.1992\n",
      "Epoch [37/50] - Train Loss: 1.0633, Test Loss: 1.2060\n",
      "Epoch [38/50] - Train Loss: 1.0584, Test Loss: 1.2120\n",
      "Epoch [39/50] - Train Loss: 1.0576, Test Loss: 1.2113\n",
      "Epoch [40/50] - Train Loss: 1.0499, Test Loss: 1.2067\n",
      "Epoch [41/50] - Train Loss: 1.0495, Test Loss: 1.2118\n",
      "Epoch [42/50] - Train Loss: 1.0486, Test Loss: 1.2185\n",
      "Epoch [43/50] - Train Loss: 1.0487, Test Loss: 1.2219\n",
      "Epoch [44/50] - Train Loss: 1.0495, Test Loss: 1.1960\n",
      "Epoch [45/50] - Train Loss: 1.0501, Test Loss: 1.1980\n",
      "Epoch [46/50] - Train Loss: 1.0513, Test Loss: 1.2027\n",
      "Epoch [47/50] - Train Loss: 1.0479, Test Loss: 1.1994\n",
      "Epoch [48/50] - Train Loss: 1.0482, Test Loss: 1.2059\n",
      "Epoch [49/50] - Train Loss: 1.0479, Test Loss: 1.2070\n",
      "Epoch [50/50] - Train Loss: 1.0475, Test Loss: 1.2121\n",
      "Avg Test Loss: 1.2121\n",
      "Testing combination: (16, 3, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1843, Test Loss: 1.1504\n",
      "Epoch [2/50] - Train Loss: 1.1529, Test Loss: 1.1523\n",
      "Epoch [3/50] - Train Loss: 1.1509, Test Loss: 1.1580\n",
      "Epoch [4/50] - Train Loss: 1.1488, Test Loss: 1.1634\n",
      "Epoch [5/50] - Train Loss: 1.1446, Test Loss: 1.1681\n",
      "Epoch [6/50] - Train Loss: 1.1255, Test Loss: 1.1718\n",
      "Epoch [7/50] - Train Loss: 1.0844, Test Loss: 1.1907\n",
      "Epoch [8/50] - Train Loss: 1.0556, Test Loss: 1.2415\n",
      "Epoch [9/50] - Train Loss: 1.0752, Test Loss: 1.2297\n",
      "Epoch [10/50] - Train Loss: 1.0562, Test Loss: 1.2403\n",
      "Epoch [11/50] - Train Loss: 1.0478, Test Loss: 1.2647\n",
      "Epoch [12/50] - Train Loss: 1.0481, Test Loss: 1.2611\n",
      "Epoch [13/50] - Train Loss: 1.0442, Test Loss: 1.2576\n",
      "Epoch [14/50] - Train Loss: 1.0425, Test Loss: 1.2668\n",
      "Epoch [15/50] - Train Loss: 1.0422, Test Loss: 1.2623\n",
      "Epoch [16/50] - Train Loss: 1.0408, Test Loss: 1.2634\n",
      "Epoch [17/50] - Train Loss: 1.0410, Test Loss: 1.2638\n",
      "Epoch [18/50] - Train Loss: 1.0408, Test Loss: 1.2613\n",
      "Epoch [19/50] - Train Loss: 1.0401, Test Loss: 1.2643\n",
      "Epoch [20/50] - Train Loss: 1.0403, Test Loss: 1.2579\n",
      "Epoch [21/50] - Train Loss: 1.0399, Test Loss: 1.2613\n",
      "Epoch [22/50] - Train Loss: 1.0393, Test Loss: 1.2564\n",
      "Epoch [23/50] - Train Loss: 1.0400, Test Loss: 1.2612\n",
      "Epoch [24/50] - Train Loss: 1.0402, Test Loss: 1.2693\n",
      "Epoch [25/50] - Train Loss: 1.0501, Test Loss: 1.2505\n",
      "Epoch [26/50] - Train Loss: 1.0406, Test Loss: 1.2697\n",
      "Epoch [27/50] - Train Loss: 1.0660, Test Loss: 1.2185\n",
      "Epoch [28/50] - Train Loss: 1.0483, Test Loss: 1.2328\n",
      "Epoch [29/50] - Train Loss: 1.0418, Test Loss: 1.2606\n",
      "Epoch [30/50] - Train Loss: 1.0415, Test Loss: 1.2662\n",
      "Epoch [31/50] - Train Loss: 1.0404, Test Loss: 1.2560\n",
      "Epoch [32/50] - Train Loss: 1.0396, Test Loss: 1.2506\n",
      "Epoch [33/50] - Train Loss: 1.0400, Test Loss: 1.2557\n",
      "Epoch [34/50] - Train Loss: 1.0399, Test Loss: 1.2537\n",
      "Epoch [35/50] - Train Loss: 1.0372, Test Loss: 1.2546\n",
      "Epoch [36/50] - Train Loss: 1.0384, Test Loss: 1.2607\n",
      "Epoch [37/50] - Train Loss: 1.0397, Test Loss: 1.2522\n",
      "Epoch [38/50] - Train Loss: 1.0364, Test Loss: 1.2522\n",
      "Epoch [39/50] - Train Loss: 1.0377, Test Loss: 1.2625\n",
      "Epoch [40/50] - Train Loss: 1.0397, Test Loss: 1.2514\n",
      "Epoch [41/50] - Train Loss: 1.0353, Test Loss: 1.2501\n",
      "Epoch [42/50] - Train Loss: 1.0365, Test Loss: 1.2639\n",
      "Epoch [43/50] - Train Loss: 1.0375, Test Loss: 1.2507\n",
      "Epoch [44/50] - Train Loss: 1.0390, Test Loss: 1.2559\n",
      "Epoch [45/50] - Train Loss: 1.0479, Test Loss: 1.2852\n",
      "Epoch [46/50] - Train Loss: 1.0433, Test Loss: 1.2436\n",
      "Epoch [47/50] - Train Loss: 1.0421, Test Loss: 1.2517\n",
      "Epoch [48/50] - Train Loss: 1.0397, Test Loss: 1.2659\n",
      "Epoch [49/50] - Train Loss: 1.0395, Test Loss: 1.2656\n",
      "Epoch [50/50] - Train Loss: 1.0389, Test Loss: 1.2571\n",
      "Avg Test Loss: 1.2571\n",
      "Testing combination: (16, 3, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5222, Test Loss: 1.7412\n",
      "Epoch [2/50] - Train Loss: 1.4888, Test Loss: 1.7364\n",
      "Epoch [3/50] - Train Loss: 1.4849, Test Loss: 1.7351\n",
      "Epoch [4/50] - Train Loss: 1.4844, Test Loss: 1.7356\n",
      "Epoch [5/50] - Train Loss: 1.4847, Test Loss: 1.7366\n",
      "Epoch [6/50] - Train Loss: 1.4849, Test Loss: 1.7377\n",
      "Epoch [7/50] - Train Loss: 1.4844, Test Loss: 1.7390\n",
      "Epoch [8/50] - Train Loss: 1.4830, Test Loss: 1.7412\n",
      "Epoch [9/50] - Train Loss: 1.4798, Test Loss: 1.7457\n",
      "Epoch [10/50] - Train Loss: 1.4708, Test Loss: 1.7597\n",
      "Epoch [11/50] - Train Loss: 1.4609, Test Loss: 1.7814\n",
      "Epoch [12/50] - Train Loss: 1.4431, Test Loss: 1.8330\n",
      "Epoch [13/50] - Train Loss: 1.4282, Test Loss: 1.8983\n",
      "Epoch [14/50] - Train Loss: 1.4348, Test Loss: 1.9148\n",
      "Epoch [15/50] - Train Loss: 1.4322, Test Loss: 1.8967\n",
      "Epoch [16/50] - Train Loss: 1.4293, Test Loss: 1.8869\n",
      "Epoch [17/50] - Train Loss: 1.4268, Test Loss: 1.8984\n",
      "Epoch [18/50] - Train Loss: 1.4248, Test Loss: 1.9369\n",
      "Epoch [19/50] - Train Loss: 1.4222, Test Loss: 1.9540\n",
      "Epoch [20/50] - Train Loss: 1.4150, Test Loss: 1.9824\n",
      "Epoch [21/50] - Train Loss: 1.4135, Test Loss: 2.0293\n",
      "Epoch [22/50] - Train Loss: 1.4118, Test Loss: 2.0775\n",
      "Epoch [23/50] - Train Loss: 1.4091, Test Loss: 2.0913\n",
      "Epoch [24/50] - Train Loss: 1.4070, Test Loss: 2.1011\n",
      "Epoch [25/50] - Train Loss: 1.4068, Test Loss: 2.1104\n",
      "Epoch [26/50] - Train Loss: 1.4056, Test Loss: 2.0987\n",
      "Epoch [27/50] - Train Loss: 1.4035, Test Loss: 2.1165\n",
      "Epoch [28/50] - Train Loss: 1.4031, Test Loss: 2.1203\n",
      "Epoch [29/50] - Train Loss: 1.4008, Test Loss: 2.1429\n",
      "Epoch [30/50] - Train Loss: 1.3981, Test Loss: 2.0403\n",
      "Epoch [31/50] - Train Loss: 1.3997, Test Loss: 2.1437\n",
      "Epoch [32/50] - Train Loss: 1.3914, Test Loss: 2.2275\n",
      "Epoch [33/50] - Train Loss: 1.4083, Test Loss: 1.8323\n",
      "Epoch [34/50] - Train Loss: 1.4514, Test Loss: 1.8865\n",
      "Epoch [35/50] - Train Loss: 1.4427, Test Loss: 1.9461\n",
      "Epoch [36/50] - Train Loss: 1.4284, Test Loss: 1.9985\n",
      "Epoch [37/50] - Train Loss: 1.4389, Test Loss: 1.9958\n",
      "Epoch [38/50] - Train Loss: 1.4322, Test Loss: 1.9566\n",
      "Epoch [39/50] - Train Loss: 1.4236, Test Loss: 1.9355\n",
      "Epoch [40/50] - Train Loss: 1.4211, Test Loss: 1.9618\n",
      "Epoch [41/50] - Train Loss: 1.4131, Test Loss: 1.9692\n",
      "Epoch [42/50] - Train Loss: 1.4068, Test Loss: 1.9641\n",
      "Epoch [43/50] - Train Loss: 1.3950, Test Loss: 2.0943\n",
      "Epoch [44/50] - Train Loss: 1.3888, Test Loss: 2.0991\n",
      "Epoch [45/50] - Train Loss: 1.3723, Test Loss: 2.2056\n",
      "Epoch [46/50] - Train Loss: 1.3751, Test Loss: 2.1675\n",
      "Epoch [47/50] - Train Loss: 1.3895, Test Loss: 2.2973\n",
      "Epoch [48/50] - Train Loss: 1.3736, Test Loss: 2.1568\n",
      "Epoch [49/50] - Train Loss: 1.3701, Test Loss: 2.0828\n",
      "Epoch [50/50] - Train Loss: 1.3723, Test Loss: 2.0893\n",
      "Avg Test Loss: 2.0893\n",
      "Testing combination: (16, 3, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1421, Test Loss: 1.1343\n",
      "Epoch [2/50] - Train Loss: 1.1323, Test Loss: 1.1214\n",
      "Epoch [3/50] - Train Loss: 1.1261, Test Loss: 1.1118\n",
      "Epoch [4/50] - Train Loss: 1.1219, Test Loss: 1.1047\n",
      "Epoch [5/50] - Train Loss: 1.1190, Test Loss: 1.0997\n",
      "Epoch [6/50] - Train Loss: 1.1170, Test Loss: 1.0963\n",
      "Epoch [7/50] - Train Loss: 1.1155, Test Loss: 1.0943\n",
      "Epoch [8/50] - Train Loss: 1.1142, Test Loss: 1.0932\n",
      "Epoch [9/50] - Train Loss: 1.1129, Test Loss: 1.0928\n",
      "Epoch [10/50] - Train Loss: 1.1115, Test Loss: 1.0929\n",
      "Epoch [11/50] - Train Loss: 1.1098, Test Loss: 1.0934\n",
      "Epoch [12/50] - Train Loss: 1.1077, Test Loss: 1.0942\n",
      "Epoch [13/50] - Train Loss: 1.1050, Test Loss: 1.0955\n",
      "Epoch [14/50] - Train Loss: 1.1015, Test Loss: 1.0975\n",
      "Epoch [15/50] - Train Loss: 1.0972, Test Loss: 1.1010\n",
      "Epoch [16/50] - Train Loss: 1.0930, Test Loss: 1.1051\n",
      "Epoch [17/50] - Train Loss: 1.0883, Test Loss: 1.1089\n",
      "Epoch [18/50] - Train Loss: 1.0842, Test Loss: 1.1138\n",
      "Epoch [19/50] - Train Loss: 1.0808, Test Loss: 1.1192\n",
      "Epoch [20/50] - Train Loss: 1.0782, Test Loss: 1.1243\n",
      "Epoch [21/50] - Train Loss: 1.0764, Test Loss: 1.1250\n",
      "Epoch [22/50] - Train Loss: 1.0756, Test Loss: 1.1324\n",
      "Epoch [23/50] - Train Loss: 1.0743, Test Loss: 1.1323\n",
      "Epoch [24/50] - Train Loss: 1.0731, Test Loss: 1.1331\n",
      "Epoch [25/50] - Train Loss: 1.0721, Test Loss: 1.1331\n",
      "Epoch [26/50] - Train Loss: 1.0705, Test Loss: 1.1324\n",
      "Epoch [27/50] - Train Loss: 1.0669, Test Loss: 1.1447\n",
      "Epoch [28/50] - Train Loss: 1.0664, Test Loss: 1.1255\n",
      "Epoch [29/50] - Train Loss: 1.0578, Test Loss: 1.1393\n",
      "Epoch [30/50] - Train Loss: 1.0692, Test Loss: 1.1832\n",
      "Epoch [31/50] - Train Loss: 1.0669, Test Loss: 1.1918\n",
      "Epoch [32/50] - Train Loss: 1.0165, Test Loss: 1.1741\n",
      "Epoch [33/50] - Train Loss: 1.0226, Test Loss: 1.2009\n",
      "Epoch [34/50] - Train Loss: 0.9589, Test Loss: 1.2232\n",
      "Epoch [35/50] - Train Loss: 1.0299, Test Loss: 1.1321\n",
      "Epoch [36/50] - Train Loss: 1.0997, Test Loss: 1.1509\n",
      "Epoch [37/50] - Train Loss: 1.0817, Test Loss: 1.1652\n",
      "Epoch [38/50] - Train Loss: 1.0704, Test Loss: 1.1776\n",
      "Epoch [39/50] - Train Loss: 1.0667, Test Loss: 1.1880\n",
      "Epoch [40/50] - Train Loss: 1.0648, Test Loss: 1.1909\n",
      "Epoch [41/50] - Train Loss: 1.0621, Test Loss: 1.1909\n",
      "Epoch [42/50] - Train Loss: 1.0601, Test Loss: 1.1911\n",
      "Epoch [43/50] - Train Loss: 1.0543, Test Loss: 1.1913\n",
      "Epoch [44/50] - Train Loss: 1.0651, Test Loss: 1.2095\n",
      "Epoch [45/50] - Train Loss: 0.9858, Test Loss: 1.1566\n",
      "Epoch [46/50] - Train Loss: 1.1382, Test Loss: 1.2352\n",
      "Epoch [47/50] - Train Loss: 1.0072, Test Loss: 1.1551\n",
      "Epoch [48/50] - Train Loss: 1.0706, Test Loss: 1.1441\n",
      "Epoch [49/50] - Train Loss: 1.0725, Test Loss: 1.1442\n",
      "Epoch [50/50] - Train Loss: 1.0668, Test Loss: 1.1484\n",
      "Avg Test Loss: 1.1484\n",
      "Testing combination: (16, 3, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1641, Test Loss: 1.2228\n",
      "Epoch [2/50] - Train Loss: 1.1590, Test Loss: 1.2146\n",
      "Epoch [3/50] - Train Loss: 1.1565, Test Loss: 1.2080\n",
      "Epoch [4/50] - Train Loss: 1.1546, Test Loss: 1.2025\n",
      "Epoch [5/50] - Train Loss: 1.1530, Test Loss: 1.1978\n",
      "Epoch [6/50] - Train Loss: 1.1516, Test Loss: 1.1936\n",
      "Epoch [7/50] - Train Loss: 1.1503, Test Loss: 1.1898\n",
      "Epoch [8/50] - Train Loss: 1.1489, Test Loss: 1.1863\n",
      "Epoch [9/50] - Train Loss: 1.1473, Test Loss: 1.1830\n",
      "Epoch [10/50] - Train Loss: 1.1455, Test Loss: 1.1798\n",
      "Epoch [11/50] - Train Loss: 1.1432, Test Loss: 1.1766\n",
      "Epoch [12/50] - Train Loss: 1.1401, Test Loss: 1.1731\n",
      "Epoch [13/50] - Train Loss: 1.1359, Test Loss: 1.1697\n",
      "Epoch [14/50] - Train Loss: 1.1300, Test Loss: 1.1667\n",
      "Epoch [15/50] - Train Loss: 1.1223, Test Loss: 1.1642\n",
      "Epoch [16/50] - Train Loss: 1.1130, Test Loss: 1.1625\n",
      "Epoch [17/50] - Train Loss: 1.1031, Test Loss: 1.1630\n",
      "Epoch [18/50] - Train Loss: 1.0934, Test Loss: 1.1665\n",
      "Epoch [19/50] - Train Loss: 1.0850, Test Loss: 1.1721\n",
      "Epoch [20/50] - Train Loss: 1.0777, Test Loss: 1.1772\n",
      "Epoch [21/50] - Train Loss: 1.0705, Test Loss: 1.1831\n",
      "Epoch [22/50] - Train Loss: 1.0648, Test Loss: 1.1903\n",
      "Epoch [23/50] - Train Loss: 1.0605, Test Loss: 1.1978\n",
      "Epoch [24/50] - Train Loss: 1.0573, Test Loss: 1.2051\n",
      "Epoch [25/50] - Train Loss: 1.0617, Test Loss: 1.2066\n",
      "Epoch [26/50] - Train Loss: 1.0528, Test Loss: 1.2154\n",
      "Epoch [27/50] - Train Loss: 1.0505, Test Loss: 1.2249\n",
      "Epoch [28/50] - Train Loss: 1.0498, Test Loss: 1.2262\n",
      "Epoch [29/50] - Train Loss: 1.0480, Test Loss: 1.2314\n",
      "Epoch [30/50] - Train Loss: 1.0416, Test Loss: 1.2351\n",
      "Epoch [31/50] - Train Loss: 1.0402, Test Loss: 1.2397\n",
      "Epoch [32/50] - Train Loss: 1.0372, Test Loss: 1.2519\n",
      "Epoch [33/50] - Train Loss: 1.0458, Test Loss: 1.2494\n",
      "Epoch [34/50] - Train Loss: 1.0475, Test Loss: 1.2555\n",
      "Epoch [35/50] - Train Loss: 1.0463, Test Loss: 1.2626\n",
      "Epoch [36/50] - Train Loss: 1.0458, Test Loss: 1.2680\n",
      "Epoch [37/50] - Train Loss: 1.0457, Test Loss: 1.2713\n",
      "Epoch [38/50] - Train Loss: 1.0455, Test Loss: 1.2729\n",
      "Epoch [39/50] - Train Loss: 1.0444, Test Loss: 1.2740\n",
      "Epoch [40/50] - Train Loss: 1.0438, Test Loss: 1.2748\n",
      "Epoch [41/50] - Train Loss: 1.0430, Test Loss: 1.2758\n",
      "Epoch [42/50] - Train Loss: 1.0417, Test Loss: 1.2759\n",
      "Epoch [43/50] - Train Loss: 1.0394, Test Loss: 1.2736\n",
      "Epoch [44/50] - Train Loss: 1.0361, Test Loss: 1.2690\n",
      "Epoch [45/50] - Train Loss: 1.0358, Test Loss: 1.2545\n",
      "Epoch [46/50] - Train Loss: 1.0322, Test Loss: 1.2490\n",
      "Epoch [47/50] - Train Loss: 1.0485, Test Loss: 1.2364\n",
      "Epoch [48/50] - Train Loss: 1.0582, Test Loss: 1.2409\n",
      "Epoch [49/50] - Train Loss: 1.0498, Test Loss: 1.2582\n",
      "Epoch [50/50] - Train Loss: 1.0471, Test Loss: 1.2701\n",
      "Avg Test Loss: 1.2701\n",
      "Testing combination: (16, 3, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5692, Test Loss: 1.8461\n",
      "Epoch [2/50] - Train Loss: 1.5530, Test Loss: 1.8273\n",
      "Epoch [3/50] - Train Loss: 1.5415, Test Loss: 1.8119\n",
      "Epoch [4/50] - Train Loss: 1.5321, Test Loss: 1.7990\n",
      "Epoch [5/50] - Train Loss: 1.5243, Test Loss: 1.7879\n",
      "Epoch [6/50] - Train Loss: 1.5175, Test Loss: 1.7784\n",
      "Epoch [7/50] - Train Loss: 1.5117, Test Loss: 1.7703\n",
      "Epoch [8/50] - Train Loss: 1.5068, Test Loss: 1.7633\n",
      "Epoch [9/50] - Train Loss: 1.5025, Test Loss: 1.7575\n",
      "Epoch [10/50] - Train Loss: 1.4989, Test Loss: 1.7526\n",
      "Epoch [11/50] - Train Loss: 1.4959, Test Loss: 1.7486\n",
      "Epoch [12/50] - Train Loss: 1.4933, Test Loss: 1.7454\n",
      "Epoch [13/50] - Train Loss: 1.4912, Test Loss: 1.7429\n",
      "Epoch [14/50] - Train Loss: 1.4894, Test Loss: 1.7410\n",
      "Epoch [15/50] - Train Loss: 1.4879, Test Loss: 1.7397\n",
      "Epoch [16/50] - Train Loss: 1.4867, Test Loss: 1.7390\n",
      "Epoch [17/50] - Train Loss: 1.4856, Test Loss: 1.7389\n",
      "Epoch [18/50] - Train Loss: 1.4846, Test Loss: 1.7393\n",
      "Epoch [19/50] - Train Loss: 1.4836, Test Loss: 1.7402\n",
      "Epoch [20/50] - Train Loss: 1.4826, Test Loss: 1.7413\n",
      "Epoch [21/50] - Train Loss: 1.4815, Test Loss: 1.7426\n",
      "Epoch [22/50] - Train Loss: 1.4804, Test Loss: 1.7442\n",
      "Epoch [23/50] - Train Loss: 1.4791, Test Loss: 1.7461\n",
      "Epoch [24/50] - Train Loss: 1.4777, Test Loss: 1.7485\n",
      "Epoch [25/50] - Train Loss: 1.4759, Test Loss: 1.7515\n",
      "Epoch [26/50] - Train Loss: 1.4738, Test Loss: 1.7550\n",
      "Epoch [27/50] - Train Loss: 1.4713, Test Loss: 1.7591\n",
      "Epoch [28/50] - Train Loss: 1.4683, Test Loss: 1.7636\n",
      "Epoch [29/50] - Train Loss: 1.4647, Test Loss: 1.7687\n",
      "Epoch [30/50] - Train Loss: 1.4606, Test Loss: 1.7748\n",
      "Epoch [31/50] - Train Loss: 1.4561, Test Loss: 1.7825\n",
      "Epoch [32/50] - Train Loss: 1.4514, Test Loss: 1.7914\n",
      "Epoch [33/50] - Train Loss: 1.4465, Test Loss: 1.8005\n",
      "Epoch [34/50] - Train Loss: 1.4418, Test Loss: 1.8095\n",
      "Epoch [35/50] - Train Loss: 1.4375, Test Loss: 1.8187\n",
      "Epoch [36/50] - Train Loss: 1.4340, Test Loss: 1.8283\n",
      "Epoch [37/50] - Train Loss: 1.4312, Test Loss: 1.8381\n",
      "Epoch [38/50] - Train Loss: 1.4291, Test Loss: 1.8477\n",
      "Epoch [39/50] - Train Loss: 1.4277, Test Loss: 1.8566\n",
      "Epoch [40/50] - Train Loss: 1.4266, Test Loss: 1.8646\n",
      "Epoch [41/50] - Train Loss: 1.4260, Test Loss: 1.8715\n",
      "Epoch [42/50] - Train Loss: 1.4255, Test Loss: 1.8773\n",
      "Epoch [43/50] - Train Loss: 1.4251, Test Loss: 1.8821\n",
      "Epoch [44/50] - Train Loss: 1.4248, Test Loss: 1.8861\n",
      "Epoch [45/50] - Train Loss: 1.4244, Test Loss: 1.8892\n",
      "Epoch [46/50] - Train Loss: 1.4238, Test Loss: 1.8910\n",
      "Epoch [47/50] - Train Loss: 1.4223, Test Loss: 1.8885\n",
      "Epoch [48/50] - Train Loss: 1.4194, Test Loss: 1.8816\n",
      "Epoch [49/50] - Train Loss: 1.4170, Test Loss: 1.8792\n",
      "Epoch [50/50] - Train Loss: 1.4124, Test Loss: 1.9172\n",
      "Avg Test Loss: 1.9172\n",
      "Testing combination: (16, 3, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1210, Test Loss: 1.0807\n",
      "Epoch [2/50] - Train Loss: 1.1204, Test Loss: 1.0807\n",
      "Epoch [3/50] - Train Loss: 1.1201, Test Loss: 1.0808\n",
      "Epoch [4/50] - Train Loss: 1.1199, Test Loss: 1.0809\n",
      "Epoch [5/50] - Train Loss: 1.1197, Test Loss: 1.0809\n",
      "Epoch [6/50] - Train Loss: 1.1195, Test Loss: 1.0810\n",
      "Epoch [7/50] - Train Loss: 1.1193, Test Loss: 1.0811\n",
      "Epoch [8/50] - Train Loss: 1.1191, Test Loss: 1.0812\n",
      "Epoch [9/50] - Train Loss: 1.1190, Test Loss: 1.0812\n",
      "Epoch [10/50] - Train Loss: 1.1188, Test Loss: 1.0813\n",
      "Epoch [11/50] - Train Loss: 1.1186, Test Loss: 1.0814\n",
      "Epoch [12/50] - Train Loss: 1.1185, Test Loss: 1.0815\n",
      "Epoch [13/50] - Train Loss: 1.1184, Test Loss: 1.0816\n",
      "Epoch [14/50] - Train Loss: 1.1182, Test Loss: 1.0817\n",
      "Epoch [15/50] - Train Loss: 1.1181, Test Loss: 1.0818\n",
      "Epoch [16/50] - Train Loss: 1.1180, Test Loss: 1.0819\n",
      "Epoch [17/50] - Train Loss: 1.1179, Test Loss: 1.0820\n",
      "Epoch [18/50] - Train Loss: 1.1178, Test Loss: 1.0820\n",
      "Epoch [19/50] - Train Loss: 1.1177, Test Loss: 1.0821\n",
      "Epoch [20/50] - Train Loss: 1.1176, Test Loss: 1.0822\n",
      "Epoch [21/50] - Train Loss: 1.1175, Test Loss: 1.0823\n",
      "Epoch [22/50] - Train Loss: 1.1174, Test Loss: 1.0824\n",
      "Epoch [23/50] - Train Loss: 1.1174, Test Loss: 1.0825\n",
      "Epoch [24/50] - Train Loss: 1.1173, Test Loss: 1.0826\n",
      "Epoch [25/50] - Train Loss: 1.1172, Test Loss: 1.0827\n",
      "Epoch [26/50] - Train Loss: 1.1172, Test Loss: 1.0828\n",
      "Epoch [27/50] - Train Loss: 1.1171, Test Loss: 1.0829\n",
      "Epoch [28/50] - Train Loss: 1.1170, Test Loss: 1.0830\n",
      "Epoch [29/50] - Train Loss: 1.1170, Test Loss: 1.0831\n",
      "Epoch [30/50] - Train Loss: 1.1169, Test Loss: 1.0832\n",
      "Epoch [31/50] - Train Loss: 1.1169, Test Loss: 1.0833\n",
      "Epoch [32/50] - Train Loss: 1.1168, Test Loss: 1.0833\n",
      "Epoch [33/50] - Train Loss: 1.1168, Test Loss: 1.0834\n",
      "Epoch [34/50] - Train Loss: 1.1167, Test Loss: 1.0835\n",
      "Epoch [35/50] - Train Loss: 1.1167, Test Loss: 1.0836\n",
      "Epoch [36/50] - Train Loss: 1.1166, Test Loss: 1.0837\n",
      "Epoch [37/50] - Train Loss: 1.1166, Test Loss: 1.0838\n",
      "Epoch [38/50] - Train Loss: 1.1166, Test Loss: 1.0839\n",
      "Epoch [39/50] - Train Loss: 1.1165, Test Loss: 1.0840\n",
      "Epoch [40/50] - Train Loss: 1.1165, Test Loss: 1.0841\n",
      "Epoch [41/50] - Train Loss: 1.1165, Test Loss: 1.0841\n",
      "Epoch [42/50] - Train Loss: 1.1164, Test Loss: 1.0842\n",
      "Epoch [43/50] - Train Loss: 1.1164, Test Loss: 1.0843\n",
      "Epoch [44/50] - Train Loss: 1.1164, Test Loss: 1.0844\n",
      "Epoch [45/50] - Train Loss: 1.1163, Test Loss: 1.0845\n",
      "Epoch [46/50] - Train Loss: 1.1163, Test Loss: 1.0846\n",
      "Epoch [47/50] - Train Loss: 1.1163, Test Loss: 1.0847\n",
      "Epoch [48/50] - Train Loss: 1.1163, Test Loss: 1.0847\n",
      "Epoch [49/50] - Train Loss: 1.1162, Test Loss: 1.0848\n",
      "Epoch [50/50] - Train Loss: 1.1162, Test Loss: 1.0849\n",
      "Avg Test Loss: 1.0849\n",
      "Testing combination: (16, 3, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1617, Test Loss: 1.2305\n",
      "Epoch [2/50] - Train Loss: 1.1611, Test Loss: 1.2294\n",
      "Epoch [3/50] - Train Loss: 1.1607, Test Loss: 1.2284\n",
      "Epoch [4/50] - Train Loss: 1.1604, Test Loss: 1.2274\n",
      "Epoch [5/50] - Train Loss: 1.1601, Test Loss: 1.2265\n",
      "Epoch [6/50] - Train Loss: 1.1598, Test Loss: 1.2256\n",
      "Epoch [7/50] - Train Loss: 1.1595, Test Loss: 1.2248\n",
      "Epoch [8/50] - Train Loss: 1.1592, Test Loss: 1.2239\n",
      "Epoch [9/50] - Train Loss: 1.1590, Test Loss: 1.2231\n",
      "Epoch [10/50] - Train Loss: 1.1587, Test Loss: 1.2222\n",
      "Epoch [11/50] - Train Loss: 1.1584, Test Loss: 1.2214\n",
      "Epoch [12/50] - Train Loss: 1.1582, Test Loss: 1.2206\n",
      "Epoch [13/50] - Train Loss: 1.1579, Test Loss: 1.2198\n",
      "Epoch [14/50] - Train Loss: 1.1577, Test Loss: 1.2190\n",
      "Epoch [15/50] - Train Loss: 1.1574, Test Loss: 1.2183\n",
      "Epoch [16/50] - Train Loss: 1.1572, Test Loss: 1.2175\n",
      "Epoch [17/50] - Train Loss: 1.1570, Test Loss: 1.2167\n",
      "Epoch [18/50] - Train Loss: 1.1567, Test Loss: 1.2160\n",
      "Epoch [19/50] - Train Loss: 1.1565, Test Loss: 1.2153\n",
      "Epoch [20/50] - Train Loss: 1.1563, Test Loss: 1.2145\n",
      "Epoch [21/50] - Train Loss: 1.1561, Test Loss: 1.2138\n",
      "Epoch [22/50] - Train Loss: 1.1559, Test Loss: 1.2131\n",
      "Epoch [23/50] - Train Loss: 1.1557, Test Loss: 1.2124\n",
      "Epoch [24/50] - Train Loss: 1.1555, Test Loss: 1.2117\n",
      "Epoch [25/50] - Train Loss: 1.1552, Test Loss: 1.2111\n",
      "Epoch [26/50] - Train Loss: 1.1550, Test Loss: 1.2104\n",
      "Epoch [27/50] - Train Loss: 1.1549, Test Loss: 1.2097\n",
      "Epoch [28/50] - Train Loss: 1.1547, Test Loss: 1.2090\n",
      "Epoch [29/50] - Train Loss: 1.1545, Test Loss: 1.2084\n",
      "Epoch [30/50] - Train Loss: 1.1543, Test Loss: 1.2077\n",
      "Epoch [31/50] - Train Loss: 1.1541, Test Loss: 1.2071\n",
      "Epoch [32/50] - Train Loss: 1.1539, Test Loss: 1.2065\n",
      "Epoch [33/50] - Train Loss: 1.1537, Test Loss: 1.2059\n",
      "Epoch [34/50] - Train Loss: 1.1535, Test Loss: 1.2052\n",
      "Epoch [35/50] - Train Loss: 1.1533, Test Loss: 1.2046\n",
      "Epoch [36/50] - Train Loss: 1.1532, Test Loss: 1.2040\n",
      "Epoch [37/50] - Train Loss: 1.1530, Test Loss: 1.2034\n",
      "Epoch [38/50] - Train Loss: 1.1528, Test Loss: 1.2028\n",
      "Epoch [39/50] - Train Loss: 1.1526, Test Loss: 1.2023\n",
      "Epoch [40/50] - Train Loss: 1.1525, Test Loss: 1.2017\n",
      "Epoch [41/50] - Train Loss: 1.1523, Test Loss: 1.2011\n",
      "Epoch [42/50] - Train Loss: 1.1521, Test Loss: 1.2006\n",
      "Epoch [43/50] - Train Loss: 1.1519, Test Loss: 1.2000\n",
      "Epoch [44/50] - Train Loss: 1.1518, Test Loss: 1.1995\n",
      "Epoch [45/50] - Train Loss: 1.1516, Test Loss: 1.1989\n",
      "Epoch [46/50] - Train Loss: 1.1514, Test Loss: 1.1984\n",
      "Epoch [47/50] - Train Loss: 1.1512, Test Loss: 1.1978\n",
      "Epoch [48/50] - Train Loss: 1.1511, Test Loss: 1.1973\n",
      "Epoch [49/50] - Train Loss: 1.1509, Test Loss: 1.1968\n",
      "Epoch [50/50] - Train Loss: 1.1507, Test Loss: 1.1963\n",
      "Avg Test Loss: 1.1963\n",
      "Testing combination: (16, 3, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.4893, Test Loss: 1.7362\n",
      "Epoch [2/50] - Train Loss: 1.4890, Test Loss: 1.7362\n",
      "Epoch [3/50] - Train Loss: 1.4889, Test Loss: 1.7361\n",
      "Epoch [4/50] - Train Loss: 1.4888, Test Loss: 1.7360\n",
      "Epoch [5/50] - Train Loss: 1.4887, Test Loss: 1.7359\n",
      "Epoch [6/50] - Train Loss: 1.4886, Test Loss: 1.7359\n",
      "Epoch [7/50] - Train Loss: 1.4885, Test Loss: 1.7358\n",
      "Epoch [8/50] - Train Loss: 1.4884, Test Loss: 1.7357\n",
      "Epoch [9/50] - Train Loss: 1.4883, Test Loss: 1.7356\n",
      "Epoch [10/50] - Train Loss: 1.4883, Test Loss: 1.7355\n",
      "Epoch [11/50] - Train Loss: 1.4882, Test Loss: 1.7355\n",
      "Epoch [12/50] - Train Loss: 1.4881, Test Loss: 1.7354\n",
      "Epoch [13/50] - Train Loss: 1.4880, Test Loss: 1.7353\n",
      "Epoch [14/50] - Train Loss: 1.4880, Test Loss: 1.7353\n",
      "Epoch [15/50] - Train Loss: 1.4879, Test Loss: 1.7352\n",
      "Epoch [16/50] - Train Loss: 1.4878, Test Loss: 1.7352\n",
      "Epoch [17/50] - Train Loss: 1.4877, Test Loss: 1.7351\n",
      "Epoch [18/50] - Train Loss: 1.4877, Test Loss: 1.7351\n",
      "Epoch [19/50] - Train Loss: 1.4876, Test Loss: 1.7350\n",
      "Epoch [20/50] - Train Loss: 1.4876, Test Loss: 1.7350\n",
      "Epoch [21/50] - Train Loss: 1.4875, Test Loss: 1.7349\n",
      "Epoch [22/50] - Train Loss: 1.4874, Test Loss: 1.7349\n",
      "Epoch [23/50] - Train Loss: 1.4874, Test Loss: 1.7349\n",
      "Epoch [24/50] - Train Loss: 1.4873, Test Loss: 1.7348\n",
      "Epoch [25/50] - Train Loss: 1.4873, Test Loss: 1.7348\n",
      "Epoch [26/50] - Train Loss: 1.4872, Test Loss: 1.7348\n",
      "Epoch [27/50] - Train Loss: 1.4871, Test Loss: 1.7348\n",
      "Epoch [28/50] - Train Loss: 1.4871, Test Loss: 1.7348\n",
      "Epoch [29/50] - Train Loss: 1.4870, Test Loss: 1.7347\n",
      "Epoch [30/50] - Train Loss: 1.4870, Test Loss: 1.7347\n",
      "Epoch [31/50] - Train Loss: 1.4869, Test Loss: 1.7347\n",
      "Epoch [32/50] - Train Loss: 1.4869, Test Loss: 1.7347\n",
      "Epoch [33/50] - Train Loss: 1.4868, Test Loss: 1.7347\n",
      "Epoch [34/50] - Train Loss: 1.4868, Test Loss: 1.7347\n",
      "Epoch [35/50] - Train Loss: 1.4867, Test Loss: 1.7347\n",
      "Epoch [36/50] - Train Loss: 1.4867, Test Loss: 1.7347\n",
      "Epoch [37/50] - Train Loss: 1.4866, Test Loss: 1.7347\n",
      "Epoch [38/50] - Train Loss: 1.4866, Test Loss: 1.7348\n",
      "Epoch [39/50] - Train Loss: 1.4865, Test Loss: 1.7348\n",
      "Epoch [40/50] - Train Loss: 1.4865, Test Loss: 1.7348\n",
      "Epoch [41/50] - Train Loss: 1.4865, Test Loss: 1.7348\n",
      "Epoch [42/50] - Train Loss: 1.4864, Test Loss: 1.7348\n",
      "Epoch [43/50] - Train Loss: 1.4864, Test Loss: 1.7349\n",
      "Epoch [44/50] - Train Loss: 1.4863, Test Loss: 1.7349\n",
      "Epoch [45/50] - Train Loss: 1.4863, Test Loss: 1.7349\n",
      "Epoch [46/50] - Train Loss: 1.4862, Test Loss: 1.7350\n",
      "Epoch [47/50] - Train Loss: 1.4862, Test Loss: 1.7350\n",
      "Epoch [48/50] - Train Loss: 1.4862, Test Loss: 1.7350\n",
      "Epoch [49/50] - Train Loss: 1.4861, Test Loss: 1.7351\n",
      "Epoch [50/50] - Train Loss: 1.4861, Test Loss: 1.7351\n",
      "Avg Test Loss: 1.7351\n",
      "Testing combination: (16, 4, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1387, Test Loss: 1.0941\n",
      "Epoch [2/50] - Train Loss: 1.1175, Test Loss: 1.0864\n",
      "Epoch [3/50] - Train Loss: 1.1179, Test Loss: 1.0854\n",
      "Epoch [4/50] - Train Loss: 1.1180, Test Loss: 1.0862\n",
      "Epoch [5/50] - Train Loss: 1.1168, Test Loss: 1.0888\n",
      "Epoch [6/50] - Train Loss: 1.1008, Test Loss: 1.1248\n",
      "Epoch [7/50] - Train Loss: 1.2339, Test Loss: 1.0860\n",
      "Epoch [8/50] - Train Loss: 1.1192, Test Loss: 1.0824\n",
      "Epoch [9/50] - Train Loss: 1.1199, Test Loss: 1.0851\n",
      "Epoch [10/50] - Train Loss: 1.1184, Test Loss: 1.0872\n",
      "Epoch [11/50] - Train Loss: 1.1178, Test Loss: 1.0879\n",
      "Epoch [12/50] - Train Loss: 1.1175, Test Loss: 1.0878\n",
      "Epoch [13/50] - Train Loss: 1.1174, Test Loss: 1.0874\n",
      "Epoch [14/50] - Train Loss: 1.1174, Test Loss: 1.0872\n",
      "Epoch [15/50] - Train Loss: 1.1173, Test Loss: 1.0871\n",
      "Epoch [16/50] - Train Loss: 1.1173, Test Loss: 1.0870\n",
      "Epoch [17/50] - Train Loss: 1.1173, Test Loss: 1.0871\n",
      "Epoch [18/50] - Train Loss: 1.1173, Test Loss: 1.0871\n",
      "Epoch [19/50] - Train Loss: 1.1173, Test Loss: 1.0871\n",
      "Epoch [20/50] - Train Loss: 1.1172, Test Loss: 1.0871\n",
      "Epoch [21/50] - Train Loss: 1.1172, Test Loss: 1.0871\n",
      "Epoch [22/50] - Train Loss: 1.1172, Test Loss: 1.0871\n",
      "Epoch [23/50] - Train Loss: 1.1172, Test Loss: 1.0871\n",
      "Epoch [24/50] - Train Loss: 1.1171, Test Loss: 1.0871\n",
      "Epoch [25/50] - Train Loss: 1.1171, Test Loss: 1.0871\n",
      "Epoch [26/50] - Train Loss: 1.1171, Test Loss: 1.0871\n",
      "Epoch [27/50] - Train Loss: 1.1171, Test Loss: 1.0871\n",
      "Epoch [28/50] - Train Loss: 1.1171, Test Loss: 1.0871\n",
      "Epoch [29/50] - Train Loss: 1.1170, Test Loss: 1.0871\n",
      "Epoch [30/50] - Train Loss: 1.1170, Test Loss: 1.0871\n",
      "Epoch [31/50] - Train Loss: 1.1170, Test Loss: 1.0871\n",
      "Epoch [32/50] - Train Loss: 1.1170, Test Loss: 1.0871\n",
      "Epoch [33/50] - Train Loss: 1.1170, Test Loss: 1.0871\n",
      "Epoch [34/50] - Train Loss: 1.1170, Test Loss: 1.0871\n",
      "Epoch [35/50] - Train Loss: 1.1170, Test Loss: 1.0871\n",
      "Epoch [36/50] - Train Loss: 1.1169, Test Loss: 1.0871\n",
      "Epoch [37/50] - Train Loss: 1.1169, Test Loss: 1.0870\n",
      "Epoch [38/50] - Train Loss: 1.1169, Test Loss: 1.0870\n",
      "Epoch [39/50] - Train Loss: 1.1169, Test Loss: 1.0870\n",
      "Epoch [40/50] - Train Loss: 1.1169, Test Loss: 1.0870\n",
      "Epoch [41/50] - Train Loss: 1.1169, Test Loss: 1.0870\n",
      "Epoch [42/50] - Train Loss: 1.1169, Test Loss: 1.0870\n",
      "Epoch [43/50] - Train Loss: 1.1169, Test Loss: 1.0870\n",
      "Epoch [44/50] - Train Loss: 1.1169, Test Loss: 1.0870\n",
      "Epoch [45/50] - Train Loss: 1.1169, Test Loss: 1.0870\n",
      "Epoch [46/50] - Train Loss: 1.1168, Test Loss: 1.0870\n",
      "Epoch [47/50] - Train Loss: 1.1168, Test Loss: 1.0870\n",
      "Epoch [48/50] - Train Loss: 1.1168, Test Loss: 1.0870\n",
      "Epoch [49/50] - Train Loss: 1.1168, Test Loss: 1.0870\n",
      "Epoch [50/50] - Train Loss: 1.1168, Test Loss: 1.0870\n",
      "Avg Test Loss: 1.0870\n",
      "Testing combination: (16, 4, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1824, Test Loss: 1.1546\n",
      "Epoch [2/50] - Train Loss: 1.1534, Test Loss: 1.1505\n",
      "Epoch [3/50] - Train Loss: 1.1519, Test Loss: 1.1536\n",
      "Epoch [4/50] - Train Loss: 1.1511, Test Loss: 1.1579\n",
      "Epoch [5/50] - Train Loss: 1.1506, Test Loss: 1.1615\n",
      "Epoch [6/50] - Train Loss: 1.1495, Test Loss: 1.1638\n",
      "Epoch [7/50] - Train Loss: 1.1505, Test Loss: 1.1640\n",
      "Epoch [8/50] - Train Loss: 1.1402, Test Loss: 1.1684\n",
      "Epoch [9/50] - Train Loss: 1.0769, Test Loss: 1.3959\n",
      "Epoch [10/50] - Train Loss: 1.1114, Test Loss: 1.1846\n",
      "Epoch [11/50] - Train Loss: 1.0586, Test Loss: 1.2235\n",
      "Epoch [12/50] - Train Loss: 1.0495, Test Loss: 1.2736\n",
      "Epoch [13/50] - Train Loss: 1.0516, Test Loss: 1.2800\n",
      "Epoch [14/50] - Train Loss: 1.0484, Test Loss: 1.2635\n",
      "Epoch [15/50] - Train Loss: 1.0482, Test Loss: 1.2588\n",
      "Epoch [16/50] - Train Loss: 1.0479, Test Loss: 1.2627\n",
      "Epoch [17/50] - Train Loss: 1.0477, Test Loss: 1.2673\n",
      "Epoch [18/50] - Train Loss: 1.0477, Test Loss: 1.2679\n",
      "Epoch [19/50] - Train Loss: 1.0476, Test Loss: 1.2659\n",
      "Epoch [20/50] - Train Loss: 1.0476, Test Loss: 1.2648\n",
      "Epoch [21/50] - Train Loss: 1.0475, Test Loss: 1.2652\n",
      "Epoch [22/50] - Train Loss: 1.0475, Test Loss: 1.2659\n",
      "Epoch [23/50] - Train Loss: 1.0474, Test Loss: 1.2660\n",
      "Epoch [24/50] - Train Loss: 1.0474, Test Loss: 1.2657\n",
      "Epoch [25/50] - Train Loss: 1.0474, Test Loss: 1.2655\n",
      "Epoch [26/50] - Train Loss: 1.0473, Test Loss: 1.2656\n",
      "Epoch [27/50] - Train Loss: 1.0473, Test Loss: 1.2656\n",
      "Epoch [28/50] - Train Loss: 1.0473, Test Loss: 1.2656\n",
      "Epoch [29/50] - Train Loss: 1.0472, Test Loss: 1.2655\n",
      "Epoch [30/50] - Train Loss: 1.0472, Test Loss: 1.2655\n",
      "Epoch [31/50] - Train Loss: 1.0472, Test Loss: 1.2655\n",
      "Epoch [32/50] - Train Loss: 1.0471, Test Loss: 1.2654\n",
      "Epoch [33/50] - Train Loss: 1.0471, Test Loss: 1.2654\n",
      "Epoch [34/50] - Train Loss: 1.0471, Test Loss: 1.2653\n",
      "Epoch [35/50] - Train Loss: 1.0471, Test Loss: 1.2653\n",
      "Epoch [36/50] - Train Loss: 1.0470, Test Loss: 1.2653\n",
      "Epoch [37/50] - Train Loss: 1.0470, Test Loss: 1.2652\n",
      "Epoch [38/50] - Train Loss: 1.0470, Test Loss: 1.2652\n",
      "Epoch [39/50] - Train Loss: 1.0469, Test Loss: 1.2651\n",
      "Epoch [40/50] - Train Loss: 1.0469, Test Loss: 1.2651\n",
      "Epoch [41/50] - Train Loss: 1.0468, Test Loss: 1.2650\n",
      "Epoch [42/50] - Train Loss: 1.0466, Test Loss: 1.2651\n",
      "Epoch [43/50] - Train Loss: 1.0460, Test Loss: 1.2649\n",
      "Epoch [44/50] - Train Loss: 1.0454, Test Loss: 1.2641\n",
      "Epoch [45/50] - Train Loss: 1.0449, Test Loss: 1.2633\n",
      "Epoch [46/50] - Train Loss: 1.0442, Test Loss: 1.2623\n",
      "Epoch [47/50] - Train Loss: 1.0433, Test Loss: 1.2609\n",
      "Epoch [48/50] - Train Loss: 1.0424, Test Loss: 1.2593\n",
      "Epoch [49/50] - Train Loss: 1.0416, Test Loss: 1.2579\n",
      "Epoch [50/50] - Train Loss: 1.0409, Test Loss: 1.2565\n",
      "Avg Test Loss: 1.2565\n",
      "Testing combination: (16, 4, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5220, Test Loss: 1.7371\n",
      "Epoch [2/50] - Train Loss: 1.4857, Test Loss: 1.7332\n",
      "Epoch [3/50] - Train Loss: 1.4846, Test Loss: 1.7334\n",
      "Epoch [4/50] - Train Loss: 1.4855, Test Loss: 1.7342\n",
      "Epoch [5/50] - Train Loss: 1.4864, Test Loss: 1.7346\n",
      "Epoch [6/50] - Train Loss: 1.4869, Test Loss: 1.7347\n",
      "Epoch [7/50] - Train Loss: 1.4871, Test Loss: 1.7346\n",
      "Epoch [8/50] - Train Loss: 1.4869, Test Loss: 1.7347\n",
      "Epoch [9/50] - Train Loss: 1.4865, Test Loss: 1.7351\n",
      "Epoch [10/50] - Train Loss: 1.4856, Test Loss: 1.7361\n",
      "Epoch [11/50] - Train Loss: 1.4828, Test Loss: 1.7405\n",
      "Epoch [12/50] - Train Loss: 1.4805, Test Loss: 1.7452\n",
      "Epoch [13/50] - Train Loss: 1.4679, Test Loss: 1.7695\n",
      "Epoch [14/50] - Train Loss: 1.4400, Test Loss: 1.8495\n",
      "Epoch [15/50] - Train Loss: 1.5165, Test Loss: 1.8205\n",
      "Epoch [16/50] - Train Loss: 1.4452, Test Loss: 1.8119\n",
      "Epoch [17/50] - Train Loss: 1.4526, Test Loss: 1.8173\n",
      "Epoch [18/50] - Train Loss: 1.4502, Test Loss: 1.8368\n",
      "Epoch [19/50] - Train Loss: 1.4441, Test Loss: 1.8722\n",
      "Epoch [20/50] - Train Loss: 1.4367, Test Loss: 1.9265\n",
      "Epoch [21/50] - Train Loss: 1.4311, Test Loss: 1.9969\n",
      "Epoch [22/50] - Train Loss: 1.4291, Test Loss: 2.0638\n",
      "Epoch [23/50] - Train Loss: 1.4292, Test Loss: 2.1029\n",
      "Epoch [24/50] - Train Loss: 1.4285, Test Loss: 2.1150\n",
      "Epoch [25/50] - Train Loss: 1.4278, Test Loss: 2.1088\n",
      "Epoch [26/50] - Train Loss: 1.4271, Test Loss: 2.0923\n",
      "Epoch [27/50] - Train Loss: 1.4263, Test Loss: 2.0765\n",
      "Epoch [28/50] - Train Loss: 1.4246, Test Loss: 2.0662\n",
      "Epoch [29/50] - Train Loss: 1.4213, Test Loss: 2.0586\n",
      "Epoch [30/50] - Train Loss: 1.4197, Test Loss: 2.0565\n",
      "Epoch [31/50] - Train Loss: 1.4181, Test Loss: 2.0586\n",
      "Epoch [32/50] - Train Loss: 1.4150, Test Loss: 2.0609\n",
      "Epoch [33/50] - Train Loss: 1.4133, Test Loss: 2.0764\n",
      "Epoch [34/50] - Train Loss: 1.4117, Test Loss: 2.0854\n",
      "Epoch [35/50] - Train Loss: 1.4656, Test Loss: 1.9379\n",
      "Epoch [36/50] - Train Loss: 1.4358, Test Loss: 2.1259\n",
      "Epoch [37/50] - Train Loss: 1.3964, Test Loss: 2.0698\n",
      "Epoch [38/50] - Train Loss: 1.4125, Test Loss: 2.0638\n",
      "Epoch [39/50] - Train Loss: 1.4161, Test Loss: 2.0623\n",
      "Epoch [40/50] - Train Loss: 1.4161, Test Loss: 2.0653\n",
      "Epoch [41/50] - Train Loss: 1.4151, Test Loss: 2.0707\n",
      "Epoch [42/50] - Train Loss: 1.4144, Test Loss: 2.0699\n",
      "Epoch [43/50] - Train Loss: 1.4138, Test Loss: 2.0590\n",
      "Epoch [44/50] - Train Loss: 1.4121, Test Loss: 2.0491\n",
      "Epoch [45/50] - Train Loss: 1.4106, Test Loss: 2.0592\n",
      "Epoch [46/50] - Train Loss: 1.4078, Test Loss: 2.0927\n",
      "Epoch [47/50] - Train Loss: 1.4038, Test Loss: 2.0711\n",
      "Epoch [48/50] - Train Loss: 1.4012, Test Loss: 2.0827\n",
      "Epoch [49/50] - Train Loss: 1.4009, Test Loss: 2.1196\n",
      "Epoch [50/50] - Train Loss: 1.3982, Test Loss: 2.0925\n",
      "Avg Test Loss: 2.0925\n",
      "Testing combination: (16, 4, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1400, Test Loss: 1.1309\n",
      "Epoch [2/50] - Train Loss: 1.1308, Test Loss: 1.1191\n",
      "Epoch [3/50] - Train Loss: 1.1254, Test Loss: 1.1104\n",
      "Epoch [4/50] - Train Loss: 1.1218, Test Loss: 1.1040\n",
      "Epoch [5/50] - Train Loss: 1.1194, Test Loss: 1.0993\n",
      "Epoch [6/50] - Train Loss: 1.1179, Test Loss: 1.0958\n",
      "Epoch [7/50] - Train Loss: 1.1169, Test Loss: 1.0934\n",
      "Epoch [8/50] - Train Loss: 1.1162, Test Loss: 1.0917\n",
      "Epoch [9/50] - Train Loss: 1.1157, Test Loss: 1.0906\n",
      "Epoch [10/50] - Train Loss: 1.1152, Test Loss: 1.0900\n",
      "Epoch [11/50] - Train Loss: 1.1146, Test Loss: 1.0896\n",
      "Epoch [12/50] - Train Loss: 1.1139, Test Loss: 1.0894\n",
      "Epoch [13/50] - Train Loss: 1.1130, Test Loss: 1.0894\n",
      "Epoch [14/50] - Train Loss: 1.1119, Test Loss: 1.0896\n",
      "Epoch [15/50] - Train Loss: 1.1107, Test Loss: 1.0899\n",
      "Epoch [16/50] - Train Loss: 1.1091, Test Loss: 1.0904\n",
      "Epoch [17/50] - Train Loss: 1.1069, Test Loss: 1.0912\n",
      "Epoch [18/50] - Train Loss: 1.1036, Test Loss: 1.0925\n",
      "Epoch [19/50] - Train Loss: 1.0994, Test Loss: 1.0951\n",
      "Epoch [20/50] - Train Loss: 1.0955, Test Loss: 1.0974\n",
      "Epoch [21/50] - Train Loss: 1.0909, Test Loss: 1.0998\n",
      "Epoch [22/50] - Train Loss: 1.0871, Test Loss: 1.1030\n",
      "Epoch [23/50] - Train Loss: 1.0840, Test Loss: 1.1067\n",
      "Epoch [24/50] - Train Loss: 1.0816, Test Loss: 1.1102\n",
      "Epoch [25/50] - Train Loss: 1.0798, Test Loss: 1.1136\n",
      "Epoch [26/50] - Train Loss: 1.0787, Test Loss: 1.1165\n",
      "Epoch [27/50] - Train Loss: 1.0780, Test Loss: 1.1190\n",
      "Epoch [28/50] - Train Loss: 1.0776, Test Loss: 1.1212\n",
      "Epoch [29/50] - Train Loss: 1.0773, Test Loss: 1.1230\n",
      "Epoch [30/50] - Train Loss: 1.0769, Test Loss: 1.1246\n",
      "Epoch [31/50] - Train Loss: 1.0765, Test Loss: 1.1260\n",
      "Epoch [32/50] - Train Loss: 1.0759, Test Loss: 1.1274\n",
      "Epoch [33/50] - Train Loss: 1.0752, Test Loss: 1.1290\n",
      "Epoch [34/50] - Train Loss: 1.0743, Test Loss: 1.1304\n",
      "Epoch [35/50] - Train Loss: 1.0732, Test Loss: 1.1318\n",
      "Epoch [36/50] - Train Loss: 1.0719, Test Loss: 1.1333\n",
      "Epoch [37/50] - Train Loss: 1.0703, Test Loss: 1.1346\n",
      "Epoch [38/50] - Train Loss: 1.0684, Test Loss: 1.1361\n",
      "Epoch [39/50] - Train Loss: 1.0662, Test Loss: 1.1379\n",
      "Epoch [40/50] - Train Loss: 1.0636, Test Loss: 1.1397\n",
      "Epoch [41/50] - Train Loss: 1.0592, Test Loss: 1.1498\n",
      "Epoch [42/50] - Train Loss: 1.0555, Test Loss: 1.1757\n",
      "Epoch [43/50] - Train Loss: 1.0465, Test Loss: 1.1794\n",
      "Epoch [44/50] - Train Loss: 1.0421, Test Loss: 1.1823\n",
      "Epoch [45/50] - Train Loss: 1.0410, Test Loss: 1.1888\n",
      "Epoch [46/50] - Train Loss: 1.0394, Test Loss: 1.1865\n",
      "Epoch [47/50] - Train Loss: 1.0373, Test Loss: 1.1882\n",
      "Epoch [48/50] - Train Loss: 1.0359, Test Loss: 1.1861\n",
      "Epoch [49/50] - Train Loss: 1.0325, Test Loss: 1.1841\n",
      "Epoch [50/50] - Train Loss: 1.0302, Test Loss: 1.1763\n",
      "Avg Test Loss: 1.1763\n",
      "Testing combination: (16, 4, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1593, Test Loss: 1.1356\n",
      "Epoch [2/50] - Train Loss: 1.1546, Test Loss: 1.1394\n",
      "Epoch [3/50] - Train Loss: 1.1526, Test Loss: 1.1431\n",
      "Epoch [4/50] - Train Loss: 1.1512, Test Loss: 1.1466\n",
      "Epoch [5/50] - Train Loss: 1.1501, Test Loss: 1.1498\n",
      "Epoch [6/50] - Train Loss: 1.1493, Test Loss: 1.1527\n",
      "Epoch [7/50] - Train Loss: 1.1486, Test Loss: 1.1553\n",
      "Epoch [8/50] - Train Loss: 1.1479, Test Loss: 1.1576\n",
      "Epoch [9/50] - Train Loss: 1.1472, Test Loss: 1.1596\n",
      "Epoch [10/50] - Train Loss: 1.1462, Test Loss: 1.1614\n",
      "Epoch [11/50] - Train Loss: 1.1449, Test Loss: 1.1631\n",
      "Epoch [12/50] - Train Loss: 1.1429, Test Loss: 1.1646\n",
      "Epoch [13/50] - Train Loss: 1.1400, Test Loss: 1.1660\n",
      "Epoch [14/50] - Train Loss: 1.1358, Test Loss: 1.1671\n",
      "Epoch [15/50] - Train Loss: 1.1298, Test Loss: 1.1677\n",
      "Epoch [16/50] - Train Loss: 1.1213, Test Loss: 1.1682\n",
      "Epoch [17/50] - Train Loss: 1.1099, Test Loss: 1.1691\n",
      "Epoch [18/50] - Train Loss: 1.0956, Test Loss: 1.1719\n",
      "Epoch [19/50] - Train Loss: 1.0815, Test Loss: 1.1773\n",
      "Epoch [20/50] - Train Loss: 1.0713, Test Loss: 1.1829\n",
      "Epoch [21/50] - Train Loss: 1.0632, Test Loss: 1.1904\n",
      "Epoch [22/50] - Train Loss: 1.0590, Test Loss: 1.1995\n",
      "Epoch [23/50] - Train Loss: 1.0565, Test Loss: 1.2087\n",
      "Epoch [24/50] - Train Loss: 1.0547, Test Loss: 1.2171\n",
      "Epoch [25/50] - Train Loss: 1.0532, Test Loss: 1.2246\n",
      "Epoch [26/50] - Train Loss: 1.0519, Test Loss: 1.2310\n",
      "Epoch [27/50] - Train Loss: 1.0506, Test Loss: 1.2365\n",
      "Epoch [28/50] - Train Loss: 1.0493, Test Loss: 1.2412\n",
      "Epoch [29/50] - Train Loss: 1.0480, Test Loss: 1.2455\n",
      "Epoch [30/50] - Train Loss: 1.0466, Test Loss: 1.2494\n",
      "Epoch [31/50] - Train Loss: 1.0453, Test Loss: 1.2531\n",
      "Epoch [32/50] - Train Loss: 1.0438, Test Loss: 1.2564\n",
      "Epoch [33/50] - Train Loss: 1.0420, Test Loss: 1.2593\n",
      "Epoch [34/50] - Train Loss: 1.0393, Test Loss: 1.2618\n",
      "Epoch [35/50] - Train Loss: 1.0364, Test Loss: 1.2634\n",
      "Epoch [36/50] - Train Loss: 1.0341, Test Loss: 1.2629\n",
      "Epoch [37/50] - Train Loss: 1.0335, Test Loss: 1.2611\n",
      "Epoch [38/50] - Train Loss: 1.0325, Test Loss: 1.2546\n",
      "Epoch [39/50] - Train Loss: 1.0335, Test Loss: 1.2635\n",
      "Epoch [40/50] - Train Loss: 1.0300, Test Loss: 1.2509\n",
      "Epoch [41/50] - Train Loss: 1.0300, Test Loss: 1.2697\n",
      "Epoch [42/50] - Train Loss: 1.0247, Test Loss: 1.2352\n",
      "Epoch [43/50] - Train Loss: 1.0422, Test Loss: 1.2366\n",
      "Epoch [44/50] - Train Loss: 1.0039, Test Loss: 1.2253\n",
      "Epoch [45/50] - Train Loss: 1.0081, Test Loss: 1.2949\n",
      "Epoch [46/50] - Train Loss: 0.9562, Test Loss: 1.1899\n",
      "Epoch [47/50] - Train Loss: 1.1309, Test Loss: 1.2260\n",
      "Epoch [48/50] - Train Loss: 0.9572, Test Loss: 1.3413\n",
      "Epoch [49/50] - Train Loss: 0.9979, Test Loss: 1.2246\n",
      "Epoch [50/50] - Train Loss: 1.0022, Test Loss: 1.2134\n",
      "Avg Test Loss: 1.2134\n",
      "Testing combination: (16, 4, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5157, Test Loss: 1.7673\n",
      "Epoch [2/50] - Train Loss: 1.5091, Test Loss: 1.7609\n",
      "Epoch [3/50] - Train Loss: 1.5042, Test Loss: 1.7549\n",
      "Epoch [4/50] - Train Loss: 1.5001, Test Loss: 1.7499\n",
      "Epoch [5/50] - Train Loss: 1.4966, Test Loss: 1.7457\n",
      "Epoch [6/50] - Train Loss: 1.4937, Test Loss: 1.7424\n",
      "Epoch [7/50] - Train Loss: 1.4914, Test Loss: 1.7399\n",
      "Epoch [8/50] - Train Loss: 1.4895, Test Loss: 1.7379\n",
      "Epoch [9/50] - Train Loss: 1.4881, Test Loss: 1.7366\n",
      "Epoch [10/50] - Train Loss: 1.4871, Test Loss: 1.7357\n",
      "Epoch [11/50] - Train Loss: 1.4863, Test Loss: 1.7352\n",
      "Epoch [12/50] - Train Loss: 1.4857, Test Loss: 1.7350\n",
      "Epoch [13/50] - Train Loss: 1.4853, Test Loss: 1.7351\n",
      "Epoch [14/50] - Train Loss: 1.4849, Test Loss: 1.7354\n",
      "Epoch [15/50] - Train Loss: 1.4847, Test Loss: 1.7358\n",
      "Epoch [16/50] - Train Loss: 1.4844, Test Loss: 1.7364\n",
      "Epoch [17/50] - Train Loss: 1.4841, Test Loss: 1.7372\n",
      "Epoch [18/50] - Train Loss: 1.4837, Test Loss: 1.7382\n",
      "Epoch [19/50] - Train Loss: 1.4832, Test Loss: 1.7393\n",
      "Epoch [20/50] - Train Loss: 1.4825, Test Loss: 1.7407\n",
      "Epoch [21/50] - Train Loss: 1.4815, Test Loss: 1.7425\n",
      "Epoch [22/50] - Train Loss: 1.4801, Test Loss: 1.7447\n",
      "Epoch [23/50] - Train Loss: 1.4784, Test Loss: 1.7473\n",
      "Epoch [24/50] - Train Loss: 1.4763, Test Loss: 1.7504\n",
      "Epoch [25/50] - Train Loss: 1.4737, Test Loss: 1.7540\n",
      "Epoch [26/50] - Train Loss: 1.4704, Test Loss: 1.7581\n",
      "Epoch [27/50] - Train Loss: 1.4662, Test Loss: 1.7631\n",
      "Epoch [28/50] - Train Loss: 1.4609, Test Loss: 1.7703\n",
      "Epoch [29/50] - Train Loss: 1.4557, Test Loss: 1.7804\n",
      "Epoch [30/50] - Train Loss: 1.4500, Test Loss: 1.7890\n",
      "Epoch [31/50] - Train Loss: 1.4441, Test Loss: 1.7966\n",
      "Epoch [32/50] - Train Loss: 1.4394, Test Loss: 1.8052\n",
      "Epoch [33/50] - Train Loss: 1.4360, Test Loss: 1.8147\n",
      "Epoch [34/50] - Train Loss: 1.4334, Test Loss: 1.8251\n",
      "Epoch [35/50] - Train Loss: 1.4314, Test Loss: 1.8357\n",
      "Epoch [36/50] - Train Loss: 1.4297, Test Loss: 1.8449\n",
      "Epoch [37/50] - Train Loss: 1.4281, Test Loss: 1.8525\n",
      "Epoch [38/50] - Train Loss: 1.4268, Test Loss: 1.8594\n",
      "Epoch [39/50] - Train Loss: 1.4257, Test Loss: 1.8661\n",
      "Epoch [40/50] - Train Loss: 1.4248, Test Loss: 1.8725\n",
      "Epoch [41/50] - Train Loss: 1.4238, Test Loss: 1.8785\n",
      "Epoch [42/50] - Train Loss: 1.4228, Test Loss: 1.8835\n",
      "Epoch [43/50] - Train Loss: 1.4218, Test Loss: 1.8876\n",
      "Epoch [44/50] - Train Loss: 1.4207, Test Loss: 1.8912\n",
      "Epoch [45/50] - Train Loss: 1.4195, Test Loss: 1.8946\n",
      "Epoch [46/50] - Train Loss: 1.4183, Test Loss: 1.8979\n",
      "Epoch [47/50] - Train Loss: 1.4168, Test Loss: 1.9009\n",
      "Epoch [48/50] - Train Loss: 1.4149, Test Loss: 1.9035\n",
      "Epoch [49/50] - Train Loss: 1.4123, Test Loss: 1.9056\n",
      "Epoch [50/50] - Train Loss: 1.4086, Test Loss: 1.9096\n",
      "Avg Test Loss: 1.9096\n",
      "Testing combination: (16, 4, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1772, Test Loss: 1.1954\n",
      "Epoch [2/50] - Train Loss: 1.1741, Test Loss: 1.1912\n",
      "Epoch [3/50] - Train Loss: 1.1714, Test Loss: 1.1873\n",
      "Epoch [4/50] - Train Loss: 1.1688, Test Loss: 1.1835\n",
      "Epoch [5/50] - Train Loss: 1.1664, Test Loss: 1.1800\n",
      "Epoch [6/50] - Train Loss: 1.1641, Test Loss: 1.1765\n",
      "Epoch [7/50] - Train Loss: 1.1618, Test Loss: 1.1733\n",
      "Epoch [8/50] - Train Loss: 1.1597, Test Loss: 1.1701\n",
      "Epoch [9/50] - Train Loss: 1.1577, Test Loss: 1.1671\n",
      "Epoch [10/50] - Train Loss: 1.1558, Test Loss: 1.1641\n",
      "Epoch [11/50] - Train Loss: 1.1539, Test Loss: 1.1613\n",
      "Epoch [12/50] - Train Loss: 1.1521, Test Loss: 1.1585\n",
      "Epoch [13/50] - Train Loss: 1.1504, Test Loss: 1.1558\n",
      "Epoch [14/50] - Train Loss: 1.1487, Test Loss: 1.1532\n",
      "Epoch [15/50] - Train Loss: 1.1471, Test Loss: 1.1507\n",
      "Epoch [16/50] - Train Loss: 1.1456, Test Loss: 1.1483\n",
      "Epoch [17/50] - Train Loss: 1.1441, Test Loss: 1.1459\n",
      "Epoch [18/50] - Train Loss: 1.1426, Test Loss: 1.1435\n",
      "Epoch [19/50] - Train Loss: 1.1412, Test Loss: 1.1412\n",
      "Epoch [20/50] - Train Loss: 1.1398, Test Loss: 1.1390\n",
      "Epoch [21/50] - Train Loss: 1.1385, Test Loss: 1.1369\n",
      "Epoch [22/50] - Train Loss: 1.1373, Test Loss: 1.1348\n",
      "Epoch [23/50] - Train Loss: 1.1361, Test Loss: 1.1327\n",
      "Epoch [24/50] - Train Loss: 1.1349, Test Loss: 1.1307\n",
      "Epoch [25/50] - Train Loss: 1.1337, Test Loss: 1.1288\n",
      "Epoch [26/50] - Train Loss: 1.1327, Test Loss: 1.1269\n",
      "Epoch [27/50] - Train Loss: 1.1316, Test Loss: 1.1251\n",
      "Epoch [28/50] - Train Loss: 1.1306, Test Loss: 1.1234\n",
      "Epoch [29/50] - Train Loss: 1.1296, Test Loss: 1.1217\n",
      "Epoch [30/50] - Train Loss: 1.1287, Test Loss: 1.1200\n",
      "Epoch [31/50] - Train Loss: 1.1278, Test Loss: 1.1184\n",
      "Epoch [32/50] - Train Loss: 1.1270, Test Loss: 1.1169\n",
      "Epoch [33/50] - Train Loss: 1.1262, Test Loss: 1.1154\n",
      "Epoch [34/50] - Train Loss: 1.1254, Test Loss: 1.1140\n",
      "Epoch [35/50] - Train Loss: 1.1247, Test Loss: 1.1126\n",
      "Epoch [36/50] - Train Loss: 1.1240, Test Loss: 1.1113\n",
      "Epoch [37/50] - Train Loss: 1.1234, Test Loss: 1.1101\n",
      "Epoch [38/50] - Train Loss: 1.1228, Test Loss: 1.1089\n",
      "Epoch [39/50] - Train Loss: 1.1222, Test Loss: 1.1077\n",
      "Epoch [40/50] - Train Loss: 1.1216, Test Loss: 1.1066\n",
      "Epoch [41/50] - Train Loss: 1.1211, Test Loss: 1.1056\n",
      "Epoch [42/50] - Train Loss: 1.1206, Test Loss: 1.1046\n",
      "Epoch [43/50] - Train Loss: 1.1202, Test Loss: 1.1036\n",
      "Epoch [44/50] - Train Loss: 1.1197, Test Loss: 1.1027\n",
      "Epoch [45/50] - Train Loss: 1.1193, Test Loss: 1.1019\n",
      "Epoch [46/50] - Train Loss: 1.1189, Test Loss: 1.1011\n",
      "Epoch [47/50] - Train Loss: 1.1186, Test Loss: 1.1003\n",
      "Epoch [48/50] - Train Loss: 1.1182, Test Loss: 1.0996\n",
      "Epoch [49/50] - Train Loss: 1.1179, Test Loss: 1.0989\n",
      "Epoch [50/50] - Train Loss: 1.1176, Test Loss: 1.0983\n",
      "Avg Test Loss: 1.0983\n",
      "Testing combination: (16, 4, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1489, Test Loss: 1.1619\n",
      "Epoch [2/50] - Train Loss: 1.1486, Test Loss: 1.1619\n",
      "Epoch [3/50] - Train Loss: 1.1486, Test Loss: 1.1619\n",
      "Epoch [4/50] - Train Loss: 1.1486, Test Loss: 1.1620\n",
      "Epoch [5/50] - Train Loss: 1.1486, Test Loss: 1.1620\n",
      "Epoch [6/50] - Train Loss: 1.1486, Test Loss: 1.1621\n",
      "Epoch [7/50] - Train Loss: 1.1485, Test Loss: 1.1621\n",
      "Epoch [8/50] - Train Loss: 1.1485, Test Loss: 1.1622\n",
      "Epoch [9/50] - Train Loss: 1.1485, Test Loss: 1.1622\n",
      "Epoch [10/50] - Train Loss: 1.1485, Test Loss: 1.1623\n",
      "Epoch [11/50] - Train Loss: 1.1485, Test Loss: 1.1623\n",
      "Epoch [12/50] - Train Loss: 1.1485, Test Loss: 1.1624\n",
      "Epoch [13/50] - Train Loss: 1.1485, Test Loss: 1.1624\n",
      "Epoch [14/50] - Train Loss: 1.1485, Test Loss: 1.1625\n",
      "Epoch [15/50] - Train Loss: 1.1485, Test Loss: 1.1625\n",
      "Epoch [16/50] - Train Loss: 1.1484, Test Loss: 1.1626\n",
      "Epoch [17/50] - Train Loss: 1.1484, Test Loss: 1.1626\n",
      "Epoch [18/50] - Train Loss: 1.1484, Test Loss: 1.1627\n",
      "Epoch [19/50] - Train Loss: 1.1484, Test Loss: 1.1627\n",
      "Epoch [20/50] - Train Loss: 1.1484, Test Loss: 1.1628\n",
      "Epoch [21/50] - Train Loss: 1.1484, Test Loss: 1.1628\n",
      "Epoch [22/50] - Train Loss: 1.1484, Test Loss: 1.1629\n",
      "Epoch [23/50] - Train Loss: 1.1483, Test Loss: 1.1629\n",
      "Epoch [24/50] - Train Loss: 1.1483, Test Loss: 1.1630\n",
      "Epoch [25/50] - Train Loss: 1.1483, Test Loss: 1.1630\n",
      "Epoch [26/50] - Train Loss: 1.1483, Test Loss: 1.1631\n",
      "Epoch [27/50] - Train Loss: 1.1483, Test Loss: 1.1631\n",
      "Epoch [28/50] - Train Loss: 1.1482, Test Loss: 1.1632\n",
      "Epoch [29/50] - Train Loss: 1.1482, Test Loss: 1.1632\n",
      "Epoch [30/50] - Train Loss: 1.1482, Test Loss: 1.1632\n",
      "Epoch [31/50] - Train Loss: 1.1482, Test Loss: 1.1633\n",
      "Epoch [32/50] - Train Loss: 1.1482, Test Loss: 1.1633\n",
      "Epoch [33/50] - Train Loss: 1.1481, Test Loss: 1.1634\n",
      "Epoch [34/50] - Train Loss: 1.1481, Test Loss: 1.1634\n",
      "Epoch [35/50] - Train Loss: 1.1481, Test Loss: 1.1635\n",
      "Epoch [36/50] - Train Loss: 1.1481, Test Loss: 1.1635\n",
      "Epoch [37/50] - Train Loss: 1.1480, Test Loss: 1.1636\n",
      "Epoch [38/50] - Train Loss: 1.1480, Test Loss: 1.1636\n",
      "Epoch [39/50] - Train Loss: 1.1480, Test Loss: 1.1637\n",
      "Epoch [40/50] - Train Loss: 1.1479, Test Loss: 1.1637\n",
      "Epoch [41/50] - Train Loss: 1.1479, Test Loss: 1.1638\n",
      "Epoch [42/50] - Train Loss: 1.1479, Test Loss: 1.1638\n",
      "Epoch [43/50] - Train Loss: 1.1478, Test Loss: 1.1639\n",
      "Epoch [44/50] - Train Loss: 1.1478, Test Loss: 1.1639\n",
      "Epoch [45/50] - Train Loss: 1.1477, Test Loss: 1.1640\n",
      "Epoch [46/50] - Train Loss: 1.1477, Test Loss: 1.1640\n",
      "Epoch [47/50] - Train Loss: 1.1476, Test Loss: 1.1641\n",
      "Epoch [48/50] - Train Loss: 1.1476, Test Loss: 1.1641\n",
      "Epoch [49/50] - Train Loss: 1.1475, Test Loss: 1.1642\n",
      "Epoch [50/50] - Train Loss: 1.1475, Test Loss: 1.1643\n",
      "Avg Test Loss: 1.1643\n",
      "Testing combination: (16, 4, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.4893, Test Loss: 1.7401\n",
      "Epoch [2/50] - Train Loss: 1.4889, Test Loss: 1.7399\n",
      "Epoch [3/50] - Train Loss: 1.4888, Test Loss: 1.7398\n",
      "Epoch [4/50] - Train Loss: 1.4887, Test Loss: 1.7396\n",
      "Epoch [5/50] - Train Loss: 1.4886, Test Loss: 1.7395\n",
      "Epoch [6/50] - Train Loss: 1.4885, Test Loss: 1.7394\n",
      "Epoch [7/50] - Train Loss: 1.4885, Test Loss: 1.7393\n",
      "Epoch [8/50] - Train Loss: 1.4884, Test Loss: 1.7391\n",
      "Epoch [9/50] - Train Loss: 1.4883, Test Loss: 1.7390\n",
      "Epoch [10/50] - Train Loss: 1.4883, Test Loss: 1.7389\n",
      "Epoch [11/50] - Train Loss: 1.4882, Test Loss: 1.7388\n",
      "Epoch [12/50] - Train Loss: 1.4881, Test Loss: 1.7387\n",
      "Epoch [13/50] - Train Loss: 1.4881, Test Loss: 1.7386\n",
      "Epoch [14/50] - Train Loss: 1.4880, Test Loss: 1.7385\n",
      "Epoch [15/50] - Train Loss: 1.4880, Test Loss: 1.7384\n",
      "Epoch [16/50] - Train Loss: 1.4879, Test Loss: 1.7383\n",
      "Epoch [17/50] - Train Loss: 1.4879, Test Loss: 1.7382\n",
      "Epoch [18/50] - Train Loss: 1.4878, Test Loss: 1.7381\n",
      "Epoch [19/50] - Train Loss: 1.4878, Test Loss: 1.7380\n",
      "Epoch [20/50] - Train Loss: 1.4877, Test Loss: 1.7379\n",
      "Epoch [21/50] - Train Loss: 1.4877, Test Loss: 1.7379\n",
      "Epoch [22/50] - Train Loss: 1.4876, Test Loss: 1.7378\n",
      "Epoch [23/50] - Train Loss: 1.4876, Test Loss: 1.7377\n",
      "Epoch [24/50] - Train Loss: 1.4875, Test Loss: 1.7376\n",
      "Epoch [25/50] - Train Loss: 1.4875, Test Loss: 1.7375\n",
      "Epoch [26/50] - Train Loss: 1.4874, Test Loss: 1.7374\n",
      "Epoch [27/50] - Train Loss: 1.4874, Test Loss: 1.7374\n",
      "Epoch [28/50] - Train Loss: 1.4873, Test Loss: 1.7373\n",
      "Epoch [29/50] - Train Loss: 1.4873, Test Loss: 1.7372\n",
      "Epoch [30/50] - Train Loss: 1.4872, Test Loss: 1.7371\n",
      "Epoch [31/50] - Train Loss: 1.4872, Test Loss: 1.7371\n",
      "Epoch [32/50] - Train Loss: 1.4872, Test Loss: 1.7370\n",
      "Epoch [33/50] - Train Loss: 1.4871, Test Loss: 1.7369\n",
      "Epoch [34/50] - Train Loss: 1.4871, Test Loss: 1.7368\n",
      "Epoch [35/50] - Train Loss: 1.4871, Test Loss: 1.7368\n",
      "Epoch [36/50] - Train Loss: 1.4870, Test Loss: 1.7367\n",
      "Epoch [37/50] - Train Loss: 1.4870, Test Loss: 1.7366\n",
      "Epoch [38/50] - Train Loss: 1.4869, Test Loss: 1.7366\n",
      "Epoch [39/50] - Train Loss: 1.4869, Test Loss: 1.7365\n",
      "Epoch [40/50] - Train Loss: 1.4869, Test Loss: 1.7365\n",
      "Epoch [41/50] - Train Loss: 1.4868, Test Loss: 1.7364\n",
      "Epoch [42/50] - Train Loss: 1.4868, Test Loss: 1.7363\n",
      "Epoch [43/50] - Train Loss: 1.4868, Test Loss: 1.7363\n",
      "Epoch [44/50] - Train Loss: 1.4867, Test Loss: 1.7362\n",
      "Epoch [45/50] - Train Loss: 1.4867, Test Loss: 1.7362\n",
      "Epoch [46/50] - Train Loss: 1.4867, Test Loss: 1.7361\n",
      "Epoch [47/50] - Train Loss: 1.4867, Test Loss: 1.7361\n",
      "Epoch [48/50] - Train Loss: 1.4866, Test Loss: 1.7360\n",
      "Epoch [49/50] - Train Loss: 1.4866, Test Loss: 1.7360\n",
      "Epoch [50/50] - Train Loss: 1.4866, Test Loss: 1.7359\n",
      "Avg Test Loss: 1.7359\n",
      "Testing combination: (32, 1, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1508, Test Loss: 1.0890\n",
      "Epoch [2/50] - Train Loss: 1.1190, Test Loss: 1.0874\n",
      "Epoch [3/50] - Train Loss: 1.1190, Test Loss: 1.0883\n",
      "Epoch [4/50] - Train Loss: 1.1181, Test Loss: 1.0883\n",
      "Epoch [5/50] - Train Loss: 1.1143, Test Loss: 1.0873\n",
      "Epoch [6/50] - Train Loss: 1.1094, Test Loss: 1.0914\n",
      "Epoch [7/50] - Train Loss: 1.0888, Test Loss: 1.1284\n",
      "Epoch [8/50] - Train Loss: 1.0817, Test Loss: 1.1475\n",
      "Epoch [9/50] - Train Loss: 1.0764, Test Loss: 1.1492\n",
      "Epoch [10/50] - Train Loss: 1.0762, Test Loss: 1.1412\n",
      "Epoch [11/50] - Train Loss: 1.0752, Test Loss: 1.1403\n",
      "Epoch [12/50] - Train Loss: 1.0768, Test Loss: 1.1309\n",
      "Epoch [13/50] - Train Loss: 1.0746, Test Loss: 1.1200\n",
      "Epoch [14/50] - Train Loss: 1.0743, Test Loss: 1.1207\n",
      "Epoch [15/50] - Train Loss: 1.0740, Test Loss: 1.1231\n",
      "Epoch [16/50] - Train Loss: 1.0737, Test Loss: 1.1219\n",
      "Epoch [17/50] - Train Loss: 1.0735, Test Loss: 1.1204\n",
      "Epoch [18/50] - Train Loss: 1.0735, Test Loss: 1.1204\n",
      "Epoch [19/50] - Train Loss: 1.0734, Test Loss: 1.1204\n",
      "Epoch [20/50] - Train Loss: 1.0733, Test Loss: 1.1201\n",
      "Epoch [21/50] - Train Loss: 1.0732, Test Loss: 1.1198\n",
      "Epoch [22/50] - Train Loss: 1.0730, Test Loss: 1.1198\n",
      "Epoch [23/50] - Train Loss: 1.0726, Test Loss: 1.1203\n",
      "Epoch [24/50] - Train Loss: 1.0705, Test Loss: 1.1213\n",
      "Epoch [25/50] - Train Loss: 1.0728, Test Loss: 1.1181\n",
      "Epoch [26/50] - Train Loss: 1.0730, Test Loss: 1.1186\n",
      "Epoch [27/50] - Train Loss: 1.0706, Test Loss: 1.1197\n",
      "Epoch [28/50] - Train Loss: 1.0686, Test Loss: 1.1160\n",
      "Epoch [29/50] - Train Loss: 1.0641, Test Loss: 1.1218\n",
      "Epoch [30/50] - Train Loss: 1.0623, Test Loss: 1.1211\n",
      "Epoch [31/50] - Train Loss: 1.0673, Test Loss: 1.1188\n",
      "Epoch [32/50] - Train Loss: 1.0774, Test Loss: 1.1180\n",
      "Epoch [33/50] - Train Loss: 1.0661, Test Loss: 1.0959\n",
      "Epoch [34/50] - Train Loss: 1.0648, Test Loss: 1.0950\n",
      "Epoch [35/50] - Train Loss: 1.0620, Test Loss: 1.0986\n",
      "Epoch [36/50] - Train Loss: 1.0619, Test Loss: 1.0982\n",
      "Epoch [37/50] - Train Loss: 1.0628, Test Loss: 1.0989\n",
      "Epoch [38/50] - Train Loss: 1.0600, Test Loss: 1.0989\n",
      "Epoch [39/50] - Train Loss: 1.0610, Test Loss: 1.0976\n",
      "Epoch [40/50] - Train Loss: 1.0619, Test Loss: 1.0971\n",
      "Epoch [41/50] - Train Loss: 1.0612, Test Loss: 1.0958\n",
      "Epoch [42/50] - Train Loss: 1.0610, Test Loss: 1.0926\n",
      "Epoch [43/50] - Train Loss: 1.0617, Test Loss: 1.0931\n",
      "Epoch [44/50] - Train Loss: 1.0581, Test Loss: 1.0926\n",
      "Epoch [45/50] - Train Loss: 1.0555, Test Loss: 1.0844\n",
      "Epoch [46/50] - Train Loss: 1.0913, Test Loss: 1.1143\n",
      "Epoch [47/50] - Train Loss: 1.0741, Test Loss: 1.1199\n",
      "Epoch [48/50] - Train Loss: 1.0692, Test Loss: 1.1228\n",
      "Epoch [49/50] - Train Loss: 1.0652, Test Loss: 1.1198\n",
      "Epoch [50/50] - Train Loss: 1.0645, Test Loss: 1.1161\n",
      "Avg Test Loss: 1.1161\n",
      "Testing combination: (32, 1, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.2058, Test Loss: 1.1600\n",
      "Epoch [2/50] - Train Loss: 1.1540, Test Loss: 1.1497\n",
      "Epoch [3/50] - Train Loss: 1.1520, Test Loss: 1.1522\n",
      "Epoch [4/50] - Train Loss: 1.1509, Test Loss: 1.1568\n",
      "Epoch [5/50] - Train Loss: 1.1504, Test Loss: 1.1608\n",
      "Epoch [6/50] - Train Loss: 1.1501, Test Loss: 1.1630\n",
      "Epoch [7/50] - Train Loss: 1.1487, Test Loss: 1.1643\n",
      "Epoch [8/50] - Train Loss: 1.1328, Test Loss: 1.1696\n",
      "Epoch [9/50] - Train Loss: 1.0613, Test Loss: 1.3311\n",
      "Epoch [10/50] - Train Loss: 1.1472, Test Loss: 1.2858\n",
      "Epoch [11/50] - Train Loss: 1.0632, Test Loss: 1.2293\n",
      "Epoch [12/50] - Train Loss: 1.0728, Test Loss: 1.2206\n",
      "Epoch [13/50] - Train Loss: 1.0694, Test Loss: 1.1843\n",
      "Epoch [14/50] - Train Loss: 1.0575, Test Loss: 1.1837\n",
      "Epoch [15/50] - Train Loss: 1.0494, Test Loss: 1.1927\n",
      "Epoch [16/50] - Train Loss: 1.0500, Test Loss: 1.1993\n",
      "Epoch [17/50] - Train Loss: 1.0486, Test Loss: 1.2000\n",
      "Epoch [18/50] - Train Loss: 1.0464, Test Loss: 1.1985\n",
      "Epoch [19/50] - Train Loss: 1.0449, Test Loss: 1.1975\n",
      "Epoch [20/50] - Train Loss: 1.0440, Test Loss: 1.1972\n",
      "Epoch [21/50] - Train Loss: 1.0436, Test Loss: 1.1966\n",
      "Epoch [22/50] - Train Loss: 1.0429, Test Loss: 1.1954\n",
      "Epoch [23/50] - Train Loss: 1.0423, Test Loss: 1.1945\n",
      "Epoch [24/50] - Train Loss: 1.0420, Test Loss: 1.1939\n",
      "Epoch [25/50] - Train Loss: 1.0417, Test Loss: 1.1928\n",
      "Epoch [26/50] - Train Loss: 1.0413, Test Loss: 1.1916\n",
      "Epoch [27/50] - Train Loss: 1.0410, Test Loss: 1.1905\n",
      "Epoch [28/50] - Train Loss: 1.0408, Test Loss: 1.1895\n",
      "Epoch [29/50] - Train Loss: 1.0407, Test Loss: 1.1885\n",
      "Epoch [30/50] - Train Loss: 1.0405, Test Loss: 1.1876\n",
      "Epoch [31/50] - Train Loss: 1.0404, Test Loss: 1.1869\n",
      "Epoch [32/50] - Train Loss: 1.0403, Test Loss: 1.1862\n",
      "Epoch [33/50] - Train Loss: 1.0402, Test Loss: 1.1855\n",
      "Epoch [34/50] - Train Loss: 1.0401, Test Loss: 1.1849\n",
      "Epoch [35/50] - Train Loss: 1.0400, Test Loss: 1.1843\n",
      "Epoch [36/50] - Train Loss: 1.0399, Test Loss: 1.1838\n",
      "Epoch [37/50] - Train Loss: 1.0398, Test Loss: 1.1834\n",
      "Epoch [38/50] - Train Loss: 1.0397, Test Loss: 1.1831\n",
      "Epoch [39/50] - Train Loss: 1.0396, Test Loss: 1.1829\n",
      "Epoch [40/50] - Train Loss: 1.0395, Test Loss: 1.1828\n",
      "Epoch [41/50] - Train Loss: 1.0393, Test Loss: 1.1830\n",
      "Epoch [42/50] - Train Loss: 1.0392, Test Loss: 1.1833\n",
      "Epoch [43/50] - Train Loss: 1.0390, Test Loss: 1.1840\n",
      "Epoch [44/50] - Train Loss: 1.0387, Test Loss: 1.1849\n",
      "Epoch [45/50] - Train Loss: 1.0385, Test Loss: 1.1864\n",
      "Epoch [46/50] - Train Loss: 1.0383, Test Loss: 1.1885\n",
      "Epoch [47/50] - Train Loss: 1.0374, Test Loss: 1.1916\n",
      "Epoch [48/50] - Train Loss: 1.0351, Test Loss: 1.1952\n",
      "Epoch [49/50] - Train Loss: 1.0323, Test Loss: 1.2002\n",
      "Epoch [50/50] - Train Loss: 1.0298, Test Loss: 1.2053\n",
      "Avg Test Loss: 1.2053\n",
      "Testing combination: (32, 1, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5394, Test Loss: 1.7679\n",
      "Epoch [2/50] - Train Loss: 1.4972, Test Loss: 1.7418\n",
      "Epoch [3/50] - Train Loss: 1.4855, Test Loss: 1.7334\n",
      "Epoch [4/50] - Train Loss: 1.4843, Test Loss: 1.7348\n",
      "Epoch [5/50] - Train Loss: 1.4870, Test Loss: 1.7390\n",
      "Epoch [6/50] - Train Loss: 1.4883, Test Loss: 1.7434\n",
      "Epoch [7/50] - Train Loss: 1.4873, Test Loss: 1.7467\n",
      "Epoch [8/50] - Train Loss: 1.4829, Test Loss: 1.7488\n",
      "Epoch [9/50] - Train Loss: 1.4688, Test Loss: 1.7554\n",
      "Epoch [10/50] - Train Loss: 1.4481, Test Loss: 1.7836\n",
      "Epoch [11/50] - Train Loss: 1.4675, Test Loss: 1.8168\n",
      "Epoch [12/50] - Train Loss: 1.4397, Test Loss: 1.8421\n",
      "Epoch [13/50] - Train Loss: 1.4414, Test Loss: 1.8512\n",
      "Epoch [14/50] - Train Loss: 1.4362, Test Loss: 1.8482\n",
      "Epoch [15/50] - Train Loss: 1.4313, Test Loss: 1.8485\n",
      "Epoch [16/50] - Train Loss: 1.4309, Test Loss: 1.8523\n",
      "Epoch [17/50] - Train Loss: 1.4310, Test Loss: 1.8520\n",
      "Epoch [18/50] - Train Loss: 1.4311, Test Loss: 1.8511\n",
      "Epoch [19/50] - Train Loss: 1.4308, Test Loss: 1.8600\n",
      "Epoch [20/50] - Train Loss: 1.4296, Test Loss: 1.8623\n",
      "Epoch [21/50] - Train Loss: 1.4289, Test Loss: 1.8634\n",
      "Epoch [22/50] - Train Loss: 1.4288, Test Loss: 1.8668\n",
      "Epoch [23/50] - Train Loss: 1.4286, Test Loss: 1.8705\n",
      "Epoch [24/50] - Train Loss: 1.4285, Test Loss: 1.8733\n",
      "Epoch [25/50] - Train Loss: 1.4284, Test Loss: 1.8755\n",
      "Epoch [26/50] - Train Loss: 1.4282, Test Loss: 1.8773\n",
      "Epoch [27/50] - Train Loss: 1.4282, Test Loss: 1.8787\n",
      "Epoch [28/50] - Train Loss: 1.4280, Test Loss: 1.8796\n",
      "Epoch [29/50] - Train Loss: 1.4278, Test Loss: 1.8809\n",
      "Epoch [30/50] - Train Loss: 1.4276, Test Loss: 1.8835\n",
      "Epoch [31/50] - Train Loss: 1.4272, Test Loss: 1.8878\n",
      "Epoch [32/50] - Train Loss: 1.4266, Test Loss: 1.8938\n",
      "Epoch [33/50] - Train Loss: 1.4257, Test Loss: 1.9057\n",
      "Epoch [34/50] - Train Loss: 1.4231, Test Loss: 1.9150\n",
      "Epoch [35/50] - Train Loss: 1.4196, Test Loss: 1.9148\n",
      "Epoch [36/50] - Train Loss: 1.4173, Test Loss: 1.9077\n",
      "Epoch [37/50] - Train Loss: 1.4139, Test Loss: 1.9092\n",
      "Epoch [38/50] - Train Loss: 1.4120, Test Loss: 1.9173\n",
      "Epoch [39/50] - Train Loss: 1.4137, Test Loss: 1.9119\n",
      "Epoch [40/50] - Train Loss: 1.4103, Test Loss: 1.9122\n",
      "Epoch [41/50] - Train Loss: 1.4107, Test Loss: 1.9118\n",
      "Epoch [42/50] - Train Loss: 1.4113, Test Loss: 1.9147\n",
      "Epoch [43/50] - Train Loss: 1.4112, Test Loss: 1.9199\n",
      "Epoch [44/50] - Train Loss: 1.4086, Test Loss: 1.9246\n",
      "Epoch [45/50] - Train Loss: 1.4078, Test Loss: 1.9192\n",
      "Epoch [46/50] - Train Loss: 1.4082, Test Loss: 1.9542\n",
      "Epoch [47/50] - Train Loss: 1.4042, Test Loss: 1.9072\n",
      "Epoch [48/50] - Train Loss: 1.4028, Test Loss: 1.9261\n",
      "Epoch [49/50] - Train Loss: 1.4086, Test Loss: 2.0157\n",
      "Epoch [50/50] - Train Loss: 1.3810, Test Loss: 1.8489\n",
      "Avg Test Loss: 1.8489\n",
      "Testing combination: (32, 1, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1240, Test Loss: 1.0799\n",
      "Epoch [2/50] - Train Loss: 1.1192, Test Loss: 1.0837\n",
      "Epoch [3/50] - Train Loss: 1.1178, Test Loss: 1.0886\n",
      "Epoch [4/50] - Train Loss: 1.1170, Test Loss: 1.0945\n",
      "Epoch [5/50] - Train Loss: 1.1162, Test Loss: 1.1015\n",
      "Epoch [6/50] - Train Loss: 1.1153, Test Loss: 1.1101\n",
      "Epoch [7/50] - Train Loss: 1.1139, Test Loss: 1.1201\n",
      "Epoch [8/50] - Train Loss: 1.1112, Test Loss: 1.1305\n",
      "Epoch [9/50] - Train Loss: 1.1059, Test Loss: 1.1422\n",
      "Epoch [10/50] - Train Loss: 1.0962, Test Loss: 1.1585\n",
      "Epoch [11/50] - Train Loss: 1.0844, Test Loss: 1.1808\n",
      "Epoch [12/50] - Train Loss: 1.0750, Test Loss: 1.2080\n",
      "Epoch [13/50] - Train Loss: 1.0713, Test Loss: 1.2254\n",
      "Epoch [14/50] - Train Loss: 1.0699, Test Loss: 1.2328\n",
      "Epoch [15/50] - Train Loss: 1.0688, Test Loss: 1.2378\n",
      "Epoch [16/50] - Train Loss: 1.0682, Test Loss: 1.2411\n",
      "Epoch [17/50] - Train Loss: 1.0679, Test Loss: 1.2435\n",
      "Epoch [18/50] - Train Loss: 1.0675, Test Loss: 1.2441\n",
      "Epoch [19/50] - Train Loss: 1.0669, Test Loss: 1.2443\n",
      "Epoch [20/50] - Train Loss: 1.0664, Test Loss: 1.2461\n",
      "Epoch [21/50] - Train Loss: 1.0660, Test Loss: 1.2490\n",
      "Epoch [22/50] - Train Loss: 1.0656, Test Loss: 1.2529\n",
      "Epoch [23/50] - Train Loss: 1.0650, Test Loss: 1.2542\n",
      "Epoch [24/50] - Train Loss: 1.0642, Test Loss: 1.2582\n",
      "Epoch [25/50] - Train Loss: 1.0631, Test Loss: 1.2623\n",
      "Epoch [26/50] - Train Loss: 1.0631, Test Loss: 1.2638\n",
      "Epoch [27/50] - Train Loss: 1.0625, Test Loss: 1.2592\n",
      "Epoch [28/50] - Train Loss: 1.0632, Test Loss: 1.2737\n",
      "Epoch [29/50] - Train Loss: 1.0546, Test Loss: 1.2445\n",
      "Epoch [30/50] - Train Loss: 1.0496, Test Loss: 1.1592\n",
      "Epoch [31/50] - Train Loss: 1.0598, Test Loss: 1.1530\n",
      "Epoch [32/50] - Train Loss: 1.1535, Test Loss: 1.2044\n",
      "Epoch [33/50] - Train Loss: 1.0479, Test Loss: 1.1719\n",
      "Epoch [34/50] - Train Loss: 1.0708, Test Loss: 1.1876\n",
      "Epoch [35/50] - Train Loss: 1.0704, Test Loss: 1.1904\n",
      "Epoch [36/50] - Train Loss: 1.0683, Test Loss: 1.1953\n",
      "Epoch [37/50] - Train Loss: 1.0662, Test Loss: 1.2009\n",
      "Epoch [38/50] - Train Loss: 1.0642, Test Loss: 1.2066\n",
      "Epoch [39/50] - Train Loss: 1.0624, Test Loss: 1.2125\n",
      "Epoch [40/50] - Train Loss: 1.0607, Test Loss: 1.2188\n",
      "Epoch [41/50] - Train Loss: 1.0591, Test Loss: 1.2254\n",
      "Epoch [42/50] - Train Loss: 1.0573, Test Loss: 1.2311\n",
      "Epoch [43/50] - Train Loss: 1.0547, Test Loss: 1.2344\n",
      "Epoch [44/50] - Train Loss: 1.0513, Test Loss: 1.2370\n",
      "Epoch [45/50] - Train Loss: 1.0454, Test Loss: 1.2384\n",
      "Epoch [46/50] - Train Loss: 1.0475, Test Loss: 1.2359\n",
      "Epoch [47/50] - Train Loss: 1.0338, Test Loss: 1.2278\n",
      "Epoch [48/50] - Train Loss: 1.0138, Test Loss: 1.3007\n",
      "Epoch [49/50] - Train Loss: 1.0508, Test Loss: 1.3281\n",
      "Epoch [50/50] - Train Loss: 1.0128, Test Loss: 1.2725\n",
      "Avg Test Loss: 1.2725\n",
      "Testing combination: (32, 1, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1549, Test Loss: 1.1427\n",
      "Epoch [2/50] - Train Loss: 1.1517, Test Loss: 1.1471\n",
      "Epoch [3/50] - Train Loss: 1.1505, Test Loss: 1.1517\n",
      "Epoch [4/50] - Train Loss: 1.1495, Test Loss: 1.1560\n",
      "Epoch [5/50] - Train Loss: 1.1484, Test Loss: 1.1601\n",
      "Epoch [6/50] - Train Loss: 1.1470, Test Loss: 1.1643\n",
      "Epoch [7/50] - Train Loss: 1.1446, Test Loss: 1.1690\n",
      "Epoch [8/50] - Train Loss: 1.1399, Test Loss: 1.1747\n",
      "Epoch [9/50] - Train Loss: 1.1305, Test Loss: 1.1816\n",
      "Epoch [10/50] - Train Loss: 1.1140, Test Loss: 1.1900\n",
      "Epoch [11/50] - Train Loss: 1.0924, Test Loss: 1.1996\n",
      "Epoch [12/50] - Train Loss: 1.0739, Test Loss: 1.2101\n",
      "Epoch [13/50] - Train Loss: 1.0611, Test Loss: 1.2223\n",
      "Epoch [14/50] - Train Loss: 1.0527, Test Loss: 1.2342\n",
      "Epoch [15/50] - Train Loss: 1.0480, Test Loss: 1.2438\n",
      "Epoch [16/50] - Train Loss: 1.0460, Test Loss: 1.2493\n",
      "Epoch [17/50] - Train Loss: 1.0451, Test Loss: 1.2530\n",
      "Epoch [18/50] - Train Loss: 1.0446, Test Loss: 1.2554\n",
      "Epoch [19/50] - Train Loss: 1.0442, Test Loss: 1.2570\n",
      "Epoch [20/50] - Train Loss: 1.0438, Test Loss: 1.2576\n",
      "Epoch [21/50] - Train Loss: 1.0435, Test Loss: 1.2579\n",
      "Epoch [22/50] - Train Loss: 1.0432, Test Loss: 1.2584\n",
      "Epoch [23/50] - Train Loss: 1.0428, Test Loss: 1.2584\n",
      "Epoch [24/50] - Train Loss: 1.0424, Test Loss: 1.2581\n",
      "Epoch [25/50] - Train Loss: 1.0419, Test Loss: 1.2578\n",
      "Epoch [26/50] - Train Loss: 1.0410, Test Loss: 1.2542\n",
      "Epoch [27/50] - Train Loss: 1.0403, Test Loss: 1.2506\n",
      "Epoch [28/50] - Train Loss: 1.0392, Test Loss: 1.2476\n",
      "Epoch [29/50] - Train Loss: 1.0379, Test Loss: 1.2443\n",
      "Epoch [30/50] - Train Loss: 1.0360, Test Loss: 1.2401\n",
      "Epoch [31/50] - Train Loss: 1.0362, Test Loss: 1.2377\n",
      "Epoch [32/50] - Train Loss: 1.0314, Test Loss: 1.2479\n",
      "Epoch [33/50] - Train Loss: 1.0407, Test Loss: 1.2286\n",
      "Epoch [34/50] - Train Loss: 1.0542, Test Loss: 1.3229\n",
      "Epoch [35/50] - Train Loss: 1.0344, Test Loss: 1.2731\n",
      "Epoch [36/50] - Train Loss: 1.0252, Test Loss: 1.2986\n",
      "Epoch [37/50] - Train Loss: 1.0345, Test Loss: 1.2896\n",
      "Epoch [38/50] - Train Loss: 1.0302, Test Loss: 1.2833\n",
      "Epoch [39/50] - Train Loss: 1.0329, Test Loss: 1.2855\n",
      "Epoch [40/50] - Train Loss: 1.0099, Test Loss: 1.2834\n",
      "Epoch [41/50] - Train Loss: 1.0293, Test Loss: 1.2502\n",
      "Epoch [42/50] - Train Loss: 1.0560, Test Loss: 1.3158\n",
      "Epoch [43/50] - Train Loss: 1.0316, Test Loss: 1.2610\n",
      "Epoch [44/50] - Train Loss: 1.0035, Test Loss: 1.3124\n",
      "Epoch [45/50] - Train Loss: 0.9956, Test Loss: 1.2841\n",
      "Epoch [46/50] - Train Loss: 0.9338, Test Loss: 1.3562\n",
      "Epoch [47/50] - Train Loss: 1.0199, Test Loss: 1.2136\n",
      "Epoch [48/50] - Train Loss: 1.0153, Test Loss: 1.3123\n",
      "Epoch [49/50] - Train Loss: 0.9876, Test Loss: 1.2435\n",
      "Epoch [50/50] - Train Loss: 0.9972, Test Loss: 1.2879\n",
      "Avg Test Loss: 1.2879\n",
      "Testing combination: (32, 1, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5323, Test Loss: 1.7784\n",
      "Epoch [2/50] - Train Loss: 1.5206, Test Loss: 1.7673\n",
      "Epoch [3/50] - Train Loss: 1.5116, Test Loss: 1.7575\n",
      "Epoch [4/50] - Train Loss: 1.5043, Test Loss: 1.7497\n",
      "Epoch [5/50] - Train Loss: 1.4985, Test Loss: 1.7438\n",
      "Epoch [6/50] - Train Loss: 1.4941, Test Loss: 1.7396\n",
      "Epoch [7/50] - Train Loss: 1.4908, Test Loss: 1.7367\n",
      "Epoch [8/50] - Train Loss: 1.4884, Test Loss: 1.7352\n",
      "Epoch [9/50] - Train Loss: 1.4866, Test Loss: 1.7344\n",
      "Epoch [10/50] - Train Loss: 1.4854, Test Loss: 1.7342\n",
      "Epoch [11/50] - Train Loss: 1.4844, Test Loss: 1.7345\n",
      "Epoch [12/50] - Train Loss: 1.4837, Test Loss: 1.7351\n",
      "Epoch [13/50] - Train Loss: 1.4831, Test Loss: 1.7358\n",
      "Epoch [14/50] - Train Loss: 1.4823, Test Loss: 1.7367\n",
      "Epoch [15/50] - Train Loss: 1.4814, Test Loss: 1.7377\n",
      "Epoch [16/50] - Train Loss: 1.4800, Test Loss: 1.7388\n",
      "Epoch [17/50] - Train Loss: 1.4780, Test Loss: 1.7400\n",
      "Epoch [18/50] - Train Loss: 1.4750, Test Loss: 1.7411\n",
      "Epoch [19/50] - Train Loss: 1.4706, Test Loss: 1.7422\n",
      "Epoch [20/50] - Train Loss: 1.4643, Test Loss: 1.7430\n",
      "Epoch [21/50] - Train Loss: 1.4570, Test Loss: 1.7427\n",
      "Epoch [22/50] - Train Loss: 1.4504, Test Loss: 1.7419\n",
      "Epoch [23/50] - Train Loss: 1.4453, Test Loss: 1.7416\n",
      "Epoch [24/50] - Train Loss: 1.4407, Test Loss: 1.7430\n",
      "Epoch [25/50] - Train Loss: 1.4362, Test Loss: 1.7460\n",
      "Epoch [26/50] - Train Loss: 1.4318, Test Loss: 1.7503\n",
      "Epoch [27/50] - Train Loss: 1.4281, Test Loss: 1.7555\n",
      "Epoch [28/50] - Train Loss: 1.4257, Test Loss: 1.7614\n",
      "Epoch [29/50] - Train Loss: 1.4242, Test Loss: 1.7673\n",
      "Epoch [30/50] - Train Loss: 1.4234, Test Loss: 1.7721\n",
      "Epoch [31/50] - Train Loss: 1.4229, Test Loss: 1.7752\n",
      "Epoch [32/50] - Train Loss: 1.4225, Test Loss: 1.7775\n",
      "Epoch [33/50] - Train Loss: 1.4219, Test Loss: 1.7790\n",
      "Epoch [34/50] - Train Loss: 1.4213, Test Loss: 1.7798\n",
      "Epoch [35/50] - Train Loss: 1.4206, Test Loss: 1.7802\n",
      "Epoch [36/50] - Train Loss: 1.4200, Test Loss: 1.7803\n",
      "Epoch [37/50] - Train Loss: 1.4195, Test Loss: 1.7802\n",
      "Epoch [38/50] - Train Loss: 1.4190, Test Loss: 1.7801\n",
      "Epoch [39/50] - Train Loss: 1.4186, Test Loss: 1.7802\n",
      "Epoch [40/50] - Train Loss: 1.4182, Test Loss: 1.7806\n",
      "Epoch [41/50] - Train Loss: 1.4178, Test Loss: 1.7810\n",
      "Epoch [42/50] - Train Loss: 1.4175, Test Loss: 1.7816\n",
      "Epoch [43/50] - Train Loss: 1.4172, Test Loss: 1.7823\n",
      "Epoch [44/50] - Train Loss: 1.4169, Test Loss: 1.7830\n",
      "Epoch [45/50] - Train Loss: 1.4166, Test Loss: 1.7837\n",
      "Epoch [46/50] - Train Loss: 1.4163, Test Loss: 1.7844\n",
      "Epoch [47/50] - Train Loss: 1.4160, Test Loss: 1.7851\n",
      "Epoch [48/50] - Train Loss: 1.4157, Test Loss: 1.7858\n",
      "Epoch [49/50] - Train Loss: 1.4153, Test Loss: 1.7865\n",
      "Epoch [50/50] - Train Loss: 1.4150, Test Loss: 1.7871\n",
      "Avg Test Loss: 1.7871\n",
      "Testing combination: (32, 1, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1195, Test Loss: 1.0970\n",
      "Epoch [2/50] - Train Loss: 1.1192, Test Loss: 1.0966\n",
      "Epoch [3/50] - Train Loss: 1.1190, Test Loss: 1.0962\n",
      "Epoch [4/50] - Train Loss: 1.1188, Test Loss: 1.0957\n",
      "Epoch [5/50] - Train Loss: 1.1187, Test Loss: 1.0953\n",
      "Epoch [6/50] - Train Loss: 1.1186, Test Loss: 1.0949\n",
      "Epoch [7/50] - Train Loss: 1.1184, Test Loss: 1.0945\n",
      "Epoch [8/50] - Train Loss: 1.1183, Test Loss: 1.0941\n",
      "Epoch [9/50] - Train Loss: 1.1182, Test Loss: 1.0937\n",
      "Epoch [10/50] - Train Loss: 1.1181, Test Loss: 1.0933\n",
      "Epoch [11/50] - Train Loss: 1.1179, Test Loss: 1.0929\n",
      "Epoch [12/50] - Train Loss: 1.1178, Test Loss: 1.0926\n",
      "Epoch [13/50] - Train Loss: 1.1177, Test Loss: 1.0923\n",
      "Epoch [14/50] - Train Loss: 1.1176, Test Loss: 1.0919\n",
      "Epoch [15/50] - Train Loss: 1.1175, Test Loss: 1.0916\n",
      "Epoch [16/50] - Train Loss: 1.1174, Test Loss: 1.0913\n",
      "Epoch [17/50] - Train Loss: 1.1173, Test Loss: 1.0910\n",
      "Epoch [18/50] - Train Loss: 1.1173, Test Loss: 1.0907\n",
      "Epoch [19/50] - Train Loss: 1.1172, Test Loss: 1.0904\n",
      "Epoch [20/50] - Train Loss: 1.1171, Test Loss: 1.0902\n",
      "Epoch [21/50] - Train Loss: 1.1170, Test Loss: 1.0899\n",
      "Epoch [22/50] - Train Loss: 1.1169, Test Loss: 1.0897\n",
      "Epoch [23/50] - Train Loss: 1.1168, Test Loss: 1.0894\n",
      "Epoch [24/50] - Train Loss: 1.1168, Test Loss: 1.0892\n",
      "Epoch [25/50] - Train Loss: 1.1167, Test Loss: 1.0890\n",
      "Epoch [26/50] - Train Loss: 1.1166, Test Loss: 1.0888\n",
      "Epoch [27/50] - Train Loss: 1.1165, Test Loss: 1.0886\n",
      "Epoch [28/50] - Train Loss: 1.1165, Test Loss: 1.0884\n",
      "Epoch [29/50] - Train Loss: 1.1164, Test Loss: 1.0882\n",
      "Epoch [30/50] - Train Loss: 1.1163, Test Loss: 1.0880\n",
      "Epoch [31/50] - Train Loss: 1.1162, Test Loss: 1.0878\n",
      "Epoch [32/50] - Train Loss: 1.1162, Test Loss: 1.0877\n",
      "Epoch [33/50] - Train Loss: 1.1161, Test Loss: 1.0875\n",
      "Epoch [34/50] - Train Loss: 1.1160, Test Loss: 1.0874\n",
      "Epoch [35/50] - Train Loss: 1.1159, Test Loss: 1.0873\n",
      "Epoch [36/50] - Train Loss: 1.1158, Test Loss: 1.0872\n",
      "Epoch [37/50] - Train Loss: 1.1158, Test Loss: 1.0871\n",
      "Epoch [38/50] - Train Loss: 1.1157, Test Loss: 1.0871\n",
      "Epoch [39/50] - Train Loss: 1.1156, Test Loss: 1.0870\n",
      "Epoch [40/50] - Train Loss: 1.1155, Test Loss: 1.0870\n",
      "Epoch [41/50] - Train Loss: 1.1154, Test Loss: 1.0870\n",
      "Epoch [42/50] - Train Loss: 1.1153, Test Loss: 1.0870\n",
      "Epoch [43/50] - Train Loss: 1.1152, Test Loss: 1.0870\n",
      "Epoch [44/50] - Train Loss: 1.1150, Test Loss: 1.0870\n",
      "Epoch [45/50] - Train Loss: 1.1149, Test Loss: 1.0870\n",
      "Epoch [46/50] - Train Loss: 1.1148, Test Loss: 1.0871\n",
      "Epoch [47/50] - Train Loss: 1.1146, Test Loss: 1.0871\n",
      "Epoch [48/50] - Train Loss: 1.1144, Test Loss: 1.0872\n",
      "Epoch [49/50] - Train Loss: 1.1142, Test Loss: 1.0874\n",
      "Epoch [50/50] - Train Loss: 1.1140, Test Loss: 1.0875\n",
      "Avg Test Loss: 1.0875\n",
      "Testing combination: (32, 1, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1573, Test Loss: 1.2171\n",
      "Epoch [2/50] - Train Loss: 1.1565, Test Loss: 1.2159\n",
      "Epoch [3/50] - Train Loss: 1.1561, Test Loss: 1.2149\n",
      "Epoch [4/50] - Train Loss: 1.1557, Test Loss: 1.2140\n",
      "Epoch [5/50] - Train Loss: 1.1554, Test Loss: 1.2131\n",
      "Epoch [6/50] - Train Loss: 1.1550, Test Loss: 1.2123\n",
      "Epoch [7/50] - Train Loss: 1.1547, Test Loss: 1.2114\n",
      "Epoch [8/50] - Train Loss: 1.1544, Test Loss: 1.2107\n",
      "Epoch [9/50] - Train Loss: 1.1541, Test Loss: 1.2100\n",
      "Epoch [10/50] - Train Loss: 1.1537, Test Loss: 1.2093\n",
      "Epoch [11/50] - Train Loss: 1.1534, Test Loss: 1.2087\n",
      "Epoch [12/50] - Train Loss: 1.1531, Test Loss: 1.2081\n",
      "Epoch [13/50] - Train Loss: 1.1528, Test Loss: 1.2076\n",
      "Epoch [14/50] - Train Loss: 1.1525, Test Loss: 1.2071\n",
      "Epoch [15/50] - Train Loss: 1.1522, Test Loss: 1.2066\n",
      "Epoch [16/50] - Train Loss: 1.1518, Test Loss: 1.2062\n",
      "Epoch [17/50] - Train Loss: 1.1515, Test Loss: 1.2058\n",
      "Epoch [18/50] - Train Loss: 1.1512, Test Loss: 1.2055\n",
      "Epoch [19/50] - Train Loss: 1.1508, Test Loss: 1.2053\n",
      "Epoch [20/50] - Train Loss: 1.1505, Test Loss: 1.2051\n",
      "Epoch [21/50] - Train Loss: 1.1501, Test Loss: 1.2049\n",
      "Epoch [22/50] - Train Loss: 1.1497, Test Loss: 1.2048\n",
      "Epoch [23/50] - Train Loss: 1.1493, Test Loss: 1.2046\n",
      "Epoch [24/50] - Train Loss: 1.1489, Test Loss: 1.2045\n",
      "Epoch [25/50] - Train Loss: 1.1485, Test Loss: 1.2045\n",
      "Epoch [26/50] - Train Loss: 1.1481, Test Loss: 1.2044\n",
      "Epoch [27/50] - Train Loss: 1.1476, Test Loss: 1.2044\n",
      "Epoch [28/50] - Train Loss: 1.1471, Test Loss: 1.2044\n",
      "Epoch [29/50] - Train Loss: 1.1466, Test Loss: 1.2045\n",
      "Epoch [30/50] - Train Loss: 1.1461, Test Loss: 1.2045\n",
      "Epoch [31/50] - Train Loss: 1.1455, Test Loss: 1.2046\n",
      "Epoch [32/50] - Train Loss: 1.1449, Test Loss: 1.2047\n",
      "Epoch [33/50] - Train Loss: 1.1443, Test Loss: 1.2049\n",
      "Epoch [34/50] - Train Loss: 1.1436, Test Loss: 1.2050\n",
      "Epoch [35/50] - Train Loss: 1.1429, Test Loss: 1.2052\n",
      "Epoch [36/50] - Train Loss: 1.1422, Test Loss: 1.2054\n",
      "Epoch [37/50] - Train Loss: 1.1414, Test Loss: 1.2055\n",
      "Epoch [38/50] - Train Loss: 1.1405, Test Loss: 1.2057\n",
      "Epoch [39/50] - Train Loss: 1.1396, Test Loss: 1.2059\n",
      "Epoch [40/50] - Train Loss: 1.1387, Test Loss: 1.2061\n",
      "Epoch [41/50] - Train Loss: 1.1376, Test Loss: 1.2063\n",
      "Epoch [42/50] - Train Loss: 1.1365, Test Loss: 1.2065\n",
      "Epoch [43/50] - Train Loss: 1.1354, Test Loss: 1.2066\n",
      "Epoch [44/50] - Train Loss: 1.1341, Test Loss: 1.2068\n",
      "Epoch [45/50] - Train Loss: 1.1328, Test Loss: 1.2070\n",
      "Epoch [46/50] - Train Loss: 1.1313, Test Loss: 1.2071\n",
      "Epoch [47/50] - Train Loss: 1.1298, Test Loss: 1.2073\n",
      "Epoch [48/50] - Train Loss: 1.1281, Test Loss: 1.2074\n",
      "Epoch [49/50] - Train Loss: 1.1263, Test Loss: 1.2076\n",
      "Epoch [50/50] - Train Loss: 1.1244, Test Loss: 1.2078\n",
      "Avg Test Loss: 1.2078\n",
      "Testing combination: (32, 1, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5272, Test Loss: 1.7875\n",
      "Epoch [2/50] - Train Loss: 1.5263, Test Loss: 1.7866\n",
      "Epoch [3/50] - Train Loss: 1.5255, Test Loss: 1.7856\n",
      "Epoch [4/50] - Train Loss: 1.5247, Test Loss: 1.7847\n",
      "Epoch [5/50] - Train Loss: 1.5238, Test Loss: 1.7838\n",
      "Epoch [6/50] - Train Loss: 1.5230, Test Loss: 1.7828\n",
      "Epoch [7/50] - Train Loss: 1.5222, Test Loss: 1.7820\n",
      "Epoch [8/50] - Train Loss: 1.5214, Test Loss: 1.7812\n",
      "Epoch [9/50] - Train Loss: 1.5206, Test Loss: 1.7804\n",
      "Epoch [10/50] - Train Loss: 1.5198, Test Loss: 1.7796\n",
      "Epoch [11/50] - Train Loss: 1.5191, Test Loss: 1.7788\n",
      "Epoch [12/50] - Train Loss: 1.5183, Test Loss: 1.7781\n",
      "Epoch [13/50] - Train Loss: 1.5176, Test Loss: 1.7775\n",
      "Epoch [14/50] - Train Loss: 1.5168, Test Loss: 1.7768\n",
      "Epoch [15/50] - Train Loss: 1.5161, Test Loss: 1.7762\n",
      "Epoch [16/50] - Train Loss: 1.5154, Test Loss: 1.7757\n",
      "Epoch [17/50] - Train Loss: 1.5147, Test Loss: 1.7751\n",
      "Epoch [18/50] - Train Loss: 1.5140, Test Loss: 1.7746\n",
      "Epoch [19/50] - Train Loss: 1.5133, Test Loss: 1.7741\n",
      "Epoch [20/50] - Train Loss: 1.5127, Test Loss: 1.7737\n",
      "Epoch [21/50] - Train Loss: 1.5120, Test Loss: 1.7733\n",
      "Epoch [22/50] - Train Loss: 1.5113, Test Loss: 1.7729\n",
      "Epoch [23/50] - Train Loss: 1.5107, Test Loss: 1.7726\n",
      "Epoch [24/50] - Train Loss: 1.5101, Test Loss: 1.7722\n",
      "Epoch [25/50] - Train Loss: 1.5094, Test Loss: 1.7719\n",
      "Epoch [26/50] - Train Loss: 1.5088, Test Loss: 1.7716\n",
      "Epoch [27/50] - Train Loss: 1.5082, Test Loss: 1.7713\n",
      "Epoch [28/50] - Train Loss: 1.5076, Test Loss: 1.7711\n",
      "Epoch [29/50] - Train Loss: 1.5070, Test Loss: 1.7709\n",
      "Epoch [30/50] - Train Loss: 1.5064, Test Loss: 1.7707\n",
      "Epoch [31/50] - Train Loss: 1.5058, Test Loss: 1.7705\n",
      "Epoch [32/50] - Train Loss: 1.5053, Test Loss: 1.7704\n",
      "Epoch [33/50] - Train Loss: 1.5047, Test Loss: 1.7703\n",
      "Epoch [34/50] - Train Loss: 1.5042, Test Loss: 1.7703\n",
      "Epoch [35/50] - Train Loss: 1.5036, Test Loss: 1.7704\n",
      "Epoch [36/50] - Train Loss: 1.5031, Test Loss: 1.7704\n",
      "Epoch [37/50] - Train Loss: 1.5025, Test Loss: 1.7705\n",
      "Epoch [38/50] - Train Loss: 1.5020, Test Loss: 1.7707\n",
      "Epoch [39/50] - Train Loss: 1.5015, Test Loss: 1.7709\n",
      "Epoch [40/50] - Train Loss: 1.5010, Test Loss: 1.7711\n",
      "Epoch [41/50] - Train Loss: 1.5005, Test Loss: 1.7714\n",
      "Epoch [42/50] - Train Loss: 1.5000, Test Loss: 1.7717\n",
      "Epoch [43/50] - Train Loss: 1.4995, Test Loss: 1.7720\n",
      "Epoch [44/50] - Train Loss: 1.4990, Test Loss: 1.7724\n",
      "Epoch [45/50] - Train Loss: 1.4985, Test Loss: 1.7728\n",
      "Epoch [46/50] - Train Loss: 1.4980, Test Loss: 1.7732\n",
      "Epoch [47/50] - Train Loss: 1.4975, Test Loss: 1.7737\n",
      "Epoch [48/50] - Train Loss: 1.4970, Test Loss: 1.7742\n",
      "Epoch [49/50] - Train Loss: 1.4966, Test Loss: 1.7747\n",
      "Epoch [50/50] - Train Loss: 1.4961, Test Loss: 1.7753\n",
      "Avg Test Loss: 1.7753\n",
      "Testing combination: (32, 2, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1487, Test Loss: 1.0820\n",
      "Epoch [2/50] - Train Loss: 1.1193, Test Loss: 1.0862\n",
      "Epoch [3/50] - Train Loss: 1.1157, Test Loss: 1.0923\n",
      "Epoch [4/50] - Train Loss: 1.0986, Test Loss: 1.1299\n",
      "Epoch [5/50] - Train Loss: 1.1812, Test Loss: 1.0944\n",
      "Epoch [6/50] - Train Loss: 1.1022, Test Loss: 1.1012\n",
      "Epoch [7/50] - Train Loss: 1.0881, Test Loss: 1.1258\n",
      "Epoch [8/50] - Train Loss: 1.0717, Test Loss: 1.1723\n",
      "Epoch [9/50] - Train Loss: 1.0724, Test Loss: 1.2070\n",
      "Epoch [10/50] - Train Loss: 1.0714, Test Loss: 1.2199\n",
      "Epoch [11/50] - Train Loss: 1.0667, Test Loss: 1.2183\n",
      "Epoch [12/50] - Train Loss: 1.0654, Test Loss: 1.2133\n",
      "Epoch [13/50] - Train Loss: 1.0658, Test Loss: 1.2137\n",
      "Epoch [14/50] - Train Loss: 1.0633, Test Loss: 1.2196\n",
      "Epoch [15/50] - Train Loss: 1.0637, Test Loss: 1.2204\n",
      "Epoch [16/50] - Train Loss: 1.0638, Test Loss: 1.2157\n",
      "Epoch [17/50] - Train Loss: 1.0648, Test Loss: 1.2133\n",
      "Epoch [18/50] - Train Loss: 1.0618, Test Loss: 1.2174\n",
      "Epoch [19/50] - Train Loss: 1.0627, Test Loss: 1.2206\n",
      "Epoch [20/50] - Train Loss: 1.0641, Test Loss: 1.2141\n",
      "Epoch [21/50] - Train Loss: 1.0610, Test Loss: 1.2170\n",
      "Epoch [22/50] - Train Loss: 1.0623, Test Loss: 1.2202\n",
      "Epoch [23/50] - Train Loss: 1.0629, Test Loss: 1.2137\n",
      "Epoch [24/50] - Train Loss: 1.0606, Test Loss: 1.2169\n",
      "Epoch [25/50] - Train Loss: 1.0635, Test Loss: 1.2175\n",
      "Epoch [26/50] - Train Loss: 1.0598, Test Loss: 1.2158\n",
      "Epoch [27/50] - Train Loss: 1.0621, Test Loss: 1.2145\n",
      "Epoch [28/50] - Train Loss: 1.0601, Test Loss: 1.2146\n",
      "Epoch [29/50] - Train Loss: 1.0825, Test Loss: 1.1285\n",
      "Epoch [30/50] - Train Loss: 1.1230, Test Loss: 1.0856\n",
      "Epoch [31/50] - Train Loss: 1.1210, Test Loss: 1.1158\n",
      "Epoch [32/50] - Train Loss: 1.1029, Test Loss: 1.1680\n",
      "Epoch [33/50] - Train Loss: 1.0831, Test Loss: 1.1646\n",
      "Epoch [34/50] - Train Loss: 1.1444, Test Loss: 1.1368\n",
      "Epoch [35/50] - Train Loss: 1.0940, Test Loss: 1.1494\n",
      "Epoch [36/50] - Train Loss: 1.0793, Test Loss: 1.1583\n",
      "Epoch [37/50] - Train Loss: 1.0698, Test Loss: 1.1942\n",
      "Epoch [38/50] - Train Loss: 1.0691, Test Loss: 1.2035\n",
      "Epoch [39/50] - Train Loss: 1.0639, Test Loss: 1.2029\n",
      "Epoch [40/50] - Train Loss: 1.0638, Test Loss: 1.2007\n",
      "Epoch [41/50] - Train Loss: 1.0618, Test Loss: 1.2045\n",
      "Epoch [42/50] - Train Loss: 1.0617, Test Loss: 1.2056\n",
      "Epoch [43/50] - Train Loss: 1.0596, Test Loss: 1.2036\n",
      "Epoch [44/50] - Train Loss: 1.0599, Test Loss: 1.2028\n",
      "Epoch [45/50] - Train Loss: 1.0593, Test Loss: 1.2026\n",
      "Epoch [46/50] - Train Loss: 1.0593, Test Loss: 1.2023\n",
      "Epoch [47/50] - Train Loss: 1.0594, Test Loss: 1.2011\n",
      "Epoch [48/50] - Train Loss: 1.0647, Test Loss: 1.1986\n",
      "Epoch [49/50] - Train Loss: 1.0613, Test Loss: 1.2026\n",
      "Epoch [50/50] - Train Loss: 1.0625, Test Loss: 1.2117\n",
      "Avg Test Loss: 1.2117\n",
      "Testing combination: (32, 2, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.2110, Test Loss: 1.1389\n",
      "Epoch [2/50] - Train Loss: 1.1560, Test Loss: 1.1402\n",
      "Epoch [3/50] - Train Loss: 1.1528, Test Loss: 1.1490\n",
      "Epoch [4/50] - Train Loss: 1.1481, Test Loss: 1.1614\n",
      "Epoch [5/50] - Train Loss: 1.1259, Test Loss: 1.1900\n",
      "Epoch [6/50] - Train Loss: 1.0685, Test Loss: 1.2510\n",
      "Epoch [7/50] - Train Loss: 1.1701, Test Loss: 1.1988\n",
      "Epoch [8/50] - Train Loss: 1.0768, Test Loss: 1.1986\n",
      "Epoch [9/50] - Train Loss: 1.0542, Test Loss: 1.2322\n",
      "Epoch [10/50] - Train Loss: 1.0546, Test Loss: 1.2960\n",
      "Epoch [11/50] - Train Loss: 1.0494, Test Loss: 1.2582\n",
      "Epoch [12/50] - Train Loss: 1.0487, Test Loss: 1.2470\n",
      "Epoch [13/50] - Train Loss: 1.0477, Test Loss: 1.2581\n",
      "Epoch [14/50] - Train Loss: 1.0477, Test Loss: 1.2669\n",
      "Epoch [15/50] - Train Loss: 1.0476, Test Loss: 1.2650\n",
      "Epoch [16/50] - Train Loss: 1.0475, Test Loss: 1.2618\n",
      "Epoch [17/50] - Train Loss: 1.0474, Test Loss: 1.2627\n",
      "Epoch [18/50] - Train Loss: 1.0473, Test Loss: 1.2641\n",
      "Epoch [19/50] - Train Loss: 1.0473, Test Loss: 1.2636\n",
      "Epoch [20/50] - Train Loss: 1.0472, Test Loss: 1.2628\n",
      "Epoch [21/50] - Train Loss: 1.0472, Test Loss: 1.2629\n",
      "Epoch [22/50] - Train Loss: 1.0472, Test Loss: 1.2630\n",
      "Epoch [23/50] - Train Loss: 1.0471, Test Loss: 1.2628\n",
      "Epoch [24/50] - Train Loss: 1.0471, Test Loss: 1.2625\n",
      "Epoch [25/50] - Train Loss: 1.0471, Test Loss: 1.2625\n",
      "Epoch [26/50] - Train Loss: 1.0470, Test Loss: 1.2624\n",
      "Epoch [27/50] - Train Loss: 1.0470, Test Loss: 1.2622\n",
      "Epoch [28/50] - Train Loss: 1.0470, Test Loss: 1.2620\n",
      "Epoch [29/50] - Train Loss: 1.0470, Test Loss: 1.2619\n",
      "Epoch [30/50] - Train Loss: 1.0469, Test Loss: 1.2618\n",
      "Epoch [31/50] - Train Loss: 1.0469, Test Loss: 1.2616\n",
      "Epoch [32/50] - Train Loss: 1.0469, Test Loss: 1.2615\n",
      "Epoch [33/50] - Train Loss: 1.0469, Test Loss: 1.2614\n",
      "Epoch [34/50] - Train Loss: 1.0468, Test Loss: 1.2612\n",
      "Epoch [35/50] - Train Loss: 1.0468, Test Loss: 1.2611\n",
      "Epoch [36/50] - Train Loss: 1.0468, Test Loss: 1.2610\n",
      "Epoch [37/50] - Train Loss: 1.0468, Test Loss: 1.2608\n",
      "Epoch [38/50] - Train Loss: 1.0468, Test Loss: 1.2607\n",
      "Epoch [39/50] - Train Loss: 1.0467, Test Loss: 1.2606\n",
      "Epoch [40/50] - Train Loss: 1.0467, Test Loss: 1.2605\n",
      "Epoch [41/50] - Train Loss: 1.0467, Test Loss: 1.2603\n",
      "Epoch [42/50] - Train Loss: 1.0467, Test Loss: 1.2602\n",
      "Epoch [43/50] - Train Loss: 1.0467, Test Loss: 1.2601\n",
      "Epoch [44/50] - Train Loss: 1.0466, Test Loss: 1.2600\n",
      "Epoch [45/50] - Train Loss: 1.0466, Test Loss: 1.2598\n",
      "Epoch [46/50] - Train Loss: 1.0466, Test Loss: 1.2597\n",
      "Epoch [47/50] - Train Loss: 1.0466, Test Loss: 1.2596\n",
      "Epoch [48/50] - Train Loss: 1.0466, Test Loss: 1.2595\n",
      "Epoch [49/50] - Train Loss: 1.0465, Test Loss: 1.2593\n",
      "Epoch [50/50] - Train Loss: 1.0465, Test Loss: 1.2592\n",
      "Avg Test Loss: 1.2592\n",
      "Testing combination: (32, 2, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5490, Test Loss: 1.7579\n",
      "Epoch [2/50] - Train Loss: 1.4928, Test Loss: 1.7365\n",
      "Epoch [3/50] - Train Loss: 1.4842, Test Loss: 1.7362\n",
      "Epoch [4/50] - Train Loss: 1.4828, Test Loss: 1.7492\n",
      "Epoch [5/50] - Train Loss: 1.4744, Test Loss: 1.7779\n",
      "Epoch [6/50] - Train Loss: 1.4497, Test Loss: 1.8774\n",
      "Epoch [7/50] - Train Loss: 1.6504, Test Loss: 1.8187\n",
      "Epoch [8/50] - Train Loss: 1.4629, Test Loss: 1.7851\n",
      "Epoch [9/50] - Train Loss: 1.4702, Test Loss: 1.7754\n",
      "Epoch [10/50] - Train Loss: 1.4659, Test Loss: 1.7726\n",
      "Epoch [11/50] - Train Loss: 1.4600, Test Loss: 1.7774\n",
      "Epoch [12/50] - Train Loss: 1.4525, Test Loss: 1.7950\n",
      "Epoch [13/50] - Train Loss: 1.4415, Test Loss: 1.8375\n",
      "Epoch [14/50] - Train Loss: 1.4302, Test Loss: 1.9058\n",
      "Epoch [15/50] - Train Loss: 1.4232, Test Loss: 1.9562\n",
      "Epoch [16/50] - Train Loss: 1.4251, Test Loss: 1.9776\n",
      "Epoch [17/50] - Train Loss: 1.4159, Test Loss: 1.9824\n",
      "Epoch [18/50] - Train Loss: 1.4144, Test Loss: 1.9805\n",
      "Epoch [19/50] - Train Loss: 1.4154, Test Loss: 1.9776\n",
      "Epoch [20/50] - Train Loss: 1.4124, Test Loss: 1.9798\n",
      "Epoch [21/50] - Train Loss: 1.4135, Test Loss: 1.9862\n",
      "Epoch [22/50] - Train Loss: 1.4132, Test Loss: 1.9854\n",
      "Epoch [23/50] - Train Loss: 1.4110, Test Loss: 1.9873\n",
      "Epoch [24/50] - Train Loss: 1.4125, Test Loss: 1.9867\n",
      "Epoch [25/50] - Train Loss: 1.4126, Test Loss: 1.9726\n",
      "Epoch [26/50] - Train Loss: 1.4094, Test Loss: 1.9612\n",
      "Epoch [27/50] - Train Loss: 1.4111, Test Loss: 1.9757\n",
      "Epoch [28/50] - Train Loss: 1.4119, Test Loss: 1.9478\n",
      "Epoch [29/50] - Train Loss: 1.4062, Test Loss: 1.9424\n",
      "Epoch [30/50] - Train Loss: 1.4075, Test Loss: 1.9701\n",
      "Epoch [31/50] - Train Loss: 1.4084, Test Loss: 1.9612\n",
      "Epoch [32/50] - Train Loss: 1.4004, Test Loss: 1.9847\n",
      "Epoch [33/50] - Train Loss: 1.3974, Test Loss: 1.9581\n",
      "Epoch [34/50] - Train Loss: 1.4060, Test Loss: 1.9933\n",
      "Epoch [35/50] - Train Loss: 1.4084, Test Loss: 1.9466\n",
      "Epoch [36/50] - Train Loss: 1.4088, Test Loss: 1.9346\n",
      "Epoch [37/50] - Train Loss: 1.4119, Test Loss: 1.9317\n",
      "Epoch [38/50] - Train Loss: 1.4065, Test Loss: 2.0497\n",
      "Epoch [39/50] - Train Loss: 1.3959, Test Loss: 1.9081\n",
      "Epoch [40/50] - Train Loss: 1.4187, Test Loss: 1.9236\n",
      "Epoch [41/50] - Train Loss: 1.4192, Test Loss: 1.9197\n",
      "Epoch [42/50] - Train Loss: 1.4147, Test Loss: 1.9134\n",
      "Epoch [43/50] - Train Loss: 1.4146, Test Loss: 1.9028\n",
      "Epoch [44/50] - Train Loss: 1.4137, Test Loss: 1.8857\n",
      "Epoch [45/50] - Train Loss: 1.4096, Test Loss: 1.9080\n",
      "Epoch [46/50] - Train Loss: 1.4039, Test Loss: 2.0218\n",
      "Epoch [47/50] - Train Loss: 1.3902, Test Loss: 1.8916\n",
      "Epoch [48/50] - Train Loss: 1.3972, Test Loss: 1.8989\n",
      "Epoch [49/50] - Train Loss: 1.4058, Test Loss: 1.9067\n",
      "Epoch [50/50] - Train Loss: 1.3951, Test Loss: 1.9400\n",
      "Avg Test Loss: 1.9400\n",
      "Testing combination: (32, 2, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1399, Test Loss: 1.1263\n",
      "Epoch [2/50] - Train Loss: 1.1272, Test Loss: 1.1103\n",
      "Epoch [3/50] - Train Loss: 1.1208, Test Loss: 1.0998\n",
      "Epoch [4/50] - Train Loss: 1.1176, Test Loss: 1.0938\n",
      "Epoch [5/50] - Train Loss: 1.1163, Test Loss: 1.0913\n",
      "Epoch [6/50] - Train Loss: 1.1158, Test Loss: 1.0910\n",
      "Epoch [7/50] - Train Loss: 1.1153, Test Loss: 1.0922\n",
      "Epoch [8/50] - Train Loss: 1.1145, Test Loss: 1.0941\n",
      "Epoch [9/50] - Train Loss: 1.1131, Test Loss: 1.0962\n",
      "Epoch [10/50] - Train Loss: 1.1107, Test Loss: 1.0990\n",
      "Epoch [11/50] - Train Loss: 1.1067, Test Loss: 1.1031\n",
      "Epoch [12/50] - Train Loss: 1.1010, Test Loss: 1.1095\n",
      "Epoch [13/50] - Train Loss: 1.0936, Test Loss: 1.1192\n",
      "Epoch [14/50] - Train Loss: 1.0856, Test Loss: 1.1343\n",
      "Epoch [15/50] - Train Loss: 1.0781, Test Loss: 1.1590\n",
      "Epoch [16/50] - Train Loss: 1.0737, Test Loss: 1.1905\n",
      "Epoch [17/50] - Train Loss: 1.0736, Test Loss: 1.2121\n",
      "Epoch [18/50] - Train Loss: 1.0729, Test Loss: 1.2223\n",
      "Epoch [19/50] - Train Loss: 1.0717, Test Loss: 1.2286\n",
      "Epoch [20/50] - Train Loss: 1.0707, Test Loss: 1.2343\n",
      "Epoch [21/50] - Train Loss: 1.0699, Test Loss: 1.2387\n",
      "Epoch [22/50] - Train Loss: 1.0691, Test Loss: 1.2416\n",
      "Epoch [23/50] - Train Loss: 1.0684, Test Loss: 1.2439\n",
      "Epoch [24/50] - Train Loss: 1.0677, Test Loss: 1.2464\n",
      "Epoch [25/50] - Train Loss: 1.0671, Test Loss: 1.2492\n",
      "Epoch [26/50] - Train Loss: 1.0666, Test Loss: 1.2516\n",
      "Epoch [27/50] - Train Loss: 1.0660, Test Loss: 1.2535\n",
      "Epoch [28/50] - Train Loss: 1.0654, Test Loss: 1.2548\n",
      "Epoch [29/50] - Train Loss: 1.0649, Test Loss: 1.2555\n",
      "Epoch [30/50] - Train Loss: 1.0642, Test Loss: 1.2559\n",
      "Epoch [31/50] - Train Loss: 1.0636, Test Loss: 1.2558\n",
      "Epoch [32/50] - Train Loss: 1.0628, Test Loss: 1.2556\n",
      "Epoch [33/50] - Train Loss: 1.0618, Test Loss: 1.2547\n",
      "Epoch [34/50] - Train Loss: 1.0543, Test Loss: 1.2648\n",
      "Epoch [35/50] - Train Loss: 1.0329, Test Loss: 1.2131\n",
      "Epoch [36/50] - Train Loss: 1.0572, Test Loss: 1.1288\n",
      "Epoch [37/50] - Train Loss: 1.1026, Test Loss: 1.1434\n",
      "Epoch [38/50] - Train Loss: 1.0732, Test Loss: 1.1745\n",
      "Epoch [39/50] - Train Loss: 1.0685, Test Loss: 1.1849\n",
      "Epoch [40/50] - Train Loss: 1.0541, Test Loss: 1.1941\n",
      "Epoch [41/50] - Train Loss: 1.0592, Test Loss: 1.2011\n",
      "Epoch [42/50] - Train Loss: 1.1463, Test Loss: 1.1730\n",
      "Epoch [43/50] - Train Loss: 1.1048, Test Loss: 1.0987\n",
      "Epoch [44/50] - Train Loss: 1.1196, Test Loss: 1.0971\n",
      "Epoch [45/50] - Train Loss: 1.1114, Test Loss: 1.1019\n",
      "Epoch [46/50] - Train Loss: 1.1060, Test Loss: 1.1081\n",
      "Epoch [47/50] - Train Loss: 1.1016, Test Loss: 1.1148\n",
      "Epoch [48/50] - Train Loss: 1.0971, Test Loss: 1.1224\n",
      "Epoch [49/50] - Train Loss: 1.0921, Test Loss: 1.1322\n",
      "Epoch [50/50] - Train Loss: 1.0859, Test Loss: 1.1456\n",
      "Avg Test Loss: 1.1456\n",
      "Testing combination: (32, 2, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.2267, Test Loss: 1.1260\n",
      "Epoch [2/50] - Train Loss: 1.2045, Test Loss: 1.1230\n",
      "Epoch [3/50] - Train Loss: 1.1888, Test Loss: 1.1234\n",
      "Epoch [4/50] - Train Loss: 1.1750, Test Loss: 1.1275\n",
      "Epoch [5/50] - Train Loss: 1.1616, Test Loss: 1.1364\n",
      "Epoch [6/50] - Train Loss: 1.1479, Test Loss: 1.1514\n",
      "Epoch [7/50] - Train Loss: 1.1335, Test Loss: 1.1722\n",
      "Epoch [8/50] - Train Loss: 1.1202, Test Loss: 1.1948\n",
      "Epoch [9/50] - Train Loss: 1.1082, Test Loss: 1.2102\n",
      "Epoch [10/50] - Train Loss: 1.0941, Test Loss: 1.2157\n",
      "Epoch [11/50] - Train Loss: 1.0779, Test Loss: 1.2187\n",
      "Epoch [12/50] - Train Loss: 1.0641, Test Loss: 1.2258\n",
      "Epoch [13/50] - Train Loss: 1.0543, Test Loss: 1.2383\n",
      "Epoch [14/50] - Train Loss: 1.0497, Test Loss: 1.2522\n",
      "Epoch [15/50] - Train Loss: 1.0484, Test Loss: 1.2631\n",
      "Epoch [16/50] - Train Loss: 1.0475, Test Loss: 1.2706\n",
      "Epoch [17/50] - Train Loss: 1.0465, Test Loss: 1.2760\n",
      "Epoch [18/50] - Train Loss: 1.0458, Test Loss: 1.2809\n",
      "Epoch [19/50] - Train Loss: 1.0452, Test Loss: 1.2854\n",
      "Epoch [20/50] - Train Loss: 1.0447, Test Loss: 1.2890\n",
      "Epoch [21/50] - Train Loss: 1.0441, Test Loss: 1.2913\n",
      "Epoch [22/50] - Train Loss: 1.0436, Test Loss: 1.2923\n",
      "Epoch [23/50] - Train Loss: 1.0430, Test Loss: 1.2924\n",
      "Epoch [24/50] - Train Loss: 1.0423, Test Loss: 1.2920\n",
      "Epoch [25/50] - Train Loss: 1.0415, Test Loss: 1.2914\n",
      "Epoch [26/50] - Train Loss: 1.0406, Test Loss: 1.2909\n",
      "Epoch [27/50] - Train Loss: 1.0396, Test Loss: 1.2901\n",
      "Epoch [28/50] - Train Loss: 1.0383, Test Loss: 1.2891\n",
      "Epoch [29/50] - Train Loss: 1.0367, Test Loss: 1.2880\n",
      "Epoch [30/50] - Train Loss: 1.0346, Test Loss: 1.2845\n",
      "Epoch [31/50] - Train Loss: 1.0325, Test Loss: 1.2801\n",
      "Epoch [32/50] - Train Loss: 1.0305, Test Loss: 1.2793\n",
      "Epoch [33/50] - Train Loss: 1.0476, Test Loss: 1.2534\n",
      "Epoch [34/50] - Train Loss: 1.0590, Test Loss: 1.2501\n",
      "Epoch [35/50] - Train Loss: 1.0423, Test Loss: 1.2748\n",
      "Epoch [36/50] - Train Loss: 1.0368, Test Loss: 1.3057\n",
      "Epoch [37/50] - Train Loss: 1.0240, Test Loss: 1.3451\n",
      "Epoch [38/50] - Train Loss: 0.9955, Test Loss: 1.2649\n",
      "Epoch [39/50] - Train Loss: 1.0148, Test Loss: 1.3198\n",
      "Epoch [40/50] - Train Loss: 0.9881, Test Loss: 1.2232\n",
      "Epoch [41/50] - Train Loss: 0.9549, Test Loss: 1.3899\n",
      "Epoch [42/50] - Train Loss: 1.0117, Test Loss: 1.2485\n",
      "Epoch [43/50] - Train Loss: 1.0555, Test Loss: 1.2458\n",
      "Epoch [44/50] - Train Loss: 1.0540, Test Loss: 1.2625\n",
      "Epoch [45/50] - Train Loss: 1.0456, Test Loss: 1.2766\n",
      "Epoch [46/50] - Train Loss: 1.0387, Test Loss: 1.2883\n",
      "Epoch [47/50] - Train Loss: 1.0337, Test Loss: 1.2967\n",
      "Epoch [48/50] - Train Loss: 1.0294, Test Loss: 1.2953\n",
      "Epoch [49/50] - Train Loss: 1.0179, Test Loss: 1.2941\n",
      "Epoch [50/50] - Train Loss: 1.0024, Test Loss: 1.2975\n",
      "Avg Test Loss: 1.2975\n",
      "Testing combination: (32, 2, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5064, Test Loss: 1.7522\n",
      "Epoch [2/50] - Train Loss: 1.4988, Test Loss: 1.7476\n",
      "Epoch [3/50] - Train Loss: 1.4944, Test Loss: 1.7435\n",
      "Epoch [4/50] - Train Loss: 1.4911, Test Loss: 1.7406\n",
      "Epoch [5/50] - Train Loss: 1.4886, Test Loss: 1.7388\n",
      "Epoch [6/50] - Train Loss: 1.4869, Test Loss: 1.7381\n",
      "Epoch [7/50] - Train Loss: 1.4857, Test Loss: 1.7381\n",
      "Epoch [8/50] - Train Loss: 1.4850, Test Loss: 1.7389\n",
      "Epoch [9/50] - Train Loss: 1.4845, Test Loss: 1.7401\n",
      "Epoch [10/50] - Train Loss: 1.4842, Test Loss: 1.7417\n",
      "Epoch [11/50] - Train Loss: 1.4839, Test Loss: 1.7438\n",
      "Epoch [12/50] - Train Loss: 1.4836, Test Loss: 1.7463\n",
      "Epoch [13/50] - Train Loss: 1.4831, Test Loss: 1.7494\n",
      "Epoch [14/50] - Train Loss: 1.4825, Test Loss: 1.7530\n",
      "Epoch [15/50] - Train Loss: 1.4815, Test Loss: 1.7571\n",
      "Epoch [16/50] - Train Loss: 1.4801, Test Loss: 1.7622\n",
      "Epoch [17/50] - Train Loss: 1.4780, Test Loss: 1.7685\n",
      "Epoch [18/50] - Train Loss: 1.4748, Test Loss: 1.7768\n",
      "Epoch [19/50] - Train Loss: 1.4700, Test Loss: 1.7883\n",
      "Epoch [20/50] - Train Loss: 1.4635, Test Loss: 1.8044\n",
      "Epoch [21/50] - Train Loss: 1.4555, Test Loss: 1.8274\n",
      "Epoch [22/50] - Train Loss: 1.4461, Test Loss: 1.8596\n",
      "Epoch [23/50] - Train Loss: 1.4356, Test Loss: 1.9027\n",
      "Epoch [24/50] - Train Loss: 1.4262, Test Loss: 1.9545\n",
      "Epoch [25/50] - Train Loss: 1.4223, Test Loss: 2.0038\n",
      "Epoch [26/50] - Train Loss: 1.4213, Test Loss: 2.0358\n",
      "Epoch [27/50] - Train Loss: 1.4200, Test Loss: 2.0540\n",
      "Epoch [28/50] - Train Loss: 1.4198, Test Loss: 2.0654\n",
      "Epoch [29/50] - Train Loss: 1.4199, Test Loss: 2.0740\n",
      "Epoch [30/50] - Train Loss: 1.4197, Test Loss: 2.0817\n",
      "Epoch [31/50] - Train Loss: 1.4191, Test Loss: 2.0891\n",
      "Epoch [32/50] - Train Loss: 1.4185, Test Loss: 2.0960\n",
      "Epoch [33/50] - Train Loss: 1.4180, Test Loss: 2.1017\n",
      "Epoch [34/50] - Train Loss: 1.4173, Test Loss: 2.1062\n",
      "Epoch [35/50] - Train Loss: 1.4165, Test Loss: 2.1102\n",
      "Epoch [36/50] - Train Loss: 1.4158, Test Loss: 2.1149\n",
      "Epoch [37/50] - Train Loss: 1.4151, Test Loss: 2.1208\n",
      "Epoch [38/50] - Train Loss: 1.4146, Test Loss: 2.1274\n",
      "Epoch [39/50] - Train Loss: 1.4142, Test Loss: 2.1338\n",
      "Epoch [40/50] - Train Loss: 1.4137, Test Loss: 2.1394\n",
      "Epoch [41/50] - Train Loss: 1.4133, Test Loss: 2.1439\n",
      "Epoch [42/50] - Train Loss: 1.4129, Test Loss: 2.1476\n",
      "Epoch [43/50] - Train Loss: 1.4124, Test Loss: 2.1508\n",
      "Epoch [44/50] - Train Loss: 1.4120, Test Loss: 2.1542\n",
      "Epoch [45/50] - Train Loss: 1.4115, Test Loss: 2.1580\n",
      "Epoch [46/50] - Train Loss: 1.4110, Test Loss: 2.1621\n",
      "Epoch [47/50] - Train Loss: 1.4105, Test Loss: 2.1662\n",
      "Epoch [48/50] - Train Loss: 1.4099, Test Loss: 2.1702\n",
      "Epoch [49/50] - Train Loss: 1.4093, Test Loss: 2.1738\n",
      "Epoch [50/50] - Train Loss: 1.4086, Test Loss: 2.1770\n",
      "Avg Test Loss: 2.1770\n",
      "Testing combination: (32, 2, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1248, Test Loss: 1.1113\n",
      "Epoch [2/50] - Train Loss: 1.1241, Test Loss: 1.1104\n",
      "Epoch [3/50] - Train Loss: 1.1236, Test Loss: 1.1095\n",
      "Epoch [4/50] - Train Loss: 1.1231, Test Loss: 1.1087\n",
      "Epoch [5/50] - Train Loss: 1.1226, Test Loss: 1.1079\n",
      "Epoch [6/50] - Train Loss: 1.1222, Test Loss: 1.1071\n",
      "Epoch [7/50] - Train Loss: 1.1217, Test Loss: 1.1063\n",
      "Epoch [8/50] - Train Loss: 1.1213, Test Loss: 1.1056\n",
      "Epoch [9/50] - Train Loss: 1.1210, Test Loss: 1.1049\n",
      "Epoch [10/50] - Train Loss: 1.1206, Test Loss: 1.1043\n",
      "Epoch [11/50] - Train Loss: 1.1203, Test Loss: 1.1037\n",
      "Epoch [12/50] - Train Loss: 1.1199, Test Loss: 1.1031\n",
      "Epoch [13/50] - Train Loss: 1.1196, Test Loss: 1.1026\n",
      "Epoch [14/50] - Train Loss: 1.1193, Test Loss: 1.1021\n",
      "Epoch [15/50] - Train Loss: 1.1190, Test Loss: 1.1016\n",
      "Epoch [16/50] - Train Loss: 1.1188, Test Loss: 1.1011\n",
      "Epoch [17/50] - Train Loss: 1.1185, Test Loss: 1.1007\n",
      "Epoch [18/50] - Train Loss: 1.1183, Test Loss: 1.1003\n",
      "Epoch [19/50] - Train Loss: 1.1180, Test Loss: 1.1000\n",
      "Epoch [20/50] - Train Loss: 1.1178, Test Loss: 1.0996\n",
      "Epoch [21/50] - Train Loss: 1.1175, Test Loss: 1.0993\n",
      "Epoch [22/50] - Train Loss: 1.1173, Test Loss: 1.0991\n",
      "Epoch [23/50] - Train Loss: 1.1171, Test Loss: 1.0988\n",
      "Epoch [24/50] - Train Loss: 1.1169, Test Loss: 1.0986\n",
      "Epoch [25/50] - Train Loss: 1.1167, Test Loss: 1.0984\n",
      "Epoch [26/50] - Train Loss: 1.1165, Test Loss: 1.0982\n",
      "Epoch [27/50] - Train Loss: 1.1163, Test Loss: 1.0981\n",
      "Epoch [28/50] - Train Loss: 1.1161, Test Loss: 1.0980\n",
      "Epoch [29/50] - Train Loss: 1.1159, Test Loss: 1.0979\n",
      "Epoch [30/50] - Train Loss: 1.1157, Test Loss: 1.0978\n",
      "Epoch [31/50] - Train Loss: 1.1155, Test Loss: 1.0978\n",
      "Epoch [32/50] - Train Loss: 1.1153, Test Loss: 1.0978\n",
      "Epoch [33/50] - Train Loss: 1.1150, Test Loss: 1.0979\n",
      "Epoch [34/50] - Train Loss: 1.1148, Test Loss: 1.0979\n",
      "Epoch [35/50] - Train Loss: 1.1146, Test Loss: 1.0980\n",
      "Epoch [36/50] - Train Loss: 1.1144, Test Loss: 1.0982\n",
      "Epoch [37/50] - Train Loss: 1.1142, Test Loss: 1.0984\n",
      "Epoch [38/50] - Train Loss: 1.1140, Test Loss: 1.0986\n",
      "Epoch [39/50] - Train Loss: 1.1137, Test Loss: 1.0989\n",
      "Epoch [40/50] - Train Loss: 1.1135, Test Loss: 1.0992\n",
      "Epoch [41/50] - Train Loss: 1.1132, Test Loss: 1.0995\n",
      "Epoch [42/50] - Train Loss: 1.1129, Test Loss: 1.0998\n",
      "Epoch [43/50] - Train Loss: 1.1126, Test Loss: 1.1002\n",
      "Epoch [44/50] - Train Loss: 1.1123, Test Loss: 1.1006\n",
      "Epoch [45/50] - Train Loss: 1.1120, Test Loss: 1.1011\n",
      "Epoch [46/50] - Train Loss: 1.1116, Test Loss: 1.1015\n",
      "Epoch [47/50] - Train Loss: 1.1112, Test Loss: 1.1020\n",
      "Epoch [48/50] - Train Loss: 1.1108, Test Loss: 1.1025\n",
      "Epoch [49/50] - Train Loss: 1.1103, Test Loss: 1.1030\n",
      "Epoch [50/50] - Train Loss: 1.1098, Test Loss: 1.1036\n",
      "Avg Test Loss: 1.1036\n",
      "Testing combination: (32, 2, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1932, Test Loss: 1.1215\n",
      "Epoch [2/50] - Train Loss: 1.1914, Test Loss: 1.1214\n",
      "Epoch [3/50] - Train Loss: 1.1899, Test Loss: 1.1214\n",
      "Epoch [4/50] - Train Loss: 1.1885, Test Loss: 1.1214\n",
      "Epoch [5/50] - Train Loss: 1.1872, Test Loss: 1.1215\n",
      "Epoch [6/50] - Train Loss: 1.1858, Test Loss: 1.1215\n",
      "Epoch [7/50] - Train Loss: 1.1845, Test Loss: 1.1216\n",
      "Epoch [8/50] - Train Loss: 1.1832, Test Loss: 1.1218\n",
      "Epoch [9/50] - Train Loss: 1.1819, Test Loss: 1.1219\n",
      "Epoch [10/50] - Train Loss: 1.1807, Test Loss: 1.1221\n",
      "Epoch [11/50] - Train Loss: 1.1794, Test Loss: 1.1224\n",
      "Epoch [12/50] - Train Loss: 1.1782, Test Loss: 1.1227\n",
      "Epoch [13/50] - Train Loss: 1.1769, Test Loss: 1.1230\n",
      "Epoch [14/50] - Train Loss: 1.1756, Test Loss: 1.1234\n",
      "Epoch [15/50] - Train Loss: 1.1744, Test Loss: 1.1238\n",
      "Epoch [16/50] - Train Loss: 1.1731, Test Loss: 1.1243\n",
      "Epoch [17/50] - Train Loss: 1.1718, Test Loss: 1.1249\n",
      "Epoch [18/50] - Train Loss: 1.1705, Test Loss: 1.1255\n",
      "Epoch [19/50] - Train Loss: 1.1691, Test Loss: 1.1262\n",
      "Epoch [20/50] - Train Loss: 1.1678, Test Loss: 1.1269\n",
      "Epoch [21/50] - Train Loss: 1.1664, Test Loss: 1.1277\n",
      "Epoch [22/50] - Train Loss: 1.1650, Test Loss: 1.1285\n",
      "Epoch [23/50] - Train Loss: 1.1635, Test Loss: 1.1294\n",
      "Epoch [24/50] - Train Loss: 1.1621, Test Loss: 1.1303\n",
      "Epoch [25/50] - Train Loss: 1.1606, Test Loss: 1.1314\n",
      "Epoch [26/50] - Train Loss: 1.1590, Test Loss: 1.1325\n",
      "Epoch [27/50] - Train Loss: 1.1574, Test Loss: 1.1337\n",
      "Epoch [28/50] - Train Loss: 1.1558, Test Loss: 1.1350\n",
      "Epoch [29/50] - Train Loss: 1.1541, Test Loss: 1.1363\n",
      "Epoch [30/50] - Train Loss: 1.1523, Test Loss: 1.1378\n",
      "Epoch [31/50] - Train Loss: 1.1505, Test Loss: 1.1394\n",
      "Epoch [32/50] - Train Loss: 1.1487, Test Loss: 1.1411\n",
      "Epoch [33/50] - Train Loss: 1.1468, Test Loss: 1.1429\n",
      "Epoch [34/50] - Train Loss: 1.1448, Test Loss: 1.1448\n",
      "Epoch [35/50] - Train Loss: 1.1427, Test Loss: 1.1468\n",
      "Epoch [36/50] - Train Loss: 1.1405, Test Loss: 1.1490\n",
      "Epoch [37/50] - Train Loss: 1.1383, Test Loss: 1.1513\n",
      "Epoch [38/50] - Train Loss: 1.1360, Test Loss: 1.1538\n",
      "Epoch [39/50] - Train Loss: 1.1336, Test Loss: 1.1564\n",
      "Epoch [40/50] - Train Loss: 1.1311, Test Loss: 1.1591\n",
      "Epoch [41/50] - Train Loss: 1.1286, Test Loss: 1.1620\n",
      "Epoch [42/50] - Train Loss: 1.1259, Test Loss: 1.1651\n",
      "Epoch [43/50] - Train Loss: 1.1232, Test Loss: 1.1682\n",
      "Epoch [44/50] - Train Loss: 1.1204, Test Loss: 1.1715\n",
      "Epoch [45/50] - Train Loss: 1.1175, Test Loss: 1.1749\n",
      "Epoch [46/50] - Train Loss: 1.1146, Test Loss: 1.1784\n",
      "Epoch [47/50] - Train Loss: 1.1116, Test Loss: 1.1820\n",
      "Epoch [48/50] - Train Loss: 1.1085, Test Loss: 1.1856\n",
      "Epoch [49/50] - Train Loss: 1.1053, Test Loss: 1.1893\n",
      "Epoch [50/50] - Train Loss: 1.1021, Test Loss: 1.1929\n",
      "Avg Test Loss: 1.1929\n",
      "Testing combination: (32, 2, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5499, Test Loss: 1.8180\n",
      "Epoch [2/50] - Train Loss: 1.5483, Test Loss: 1.8159\n",
      "Epoch [3/50] - Train Loss: 1.5467, Test Loss: 1.8137\n",
      "Epoch [4/50] - Train Loss: 1.5452, Test Loss: 1.8116\n",
      "Epoch [5/50] - Train Loss: 1.5436, Test Loss: 1.8095\n",
      "Epoch [6/50] - Train Loss: 1.5421, Test Loss: 1.8074\n",
      "Epoch [7/50] - Train Loss: 1.5406, Test Loss: 1.8054\n",
      "Epoch [8/50] - Train Loss: 1.5391, Test Loss: 1.8034\n",
      "Epoch [9/50] - Train Loss: 1.5377, Test Loss: 1.8015\n",
      "Epoch [10/50] - Train Loss: 1.5362, Test Loss: 1.7996\n",
      "Epoch [11/50] - Train Loss: 1.5348, Test Loss: 1.7977\n",
      "Epoch [12/50] - Train Loss: 1.5335, Test Loss: 1.7959\n",
      "Epoch [13/50] - Train Loss: 1.5321, Test Loss: 1.7941\n",
      "Epoch [14/50] - Train Loss: 1.5308, Test Loss: 1.7924\n",
      "Epoch [15/50] - Train Loss: 1.5295, Test Loss: 1.7907\n",
      "Epoch [16/50] - Train Loss: 1.5282, Test Loss: 1.7890\n",
      "Epoch [17/50] - Train Loss: 1.5269, Test Loss: 1.7874\n",
      "Epoch [18/50] - Train Loss: 1.5257, Test Loss: 1.7857\n",
      "Epoch [19/50] - Train Loss: 1.5244, Test Loss: 1.7842\n",
      "Epoch [20/50] - Train Loss: 1.5232, Test Loss: 1.7827\n",
      "Epoch [21/50] - Train Loss: 1.5220, Test Loss: 1.7812\n",
      "Epoch [22/50] - Train Loss: 1.5208, Test Loss: 1.7797\n",
      "Epoch [23/50] - Train Loss: 1.5196, Test Loss: 1.7783\n",
      "Epoch [24/50] - Train Loss: 1.5185, Test Loss: 1.7769\n",
      "Epoch [25/50] - Train Loss: 1.5173, Test Loss: 1.7755\n",
      "Epoch [26/50] - Train Loss: 1.5162, Test Loss: 1.7742\n",
      "Epoch [27/50] - Train Loss: 1.5151, Test Loss: 1.7729\n",
      "Epoch [28/50] - Train Loss: 1.5140, Test Loss: 1.7717\n",
      "Epoch [29/50] - Train Loss: 1.5129, Test Loss: 1.7705\n",
      "Epoch [30/50] - Train Loss: 1.5118, Test Loss: 1.7693\n",
      "Epoch [31/50] - Train Loss: 1.5107, Test Loss: 1.7682\n",
      "Epoch [32/50] - Train Loss: 1.5097, Test Loss: 1.7671\n",
      "Epoch [33/50] - Train Loss: 1.5086, Test Loss: 1.7661\n",
      "Epoch [34/50] - Train Loss: 1.5076, Test Loss: 1.7651\n",
      "Epoch [35/50] - Train Loss: 1.5066, Test Loss: 1.7641\n",
      "Epoch [36/50] - Train Loss: 1.5056, Test Loss: 1.7632\n",
      "Epoch [37/50] - Train Loss: 1.5046, Test Loss: 1.7623\n",
      "Epoch [38/50] - Train Loss: 1.5036, Test Loss: 1.7615\n",
      "Epoch [39/50] - Train Loss: 1.5027, Test Loss: 1.7607\n",
      "Epoch [40/50] - Train Loss: 1.5018, Test Loss: 1.7599\n",
      "Epoch [41/50] - Train Loss: 1.5008, Test Loss: 1.7592\n",
      "Epoch [42/50] - Train Loss: 1.4999, Test Loss: 1.7586\n",
      "Epoch [43/50] - Train Loss: 1.4990, Test Loss: 1.7579\n",
      "Epoch [44/50] - Train Loss: 1.4981, Test Loss: 1.7574\n",
      "Epoch [45/50] - Train Loss: 1.4973, Test Loss: 1.7568\n",
      "Epoch [46/50] - Train Loss: 1.4964, Test Loss: 1.7564\n",
      "Epoch [47/50] - Train Loss: 1.4956, Test Loss: 1.7560\n",
      "Epoch [48/50] - Train Loss: 1.4947, Test Loss: 1.7556\n",
      "Epoch [49/50] - Train Loss: 1.4939, Test Loss: 1.7554\n",
      "Epoch [50/50] - Train Loss: 1.4931, Test Loss: 1.7552\n",
      "Avg Test Loss: 1.7552\n",
      "Testing combination: (32, 3, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1677, Test Loss: 1.0808\n",
      "Epoch [2/50] - Train Loss: 1.1241, Test Loss: 1.0817\n",
      "Epoch [3/50] - Train Loss: 1.1210, Test Loss: 1.0881\n",
      "Epoch [4/50] - Train Loss: 1.1091, Test Loss: 1.1062\n",
      "Epoch [5/50] - Train Loss: 1.0961, Test Loss: 1.1268\n",
      "Epoch [6/50] - Train Loss: 1.0856, Test Loss: 1.1506\n",
      "Epoch [7/50] - Train Loss: 1.0829, Test Loss: 1.1638\n",
      "Epoch [8/50] - Train Loss: 1.0688, Test Loss: 1.2038\n",
      "Epoch [9/50] - Train Loss: 1.0685, Test Loss: 1.2236\n",
      "Epoch [10/50] - Train Loss: 1.0695, Test Loss: 1.2359\n",
      "Epoch [11/50] - Train Loss: 1.0754, Test Loss: 1.1746\n",
      "Epoch [12/50] - Train Loss: 1.0692, Test Loss: 1.2146\n",
      "Epoch [13/50] - Train Loss: 1.0656, Test Loss: 1.2086\n",
      "Epoch [14/50] - Train Loss: 1.0662, Test Loss: 1.1951\n",
      "Epoch [15/50] - Train Loss: 1.0645, Test Loss: 1.2117\n",
      "Epoch [16/50] - Train Loss: 1.0674, Test Loss: 1.2228\n",
      "Epoch [17/50] - Train Loss: 1.0650, Test Loss: 1.1979\n",
      "Epoch [18/50] - Train Loss: 1.0636, Test Loss: 1.2027\n",
      "Epoch [19/50] - Train Loss: 1.0654, Test Loss: 1.2074\n",
      "Epoch [20/50] - Train Loss: 1.0642, Test Loss: 1.2033\n",
      "Epoch [21/50] - Train Loss: 1.0627, Test Loss: 1.2054\n",
      "Epoch [22/50] - Train Loss: 1.0656, Test Loss: 1.2045\n",
      "Epoch [23/50] - Train Loss: 1.0627, Test Loss: 1.2004\n",
      "Epoch [24/50] - Train Loss: 1.0624, Test Loss: 1.2067\n",
      "Epoch [25/50] - Train Loss: 1.0636, Test Loss: 1.2043\n",
      "Epoch [26/50] - Train Loss: 1.0607, Test Loss: 1.2002\n",
      "Epoch [27/50] - Train Loss: 1.0611, Test Loss: 1.2016\n",
      "Epoch [28/50] - Train Loss: 1.0609, Test Loss: 1.2018\n",
      "Epoch [29/50] - Train Loss: 1.0609, Test Loss: 1.2017\n",
      "Epoch [30/50] - Train Loss: 1.0604, Test Loss: 1.2023\n",
      "Epoch [31/50] - Train Loss: 1.0604, Test Loss: 1.2011\n",
      "Epoch [32/50] - Train Loss: 1.0596, Test Loss: 1.2026\n",
      "Epoch [33/50] - Train Loss: 1.0609, Test Loss: 1.1983\n",
      "Epoch [34/50] - Train Loss: 1.0594, Test Loss: 1.1993\n",
      "Epoch [35/50] - Train Loss: 1.0633, Test Loss: 1.2041\n",
      "Epoch [36/50] - Train Loss: 1.0586, Test Loss: 1.1959\n",
      "Epoch [37/50] - Train Loss: 1.0612, Test Loss: 1.2015\n",
      "Epoch [38/50] - Train Loss: 1.0586, Test Loss: 1.1927\n",
      "Epoch [39/50] - Train Loss: 1.0608, Test Loss: 1.1887\n",
      "Epoch [40/50] - Train Loss: 1.0609, Test Loss: 1.1922\n",
      "Epoch [41/50] - Train Loss: 1.0612, Test Loss: 1.2018\n",
      "Epoch [42/50] - Train Loss: 1.0648, Test Loss: 1.2028\n",
      "Epoch [43/50] - Train Loss: 1.0619, Test Loss: 1.2243\n",
      "Epoch [44/50] - Train Loss: 1.0621, Test Loss: 1.1813\n",
      "Epoch [45/50] - Train Loss: 1.0613, Test Loss: 1.1762\n",
      "Epoch [46/50] - Train Loss: 1.0642, Test Loss: 1.1967\n",
      "Epoch [47/50] - Train Loss: 1.0537, Test Loss: 1.1773\n",
      "Epoch [48/50] - Train Loss: 1.0478, Test Loss: 1.1451\n",
      "Epoch [49/50] - Train Loss: 1.0273, Test Loss: 1.0835\n",
      "Epoch [50/50] - Train Loss: 1.0384, Test Loss: 1.1888\n",
      "Avg Test Loss: 1.1888\n",
      "Testing combination: (32, 3, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.2446, Test Loss: 1.1598\n",
      "Epoch [2/50] - Train Loss: 1.1526, Test Loss: 1.1543\n",
      "Epoch [3/50] - Train Loss: 1.1477, Test Loss: 1.1591\n",
      "Epoch [4/50] - Train Loss: 1.1237, Test Loss: 1.1864\n",
      "Epoch [5/50] - Train Loss: 1.0629, Test Loss: 1.2541\n",
      "Epoch [6/50] - Train Loss: 1.3768, Test Loss: 1.1656\n",
      "Epoch [7/50] - Train Loss: 1.1332, Test Loss: 1.1560\n",
      "Epoch [8/50] - Train Loss: 1.1177, Test Loss: 1.1588\n",
      "Epoch [9/50] - Train Loss: 1.1007, Test Loss: 1.1685\n",
      "Epoch [10/50] - Train Loss: 1.0763, Test Loss: 1.1912\n",
      "Epoch [11/50] - Train Loss: 1.0522, Test Loss: 1.2386\n",
      "Epoch [12/50] - Train Loss: 1.0519, Test Loss: 1.2765\n",
      "Epoch [13/50] - Train Loss: 1.0489, Test Loss: 1.2818\n",
      "Epoch [14/50] - Train Loss: 1.0490, Test Loss: 1.2775\n",
      "Epoch [15/50] - Train Loss: 1.0482, Test Loss: 1.2835\n",
      "Epoch [16/50] - Train Loss: 1.0480, Test Loss: 1.2780\n",
      "Epoch [17/50] - Train Loss: 1.0477, Test Loss: 1.2716\n",
      "Epoch [18/50] - Train Loss: 1.0476, Test Loss: 1.2699\n",
      "Epoch [19/50] - Train Loss: 1.0475, Test Loss: 1.2713\n",
      "Epoch [20/50] - Train Loss: 1.0475, Test Loss: 1.2724\n",
      "Epoch [21/50] - Train Loss: 1.0475, Test Loss: 1.2722\n",
      "Epoch [22/50] - Train Loss: 1.0474, Test Loss: 1.2714\n",
      "Epoch [23/50] - Train Loss: 1.0474, Test Loss: 1.2710\n",
      "Epoch [24/50] - Train Loss: 1.0473, Test Loss: 1.2710\n",
      "Epoch [25/50] - Train Loss: 1.0473, Test Loss: 1.2711\n",
      "Epoch [26/50] - Train Loss: 1.0472, Test Loss: 1.2710\n",
      "Epoch [27/50] - Train Loss: 1.0472, Test Loss: 1.2708\n",
      "Epoch [28/50] - Train Loss: 1.0472, Test Loss: 1.2706\n",
      "Epoch [29/50] - Train Loss: 1.0472, Test Loss: 1.2705\n",
      "Epoch [30/50] - Train Loss: 1.0471, Test Loss: 1.2704\n",
      "Epoch [31/50] - Train Loss: 1.0471, Test Loss: 1.2703\n",
      "Epoch [32/50] - Train Loss: 1.0471, Test Loss: 1.2702\n",
      "Epoch [33/50] - Train Loss: 1.0470, Test Loss: 1.2701\n",
      "Epoch [34/50] - Train Loss: 1.0470, Test Loss: 1.2700\n",
      "Epoch [35/50] - Train Loss: 1.0470, Test Loss: 1.2699\n",
      "Epoch [36/50] - Train Loss: 1.0470, Test Loss: 1.2698\n",
      "Epoch [37/50] - Train Loss: 1.0470, Test Loss: 1.2696\n",
      "Epoch [38/50] - Train Loss: 1.0469, Test Loss: 1.2695\n",
      "Epoch [39/50] - Train Loss: 1.0469, Test Loss: 1.2694\n",
      "Epoch [40/50] - Train Loss: 1.0469, Test Loss: 1.2693\n",
      "Epoch [41/50] - Train Loss: 1.0469, Test Loss: 1.2692\n",
      "Epoch [42/50] - Train Loss: 1.0469, Test Loss: 1.2691\n",
      "Epoch [43/50] - Train Loss: 1.0468, Test Loss: 1.2690\n",
      "Epoch [44/50] - Train Loss: 1.0468, Test Loss: 1.2689\n",
      "Epoch [45/50] - Train Loss: 1.0468, Test Loss: 1.2688\n",
      "Epoch [46/50] - Train Loss: 1.0468, Test Loss: 1.2687\n",
      "Epoch [47/50] - Train Loss: 1.0468, Test Loss: 1.2686\n",
      "Epoch [48/50] - Train Loss: 1.0468, Test Loss: 1.2685\n",
      "Epoch [49/50] - Train Loss: 1.0468, Test Loss: 1.2684\n",
      "Epoch [50/50] - Train Loss: 1.0467, Test Loss: 1.2683\n",
      "Avg Test Loss: 1.2683\n",
      "Testing combination: (32, 3, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5443, Test Loss: 1.7345\n",
      "Epoch [2/50] - Train Loss: 1.4885, Test Loss: 1.7344\n",
      "Epoch [3/50] - Train Loss: 1.4856, Test Loss: 1.7364\n",
      "Epoch [4/50] - Train Loss: 1.4837, Test Loss: 1.7413\n",
      "Epoch [5/50] - Train Loss: 1.4781, Test Loss: 1.7552\n",
      "Epoch [6/50] - Train Loss: 1.4583, Test Loss: 1.8217\n",
      "Epoch [7/50] - Train Loss: 1.5073, Test Loss: 1.7978\n",
      "Epoch [8/50] - Train Loss: 1.4582, Test Loss: 1.7998\n",
      "Epoch [9/50] - Train Loss: 1.4585, Test Loss: 1.8199\n",
      "Epoch [10/50] - Train Loss: 1.4491, Test Loss: 1.8656\n",
      "Epoch [11/50] - Train Loss: 1.4374, Test Loss: 1.9486\n",
      "Epoch [12/50] - Train Loss: 1.4306, Test Loss: 2.0586\n",
      "Epoch [13/50] - Train Loss: 1.4316, Test Loss: 2.1207\n",
      "Epoch [14/50] - Train Loss: 1.4280, Test Loss: 2.0557\n",
      "Epoch [15/50] - Train Loss: 1.4271, Test Loss: 2.0406\n",
      "Epoch [16/50] - Train Loss: 1.4245, Test Loss: 2.0666\n",
      "Epoch [17/50] - Train Loss: 1.4213, Test Loss: 2.0869\n",
      "Epoch [18/50] - Train Loss: 1.4188, Test Loss: 2.0904\n",
      "Epoch [19/50] - Train Loss: 1.4178, Test Loss: 2.0678\n",
      "Epoch [20/50] - Train Loss: 1.4109, Test Loss: 2.0634\n",
      "Epoch [21/50] - Train Loss: 1.4108, Test Loss: 2.0747\n",
      "Epoch [22/50] - Train Loss: 1.4139, Test Loss: 2.0704\n",
      "Epoch [23/50] - Train Loss: 1.4074, Test Loss: 2.0669\n",
      "Epoch [24/50] - Train Loss: 1.4093, Test Loss: 2.0751\n",
      "Epoch [25/50] - Train Loss: 1.4110, Test Loss: 2.0938\n",
      "Epoch [26/50] - Train Loss: 1.4077, Test Loss: 2.0793\n",
      "Epoch [27/50] - Train Loss: 1.4038, Test Loss: 2.0772\n",
      "Epoch [28/50] - Train Loss: 1.4051, Test Loss: 2.1027\n",
      "Epoch [29/50] - Train Loss: 1.4041, Test Loss: 2.0940\n",
      "Epoch [30/50] - Train Loss: 1.4017, Test Loss: 2.1224\n",
      "Epoch [31/50] - Train Loss: 1.4012, Test Loss: 2.0511\n",
      "Epoch [32/50] - Train Loss: 1.4128, Test Loss: 2.1303\n",
      "Epoch [33/50] - Train Loss: 1.4105, Test Loss: 2.1522\n",
      "Epoch [34/50] - Train Loss: 1.3946, Test Loss: 2.0843\n",
      "Epoch [35/50] - Train Loss: 1.4023, Test Loss: 2.0612\n",
      "Epoch [36/50] - Train Loss: 1.4020, Test Loss: 2.1166\n",
      "Epoch [37/50] - Train Loss: 1.3952, Test Loss: 2.0180\n",
      "Epoch [38/50] - Train Loss: 1.3992, Test Loss: 2.0134\n",
      "Epoch [39/50] - Train Loss: 1.4011, Test Loss: 2.1223\n",
      "Epoch [40/50] - Train Loss: 1.3912, Test Loss: 2.1929\n",
      "Epoch [41/50] - Train Loss: 1.3733, Test Loss: 2.1188\n",
      "Epoch [42/50] - Train Loss: 1.3807, Test Loss: 2.2081\n",
      "Epoch [43/50] - Train Loss: 1.3702, Test Loss: 2.1733\n",
      "Epoch [44/50] - Train Loss: 1.3709, Test Loss: 2.2048\n",
      "Epoch [45/50] - Train Loss: 1.3655, Test Loss: 2.1708\n",
      "Epoch [46/50] - Train Loss: 1.3622, Test Loss: 2.1594\n",
      "Epoch [47/50] - Train Loss: 1.3517, Test Loss: 2.4499\n",
      "Epoch [48/50] - Train Loss: 1.3882, Test Loss: 2.0528\n",
      "Epoch [49/50] - Train Loss: 1.5058, Test Loss: 1.9547\n",
      "Epoch [50/50] - Train Loss: 1.4399, Test Loss: 2.0110\n",
      "Avg Test Loss: 2.0110\n",
      "Testing combination: (32, 3, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1365, Test Loss: 1.1189\n",
      "Epoch [2/50] - Train Loss: 1.1236, Test Loss: 1.1040\n",
      "Epoch [3/50] - Train Loss: 1.1185, Test Loss: 1.0957\n",
      "Epoch [4/50] - Train Loss: 1.1165, Test Loss: 1.0916\n",
      "Epoch [5/50] - Train Loss: 1.1157, Test Loss: 1.0903\n",
      "Epoch [6/50] - Train Loss: 1.1150, Test Loss: 1.0908\n",
      "Epoch [7/50] - Train Loss: 1.1138, Test Loss: 1.0924\n",
      "Epoch [8/50] - Train Loss: 1.1113, Test Loss: 1.0951\n",
      "Epoch [9/50] - Train Loss: 1.1064, Test Loss: 1.1000\n",
      "Epoch [10/50] - Train Loss: 1.0981, Test Loss: 1.1097\n",
      "Epoch [11/50] - Train Loss: 1.0848, Test Loss: 1.1291\n",
      "Epoch [12/50] - Train Loss: 1.0759, Test Loss: 1.1493\n",
      "Epoch [13/50] - Train Loss: 1.0768, Test Loss: 1.1588\n",
      "Epoch [14/50] - Train Loss: 1.0753, Test Loss: 1.1655\n",
      "Epoch [15/50] - Train Loss: 1.0744, Test Loss: 1.1719\n",
      "Epoch [16/50] - Train Loss: 1.0738, Test Loss: 1.1766\n",
      "Epoch [17/50] - Train Loss: 1.0727, Test Loss: 1.1807\n",
      "Epoch [18/50] - Train Loss: 1.0714, Test Loss: 1.1858\n",
      "Epoch [19/50] - Train Loss: 1.0703, Test Loss: 1.1919\n",
      "Epoch [20/50] - Train Loss: 1.0692, Test Loss: 1.1982\n",
      "Epoch [21/50] - Train Loss: 1.0681, Test Loss: 1.2046\n",
      "Epoch [22/50] - Train Loss: 1.0666, Test Loss: 1.2112\n",
      "Epoch [23/50] - Train Loss: 1.0647, Test Loss: 1.2180\n",
      "Epoch [24/50] - Train Loss: 1.0625, Test Loss: 1.2192\n",
      "Epoch [25/50] - Train Loss: 1.0599, Test Loss: 1.2306\n",
      "Epoch [26/50] - Train Loss: 1.0555, Test Loss: 1.2144\n",
      "Epoch [27/50] - Train Loss: 1.0516, Test Loss: 1.1680\n",
      "Epoch [28/50] - Train Loss: 1.0496, Test Loss: 1.1996\n",
      "Epoch [29/50] - Train Loss: 1.0728, Test Loss: 1.1930\n",
      "Epoch [30/50] - Train Loss: 1.0535, Test Loss: 1.1901\n",
      "Epoch [31/50] - Train Loss: 1.0618, Test Loss: 1.2185\n",
      "Epoch [32/50] - Train Loss: 1.0874, Test Loss: 1.1943\n",
      "Epoch [33/50] - Train Loss: 1.1118, Test Loss: 1.0813\n",
      "Epoch [34/50] - Train Loss: 1.1226, Test Loss: 1.0821\n",
      "Epoch [35/50] - Train Loss: 1.1192, Test Loss: 1.0846\n",
      "Epoch [36/50] - Train Loss: 1.1174, Test Loss: 1.0870\n",
      "Epoch [37/50] - Train Loss: 1.1165, Test Loss: 1.0887\n",
      "Epoch [38/50] - Train Loss: 1.1160, Test Loss: 1.0897\n",
      "Epoch [39/50] - Train Loss: 1.1155, Test Loss: 1.0903\n",
      "Epoch [40/50] - Train Loss: 1.1151, Test Loss: 1.0907\n",
      "Epoch [41/50] - Train Loss: 1.1146, Test Loss: 1.0912\n",
      "Epoch [42/50] - Train Loss: 1.1139, Test Loss: 1.0918\n",
      "Epoch [43/50] - Train Loss: 1.1131, Test Loss: 1.0926\n",
      "Epoch [44/50] - Train Loss: 1.1121, Test Loss: 1.0936\n",
      "Epoch [45/50] - Train Loss: 1.1106, Test Loss: 1.0950\n",
      "Epoch [46/50] - Train Loss: 1.1087, Test Loss: 1.0967\n",
      "Epoch [47/50] - Train Loss: 1.1060, Test Loss: 1.0989\n",
      "Epoch [48/50] - Train Loss: 1.1025, Test Loss: 1.1020\n",
      "Epoch [49/50] - Train Loss: 1.0981, Test Loss: 1.1065\n",
      "Epoch [50/50] - Train Loss: 1.0925, Test Loss: 1.1130\n",
      "Avg Test Loss: 1.1130\n",
      "Testing combination: (32, 3, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1641, Test Loss: 1.2035\n",
      "Epoch [2/50] - Train Loss: 1.1547, Test Loss: 1.1911\n",
      "Epoch [3/50] - Train Loss: 1.1520, Test Loss: 1.1831\n",
      "Epoch [4/50] - Train Loss: 1.1506, Test Loss: 1.1776\n",
      "Epoch [5/50] - Train Loss: 1.1496, Test Loss: 1.1739\n",
      "Epoch [6/50] - Train Loss: 1.1487, Test Loss: 1.1715\n",
      "Epoch [7/50] - Train Loss: 1.1473, Test Loss: 1.1703\n",
      "Epoch [8/50] - Train Loss: 1.1448, Test Loss: 1.1699\n",
      "Epoch [9/50] - Train Loss: 1.1396, Test Loss: 1.1701\n",
      "Epoch [10/50] - Train Loss: 1.1297, Test Loss: 1.1708\n",
      "Epoch [11/50] - Train Loss: 1.1123, Test Loss: 1.1734\n",
      "Epoch [12/50] - Train Loss: 1.0863, Test Loss: 1.1832\n",
      "Epoch [13/50] - Train Loss: 1.0594, Test Loss: 1.2094\n",
      "Epoch [14/50] - Train Loss: 1.0521, Test Loss: 1.2385\n",
      "Epoch [15/50] - Train Loss: 1.0521, Test Loss: 1.2566\n",
      "Epoch [16/50] - Train Loss: 1.0499, Test Loss: 1.2656\n",
      "Epoch [17/50] - Train Loss: 1.0478, Test Loss: 1.2733\n",
      "Epoch [18/50] - Train Loss: 1.0466, Test Loss: 1.2816\n",
      "Epoch [19/50] - Train Loss: 1.0461, Test Loss: 1.2876\n",
      "Epoch [20/50] - Train Loss: 1.0458, Test Loss: 1.2899\n",
      "Epoch [21/50] - Train Loss: 1.0455, Test Loss: 1.2905\n",
      "Epoch [22/50] - Train Loss: 1.0452, Test Loss: 1.2914\n",
      "Epoch [23/50] - Train Loss: 1.0450, Test Loss: 1.2921\n",
      "Epoch [24/50] - Train Loss: 1.0448, Test Loss: 1.2921\n",
      "Epoch [25/50] - Train Loss: 1.0445, Test Loss: 1.2917\n",
      "Epoch [26/50] - Train Loss: 1.0442, Test Loss: 1.2912\n",
      "Epoch [27/50] - Train Loss: 1.0439, Test Loss: 1.2904\n",
      "Epoch [28/50] - Train Loss: 1.0435, Test Loss: 1.2896\n",
      "Epoch [29/50] - Train Loss: 1.0430, Test Loss: 1.2886\n",
      "Epoch [30/50] - Train Loss: 1.0425, Test Loss: 1.2867\n",
      "Epoch [31/50] - Train Loss: 1.0417, Test Loss: 1.2846\n",
      "Epoch [32/50] - Train Loss: 1.0404, Test Loss: 1.2821\n",
      "Epoch [33/50] - Train Loss: 1.0382, Test Loss: 1.2780\n",
      "Epoch [34/50] - Train Loss: 1.0342, Test Loss: 1.2668\n",
      "Epoch [35/50] - Train Loss: 1.0401, Test Loss: 1.2697\n",
      "Epoch [36/50] - Train Loss: 1.0280, Test Loss: 1.2636\n",
      "Epoch [37/50] - Train Loss: 1.0326, Test Loss: 1.2512\n",
      "Epoch [38/50] - Train Loss: 1.1109, Test Loss: 1.2882\n",
      "Epoch [39/50] - Train Loss: 1.0139, Test Loss: 1.2142\n",
      "Epoch [40/50] - Train Loss: 1.0298, Test Loss: 1.2492\n",
      "Epoch [41/50] - Train Loss: 1.0256, Test Loss: 1.2787\n",
      "Epoch [42/50] - Train Loss: 1.0140, Test Loss: 1.2754\n",
      "Epoch [43/50] - Train Loss: 0.9905, Test Loss: 1.2582\n",
      "Epoch [44/50] - Train Loss: 0.9988, Test Loss: 1.2281\n",
      "Epoch [45/50] - Train Loss: 1.0776, Test Loss: 1.2050\n",
      "Epoch [46/50] - Train Loss: 1.0787, Test Loss: 1.2318\n",
      "Epoch [47/50] - Train Loss: 1.0467, Test Loss: 1.2856\n",
      "Epoch [48/50] - Train Loss: 1.0454, Test Loss: 1.3095\n",
      "Epoch [49/50] - Train Loss: 1.0389, Test Loss: 1.3006\n",
      "Epoch [50/50] - Train Loss: 1.0360, Test Loss: 1.2891\n",
      "Avg Test Loss: 1.2891\n",
      "Testing combination: (32, 3, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5168, Test Loss: 1.7638\n",
      "Epoch [2/50] - Train Loss: 1.5037, Test Loss: 1.7540\n",
      "Epoch [3/50] - Train Loss: 1.4976, Test Loss: 1.7478\n",
      "Epoch [4/50] - Train Loss: 1.4936, Test Loss: 1.7439\n",
      "Epoch [5/50] - Train Loss: 1.4908, Test Loss: 1.7415\n",
      "Epoch [6/50] - Train Loss: 1.4887, Test Loss: 1.7404\n",
      "Epoch [7/50] - Train Loss: 1.4871, Test Loss: 1.7403\n",
      "Epoch [8/50] - Train Loss: 1.4857, Test Loss: 1.7412\n",
      "Epoch [9/50] - Train Loss: 1.4842, Test Loss: 1.7430\n",
      "Epoch [10/50] - Train Loss: 1.4826, Test Loss: 1.7460\n",
      "Epoch [11/50] - Train Loss: 1.4804, Test Loss: 1.7501\n",
      "Epoch [12/50] - Train Loss: 1.4773, Test Loss: 1.7560\n",
      "Epoch [13/50] - Train Loss: 1.4729, Test Loss: 1.7651\n",
      "Epoch [14/50] - Train Loss: 1.4668, Test Loss: 1.7801\n",
      "Epoch [15/50] - Train Loss: 1.4582, Test Loss: 1.8052\n",
      "Epoch [16/50] - Train Loss: 1.4468, Test Loss: 1.8438\n",
      "Epoch [17/50] - Train Loss: 1.4347, Test Loss: 1.8924\n",
      "Epoch [18/50] - Train Loss: 1.4270, Test Loss: 1.9358\n",
      "Epoch [19/50] - Train Loss: 1.4251, Test Loss: 1.9579\n",
      "Epoch [20/50] - Train Loss: 1.4231, Test Loss: 1.9643\n",
      "Epoch [21/50] - Train Loss: 1.4221, Test Loss: 1.9672\n",
      "Epoch [22/50] - Train Loss: 1.4219, Test Loss: 1.9720\n",
      "Epoch [23/50] - Train Loss: 1.4215, Test Loss: 1.9798\n",
      "Epoch [24/50] - Train Loss: 1.4210, Test Loss: 1.9894\n",
      "Epoch [25/50] - Train Loss: 1.4205, Test Loss: 1.9986\n",
      "Epoch [26/50] - Train Loss: 1.4201, Test Loss: 2.0057\n",
      "Epoch [27/50] - Train Loss: 1.4195, Test Loss: 2.0105\n",
      "Epoch [28/50] - Train Loss: 1.4189, Test Loss: 2.0143\n",
      "Epoch [29/50] - Train Loss: 1.4181, Test Loss: 2.0187\n",
      "Epoch [30/50] - Train Loss: 1.4174, Test Loss: 2.0249\n",
      "Epoch [31/50] - Train Loss: 1.4166, Test Loss: 2.0332\n",
      "Epoch [32/50] - Train Loss: 1.4159, Test Loss: 2.0429\n",
      "Epoch [33/50] - Train Loss: 1.4152, Test Loss: 2.0527\n",
      "Epoch [34/50] - Train Loss: 1.4145, Test Loss: 2.0619\n",
      "Epoch [35/50] - Train Loss: 1.4139, Test Loss: 2.0702\n",
      "Epoch [36/50] - Train Loss: 1.4131, Test Loss: 2.0779\n",
      "Epoch [37/50] - Train Loss: 1.4124, Test Loss: 2.0854\n",
      "Epoch [38/50] - Train Loss: 1.4117, Test Loss: 2.0933\n",
      "Epoch [39/50] - Train Loss: 1.4110, Test Loss: 2.1012\n",
      "Epoch [40/50] - Train Loss: 1.4102, Test Loss: 2.1087\n",
      "Epoch [41/50] - Train Loss: 1.4093, Test Loss: 2.1159\n",
      "Epoch [42/50] - Train Loss: 1.4083, Test Loss: 2.1226\n",
      "Epoch [43/50] - Train Loss: 1.4071, Test Loss: 2.1295\n",
      "Epoch [44/50] - Train Loss: 1.4056, Test Loss: 2.1368\n",
      "Epoch [45/50] - Train Loss: 1.4035, Test Loss: 2.1437\n",
      "Epoch [46/50] - Train Loss: 1.4008, Test Loss: 2.1543\n",
      "Epoch [47/50] - Train Loss: 1.3980, Test Loss: 2.1799\n",
      "Epoch [48/50] - Train Loss: 1.3908, Test Loss: 2.1836\n",
      "Epoch [49/50] - Train Loss: 1.3797, Test Loss: 2.1847\n",
      "Epoch [50/50] - Train Loss: 1.4066, Test Loss: 2.1642\n",
      "Avg Test Loss: 2.1642\n",
      "Testing combination: (32, 3, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1459, Test Loss: 1.0901\n",
      "Epoch [2/50] - Train Loss: 1.1436, Test Loss: 1.0891\n",
      "Epoch [3/50] - Train Loss: 1.1420, Test Loss: 1.0882\n",
      "Epoch [4/50] - Train Loss: 1.1404, Test Loss: 1.0874\n",
      "Epoch [5/50] - Train Loss: 1.1390, Test Loss: 1.0866\n",
      "Epoch [6/50] - Train Loss: 1.1376, Test Loss: 1.0859\n",
      "Epoch [7/50] - Train Loss: 1.1363, Test Loss: 1.0852\n",
      "Epoch [8/50] - Train Loss: 1.1350, Test Loss: 1.0846\n",
      "Epoch [9/50] - Train Loss: 1.1338, Test Loss: 1.0841\n",
      "Epoch [10/50] - Train Loss: 1.1326, Test Loss: 1.0836\n",
      "Epoch [11/50] - Train Loss: 1.1315, Test Loss: 1.0831\n",
      "Epoch [12/50] - Train Loss: 1.1304, Test Loss: 1.0827\n",
      "Epoch [13/50] - Train Loss: 1.1293, Test Loss: 1.0824\n",
      "Epoch [14/50] - Train Loss: 1.1283, Test Loss: 1.0821\n",
      "Epoch [15/50] - Train Loss: 1.1273, Test Loss: 1.0818\n",
      "Epoch [16/50] - Train Loss: 1.1264, Test Loss: 1.0816\n",
      "Epoch [17/50] - Train Loss: 1.1255, Test Loss: 1.0815\n",
      "Epoch [18/50] - Train Loss: 1.1246, Test Loss: 1.0814\n",
      "Epoch [19/50] - Train Loss: 1.1238, Test Loss: 1.0813\n",
      "Epoch [20/50] - Train Loss: 1.1230, Test Loss: 1.0813\n",
      "Epoch [21/50] - Train Loss: 1.1223, Test Loss: 1.0814\n",
      "Epoch [22/50] - Train Loss: 1.1216, Test Loss: 1.0815\n",
      "Epoch [23/50] - Train Loss: 1.1209, Test Loss: 1.0816\n",
      "Epoch [24/50] - Train Loss: 1.1202, Test Loss: 1.0818\n",
      "Epoch [25/50] - Train Loss: 1.1196, Test Loss: 1.0821\n",
      "Epoch [26/50] - Train Loss: 1.1190, Test Loss: 1.0824\n",
      "Epoch [27/50] - Train Loss: 1.1185, Test Loss: 1.0827\n",
      "Epoch [28/50] - Train Loss: 1.1180, Test Loss: 1.0831\n",
      "Epoch [29/50] - Train Loss: 1.1175, Test Loss: 1.0836\n",
      "Epoch [30/50] - Train Loss: 1.1170, Test Loss: 1.0840\n",
      "Epoch [31/50] - Train Loss: 1.1165, Test Loss: 1.0846\n",
      "Epoch [32/50] - Train Loss: 1.1160, Test Loss: 1.0851\n",
      "Epoch [33/50] - Train Loss: 1.1155, Test Loss: 1.0858\n",
      "Epoch [34/50] - Train Loss: 1.1150, Test Loss: 1.0864\n",
      "Epoch [35/50] - Train Loss: 1.1145, Test Loss: 1.0872\n",
      "Epoch [36/50] - Train Loss: 1.1140, Test Loss: 1.0879\n",
      "Epoch [37/50] - Train Loss: 1.1135, Test Loss: 1.0888\n",
      "Epoch [38/50] - Train Loss: 1.1130, Test Loss: 1.0896\n",
      "Epoch [39/50] - Train Loss: 1.1124, Test Loss: 1.0906\n",
      "Epoch [40/50] - Train Loss: 1.1118, Test Loss: 1.0916\n",
      "Epoch [41/50] - Train Loss: 1.1111, Test Loss: 1.0926\n",
      "Epoch [42/50] - Train Loss: 1.1104, Test Loss: 1.0938\n",
      "Epoch [43/50] - Train Loss: 1.1097, Test Loss: 1.0950\n",
      "Epoch [44/50] - Train Loss: 1.1089, Test Loss: 1.0963\n",
      "Epoch [45/50] - Train Loss: 1.1079, Test Loss: 1.0978\n",
      "Epoch [46/50] - Train Loss: 1.1069, Test Loss: 1.0993\n",
      "Epoch [47/50] - Train Loss: 1.1058, Test Loss: 1.1010\n",
      "Epoch [48/50] - Train Loss: 1.1046, Test Loss: 1.1029\n",
      "Epoch [49/50] - Train Loss: 1.1033, Test Loss: 1.1048\n",
      "Epoch [50/50] - Train Loss: 1.1018, Test Loss: 1.1069\n",
      "Avg Test Loss: 1.1069\n",
      "Testing combination: (32, 3, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1527, Test Loss: 1.1420\n",
      "Epoch [2/50] - Train Loss: 1.1523, Test Loss: 1.1424\n",
      "Epoch [3/50] - Train Loss: 1.1521, Test Loss: 1.1429\n",
      "Epoch [4/50] - Train Loss: 1.1519, Test Loss: 1.1433\n",
      "Epoch [5/50] - Train Loss: 1.1517, Test Loss: 1.1437\n",
      "Epoch [6/50] - Train Loss: 1.1516, Test Loss: 1.1441\n",
      "Epoch [7/50] - Train Loss: 1.1514, Test Loss: 1.1446\n",
      "Epoch [8/50] - Train Loss: 1.1513, Test Loss: 1.1450\n",
      "Epoch [9/50] - Train Loss: 1.1512, Test Loss: 1.1454\n",
      "Epoch [10/50] - Train Loss: 1.1510, Test Loss: 1.1458\n",
      "Epoch [11/50] - Train Loss: 1.1509, Test Loss: 1.1462\n",
      "Epoch [12/50] - Train Loss: 1.1508, Test Loss: 1.1465\n",
      "Epoch [13/50] - Train Loss: 1.1507, Test Loss: 1.1469\n",
      "Epoch [14/50] - Train Loss: 1.1506, Test Loss: 1.1473\n",
      "Epoch [15/50] - Train Loss: 1.1505, Test Loss: 1.1477\n",
      "Epoch [16/50] - Train Loss: 1.1504, Test Loss: 1.1480\n",
      "Epoch [17/50] - Train Loss: 1.1503, Test Loss: 1.1484\n",
      "Epoch [18/50] - Train Loss: 1.1502, Test Loss: 1.1488\n",
      "Epoch [19/50] - Train Loss: 1.1501, Test Loss: 1.1491\n",
      "Epoch [20/50] - Train Loss: 1.1500, Test Loss: 1.1495\n",
      "Epoch [21/50] - Train Loss: 1.1499, Test Loss: 1.1498\n",
      "Epoch [22/50] - Train Loss: 1.1498, Test Loss: 1.1502\n",
      "Epoch [23/50] - Train Loss: 1.1497, Test Loss: 1.1505\n",
      "Epoch [24/50] - Train Loss: 1.1496, Test Loss: 1.1509\n",
      "Epoch [25/50] - Train Loss: 1.1496, Test Loss: 1.1512\n",
      "Epoch [26/50] - Train Loss: 1.1495, Test Loss: 1.1515\n",
      "Epoch [27/50] - Train Loss: 1.1494, Test Loss: 1.1519\n",
      "Epoch [28/50] - Train Loss: 1.1493, Test Loss: 1.1522\n",
      "Epoch [29/50] - Train Loss: 1.1492, Test Loss: 1.1525\n",
      "Epoch [30/50] - Train Loss: 1.1491, Test Loss: 1.1529\n",
      "Epoch [31/50] - Train Loss: 1.1490, Test Loss: 1.1532\n",
      "Epoch [32/50] - Train Loss: 1.1489, Test Loss: 1.1535\n",
      "Epoch [33/50] - Train Loss: 1.1489, Test Loss: 1.1539\n",
      "Epoch [34/50] - Train Loss: 1.1488, Test Loss: 1.1542\n",
      "Epoch [35/50] - Train Loss: 1.1487, Test Loss: 1.1546\n",
      "Epoch [36/50] - Train Loss: 1.1485, Test Loss: 1.1549\n",
      "Epoch [37/50] - Train Loss: 1.1484, Test Loss: 1.1553\n",
      "Epoch [38/50] - Train Loss: 1.1483, Test Loss: 1.1556\n",
      "Epoch [39/50] - Train Loss: 1.1482, Test Loss: 1.1560\n",
      "Epoch [40/50] - Train Loss: 1.1480, Test Loss: 1.1564\n",
      "Epoch [41/50] - Train Loss: 1.1479, Test Loss: 1.1568\n",
      "Epoch [42/50] - Train Loss: 1.1477, Test Loss: 1.1572\n",
      "Epoch [43/50] - Train Loss: 1.1475, Test Loss: 1.1577\n",
      "Epoch [44/50] - Train Loss: 1.1473, Test Loss: 1.1582\n",
      "Epoch [45/50] - Train Loss: 1.1471, Test Loss: 1.1587\n",
      "Epoch [46/50] - Train Loss: 1.1468, Test Loss: 1.1592\n",
      "Epoch [47/50] - Train Loss: 1.1466, Test Loss: 1.1598\n",
      "Epoch [48/50] - Train Loss: 1.1462, Test Loss: 1.1604\n",
      "Epoch [49/50] - Train Loss: 1.1458, Test Loss: 1.1610\n",
      "Epoch [50/50] - Train Loss: 1.1454, Test Loss: 1.1617\n",
      "Avg Test Loss: 1.1617\n",
      "Testing combination: (32, 3, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.4895, Test Loss: 1.7368\n",
      "Epoch [2/50] - Train Loss: 1.4891, Test Loss: 1.7368\n",
      "Epoch [3/50] - Train Loss: 1.4890, Test Loss: 1.7367\n",
      "Epoch [4/50] - Train Loss: 1.4889, Test Loss: 1.7367\n",
      "Epoch [5/50] - Train Loss: 1.4887, Test Loss: 1.7366\n",
      "Epoch [6/50] - Train Loss: 1.4886, Test Loss: 1.7366\n",
      "Epoch [7/50] - Train Loss: 1.4885, Test Loss: 1.7365\n",
      "Epoch [8/50] - Train Loss: 1.4884, Test Loss: 1.7364\n",
      "Epoch [9/50] - Train Loss: 1.4883, Test Loss: 1.7364\n",
      "Epoch [10/50] - Train Loss: 1.4882, Test Loss: 1.7364\n",
      "Epoch [11/50] - Train Loss: 1.4881, Test Loss: 1.7363\n",
      "Epoch [12/50] - Train Loss: 1.4880, Test Loss: 1.7363\n",
      "Epoch [13/50] - Train Loss: 1.4879, Test Loss: 1.7363\n",
      "Epoch [14/50] - Train Loss: 1.4878, Test Loss: 1.7362\n",
      "Epoch [15/50] - Train Loss: 1.4877, Test Loss: 1.7362\n",
      "Epoch [16/50] - Train Loss: 1.4876, Test Loss: 1.7362\n",
      "Epoch [17/50] - Train Loss: 1.4875, Test Loss: 1.7362\n",
      "Epoch [18/50] - Train Loss: 1.4874, Test Loss: 1.7362\n",
      "Epoch [19/50] - Train Loss: 1.4873, Test Loss: 1.7362\n",
      "Epoch [20/50] - Train Loss: 1.4872, Test Loss: 1.7362\n",
      "Epoch [21/50] - Train Loss: 1.4872, Test Loss: 1.7362\n",
      "Epoch [22/50] - Train Loss: 1.4871, Test Loss: 1.7362\n",
      "Epoch [23/50] - Train Loss: 1.4870, Test Loss: 1.7362\n",
      "Epoch [24/50] - Train Loss: 1.4869, Test Loss: 1.7362\n",
      "Epoch [25/50] - Train Loss: 1.4868, Test Loss: 1.7363\n",
      "Epoch [26/50] - Train Loss: 1.4868, Test Loss: 1.7363\n",
      "Epoch [27/50] - Train Loss: 1.4867, Test Loss: 1.7363\n",
      "Epoch [28/50] - Train Loss: 1.4866, Test Loss: 1.7364\n",
      "Epoch [29/50] - Train Loss: 1.4865, Test Loss: 1.7364\n",
      "Epoch [30/50] - Train Loss: 1.4865, Test Loss: 1.7365\n",
      "Epoch [31/50] - Train Loss: 1.4864, Test Loss: 1.7365\n",
      "Epoch [32/50] - Train Loss: 1.4863, Test Loss: 1.7366\n",
      "Epoch [33/50] - Train Loss: 1.4863, Test Loss: 1.7367\n",
      "Epoch [34/50] - Train Loss: 1.4862, Test Loss: 1.7367\n",
      "Epoch [35/50] - Train Loss: 1.4861, Test Loss: 1.7368\n",
      "Epoch [36/50] - Train Loss: 1.4860, Test Loss: 1.7369\n",
      "Epoch [37/50] - Train Loss: 1.4860, Test Loss: 1.7370\n",
      "Epoch [38/50] - Train Loss: 1.4859, Test Loss: 1.7371\n",
      "Epoch [39/50] - Train Loss: 1.4858, Test Loss: 1.7373\n",
      "Epoch [40/50] - Train Loss: 1.4858, Test Loss: 1.7374\n",
      "Epoch [41/50] - Train Loss: 1.4857, Test Loss: 1.7375\n",
      "Epoch [42/50] - Train Loss: 1.4856, Test Loss: 1.7377\n",
      "Epoch [43/50] - Train Loss: 1.4856, Test Loss: 1.7378\n",
      "Epoch [44/50] - Train Loss: 1.4855, Test Loss: 1.7380\n",
      "Epoch [45/50] - Train Loss: 1.4854, Test Loss: 1.7382\n",
      "Epoch [46/50] - Train Loss: 1.4853, Test Loss: 1.7384\n",
      "Epoch [47/50] - Train Loss: 1.4852, Test Loss: 1.7386\n",
      "Epoch [48/50] - Train Loss: 1.4852, Test Loss: 1.7388\n",
      "Epoch [49/50] - Train Loss: 1.4851, Test Loss: 1.7391\n",
      "Epoch [50/50] - Train Loss: 1.4850, Test Loss: 1.7394\n",
      "Avg Test Loss: 1.7394\n",
      "Testing combination: (32, 4, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1742, Test Loss: 1.0973\n",
      "Epoch [2/50] - Train Loss: 1.1171, Test Loss: 1.0856\n",
      "Epoch [3/50] - Train Loss: 1.1182, Test Loss: 1.0851\n",
      "Epoch [4/50] - Train Loss: 1.1179, Test Loss: 1.0866\n",
      "Epoch [5/50] - Train Loss: 1.1158, Test Loss: 1.0913\n",
      "Epoch [6/50] - Train Loss: 1.1093, Test Loss: 1.1302\n",
      "Epoch [7/50] - Train Loss: 1.0966, Test Loss: 1.1208\n",
      "Epoch [8/50] - Train Loss: 1.2464, Test Loss: 1.0815\n",
      "Epoch [9/50] - Train Loss: 1.1334, Test Loss: 1.0806\n",
      "Epoch [10/50] - Train Loss: 1.1242, Test Loss: 1.0842\n",
      "Epoch [11/50] - Train Loss: 1.1199, Test Loss: 1.0883\n",
      "Epoch [12/50] - Train Loss: 1.1185, Test Loss: 1.0884\n",
      "Epoch [13/50] - Train Loss: 1.1179, Test Loss: 1.0872\n",
      "Epoch [14/50] - Train Loss: 1.1177, Test Loss: 1.0865\n",
      "Epoch [15/50] - Train Loss: 1.1178, Test Loss: 1.0862\n",
      "Epoch [16/50] - Train Loss: 1.1178, Test Loss: 1.0863\n",
      "Epoch [17/50] - Train Loss: 1.1177, Test Loss: 1.0864\n",
      "Epoch [18/50] - Train Loss: 1.1177, Test Loss: 1.0866\n",
      "Epoch [19/50] - Train Loss: 1.1176, Test Loss: 1.0866\n",
      "Epoch [20/50] - Train Loss: 1.1175, Test Loss: 1.0867\n",
      "Epoch [21/50] - Train Loss: 1.1175, Test Loss: 1.0867\n",
      "Epoch [22/50] - Train Loss: 1.1175, Test Loss: 1.0867\n",
      "Epoch [23/50] - Train Loss: 1.1174, Test Loss: 1.0867\n",
      "Epoch [24/50] - Train Loss: 1.1174, Test Loss: 1.0867\n",
      "Epoch [25/50] - Train Loss: 1.1173, Test Loss: 1.0867\n",
      "Epoch [26/50] - Train Loss: 1.1173, Test Loss: 1.0867\n",
      "Epoch [27/50] - Train Loss: 1.1173, Test Loss: 1.0867\n",
      "Epoch [28/50] - Train Loss: 1.1175, Test Loss: 1.0867\n",
      "Epoch [29/50] - Train Loss: 1.1173, Test Loss: 1.0868\n",
      "Epoch [30/50] - Train Loss: 1.1172, Test Loss: 1.0868\n",
      "Epoch [31/50] - Train Loss: 1.1172, Test Loss: 1.0868\n",
      "Epoch [32/50] - Train Loss: 1.1173, Test Loss: 1.0868\n",
      "Epoch [33/50] - Train Loss: 1.1172, Test Loss: 1.0868\n",
      "Epoch [34/50] - Train Loss: 1.1169, Test Loss: 1.0872\n",
      "Epoch [35/50] - Train Loss: 1.1170, Test Loss: 1.0869\n",
      "Epoch [36/50] - Train Loss: 1.1171, Test Loss: 1.0869\n",
      "Epoch [37/50] - Train Loss: 1.1170, Test Loss: 1.0869\n",
      "Epoch [38/50] - Train Loss: 1.1169, Test Loss: 1.0869\n",
      "Epoch [39/50] - Train Loss: 1.1168, Test Loss: 1.0869\n",
      "Epoch [40/50] - Train Loss: 1.1167, Test Loss: 1.0869\n",
      "Epoch [41/50] - Train Loss: 1.1164, Test Loss: 1.0867\n",
      "Epoch [42/50] - Train Loss: 1.1160, Test Loss: 1.0867\n",
      "Epoch [43/50] - Train Loss: 1.1156, Test Loss: 1.0865\n",
      "Epoch [44/50] - Train Loss: 1.1164, Test Loss: 1.0874\n",
      "Epoch [45/50] - Train Loss: 1.1153, Test Loss: 1.0878\n",
      "Epoch [46/50] - Train Loss: 1.1131, Test Loss: 1.0869\n",
      "Epoch [47/50] - Train Loss: 1.1064, Test Loss: 1.1090\n",
      "Epoch [48/50] - Train Loss: 1.1636, Test Loss: 1.1243\n",
      "Epoch [49/50] - Train Loss: 1.1174, Test Loss: 1.0829\n",
      "Epoch [50/50] - Train Loss: 1.1205, Test Loss: 1.0815\n",
      "Avg Test Loss: 1.0815\n",
      "Testing combination: (32, 4, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.2318, Test Loss: 1.1327\n",
      "Epoch [2/50] - Train Loss: 1.1589, Test Loss: 1.1375\n",
      "Epoch [3/50] - Train Loss: 1.1539, Test Loss: 1.1499\n",
      "Epoch [4/50] - Train Loss: 1.1480, Test Loss: 1.1640\n",
      "Epoch [5/50] - Train Loss: 1.1166, Test Loss: 1.1812\n",
      "Epoch [6/50] - Train Loss: 1.0834, Test Loss: 1.2185\n",
      "Epoch [7/50] - Train Loss: 1.0585, Test Loss: 1.2431\n",
      "Epoch [8/50] - Train Loss: 1.1116, Test Loss: 1.1953\n",
      "Epoch [9/50] - Train Loss: 1.0727, Test Loss: 1.2187\n",
      "Epoch [10/50] - Train Loss: 1.0505, Test Loss: 1.2674\n",
      "Epoch [11/50] - Train Loss: 1.0516, Test Loss: 1.2891\n",
      "Epoch [12/50] - Train Loss: 1.0491, Test Loss: 1.2707\n",
      "Epoch [13/50] - Train Loss: 1.0483, Test Loss: 1.2575\n",
      "Epoch [14/50] - Train Loss: 1.0481, Test Loss: 1.2596\n",
      "Epoch [15/50] - Train Loss: 1.0478, Test Loss: 1.2669\n",
      "Epoch [16/50] - Train Loss: 1.0478, Test Loss: 1.2691\n",
      "Epoch [17/50] - Train Loss: 1.0476, Test Loss: 1.2666\n",
      "Epoch [18/50] - Train Loss: 1.0476, Test Loss: 1.2654\n",
      "Epoch [19/50] - Train Loss: 1.0475, Test Loss: 1.2667\n",
      "Epoch [20/50] - Train Loss: 1.0474, Test Loss: 1.2673\n",
      "Epoch [21/50] - Train Loss: 1.0474, Test Loss: 1.2668\n",
      "Epoch [22/50] - Train Loss: 1.0473, Test Loss: 1.2666\n",
      "Epoch [23/50] - Train Loss: 1.0473, Test Loss: 1.2670\n",
      "Epoch [24/50] - Train Loss: 1.0472, Test Loss: 1.2670\n",
      "Epoch [25/50] - Train Loss: 1.0472, Test Loss: 1.2669\n",
      "Epoch [26/50] - Train Loss: 1.0471, Test Loss: 1.2669\n",
      "Epoch [27/50] - Train Loss: 1.0470, Test Loss: 1.2667\n",
      "Epoch [28/50] - Train Loss: 1.0468, Test Loss: 1.2664\n",
      "Epoch [29/50] - Train Loss: 1.0463, Test Loss: 1.2651\n",
      "Epoch [30/50] - Train Loss: 1.0443, Test Loss: 1.2629\n",
      "Epoch [31/50] - Train Loss: 1.0396, Test Loss: 1.2588\n",
      "Epoch [32/50] - Train Loss: 1.0445, Test Loss: 1.2656\n",
      "Epoch [33/50] - Train Loss: 1.0470, Test Loss: 1.2597\n",
      "Epoch [34/50] - Train Loss: 1.0417, Test Loss: 1.2703\n",
      "Epoch [35/50] - Train Loss: 1.0395, Test Loss: 1.2585\n",
      "Epoch [36/50] - Train Loss: 1.0389, Test Loss: 1.2539\n",
      "Epoch [37/50] - Train Loss: 1.0385, Test Loss: 1.2569\n",
      "Epoch [38/50] - Train Loss: 1.0383, Test Loss: 1.2532\n",
      "Epoch [39/50] - Train Loss: 1.0385, Test Loss: 1.2531\n",
      "Epoch [40/50] - Train Loss: 1.0378, Test Loss: 1.2566\n",
      "Epoch [41/50] - Train Loss: 1.0377, Test Loss: 1.2576\n",
      "Epoch [42/50] - Train Loss: 1.0377, Test Loss: 1.2538\n",
      "Epoch [43/50] - Train Loss: 1.0376, Test Loss: 1.2507\n",
      "Epoch [44/50] - Train Loss: 1.0381, Test Loss: 1.2537\n",
      "Epoch [45/50] - Train Loss: 1.0372, Test Loss: 1.2555\n",
      "Epoch [46/50] - Train Loss: 1.0372, Test Loss: 1.2523\n",
      "Epoch [47/50] - Train Loss: 1.0380, Test Loss: 1.2513\n",
      "Epoch [48/50] - Train Loss: 1.0367, Test Loss: 1.2539\n",
      "Epoch [49/50] - Train Loss: 1.0371, Test Loss: 1.2537\n",
      "Epoch [50/50] - Train Loss: 1.0375, Test Loss: 1.2514\n",
      "Avg Test Loss: 1.2514\n",
      "Testing combination: (32, 4, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5322, Test Loss: 1.7380\n",
      "Epoch [2/50] - Train Loss: 1.4858, Test Loss: 1.7332\n",
      "Epoch [3/50] - Train Loss: 1.4849, Test Loss: 1.7333\n",
      "Epoch [4/50] - Train Loss: 1.4858, Test Loss: 1.7340\n",
      "Epoch [5/50] - Train Loss: 1.4865, Test Loss: 1.7347\n",
      "Epoch [6/50] - Train Loss: 1.4863, Test Loss: 1.7361\n",
      "Epoch [7/50] - Train Loss: 1.4835, Test Loss: 1.7422\n",
      "Epoch [8/50] - Train Loss: 1.4968, Test Loss: 1.7392\n",
      "Epoch [9/50] - Train Loss: 1.4834, Test Loss: 1.7386\n",
      "Epoch [10/50] - Train Loss: 1.4826, Test Loss: 1.7411\n",
      "Epoch [11/50] - Train Loss: 1.4785, Test Loss: 1.7501\n",
      "Epoch [12/50] - Train Loss: 1.4659, Test Loss: 1.7804\n",
      "Epoch [13/50] - Train Loss: 1.4342, Test Loss: 1.8791\n",
      "Epoch [14/50] - Train Loss: 1.4391, Test Loss: 1.9073\n",
      "Epoch [15/50] - Train Loss: 1.4410, Test Loss: 1.9182\n",
      "Epoch [16/50] - Train Loss: 1.4373, Test Loss: 1.9930\n",
      "Epoch [17/50] - Train Loss: 1.4312, Test Loss: 2.0944\n",
      "Epoch [18/50] - Train Loss: 1.4321, Test Loss: 2.1374\n",
      "Epoch [19/50] - Train Loss: 1.4316, Test Loss: 2.1077\n",
      "Epoch [20/50] - Train Loss: 1.4294, Test Loss: 2.0626\n",
      "Epoch [21/50] - Train Loss: 1.4289, Test Loss: 2.0352\n",
      "Epoch [22/50] - Train Loss: 1.4286, Test Loss: 2.0312\n",
      "Epoch [23/50] - Train Loss: 1.4281, Test Loss: 2.0439\n",
      "Epoch [24/50] - Train Loss: 1.4278, Test Loss: 2.0613\n",
      "Epoch [25/50] - Train Loss: 1.4277, Test Loss: 2.0733\n",
      "Epoch [26/50] - Train Loss: 1.4277, Test Loss: 2.0755\n",
      "Epoch [27/50] - Train Loss: 1.4275, Test Loss: 2.0701\n",
      "Epoch [28/50] - Train Loss: 1.4272, Test Loss: 2.0622\n",
      "Epoch [29/50] - Train Loss: 1.4264, Test Loss: 2.0568\n",
      "Epoch [30/50] - Train Loss: 1.4246, Test Loss: 2.0552\n",
      "Epoch [31/50] - Train Loss: 1.4233, Test Loss: 2.0523\n",
      "Epoch [32/50] - Train Loss: 1.4186, Test Loss: 2.0521\n",
      "Epoch [33/50] - Train Loss: 1.4165, Test Loss: 2.0635\n",
      "Epoch [34/50] - Train Loss: 1.4139, Test Loss: 2.0566\n",
      "Epoch [35/50] - Train Loss: 1.4110, Test Loss: 2.0697\n",
      "Epoch [36/50] - Train Loss: 1.4117, Test Loss: 2.0869\n",
      "Epoch [37/50] - Train Loss: 1.4148, Test Loss: 2.0496\n",
      "Epoch [38/50] - Train Loss: 1.4098, Test Loss: 2.0607\n",
      "Epoch [39/50] - Train Loss: 1.4123, Test Loss: 2.0959\n",
      "Epoch [40/50] - Train Loss: 1.4120, Test Loss: 2.0210\n",
      "Epoch [41/50] - Train Loss: 1.4147, Test Loss: 2.0564\n",
      "Epoch [42/50] - Train Loss: 1.4145, Test Loss: 2.1161\n",
      "Epoch [43/50] - Train Loss: 1.4133, Test Loss: 2.0982\n",
      "Epoch [44/50] - Train Loss: 1.4130, Test Loss: 2.0636\n",
      "Epoch [45/50] - Train Loss: 1.4124, Test Loss: 2.0387\n",
      "Epoch [46/50] - Train Loss: 1.4084, Test Loss: 2.0670\n",
      "Epoch [47/50] - Train Loss: 1.4074, Test Loss: 2.0356\n",
      "Epoch [48/50] - Train Loss: 1.4041, Test Loss: 2.0534\n",
      "Epoch [49/50] - Train Loss: 1.4053, Test Loss: 2.1365\n",
      "Epoch [50/50] - Train Loss: 1.3981, Test Loss: 2.0697\n",
      "Avg Test Loss: 2.0697\n",
      "Testing combination: (32, 4, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1206, Test Loss: 1.0901\n",
      "Epoch [2/50] - Train Loss: 1.1171, Test Loss: 1.0896\n",
      "Epoch [3/50] - Train Loss: 1.1167, Test Loss: 1.0890\n",
      "Epoch [4/50] - Train Loss: 1.1164, Test Loss: 1.0886\n",
      "Epoch [5/50] - Train Loss: 1.1162, Test Loss: 1.0885\n",
      "Epoch [6/50] - Train Loss: 1.1158, Test Loss: 1.0888\n",
      "Epoch [7/50] - Train Loss: 1.1151, Test Loss: 1.0896\n",
      "Epoch [8/50] - Train Loss: 1.1136, Test Loss: 1.0911\n",
      "Epoch [9/50] - Train Loss: 1.1103, Test Loss: 1.0944\n",
      "Epoch [10/50] - Train Loss: 1.1028, Test Loss: 1.1023\n",
      "Epoch [11/50] - Train Loss: 1.0875, Test Loss: 1.1217\n",
      "Epoch [12/50] - Train Loss: 1.0845, Test Loss: 1.1278\n",
      "Epoch [13/50] - Train Loss: 1.0769, Test Loss: 1.1453\n",
      "Epoch [14/50] - Train Loss: 1.0765, Test Loss: 1.1578\n",
      "Epoch [15/50] - Train Loss: 1.0791, Test Loss: 1.1566\n",
      "Epoch [16/50] - Train Loss: 1.0771, Test Loss: 1.1551\n",
      "Epoch [17/50] - Train Loss: 1.0752, Test Loss: 1.1577\n",
      "Epoch [18/50] - Train Loss: 1.0742, Test Loss: 1.1617\n",
      "Epoch [19/50] - Train Loss: 1.0733, Test Loss: 1.1658\n",
      "Epoch [20/50] - Train Loss: 1.0719, Test Loss: 1.1711\n",
      "Epoch [21/50] - Train Loss: 1.0703, Test Loss: 1.1781\n",
      "Epoch [22/50] - Train Loss: 1.0687, Test Loss: 1.1861\n",
      "Epoch [23/50] - Train Loss: 1.0667, Test Loss: 1.1952\n",
      "Epoch [24/50] - Train Loss: 1.0636, Test Loss: 1.2065\n",
      "Epoch [25/50] - Train Loss: 1.0596, Test Loss: 1.2180\n",
      "Epoch [26/50] - Train Loss: 1.0633, Test Loss: 1.2113\n",
      "Epoch [27/50] - Train Loss: 1.0535, Test Loss: 1.2401\n",
      "Epoch [28/50] - Train Loss: 1.0443, Test Loss: 1.2043\n",
      "Epoch [29/50] - Train Loss: 1.0585, Test Loss: 1.1960\n",
      "Epoch [30/50] - Train Loss: 1.0464, Test Loss: 1.1857\n",
      "Epoch [31/50] - Train Loss: 1.0511, Test Loss: 1.2576\n",
      "Epoch [32/50] - Train Loss: 1.0146, Test Loss: 1.1960\n",
      "Epoch [33/50] - Train Loss: 1.0530, Test Loss: 1.1801\n",
      "Epoch [34/50] - Train Loss: 1.0054, Test Loss: 1.1676\n",
      "Epoch [35/50] - Train Loss: 1.0647, Test Loss: 1.1384\n",
      "Epoch [36/50] - Train Loss: 0.9973, Test Loss: 1.1610\n",
      "Epoch [37/50] - Train Loss: 1.0387, Test Loss: 1.1867\n",
      "Epoch [38/50] - Train Loss: 1.0378, Test Loss: 1.1676\n",
      "Epoch [39/50] - Train Loss: 0.9596, Test Loss: 1.3667\n",
      "Epoch [40/50] - Train Loss: 0.9164, Test Loss: 1.3665\n",
      "Epoch [41/50] - Train Loss: 0.9316, Test Loss: 1.1776\n",
      "Epoch [42/50] - Train Loss: 0.8545, Test Loss: 1.4820\n",
      "Epoch [43/50] - Train Loss: 0.8766, Test Loss: 1.3654\n",
      "Epoch [44/50] - Train Loss: 0.8185, Test Loss: 1.3735\n",
      "Epoch [45/50] - Train Loss: 0.8120, Test Loss: 1.4346\n",
      "Epoch [46/50] - Train Loss: 0.7845, Test Loss: 1.6038\n",
      "Epoch [47/50] - Train Loss: 0.7978, Test Loss: 1.4483\n",
      "Epoch [48/50] - Train Loss: 0.8495, Test Loss: 1.3048\n",
      "Epoch [49/50] - Train Loss: 0.8383, Test Loss: 1.5493\n",
      "Epoch [50/50] - Train Loss: 0.7958, Test Loss: 2.0708\n",
      "Avg Test Loss: 2.0708\n",
      "Testing combination: (32, 4, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1836, Test Loss: 1.1229\n",
      "Epoch [2/50] - Train Loss: 1.1678, Test Loss: 1.1277\n",
      "Epoch [3/50] - Train Loss: 1.1591, Test Loss: 1.1347\n",
      "Epoch [4/50] - Train Loss: 1.1532, Test Loss: 1.1433\n",
      "Epoch [5/50] - Train Loss: 1.1494, Test Loss: 1.1523\n",
      "Epoch [6/50] - Train Loss: 1.1463, Test Loss: 1.1612\n",
      "Epoch [7/50] - Train Loss: 1.1424, Test Loss: 1.1698\n",
      "Epoch [8/50] - Train Loss: 1.1348, Test Loss: 1.1796\n",
      "Epoch [9/50] - Train Loss: 1.1195, Test Loss: 1.1924\n",
      "Epoch [10/50] - Train Loss: 1.0956, Test Loss: 1.2085\n",
      "Epoch [11/50] - Train Loss: 1.0700, Test Loss: 1.2244\n",
      "Epoch [12/50] - Train Loss: 1.0564, Test Loss: 1.2357\n",
      "Epoch [13/50] - Train Loss: 1.0524, Test Loss: 1.2444\n",
      "Epoch [14/50] - Train Loss: 1.0499, Test Loss: 1.2521\n",
      "Epoch [15/50] - Train Loss: 1.0475, Test Loss: 1.2607\n",
      "Epoch [16/50] - Train Loss: 1.0462, Test Loss: 1.2700\n",
      "Epoch [17/50] - Train Loss: 1.0456, Test Loss: 1.2765\n",
      "Epoch [18/50] - Train Loss: 1.0450, Test Loss: 1.2789\n",
      "Epoch [19/50] - Train Loss: 1.0444, Test Loss: 1.2797\n",
      "Epoch [20/50] - Train Loss: 1.0435, Test Loss: 1.2798\n",
      "Epoch [21/50] - Train Loss: 1.0421, Test Loss: 1.2777\n",
      "Epoch [22/50] - Train Loss: 1.0394, Test Loss: 1.2744\n",
      "Epoch [23/50] - Train Loss: 1.0355, Test Loss: 1.2673\n",
      "Epoch [24/50] - Train Loss: 1.0339, Test Loss: 1.2554\n",
      "Epoch [25/50] - Train Loss: 1.0352, Test Loss: 1.2493\n",
      "Epoch [26/50] - Train Loss: 1.0365, Test Loss: 1.2781\n",
      "Epoch [27/50] - Train Loss: 1.0495, Test Loss: 1.2507\n",
      "Epoch [28/50] - Train Loss: 1.0397, Test Loss: 1.2656\n",
      "Epoch [29/50] - Train Loss: 1.0352, Test Loss: 1.2856\n",
      "Epoch [30/50] - Train Loss: 1.0321, Test Loss: 1.2608\n",
      "Epoch [31/50] - Train Loss: 1.0303, Test Loss: 1.2588\n",
      "Epoch [32/50] - Train Loss: 1.0415, Test Loss: 1.2286\n",
      "Epoch [33/50] - Train Loss: 1.0132, Test Loss: 1.2381\n",
      "Epoch [34/50] - Train Loss: 1.0326, Test Loss: 1.3048\n",
      "Epoch [35/50] - Train Loss: 0.9756, Test Loss: 1.2776\n",
      "Epoch [36/50] - Train Loss: 1.0155, Test Loss: 1.2313\n",
      "Epoch [37/50] - Train Loss: 1.0069, Test Loss: 1.2632\n",
      "Epoch [38/50] - Train Loss: 0.9789, Test Loss: 1.2749\n",
      "Epoch [39/50] - Train Loss: 0.9838, Test Loss: 1.3408\n",
      "Epoch [40/50] - Train Loss: 1.1003, Test Loss: 1.2526\n",
      "Epoch [41/50] - Train Loss: 1.0544, Test Loss: 1.2283\n",
      "Epoch [42/50] - Train Loss: 1.0506, Test Loss: 1.2436\n",
      "Epoch [43/50] - Train Loss: 1.0437, Test Loss: 1.2573\n",
      "Epoch [44/50] - Train Loss: 1.0371, Test Loss: 1.2665\n",
      "Epoch [45/50] - Train Loss: 1.0317, Test Loss: 1.2661\n",
      "Epoch [46/50] - Train Loss: 1.0246, Test Loss: 1.2575\n",
      "Epoch [47/50] - Train Loss: 1.0135, Test Loss: 1.2466\n",
      "Epoch [48/50] - Train Loss: 0.9938, Test Loss: 1.2398\n",
      "Epoch [49/50] - Train Loss: 0.9611, Test Loss: 1.2014\n",
      "Epoch [50/50] - Train Loss: 0.9625, Test Loss: 1.2953\n",
      "Avg Test Loss: 1.2953\n",
      "Testing combination: (32, 4, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.4944, Test Loss: 1.7362\n",
      "Epoch [2/50] - Train Loss: 1.4885, Test Loss: 1.7350\n",
      "Epoch [3/50] - Train Loss: 1.4873, Test Loss: 1.7344\n",
      "Epoch [4/50] - Train Loss: 1.4867, Test Loss: 1.7342\n",
      "Epoch [5/50] - Train Loss: 1.4863, Test Loss: 1.7342\n",
      "Epoch [6/50] - Train Loss: 1.4860, Test Loss: 1.7344\n",
      "Epoch [7/50] - Train Loss: 1.4857, Test Loss: 1.7347\n",
      "Epoch [8/50] - Train Loss: 1.4855, Test Loss: 1.7352\n",
      "Epoch [9/50] - Train Loss: 1.4851, Test Loss: 1.7359\n",
      "Epoch [10/50] - Train Loss: 1.4846, Test Loss: 1.7369\n",
      "Epoch [11/50] - Train Loss: 1.4839, Test Loss: 1.7384\n",
      "Epoch [12/50] - Train Loss: 1.4827, Test Loss: 1.7405\n",
      "Epoch [13/50] - Train Loss: 1.4808, Test Loss: 1.7435\n",
      "Epoch [14/50] - Train Loss: 1.4781, Test Loss: 1.7479\n",
      "Epoch [15/50] - Train Loss: 1.4740, Test Loss: 1.7545\n",
      "Epoch [16/50] - Train Loss: 1.4679, Test Loss: 1.7649\n",
      "Epoch [17/50] - Train Loss: 1.4587, Test Loss: 1.7820\n",
      "Epoch [18/50] - Train Loss: 1.4473, Test Loss: 1.8092\n",
      "Epoch [19/50] - Train Loss: 1.4362, Test Loss: 1.8398\n",
      "Epoch [20/50] - Train Loss: 1.4271, Test Loss: 1.8681\n",
      "Epoch [21/50] - Train Loss: 1.4231, Test Loss: 1.8934\n",
      "Epoch [22/50] - Train Loss: 1.4228, Test Loss: 1.9126\n",
      "Epoch [23/50] - Train Loss: 1.4236, Test Loss: 1.9249\n",
      "Epoch [24/50] - Train Loss: 1.4242, Test Loss: 1.9323\n",
      "Epoch [25/50] - Train Loss: 1.4243, Test Loss: 1.9375\n",
      "Epoch [26/50] - Train Loss: 1.4240, Test Loss: 1.9422\n",
      "Epoch [27/50] - Train Loss: 1.4233, Test Loss: 1.9468\n",
      "Epoch [28/50] - Train Loss: 1.4226, Test Loss: 1.9512\n",
      "Epoch [29/50] - Train Loss: 1.4219, Test Loss: 1.9550\n",
      "Epoch [30/50] - Train Loss: 1.4210, Test Loss: 1.9588\n",
      "Epoch [31/50] - Train Loss: 1.4199, Test Loss: 1.9634\n",
      "Epoch [32/50] - Train Loss: 1.4187, Test Loss: 1.9701\n",
      "Epoch [33/50] - Train Loss: 1.4174, Test Loss: 1.9794\n",
      "Epoch [34/50] - Train Loss: 1.4160, Test Loss: 1.9912\n",
      "Epoch [35/50] - Train Loss: 1.4143, Test Loss: 2.0047\n",
      "Epoch [36/50] - Train Loss: 1.4125, Test Loss: 2.0196\n",
      "Epoch [37/50] - Train Loss: 1.4103, Test Loss: 2.0357\n",
      "Epoch [38/50] - Train Loss: 1.4074, Test Loss: 2.0513\n",
      "Epoch [39/50] - Train Loss: 1.4033, Test Loss: 2.0658\n",
      "Epoch [40/50] - Train Loss: 1.3988, Test Loss: 2.0966\n",
      "Epoch [41/50] - Train Loss: 1.3953, Test Loss: 2.1601\n",
      "Epoch [42/50] - Train Loss: 1.3794, Test Loss: 2.1056\n",
      "Epoch [43/50] - Train Loss: 1.3785, Test Loss: 2.1316\n",
      "Epoch [44/50] - Train Loss: 1.3824, Test Loss: 1.8644\n",
      "Epoch [45/50] - Train Loss: 1.6676, Test Loss: 2.1912\n",
      "Epoch [46/50] - Train Loss: 1.2990, Test Loss: 1.9284\n",
      "Epoch [47/50] - Train Loss: 1.3991, Test Loss: 1.9025\n",
      "Epoch [48/50] - Train Loss: 1.3981, Test Loss: 1.9037\n",
      "Epoch [49/50] - Train Loss: 1.3936, Test Loss: 1.9166\n",
      "Epoch [50/50] - Train Loss: 1.3822, Test Loss: 1.9220\n",
      "Avg Test Loss: 1.9220\n",
      "Testing combination: (32, 4, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1185, Test Loss: 1.0819\n",
      "Epoch [2/50] - Train Loss: 1.1179, Test Loss: 1.0821\n",
      "Epoch [3/50] - Train Loss: 1.1177, Test Loss: 1.0822\n",
      "Epoch [4/50] - Train Loss: 1.1175, Test Loss: 1.0824\n",
      "Epoch [5/50] - Train Loss: 1.1174, Test Loss: 1.0825\n",
      "Epoch [6/50] - Train Loss: 1.1173, Test Loss: 1.0826\n",
      "Epoch [7/50] - Train Loss: 1.1172, Test Loss: 1.0828\n",
      "Epoch [8/50] - Train Loss: 1.1171, Test Loss: 1.0829\n",
      "Epoch [9/50] - Train Loss: 1.1170, Test Loss: 1.0831\n",
      "Epoch [10/50] - Train Loss: 1.1170, Test Loss: 1.0832\n",
      "Epoch [11/50] - Train Loss: 1.1169, Test Loss: 1.0833\n",
      "Epoch [12/50] - Train Loss: 1.1168, Test Loss: 1.0834\n",
      "Epoch [13/50] - Train Loss: 1.1167, Test Loss: 1.0836\n",
      "Epoch [14/50] - Train Loss: 1.1167, Test Loss: 1.0837\n",
      "Epoch [15/50] - Train Loss: 1.1166, Test Loss: 1.0838\n",
      "Epoch [16/50] - Train Loss: 1.1165, Test Loss: 1.0840\n",
      "Epoch [17/50] - Train Loss: 1.1165, Test Loss: 1.0841\n",
      "Epoch [18/50] - Train Loss: 1.1164, Test Loss: 1.0842\n",
      "Epoch [19/50] - Train Loss: 1.1164, Test Loss: 1.0843\n",
      "Epoch [20/50] - Train Loss: 1.1163, Test Loss: 1.0845\n",
      "Epoch [21/50] - Train Loss: 1.1163, Test Loss: 1.0846\n",
      "Epoch [22/50] - Train Loss: 1.1162, Test Loss: 1.0847\n",
      "Epoch [23/50] - Train Loss: 1.1162, Test Loss: 1.0848\n",
      "Epoch [24/50] - Train Loss: 1.1161, Test Loss: 1.0850\n",
      "Epoch [25/50] - Train Loss: 1.1161, Test Loss: 1.0851\n",
      "Epoch [26/50] - Train Loss: 1.1160, Test Loss: 1.0852\n",
      "Epoch [27/50] - Train Loss: 1.1159, Test Loss: 1.0854\n",
      "Epoch [28/50] - Train Loss: 1.1159, Test Loss: 1.0855\n",
      "Epoch [29/50] - Train Loss: 1.1158, Test Loss: 1.0856\n",
      "Epoch [30/50] - Train Loss: 1.1158, Test Loss: 1.0858\n",
      "Epoch [31/50] - Train Loss: 1.1157, Test Loss: 1.0859\n",
      "Epoch [32/50] - Train Loss: 1.1156, Test Loss: 1.0861\n",
      "Epoch [33/50] - Train Loss: 1.1155, Test Loss: 1.0862\n",
      "Epoch [34/50] - Train Loss: 1.1154, Test Loss: 1.0864\n",
      "Epoch [35/50] - Train Loss: 1.1153, Test Loss: 1.0866\n",
      "Epoch [36/50] - Train Loss: 1.1152, Test Loss: 1.0868\n",
      "Epoch [37/50] - Train Loss: 1.1150, Test Loss: 1.0870\n",
      "Epoch [38/50] - Train Loss: 1.1149, Test Loss: 1.0872\n",
      "Epoch [39/50] - Train Loss: 1.1147, Test Loss: 1.0874\n",
      "Epoch [40/50] - Train Loss: 1.1145, Test Loss: 1.0877\n",
      "Epoch [41/50] - Train Loss: 1.1142, Test Loss: 1.0880\n",
      "Epoch [42/50] - Train Loss: 1.1140, Test Loss: 1.0883\n",
      "Epoch [43/50] - Train Loss: 1.1136, Test Loss: 1.0886\n",
      "Epoch [44/50] - Train Loss: 1.1133, Test Loss: 1.0890\n",
      "Epoch [45/50] - Train Loss: 1.1128, Test Loss: 1.0894\n",
      "Epoch [46/50] - Train Loss: 1.1123, Test Loss: 1.0899\n",
      "Epoch [47/50] - Train Loss: 1.1117, Test Loss: 1.0904\n",
      "Epoch [48/50] - Train Loss: 1.1109, Test Loss: 1.0911\n",
      "Epoch [49/50] - Train Loss: 1.1100, Test Loss: 1.0918\n",
      "Epoch [50/50] - Train Loss: 1.1090, Test Loss: 1.0927\n",
      "Avg Test Loss: 1.0927\n",
      "Testing combination: (32, 4, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1505, Test Loss: 1.1492\n",
      "Epoch [2/50] - Train Loss: 1.1502, Test Loss: 1.1495\n",
      "Epoch [3/50] - Train Loss: 1.1501, Test Loss: 1.1497\n",
      "Epoch [4/50] - Train Loss: 1.1500, Test Loss: 1.1500\n",
      "Epoch [5/50] - Train Loss: 1.1499, Test Loss: 1.1503\n",
      "Epoch [6/50] - Train Loss: 1.1499, Test Loss: 1.1506\n",
      "Epoch [7/50] - Train Loss: 1.1498, Test Loss: 1.1509\n",
      "Epoch [8/50] - Train Loss: 1.1497, Test Loss: 1.1512\n",
      "Epoch [9/50] - Train Loss: 1.1497, Test Loss: 1.1515\n",
      "Epoch [10/50] - Train Loss: 1.1496, Test Loss: 1.1517\n",
      "Epoch [11/50] - Train Loss: 1.1496, Test Loss: 1.1520\n",
      "Epoch [12/50] - Train Loss: 1.1495, Test Loss: 1.1523\n",
      "Epoch [13/50] - Train Loss: 1.1494, Test Loss: 1.1525\n",
      "Epoch [14/50] - Train Loss: 1.1494, Test Loss: 1.1528\n",
      "Epoch [15/50] - Train Loss: 1.1493, Test Loss: 1.1530\n",
      "Epoch [16/50] - Train Loss: 1.1493, Test Loss: 1.1533\n",
      "Epoch [17/50] - Train Loss: 1.1492, Test Loss: 1.1535\n",
      "Epoch [18/50] - Train Loss: 1.1492, Test Loss: 1.1538\n",
      "Epoch [19/50] - Train Loss: 1.1491, Test Loss: 1.1540\n",
      "Epoch [20/50] - Train Loss: 1.1491, Test Loss: 1.1542\n",
      "Epoch [21/50] - Train Loss: 1.1490, Test Loss: 1.1545\n",
      "Epoch [22/50] - Train Loss: 1.1489, Test Loss: 1.1547\n",
      "Epoch [23/50] - Train Loss: 1.1489, Test Loss: 1.1550\n",
      "Epoch [24/50] - Train Loss: 1.1488, Test Loss: 1.1552\n",
      "Epoch [25/50] - Train Loss: 1.1487, Test Loss: 1.1554\n",
      "Epoch [26/50] - Train Loss: 1.1487, Test Loss: 1.1557\n",
      "Epoch [27/50] - Train Loss: 1.1486, Test Loss: 1.1559\n",
      "Epoch [28/50] - Train Loss: 1.1485, Test Loss: 1.1561\n",
      "Epoch [29/50] - Train Loss: 1.1484, Test Loss: 1.1564\n",
      "Epoch [30/50] - Train Loss: 1.1483, Test Loss: 1.1566\n",
      "Epoch [31/50] - Train Loss: 1.1482, Test Loss: 1.1569\n",
      "Epoch [32/50] - Train Loss: 1.1481, Test Loss: 1.1571\n",
      "Epoch [33/50] - Train Loss: 1.1480, Test Loss: 1.1574\n",
      "Epoch [34/50] - Train Loss: 1.1478, Test Loss: 1.1577\n",
      "Epoch [35/50] - Train Loss: 1.1477, Test Loss: 1.1580\n",
      "Epoch [36/50] - Train Loss: 1.1475, Test Loss: 1.1583\n",
      "Epoch [37/50] - Train Loss: 1.1472, Test Loss: 1.1586\n",
      "Epoch [38/50] - Train Loss: 1.1470, Test Loss: 1.1589\n",
      "Epoch [39/50] - Train Loss: 1.1466, Test Loss: 1.1593\n",
      "Epoch [40/50] - Train Loss: 1.1463, Test Loss: 1.1597\n",
      "Epoch [41/50] - Train Loss: 1.1458, Test Loss: 1.1602\n",
      "Epoch [42/50] - Train Loss: 1.1452, Test Loss: 1.1607\n",
      "Epoch [43/50] - Train Loss: 1.1445, Test Loss: 1.1613\n",
      "Epoch [44/50] - Train Loss: 1.1436, Test Loss: 1.1620\n",
      "Epoch [45/50] - Train Loss: 1.1424, Test Loss: 1.1627\n",
      "Epoch [46/50] - Train Loss: 1.1411, Test Loss: 1.1636\n",
      "Epoch [47/50] - Train Loss: 1.1394, Test Loss: 1.1647\n",
      "Epoch [48/50] - Train Loss: 1.1373, Test Loss: 1.1659\n",
      "Epoch [49/50] - Train Loss: 1.1348, Test Loss: 1.1673\n",
      "Epoch [50/50] - Train Loss: 1.1317, Test Loss: 1.1689\n",
      "Avg Test Loss: 1.1689\n",
      "Testing combination: (32, 4, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.4862, Test Loss: 1.7331\n",
      "Epoch [2/50] - Train Loss: 1.4857, Test Loss: 1.7331\n",
      "Epoch [3/50] - Train Loss: 1.4856, Test Loss: 1.7331\n",
      "Epoch [4/50] - Train Loss: 1.4856, Test Loss: 1.7331\n",
      "Epoch [5/50] - Train Loss: 1.4855, Test Loss: 1.7331\n",
      "Epoch [6/50] - Train Loss: 1.4855, Test Loss: 1.7331\n",
      "Epoch [7/50] - Train Loss: 1.4855, Test Loss: 1.7331\n",
      "Epoch [8/50] - Train Loss: 1.4855, Test Loss: 1.7331\n",
      "Epoch [9/50] - Train Loss: 1.4855, Test Loss: 1.7331\n",
      "Epoch [10/50] - Train Loss: 1.4855, Test Loss: 1.7332\n",
      "Epoch [11/50] - Train Loss: 1.4855, Test Loss: 1.7332\n",
      "Epoch [12/50] - Train Loss: 1.4855, Test Loss: 1.7332\n",
      "Epoch [13/50] - Train Loss: 1.4855, Test Loss: 1.7332\n",
      "Epoch [14/50] - Train Loss: 1.4855, Test Loss: 1.7332\n",
      "Epoch [15/50] - Train Loss: 1.4855, Test Loss: 1.7332\n",
      "Epoch [16/50] - Train Loss: 1.4855, Test Loss: 1.7332\n",
      "Epoch [17/50] - Train Loss: 1.4855, Test Loss: 1.7333\n",
      "Epoch [18/50] - Train Loss: 1.4855, Test Loss: 1.7333\n",
      "Epoch [19/50] - Train Loss: 1.4855, Test Loss: 1.7333\n",
      "Epoch [20/50] - Train Loss: 1.4854, Test Loss: 1.7333\n",
      "Epoch [21/50] - Train Loss: 1.4854, Test Loss: 1.7333\n",
      "Epoch [22/50] - Train Loss: 1.4854, Test Loss: 1.7333\n",
      "Epoch [23/50] - Train Loss: 1.4854, Test Loss: 1.7334\n",
      "Epoch [24/50] - Train Loss: 1.4854, Test Loss: 1.7334\n",
      "Epoch [25/50] - Train Loss: 1.4854, Test Loss: 1.7334\n",
      "Epoch [26/50] - Train Loss: 1.4854, Test Loss: 1.7334\n",
      "Epoch [27/50] - Train Loss: 1.4854, Test Loss: 1.7335\n",
      "Epoch [28/50] - Train Loss: 1.4854, Test Loss: 1.7335\n",
      "Epoch [29/50] - Train Loss: 1.4854, Test Loss: 1.7335\n",
      "Epoch [30/50] - Train Loss: 1.4854, Test Loss: 1.7335\n",
      "Epoch [31/50] - Train Loss: 1.4853, Test Loss: 1.7336\n",
      "Epoch [32/50] - Train Loss: 1.4853, Test Loss: 1.7336\n",
      "Epoch [33/50] - Train Loss: 1.4853, Test Loss: 1.7336\n",
      "Epoch [34/50] - Train Loss: 1.4853, Test Loss: 1.7337\n",
      "Epoch [35/50] - Train Loss: 1.4853, Test Loss: 1.7337\n",
      "Epoch [36/50] - Train Loss: 1.4853, Test Loss: 1.7338\n",
      "Epoch [37/50] - Train Loss: 1.4852, Test Loss: 1.7338\n",
      "Epoch [38/50] - Train Loss: 1.4852, Test Loss: 1.7339\n",
      "Epoch [39/50] - Train Loss: 1.4852, Test Loss: 1.7339\n",
      "Epoch [40/50] - Train Loss: 1.4852, Test Loss: 1.7340\n",
      "Epoch [41/50] - Train Loss: 1.4851, Test Loss: 1.7341\n",
      "Epoch [42/50] - Train Loss: 1.4851, Test Loss: 1.7341\n",
      "Epoch [43/50] - Train Loss: 1.4851, Test Loss: 1.7342\n",
      "Epoch [44/50] - Train Loss: 1.4850, Test Loss: 1.7343\n",
      "Epoch [45/50] - Train Loss: 1.4850, Test Loss: 1.7344\n",
      "Epoch [46/50] - Train Loss: 1.4850, Test Loss: 1.7345\n",
      "Epoch [47/50] - Train Loss: 1.4849, Test Loss: 1.7346\n",
      "Epoch [48/50] - Train Loss: 1.4848, Test Loss: 1.7348\n",
      "Epoch [49/50] - Train Loss: 1.4848, Test Loss: 1.7349\n",
      "Epoch [50/50] - Train Loss: 1.4847, Test Loss: 1.7351\n",
      "Avg Test Loss: 1.7351\n",
      "Testing combination: (64, 1, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1859, Test Loss: 1.0770\n",
      "Epoch [2/50] - Train Loss: 1.1232, Test Loss: 1.0890\n",
      "Epoch [3/50] - Train Loss: 1.1107, Test Loss: 1.1111\n",
      "Epoch [4/50] - Train Loss: 1.0968, Test Loss: 1.1517\n",
      "Epoch [5/50] - Train Loss: 1.0723, Test Loss: 1.1775\n",
      "Epoch [6/50] - Train Loss: 1.1089, Test Loss: 1.1665\n",
      "Epoch [7/50] - Train Loss: 1.0863, Test Loss: 1.1738\n",
      "Epoch [8/50] - Train Loss: 1.0763, Test Loss: 1.1840\n",
      "Epoch [9/50] - Train Loss: 1.0750, Test Loss: 1.1941\n",
      "Epoch [10/50] - Train Loss: 1.0851, Test Loss: 1.1790\n",
      "Epoch [11/50] - Train Loss: 1.0856, Test Loss: 1.1787\n",
      "Epoch [12/50] - Train Loss: 1.0715, Test Loss: 1.1869\n",
      "Epoch [13/50] - Train Loss: 1.0672, Test Loss: 1.1896\n",
      "Epoch [14/50] - Train Loss: 1.0643, Test Loss: 1.1845\n",
      "Epoch [15/50] - Train Loss: 1.0646, Test Loss: 1.1827\n",
      "Epoch [16/50] - Train Loss: 1.0642, Test Loss: 1.1839\n",
      "Epoch [17/50] - Train Loss: 1.0651, Test Loss: 1.1858\n",
      "Epoch [18/50] - Train Loss: 1.0641, Test Loss: 1.1871\n",
      "Epoch [19/50] - Train Loss: 1.0641, Test Loss: 1.1866\n",
      "Epoch [20/50] - Train Loss: 1.0673, Test Loss: 1.1840\n",
      "Epoch [21/50] - Train Loss: 1.0669, Test Loss: 1.1884\n",
      "Epoch [22/50] - Train Loss: 1.0659, Test Loss: 1.1923\n",
      "Epoch [23/50] - Train Loss: 1.0641, Test Loss: 1.1865\n",
      "Epoch [24/50] - Train Loss: 1.0643, Test Loss: 1.1810\n",
      "Epoch [25/50] - Train Loss: 1.0629, Test Loss: 1.1777\n",
      "Epoch [26/50] - Train Loss: 1.0602, Test Loss: 1.1856\n",
      "Epoch [27/50] - Train Loss: 1.0582, Test Loss: 1.1890\n",
      "Epoch [28/50] - Train Loss: 1.0496, Test Loss: 1.2963\n",
      "Epoch [29/50] - Train Loss: 1.1723, Test Loss: 1.1361\n",
      "Epoch [30/50] - Train Loss: 1.0887, Test Loss: 1.1743\n",
      "Epoch [31/50] - Train Loss: 1.0769, Test Loss: 1.2292\n",
      "Epoch [32/50] - Train Loss: 1.0753, Test Loss: 1.2486\n",
      "Epoch [33/50] - Train Loss: 1.0641, Test Loss: 1.2276\n",
      "Epoch [34/50] - Train Loss: 1.0608, Test Loss: 1.2028\n",
      "Epoch [35/50] - Train Loss: 1.0624, Test Loss: 1.2191\n",
      "Epoch [36/50] - Train Loss: 1.0609, Test Loss: 1.2001\n",
      "Epoch [37/50] - Train Loss: 1.0629, Test Loss: 1.2709\n",
      "Epoch [38/50] - Train Loss: 1.0793, Test Loss: 1.1934\n",
      "Epoch [39/50] - Train Loss: 1.0707, Test Loss: 1.2144\n",
      "Epoch [40/50] - Train Loss: 1.0753, Test Loss: 1.2308\n",
      "Epoch [41/50] - Train Loss: 1.0660, Test Loss: 1.2237\n",
      "Epoch [42/50] - Train Loss: 1.0640, Test Loss: 1.2165\n",
      "Epoch [43/50] - Train Loss: 1.0626, Test Loss: 1.2106\n",
      "Epoch [44/50] - Train Loss: 1.0588, Test Loss: 1.2259\n",
      "Epoch [45/50] - Train Loss: 1.0532, Test Loss: 1.1967\n",
      "Epoch [46/50] - Train Loss: 1.0589, Test Loss: 1.2153\n",
      "Epoch [47/50] - Train Loss: 1.0406, Test Loss: 1.3420\n",
      "Epoch [48/50] - Train Loss: 1.1690, Test Loss: 1.1098\n",
      "Epoch [49/50] - Train Loss: 1.0976, Test Loss: 1.1418\n",
      "Epoch [50/50] - Train Loss: 1.0767, Test Loss: 1.1966\n",
      "Avg Test Loss: 1.1966\n",
      "Testing combination: (64, 1, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.2393, Test Loss: 1.1464\n",
      "Epoch [2/50] - Train Loss: 1.1533, Test Loss: 1.1453\n",
      "Epoch [3/50] - Train Loss: 1.1517, Test Loss: 1.1497\n",
      "Epoch [4/50] - Train Loss: 1.1499, Test Loss: 1.1563\n",
      "Epoch [5/50] - Train Loss: 1.1351, Test Loss: 1.1641\n",
      "Epoch [6/50] - Train Loss: 1.0697, Test Loss: 1.2060\n",
      "Epoch [7/50] - Train Loss: 1.4976, Test Loss: 1.1278\n",
      "Epoch [8/50] - Train Loss: 1.1364, Test Loss: 1.1317\n",
      "Epoch [9/50] - Train Loss: 1.1091, Test Loss: 1.1338\n",
      "Epoch [10/50] - Train Loss: 1.0693, Test Loss: 1.1269\n",
      "Epoch [11/50] - Train Loss: 1.0530, Test Loss: 1.1197\n",
      "Epoch [12/50] - Train Loss: 1.0492, Test Loss: 1.1203\n",
      "Epoch [13/50] - Train Loss: 1.0474, Test Loss: 1.1221\n",
      "Epoch [14/50] - Train Loss: 1.0424, Test Loss: 1.1249\n",
      "Epoch [15/50] - Train Loss: 1.1581, Test Loss: 1.1214\n",
      "Epoch [16/50] - Train Loss: 1.0564, Test Loss: 1.1234\n",
      "Epoch [17/50] - Train Loss: 1.0497, Test Loss: 1.1218\n",
      "Epoch [18/50] - Train Loss: 1.0490, Test Loss: 1.1204\n",
      "Epoch [19/50] - Train Loss: 1.0474, Test Loss: 1.1200\n",
      "Epoch [20/50] - Train Loss: 1.0470, Test Loss: 1.1200\n",
      "Epoch [21/50] - Train Loss: 1.0467, Test Loss: 1.1200\n",
      "Epoch [22/50] - Train Loss: 1.0464, Test Loss: 1.1203\n",
      "Epoch [23/50] - Train Loss: 1.0459, Test Loss: 1.1207\n",
      "Epoch [24/50] - Train Loss: 1.0450, Test Loss: 1.1212\n",
      "Epoch [25/50] - Train Loss: 1.0436, Test Loss: 1.1230\n",
      "Epoch [26/50] - Train Loss: 1.0424, Test Loss: 1.1178\n",
      "Epoch [27/50] - Train Loss: 1.0447, Test Loss: 1.1089\n",
      "Epoch [28/50] - Train Loss: 1.0456, Test Loss: 1.1153\n",
      "Epoch [29/50] - Train Loss: 1.0416, Test Loss: 1.1171\n",
      "Epoch [30/50] - Train Loss: 1.0401, Test Loss: 1.1179\n",
      "Epoch [31/50] - Train Loss: 1.0389, Test Loss: 1.1190\n",
      "Epoch [32/50] - Train Loss: 1.0369, Test Loss: 1.1213\n",
      "Epoch [33/50] - Train Loss: 1.0376, Test Loss: 1.1234\n",
      "Epoch [34/50] - Train Loss: 1.0369, Test Loss: 1.1187\n",
      "Epoch [35/50] - Train Loss: 1.0357, Test Loss: 1.1342\n",
      "Epoch [36/50] - Train Loss: 1.0358, Test Loss: 1.0918\n",
      "Epoch [37/50] - Train Loss: 1.0586, Test Loss: 1.1160\n",
      "Epoch [38/50] - Train Loss: 1.0455, Test Loss: 1.1159\n",
      "Epoch [39/50] - Train Loss: 1.0442, Test Loss: 1.1164\n",
      "Epoch [40/50] - Train Loss: 1.0425, Test Loss: 1.1159\n",
      "Epoch [41/50] - Train Loss: 1.0407, Test Loss: 1.1171\n",
      "Epoch [42/50] - Train Loss: 1.0405, Test Loss: 1.1147\n",
      "Epoch [43/50] - Train Loss: 1.0381, Test Loss: 1.1134\n",
      "Epoch [44/50] - Train Loss: 1.0381, Test Loss: 1.1142\n",
      "Epoch [45/50] - Train Loss: 1.0435, Test Loss: 1.1170\n",
      "Epoch [46/50] - Train Loss: 1.0373, Test Loss: 1.1035\n",
      "Epoch [47/50] - Train Loss: 1.0434, Test Loss: 1.1118\n",
      "Epoch [48/50] - Train Loss: 1.0386, Test Loss: 1.1104\n",
      "Epoch [49/50] - Train Loss: 1.0366, Test Loss: 1.1125\n",
      "Epoch [50/50] - Train Loss: 1.0494, Test Loss: 1.1124\n",
      "Avg Test Loss: 1.1124\n",
      "Testing combination: (64, 1, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5741, Test Loss: 1.7455\n",
      "Epoch [2/50] - Train Loss: 1.4835, Test Loss: 1.7371\n",
      "Epoch [3/50] - Train Loss: 1.4843, Test Loss: 1.7437\n",
      "Epoch [4/50] - Train Loss: 1.4839, Test Loss: 1.7485\n",
      "Epoch [5/50] - Train Loss: 1.4643, Test Loss: 1.7690\n",
      "Epoch [6/50] - Train Loss: 1.4321, Test Loss: 1.8568\n",
      "Epoch [7/50] - Train Loss: 2.0880, Test Loss: 1.7617\n",
      "Epoch [8/50] - Train Loss: 1.4566, Test Loss: 1.7241\n",
      "Epoch [9/50] - Train Loss: 1.4618, Test Loss: 1.7122\n",
      "Epoch [10/50] - Train Loss: 1.4564, Test Loss: 1.7093\n",
      "Epoch [11/50] - Train Loss: 1.4490, Test Loss: 1.7107\n",
      "Epoch [12/50] - Train Loss: 1.4389, Test Loss: 1.7148\n",
      "Epoch [13/50] - Train Loss: 1.4289, Test Loss: 1.7214\n",
      "Epoch [14/50] - Train Loss: 1.4232, Test Loss: 1.7301\n",
      "Epoch [15/50] - Train Loss: 1.4202, Test Loss: 1.7411\n",
      "Epoch [16/50] - Train Loss: 1.4228, Test Loss: 1.7438\n",
      "Epoch [17/50] - Train Loss: 1.4223, Test Loss: 1.7476\n",
      "Epoch [18/50] - Train Loss: 1.4250, Test Loss: 1.7445\n",
      "Epoch [19/50] - Train Loss: 1.4223, Test Loss: 1.7389\n",
      "Epoch [20/50] - Train Loss: 1.4174, Test Loss: 1.7300\n",
      "Epoch [21/50] - Train Loss: 1.4143, Test Loss: 1.7358\n",
      "Epoch [22/50] - Train Loss: 1.4182, Test Loss: 1.7304\n",
      "Epoch [23/50] - Train Loss: 1.4088, Test Loss: 1.7293\n",
      "Epoch [24/50] - Train Loss: 1.4101, Test Loss: 1.7408\n",
      "Epoch [25/50] - Train Loss: 1.4107, Test Loss: 1.7569\n",
      "Epoch [26/50] - Train Loss: 1.4087, Test Loss: 1.7405\n",
      "Epoch [27/50] - Train Loss: 1.4065, Test Loss: 1.7451\n",
      "Epoch [28/50] - Train Loss: 1.4075, Test Loss: 1.7734\n",
      "Epoch [29/50] - Train Loss: 1.4066, Test Loss: 1.7410\n",
      "Epoch [30/50] - Train Loss: 1.4030, Test Loss: 1.7468\n",
      "Epoch [31/50] - Train Loss: 1.4034, Test Loss: 1.7993\n",
      "Epoch [32/50] - Train Loss: 1.3998, Test Loss: 1.7180\n",
      "Epoch [33/50] - Train Loss: 1.4015, Test Loss: 1.7204\n",
      "Epoch [34/50] - Train Loss: 1.4032, Test Loss: 1.8341\n",
      "Epoch [35/50] - Train Loss: 1.3901, Test Loss: 1.7103\n",
      "Epoch [36/50] - Train Loss: 1.4105, Test Loss: 1.7132\n",
      "Epoch [37/50] - Train Loss: 1.4081, Test Loss: 1.7887\n",
      "Epoch [38/50] - Train Loss: 1.3999, Test Loss: 1.7051\n",
      "Epoch [39/50] - Train Loss: 1.3984, Test Loss: 1.7066\n",
      "Epoch [40/50] - Train Loss: 1.4065, Test Loss: 1.7364\n",
      "Epoch [41/50] - Train Loss: 1.4003, Test Loss: 1.9363\n",
      "Epoch [42/50] - Train Loss: 1.4073, Test Loss: 1.6980\n",
      "Epoch [43/50] - Train Loss: 1.4136, Test Loss: 1.7307\n",
      "Epoch [44/50] - Train Loss: 1.4298, Test Loss: 1.7298\n",
      "Epoch [45/50] - Train Loss: 1.4223, Test Loss: 1.7145\n",
      "Epoch [46/50] - Train Loss: 1.4129, Test Loss: 1.6962\n",
      "Epoch [47/50] - Train Loss: 1.4093, Test Loss: 1.7193\n",
      "Epoch [48/50] - Train Loss: 1.3934, Test Loss: 1.9368\n",
      "Epoch [49/50] - Train Loss: 1.3783, Test Loss: 1.7265\n",
      "Epoch [50/50] - Train Loss: 1.3833, Test Loss: 1.7255\n",
      "Avg Test Loss: 1.7255\n",
      "Testing combination: (64, 1, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1255, Test Loss: 1.1039\n",
      "Epoch [2/50] - Train Loss: 1.1193, Test Loss: 1.0985\n",
      "Epoch [3/50] - Train Loss: 1.1171, Test Loss: 1.0962\n",
      "Epoch [4/50] - Train Loss: 1.1160, Test Loss: 1.0964\n",
      "Epoch [5/50] - Train Loss: 1.1148, Test Loss: 1.0992\n",
      "Epoch [6/50] - Train Loss: 1.1122, Test Loss: 1.1050\n",
      "Epoch [7/50] - Train Loss: 1.1049, Test Loss: 1.1136\n",
      "Epoch [8/50] - Train Loss: 1.0897, Test Loss: 1.1330\n",
      "Epoch [9/50] - Train Loss: 1.0731, Test Loss: 1.1787\n",
      "Epoch [10/50] - Train Loss: 1.0746, Test Loss: 1.2070\n",
      "Epoch [11/50] - Train Loss: 1.0702, Test Loss: 1.2098\n",
      "Epoch [12/50] - Train Loss: 1.0694, Test Loss: 1.2098\n",
      "Epoch [13/50] - Train Loss: 1.0690, Test Loss: 1.2071\n",
      "Epoch [14/50] - Train Loss: 1.0682, Test Loss: 1.2044\n",
      "Epoch [15/50] - Train Loss: 1.0672, Test Loss: 1.2049\n",
      "Epoch [16/50] - Train Loss: 1.0664, Test Loss: 1.2047\n",
      "Epoch [17/50] - Train Loss: 1.0652, Test Loss: 1.2065\n",
      "Epoch [18/50] - Train Loss: 1.0634, Test Loss: 1.2029\n",
      "Epoch [19/50] - Train Loss: 1.0603, Test Loss: 1.1983\n",
      "Epoch [20/50] - Train Loss: 1.0576, Test Loss: 1.2324\n",
      "Epoch [21/50] - Train Loss: 1.0636, Test Loss: 1.2298\n",
      "Epoch [22/50] - Train Loss: 1.0568, Test Loss: 1.2459\n",
      "Epoch [23/50] - Train Loss: 1.0638, Test Loss: 1.2553\n",
      "Epoch [24/50] - Train Loss: 1.0635, Test Loss: 1.2469\n",
      "Epoch [25/50] - Train Loss: 1.0834, Test Loss: 1.2073\n",
      "Epoch [26/50] - Train Loss: 1.1091, Test Loss: 1.1324\n",
      "Epoch [27/50] - Train Loss: 1.1054, Test Loss: 1.1417\n",
      "Epoch [28/50] - Train Loss: 1.0941, Test Loss: 1.1527\n",
      "Epoch [29/50] - Train Loss: 1.0832, Test Loss: 1.1660\n",
      "Epoch [30/50] - Train Loss: 1.0760, Test Loss: 1.1797\n",
      "Epoch [31/50] - Train Loss: 1.0715, Test Loss: 1.1934\n",
      "Epoch [32/50] - Train Loss: 1.0689, Test Loss: 1.2050\n",
      "Epoch [33/50] - Train Loss: 1.0675, Test Loss: 1.2123\n",
      "Epoch [34/50] - Train Loss: 1.0669, Test Loss: 1.2145\n",
      "Epoch [35/50] - Train Loss: 1.0664, Test Loss: 1.2128\n",
      "Epoch [36/50] - Train Loss: 1.0651, Test Loss: 1.2102\n",
      "Epoch [37/50] - Train Loss: 1.0636, Test Loss: 1.2079\n",
      "Epoch [38/50] - Train Loss: 1.0616, Test Loss: 1.2059\n",
      "Epoch [39/50] - Train Loss: 1.0574, Test Loss: 1.2024\n",
      "Epoch [40/50] - Train Loss: 1.0522, Test Loss: 1.2123\n",
      "Epoch [41/50] - Train Loss: 1.0626, Test Loss: 1.1684\n",
      "Epoch [42/50] - Train Loss: 1.0795, Test Loss: 1.1633\n",
      "Epoch [43/50] - Train Loss: 1.0758, Test Loss: 1.1679\n",
      "Epoch [44/50] - Train Loss: 1.0714, Test Loss: 1.1840\n",
      "Epoch [45/50] - Train Loss: 1.0668, Test Loss: 1.2037\n",
      "Epoch [46/50] - Train Loss: 1.0617, Test Loss: 1.2236\n",
      "Epoch [47/50] - Train Loss: 1.0566, Test Loss: 1.2458\n",
      "Epoch [48/50] - Train Loss: 1.0536, Test Loss: 1.2575\n",
      "Epoch [49/50] - Train Loss: 1.0478, Test Loss: 1.2490\n",
      "Epoch [50/50] - Train Loss: 1.0435, Test Loss: 1.2631\n",
      "Avg Test Loss: 1.2631\n",
      "Testing combination: (64, 1, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1726, Test Loss: 1.2121\n",
      "Epoch [2/50] - Train Loss: 1.1560, Test Loss: 1.1942\n",
      "Epoch [3/50] - Train Loss: 1.1514, Test Loss: 1.1855\n",
      "Epoch [4/50] - Train Loss: 1.1487, Test Loss: 1.1814\n",
      "Epoch [5/50] - Train Loss: 1.1463, Test Loss: 1.1815\n",
      "Epoch [6/50] - Train Loss: 1.1425, Test Loss: 1.1866\n",
      "Epoch [7/50] - Train Loss: 1.1345, Test Loss: 1.1976\n",
      "Epoch [8/50] - Train Loss: 1.1152, Test Loss: 1.2111\n",
      "Epoch [9/50] - Train Loss: 1.0777, Test Loss: 1.2218\n",
      "Epoch [10/50] - Train Loss: 1.0494, Test Loss: 1.2359\n",
      "Epoch [11/50] - Train Loss: 1.0503, Test Loss: 1.2410\n",
      "Epoch [12/50] - Train Loss: 1.0477, Test Loss: 1.2267\n",
      "Epoch [13/50] - Train Loss: 1.0461, Test Loss: 1.2200\n",
      "Epoch [14/50] - Train Loss: 1.0456, Test Loss: 1.2212\n",
      "Epoch [15/50] - Train Loss: 1.0451, Test Loss: 1.2248\n",
      "Epoch [16/50] - Train Loss: 1.0450, Test Loss: 1.2278\n",
      "Epoch [17/50] - Train Loss: 1.0448, Test Loss: 1.2298\n",
      "Epoch [18/50] - Train Loss: 1.0444, Test Loss: 1.2332\n",
      "Epoch [19/50] - Train Loss: 1.0436, Test Loss: 1.2354\n",
      "Epoch [20/50] - Train Loss: 1.0429, Test Loss: 1.2349\n",
      "Epoch [21/50] - Train Loss: 1.0421, Test Loss: 1.2336\n",
      "Epoch [22/50] - Train Loss: 1.0408, Test Loss: 1.2321\n",
      "Epoch [23/50] - Train Loss: 1.0386, Test Loss: 1.2287\n",
      "Epoch [24/50] - Train Loss: 1.0362, Test Loss: 1.2256\n",
      "Epoch [25/50] - Train Loss: 1.0412, Test Loss: 1.2279\n",
      "Epoch [26/50] - Train Loss: 1.0294, Test Loss: 1.2341\n",
      "Epoch [27/50] - Train Loss: 1.0307, Test Loss: 1.2248\n",
      "Epoch [28/50] - Train Loss: 1.1713, Test Loss: 1.2648\n",
      "Epoch [29/50] - Train Loss: 1.0718, Test Loss: 1.2454\n",
      "Epoch [30/50] - Train Loss: 1.0709, Test Loss: 1.2554\n",
      "Epoch [31/50] - Train Loss: 1.0557, Test Loss: 1.2730\n",
      "Epoch [32/50] - Train Loss: 1.0471, Test Loss: 1.2903\n",
      "Epoch [33/50] - Train Loss: 1.0437, Test Loss: 1.3037\n",
      "Epoch [34/50] - Train Loss: 1.0432, Test Loss: 1.3108\n",
      "Epoch [35/50] - Train Loss: 1.0432, Test Loss: 1.3119\n",
      "Epoch [36/50] - Train Loss: 1.0429, Test Loss: 1.3097\n",
      "Epoch [37/50] - Train Loss: 1.0426, Test Loss: 1.3067\n",
      "Epoch [38/50] - Train Loss: 1.0423, Test Loss: 1.3042\n",
      "Epoch [39/50] - Train Loss: 1.0421, Test Loss: 1.3033\n",
      "Epoch [40/50] - Train Loss: 1.0418, Test Loss: 1.3033\n",
      "Epoch [41/50] - Train Loss: 1.0414, Test Loss: 1.3034\n",
      "Epoch [42/50] - Train Loss: 1.0409, Test Loss: 1.3035\n",
      "Epoch [43/50] - Train Loss: 1.0401, Test Loss: 1.3032\n",
      "Epoch [44/50] - Train Loss: 1.0385, Test Loss: 1.3035\n",
      "Epoch [45/50] - Train Loss: 1.0365, Test Loss: 1.3038\n",
      "Epoch [46/50] - Train Loss: 1.0340, Test Loss: 1.3032\n",
      "Epoch [47/50] - Train Loss: 1.0286, Test Loss: 1.2925\n",
      "Epoch [48/50] - Train Loss: 1.0415, Test Loss: 1.2870\n",
      "Epoch [49/50] - Train Loss: 1.0939, Test Loss: 1.1862\n",
      "Epoch [50/50] - Train Loss: 1.0637, Test Loss: 1.2135\n",
      "Avg Test Loss: 1.2135\n",
      "Testing combination: (64, 1, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.4921, Test Loss: 1.7409\n",
      "Epoch [2/50] - Train Loss: 1.4868, Test Loss: 1.7480\n",
      "Epoch [3/50] - Train Loss: 1.4857, Test Loss: 1.7559\n",
      "Epoch [4/50] - Train Loss: 1.4847, Test Loss: 1.7654\n",
      "Epoch [5/50] - Train Loss: 1.4835, Test Loss: 1.7771\n",
      "Epoch [6/50] - Train Loss: 1.4817, Test Loss: 1.7908\n",
      "Epoch [7/50] - Train Loss: 1.4787, Test Loss: 1.8058\n",
      "Epoch [8/50] - Train Loss: 1.4735, Test Loss: 1.8204\n",
      "Epoch [9/50] - Train Loss: 1.4647, Test Loss: 1.8330\n",
      "Epoch [10/50] - Train Loss: 1.4526, Test Loss: 1.8459\n",
      "Epoch [11/50] - Train Loss: 1.4397, Test Loss: 1.8622\n",
      "Epoch [12/50] - Train Loss: 1.4289, Test Loss: 1.8838\n",
      "Epoch [13/50] - Train Loss: 1.4240, Test Loss: 1.9069\n",
      "Epoch [14/50] - Train Loss: 1.4226, Test Loss: 1.9234\n",
      "Epoch [15/50] - Train Loss: 1.4203, Test Loss: 1.9334\n",
      "Epoch [16/50] - Train Loss: 1.4193, Test Loss: 1.9370\n",
      "Epoch [17/50] - Train Loss: 1.4192, Test Loss: 1.9351\n",
      "Epoch [18/50] - Train Loss: 1.4192, Test Loss: 1.9317\n",
      "Epoch [19/50] - Train Loss: 1.4190, Test Loss: 1.9276\n",
      "Epoch [20/50] - Train Loss: 1.4187, Test Loss: 1.9234\n",
      "Epoch [21/50] - Train Loss: 1.4185, Test Loss: 1.9204\n",
      "Epoch [22/50] - Train Loss: 1.4182, Test Loss: 1.9189\n",
      "Epoch [23/50] - Train Loss: 1.4176, Test Loss: 1.9178\n",
      "Epoch [24/50] - Train Loss: 1.4171, Test Loss: 1.9162\n",
      "Epoch [25/50] - Train Loss: 1.4166, Test Loss: 1.9117\n",
      "Epoch [26/50] - Train Loss: 1.4161, Test Loss: 1.9105\n",
      "Epoch [27/50] - Train Loss: 1.4155, Test Loss: 1.9114\n",
      "Epoch [28/50] - Train Loss: 1.4147, Test Loss: 1.9121\n",
      "Epoch [29/50] - Train Loss: 1.4138, Test Loss: 1.9140\n",
      "Epoch [30/50] - Train Loss: 1.4126, Test Loss: 1.9173\n",
      "Epoch [31/50] - Train Loss: 1.4110, Test Loss: 1.9220\n",
      "Epoch [32/50] - Train Loss: 1.4088, Test Loss: 1.9280\n",
      "Epoch [33/50] - Train Loss: 1.4056, Test Loss: 1.9295\n",
      "Epoch [34/50] - Train Loss: 1.4015, Test Loss: 1.9252\n",
      "Epoch [35/50] - Train Loss: 1.4142, Test Loss: 1.9272\n",
      "Epoch [36/50] - Train Loss: 1.3707, Test Loss: 2.0181\n",
      "Epoch [37/50] - Train Loss: 1.4020, Test Loss: 1.9217\n",
      "Epoch [38/50] - Train Loss: 1.5786, Test Loss: 2.0669\n",
      "Epoch [39/50] - Train Loss: 1.3471, Test Loss: 1.9005\n",
      "Epoch [40/50] - Train Loss: 1.4157, Test Loss: 1.9818\n",
      "Epoch [41/50] - Train Loss: 1.4313, Test Loss: 1.9806\n",
      "Epoch [42/50] - Train Loss: 1.4298, Test Loss: 1.9793\n",
      "Epoch [43/50] - Train Loss: 1.4261, Test Loss: 1.9519\n",
      "Epoch [44/50] - Train Loss: 1.4221, Test Loss: 1.8983\n",
      "Epoch [45/50] - Train Loss: 1.4177, Test Loss: 1.8944\n",
      "Epoch [46/50] - Train Loss: 1.4127, Test Loss: 1.8945\n",
      "Epoch [47/50] - Train Loss: 1.4081, Test Loss: 1.8978\n",
      "Epoch [48/50] - Train Loss: 1.4045, Test Loss: 1.9023\n",
      "Epoch [49/50] - Train Loss: 1.4011, Test Loss: 1.9071\n",
      "Epoch [50/50] - Train Loss: 1.3980, Test Loss: 1.9142\n",
      "Avg Test Loss: 1.9142\n",
      "Testing combination: (64, 1, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1259, Test Loss: 1.0811\n",
      "Epoch [2/50] - Train Loss: 1.1243, Test Loss: 1.0814\n",
      "Epoch [3/50] - Train Loss: 1.1234, Test Loss: 1.0819\n",
      "Epoch [4/50] - Train Loss: 1.1226, Test Loss: 1.0824\n",
      "Epoch [5/50] - Train Loss: 1.1219, Test Loss: 1.0829\n",
      "Epoch [6/50] - Train Loss: 1.1213, Test Loss: 1.0835\n",
      "Epoch [7/50] - Train Loss: 1.1207, Test Loss: 1.0842\n",
      "Epoch [8/50] - Train Loss: 1.1202, Test Loss: 1.0849\n",
      "Epoch [9/50] - Train Loss: 1.1196, Test Loss: 1.0857\n",
      "Epoch [10/50] - Train Loss: 1.1192, Test Loss: 1.0866\n",
      "Epoch [11/50] - Train Loss: 1.1187, Test Loss: 1.0876\n",
      "Epoch [12/50] - Train Loss: 1.1183, Test Loss: 1.0886\n",
      "Epoch [13/50] - Train Loss: 1.1179, Test Loss: 1.0897\n",
      "Epoch [14/50] - Train Loss: 1.1175, Test Loss: 1.0909\n",
      "Epoch [15/50] - Train Loss: 1.1171, Test Loss: 1.0923\n",
      "Epoch [16/50] - Train Loss: 1.1166, Test Loss: 1.0938\n",
      "Epoch [17/50] - Train Loss: 1.1162, Test Loss: 1.0954\n",
      "Epoch [18/50] - Train Loss: 1.1158, Test Loss: 1.0973\n",
      "Epoch [19/50] - Train Loss: 1.1154, Test Loss: 1.0993\n",
      "Epoch [20/50] - Train Loss: 1.1149, Test Loss: 1.1016\n",
      "Epoch [21/50] - Train Loss: 1.1144, Test Loss: 1.1043\n",
      "Epoch [22/50] - Train Loss: 1.1138, Test Loss: 1.1073\n",
      "Epoch [23/50] - Train Loss: 1.1131, Test Loss: 1.1107\n",
      "Epoch [24/50] - Train Loss: 1.1124, Test Loss: 1.1147\n",
      "Epoch [25/50] - Train Loss: 1.1114, Test Loss: 1.1191\n",
      "Epoch [26/50] - Train Loss: 1.1103, Test Loss: 1.1241\n",
      "Epoch [27/50] - Train Loss: 1.1089, Test Loss: 1.1298\n",
      "Epoch [28/50] - Train Loss: 1.1072, Test Loss: 1.1360\n",
      "Epoch [29/50] - Train Loss: 1.1052, Test Loss: 1.1430\n",
      "Epoch [30/50] - Train Loss: 1.1027, Test Loss: 1.1506\n",
      "Epoch [31/50] - Train Loss: 1.0997, Test Loss: 1.1591\n",
      "Epoch [32/50] - Train Loss: 1.0964, Test Loss: 1.1683\n",
      "Epoch [33/50] - Train Loss: 1.0927, Test Loss: 1.1782\n",
      "Epoch [34/50] - Train Loss: 1.0889, Test Loss: 1.1885\n",
      "Epoch [35/50] - Train Loss: 1.0852, Test Loss: 1.1988\n",
      "Epoch [36/50] - Train Loss: 1.0818, Test Loss: 1.2088\n",
      "Epoch [37/50] - Train Loss: 1.0789, Test Loss: 1.2180\n",
      "Epoch [38/50] - Train Loss: 1.0764, Test Loss: 1.2264\n",
      "Epoch [39/50] - Train Loss: 1.0744, Test Loss: 1.2338\n",
      "Epoch [40/50] - Train Loss: 1.0729, Test Loss: 1.2402\n",
      "Epoch [41/50] - Train Loss: 1.0718, Test Loss: 1.2458\n",
      "Epoch [42/50] - Train Loss: 1.0710, Test Loss: 1.2502\n",
      "Epoch [43/50] - Train Loss: 1.0704, Test Loss: 1.2538\n",
      "Epoch [44/50] - Train Loss: 1.0699, Test Loss: 1.2565\n",
      "Epoch [45/50] - Train Loss: 1.0695, Test Loss: 1.2584\n",
      "Epoch [46/50] - Train Loss: 1.0692, Test Loss: 1.2598\n",
      "Epoch [47/50] - Train Loss: 1.0690, Test Loss: 1.2609\n",
      "Epoch [48/50] - Train Loss: 1.0687, Test Loss: 1.2617\n",
      "Epoch [49/50] - Train Loss: 1.0685, Test Loss: 1.2624\n",
      "Epoch [50/50] - Train Loss: 1.0683, Test Loss: 1.2630\n",
      "Avg Test Loss: 1.2630\n",
      "Testing combination: (64, 1, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1572, Test Loss: 1.1338\n",
      "Epoch [2/50] - Train Loss: 1.1562, Test Loss: 1.1347\n",
      "Epoch [3/50] - Train Loss: 1.1557, Test Loss: 1.1355\n",
      "Epoch [4/50] - Train Loss: 1.1552, Test Loss: 1.1364\n",
      "Epoch [5/50] - Train Loss: 1.1547, Test Loss: 1.1373\n",
      "Epoch [6/50] - Train Loss: 1.1542, Test Loss: 1.1382\n",
      "Epoch [7/50] - Train Loss: 1.1538, Test Loss: 1.1391\n",
      "Epoch [8/50] - Train Loss: 1.1533, Test Loss: 1.1400\n",
      "Epoch [9/50] - Train Loss: 1.1529, Test Loss: 1.1409\n",
      "Epoch [10/50] - Train Loss: 1.1525, Test Loss: 1.1418\n",
      "Epoch [11/50] - Train Loss: 1.1522, Test Loss: 1.1427\n",
      "Epoch [12/50] - Train Loss: 1.1518, Test Loss: 1.1437\n",
      "Epoch [13/50] - Train Loss: 1.1514, Test Loss: 1.1447\n",
      "Epoch [14/50] - Train Loss: 1.1510, Test Loss: 1.1457\n",
      "Epoch [15/50] - Train Loss: 1.1507, Test Loss: 1.1468\n",
      "Epoch [16/50] - Train Loss: 1.1503, Test Loss: 1.1479\n",
      "Epoch [17/50] - Train Loss: 1.1499, Test Loss: 1.1490\n",
      "Epoch [18/50] - Train Loss: 1.1495, Test Loss: 1.1502\n",
      "Epoch [19/50] - Train Loss: 1.1491, Test Loss: 1.1515\n",
      "Epoch [20/50] - Train Loss: 1.1487, Test Loss: 1.1528\n",
      "Epoch [21/50] - Train Loss: 1.1483, Test Loss: 1.1542\n",
      "Epoch [22/50] - Train Loss: 1.1478, Test Loss: 1.1556\n",
      "Epoch [23/50] - Train Loss: 1.1473, Test Loss: 1.1572\n",
      "Epoch [24/50] - Train Loss: 1.1467, Test Loss: 1.1589\n",
      "Epoch [25/50] - Train Loss: 1.1460, Test Loss: 1.1608\n",
      "Epoch [26/50] - Train Loss: 1.1453, Test Loss: 1.1628\n",
      "Epoch [27/50] - Train Loss: 1.1445, Test Loss: 1.1650\n",
      "Epoch [28/50] - Train Loss: 1.1436, Test Loss: 1.1673\n",
      "Epoch [29/50] - Train Loss: 1.1425, Test Loss: 1.1698\n",
      "Epoch [30/50] - Train Loss: 1.1412, Test Loss: 1.1724\n",
      "Epoch [31/50] - Train Loss: 1.1397, Test Loss: 1.1753\n",
      "Epoch [32/50] - Train Loss: 1.1380, Test Loss: 1.1783\n",
      "Epoch [33/50] - Train Loss: 1.1359, Test Loss: 1.1816\n",
      "Epoch [34/50] - Train Loss: 1.1336, Test Loss: 1.1850\n",
      "Epoch [35/50] - Train Loss: 1.1308, Test Loss: 1.1888\n",
      "Epoch [36/50] - Train Loss: 1.1275, Test Loss: 1.1930\n",
      "Epoch [37/50] - Train Loss: 1.1237, Test Loss: 1.1976\n",
      "Epoch [38/50] - Train Loss: 1.1194, Test Loss: 1.2027\n",
      "Epoch [39/50] - Train Loss: 1.1144, Test Loss: 1.2083\n",
      "Epoch [40/50] - Train Loss: 1.1088, Test Loss: 1.2143\n",
      "Epoch [41/50] - Train Loss: 1.1026, Test Loss: 1.2207\n",
      "Epoch [42/50] - Train Loss: 1.0960, Test Loss: 1.2272\n",
      "Epoch [43/50] - Train Loss: 1.0890, Test Loss: 1.2340\n",
      "Epoch [44/50] - Train Loss: 1.0819, Test Loss: 1.2409\n",
      "Epoch [45/50] - Train Loss: 1.0749, Test Loss: 1.2480\n",
      "Epoch [46/50] - Train Loss: 1.0685, Test Loss: 1.2551\n",
      "Epoch [47/50] - Train Loss: 1.0628, Test Loss: 1.2620\n",
      "Epoch [48/50] - Train Loss: 1.0583, Test Loss: 1.2686\n",
      "Epoch [49/50] - Train Loss: 1.0548, Test Loss: 1.2746\n",
      "Epoch [50/50] - Train Loss: 1.0522, Test Loss: 1.2800\n",
      "Avg Test Loss: 1.2800\n",
      "Testing combination: (64, 1, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.4865, Test Loss: 1.7355\n",
      "Epoch [2/50] - Train Loss: 1.4859, Test Loss: 1.7357\n",
      "Epoch [3/50] - Train Loss: 1.4858, Test Loss: 1.7358\n",
      "Epoch [4/50] - Train Loss: 1.4858, Test Loss: 1.7360\n",
      "Epoch [5/50] - Train Loss: 1.4857, Test Loss: 1.7362\n",
      "Epoch [6/50] - Train Loss: 1.4857, Test Loss: 1.7364\n",
      "Epoch [7/50] - Train Loss: 1.4857, Test Loss: 1.7366\n",
      "Epoch [8/50] - Train Loss: 1.4856, Test Loss: 1.7368\n",
      "Epoch [9/50] - Train Loss: 1.4856, Test Loss: 1.7370\n",
      "Epoch [10/50] - Train Loss: 1.4856, Test Loss: 1.7372\n",
      "Epoch [11/50] - Train Loss: 1.4855, Test Loss: 1.7374\n",
      "Epoch [12/50] - Train Loss: 1.4855, Test Loss: 1.7377\n",
      "Epoch [13/50] - Train Loss: 1.4855, Test Loss: 1.7379\n",
      "Epoch [14/50] - Train Loss: 1.4854, Test Loss: 1.7382\n",
      "Epoch [15/50] - Train Loss: 1.4854, Test Loss: 1.7385\n",
      "Epoch [16/50] - Train Loss: 1.4854, Test Loss: 1.7388\n",
      "Epoch [17/50] - Train Loss: 1.4853, Test Loss: 1.7391\n",
      "Epoch [18/50] - Train Loss: 1.4853, Test Loss: 1.7394\n",
      "Epoch [19/50] - Train Loss: 1.4853, Test Loss: 1.7398\n",
      "Epoch [20/50] - Train Loss: 1.4852, Test Loss: 1.7402\n",
      "Epoch [21/50] - Train Loss: 1.4852, Test Loss: 1.7406\n",
      "Epoch [22/50] - Train Loss: 1.4852, Test Loss: 1.7410\n",
      "Epoch [23/50] - Train Loss: 1.4851, Test Loss: 1.7414\n",
      "Epoch [24/50] - Train Loss: 1.4851, Test Loss: 1.7418\n",
      "Epoch [25/50] - Train Loss: 1.4851, Test Loss: 1.7423\n",
      "Epoch [26/50] - Train Loss: 1.4850, Test Loss: 1.7427\n",
      "Epoch [27/50] - Train Loss: 1.4850, Test Loss: 1.7432\n",
      "Epoch [28/50] - Train Loss: 1.4850, Test Loss: 1.7437\n",
      "Epoch [29/50] - Train Loss: 1.4849, Test Loss: 1.7442\n",
      "Epoch [30/50] - Train Loss: 1.4849, Test Loss: 1.7447\n",
      "Epoch [31/50] - Train Loss: 1.4848, Test Loss: 1.7453\n",
      "Epoch [32/50] - Train Loss: 1.4848, Test Loss: 1.7459\n",
      "Epoch [33/50] - Train Loss: 1.4847, Test Loss: 1.7465\n",
      "Epoch [34/50] - Train Loss: 1.4846, Test Loss: 1.7471\n",
      "Epoch [35/50] - Train Loss: 1.4846, Test Loss: 1.7478\n",
      "Epoch [36/50] - Train Loss: 1.4845, Test Loss: 1.7485\n",
      "Epoch [37/50] - Train Loss: 1.4844, Test Loss: 1.7492\n",
      "Epoch [38/50] - Train Loss: 1.4844, Test Loss: 1.7500\n",
      "Epoch [39/50] - Train Loss: 1.4843, Test Loss: 1.7508\n",
      "Epoch [40/50] - Train Loss: 1.4842, Test Loss: 1.7516\n",
      "Epoch [41/50] - Train Loss: 1.4841, Test Loss: 1.7525\n",
      "Epoch [42/50] - Train Loss: 1.4840, Test Loss: 1.7534\n",
      "Epoch [43/50] - Train Loss: 1.4839, Test Loss: 1.7543\n",
      "Epoch [44/50] - Train Loss: 1.4838, Test Loss: 1.7553\n",
      "Epoch [45/50] - Train Loss: 1.4836, Test Loss: 1.7563\n",
      "Epoch [46/50] - Train Loss: 1.4835, Test Loss: 1.7574\n",
      "Epoch [47/50] - Train Loss: 1.4833, Test Loss: 1.7585\n",
      "Epoch [48/50] - Train Loss: 1.4831, Test Loss: 1.7596\n",
      "Epoch [49/50] - Train Loss: 1.4829, Test Loss: 1.7608\n",
      "Epoch [50/50] - Train Loss: 1.4827, Test Loss: 1.7620\n",
      "Avg Test Loss: 1.7620\n",
      "Testing combination: (64, 2, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.3075, Test Loss: 1.0792\n",
      "Epoch [2/50] - Train Loss: 1.1214, Test Loss: 1.0802\n",
      "Epoch [3/50] - Train Loss: 1.1170, Test Loss: 1.0874\n",
      "Epoch [4/50] - Train Loss: 1.0992, Test Loss: 1.1236\n",
      "Epoch [5/50] - Train Loss: 1.0901, Test Loss: 1.1451\n",
      "Epoch [6/50] - Train Loss: 1.0762, Test Loss: 1.1835\n",
      "Epoch [7/50] - Train Loss: 1.0842, Test Loss: 1.1285\n",
      "Epoch [8/50] - Train Loss: 1.0760, Test Loss: 1.1515\n",
      "Epoch [9/50] - Train Loss: 1.0778, Test Loss: 1.1742\n",
      "Epoch [10/50] - Train Loss: 1.0750, Test Loss: 1.1468\n",
      "Epoch [11/50] - Train Loss: 1.0729, Test Loss: 1.1588\n",
      "Epoch [12/50] - Train Loss: 1.0704, Test Loss: 1.1637\n",
      "Epoch [13/50] - Train Loss: 1.0690, Test Loss: 1.1591\n",
      "Epoch [14/50] - Train Loss: 1.0664, Test Loss: 1.1611\n",
      "Epoch [15/50] - Train Loss: 1.0653, Test Loss: 1.1667\n",
      "Epoch [16/50] - Train Loss: 1.0710, Test Loss: 1.1680\n",
      "Epoch [17/50] - Train Loss: 1.0644, Test Loss: 1.1728\n",
      "Epoch [18/50] - Train Loss: 1.0627, Test Loss: 1.1758\n",
      "Epoch [19/50] - Train Loss: 1.0631, Test Loss: 1.1731\n",
      "Epoch [20/50] - Train Loss: 1.0662, Test Loss: 1.1798\n",
      "Epoch [21/50] - Train Loss: 1.0762, Test Loss: 1.1746\n",
      "Epoch [22/50] - Train Loss: 1.0722, Test Loss: 1.1963\n",
      "Epoch [23/50] - Train Loss: 1.0704, Test Loss: 1.1523\n",
      "Epoch [24/50] - Train Loss: 1.0643, Test Loss: 1.1749\n",
      "Epoch [25/50] - Train Loss: 1.0631, Test Loss: 1.1747\n",
      "Epoch [26/50] - Train Loss: 1.0657, Test Loss: 1.1704\n",
      "Epoch [27/50] - Train Loss: 1.0698, Test Loss: 1.1806\n",
      "Epoch [28/50] - Train Loss: 1.0653, Test Loss: 1.1712\n",
      "Epoch [29/50] - Train Loss: 1.0640, Test Loss: 1.1662\n",
      "Epoch [30/50] - Train Loss: 1.0675, Test Loss: 1.1665\n",
      "Epoch [31/50] - Train Loss: 1.0730, Test Loss: 1.1696\n",
      "Epoch [32/50] - Train Loss: 1.0755, Test Loss: 1.1857\n",
      "Epoch [33/50] - Train Loss: 1.0721, Test Loss: 1.1478\n",
      "Epoch [34/50] - Train Loss: 1.0654, Test Loss: 1.1966\n",
      "Epoch [35/50] - Train Loss: 1.0636, Test Loss: 1.1727\n",
      "Epoch [36/50] - Train Loss: 1.0625, Test Loss: 1.1759\n",
      "Epoch [37/50] - Train Loss: 1.0619, Test Loss: 1.1780\n",
      "Epoch [38/50] - Train Loss: 1.0607, Test Loss: 1.1731\n",
      "Epoch [39/50] - Train Loss: 1.0609, Test Loss: 1.1726\n",
      "Epoch [40/50] - Train Loss: 1.0612, Test Loss: 1.1738\n",
      "Epoch [41/50] - Train Loss: 1.0639, Test Loss: 1.1583\n",
      "Epoch [42/50] - Train Loss: 1.0837, Test Loss: 1.2172\n",
      "Epoch [43/50] - Train Loss: 1.0793, Test Loss: 1.1759\n",
      "Epoch [44/50] - Train Loss: 1.0740, Test Loss: 1.1962\n",
      "Epoch [45/50] - Train Loss: 1.0699, Test Loss: 1.2194\n",
      "Epoch [46/50] - Train Loss: 1.0648, Test Loss: 1.1892\n",
      "Epoch [47/50] - Train Loss: 1.0616, Test Loss: 1.1892\n",
      "Epoch [48/50] - Train Loss: 1.0609, Test Loss: 1.1925\n",
      "Epoch [49/50] - Train Loss: 1.0610, Test Loss: 1.1859\n",
      "Epoch [50/50] - Train Loss: 1.0628, Test Loss: 1.1826\n",
      "Avg Test Loss: 1.1826\n",
      "Testing combination: (64, 2, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.3155, Test Loss: 1.1254\n",
      "Epoch [2/50] - Train Loss: 1.1649, Test Loss: 1.1360\n",
      "Epoch [3/50] - Train Loss: 1.1471, Test Loss: 1.1725\n",
      "Epoch [4/50] - Train Loss: 1.0950, Test Loss: 1.2325\n",
      "Epoch [5/50] - Train Loss: 1.1095, Test Loss: 1.2741\n",
      "Epoch [6/50] - Train Loss: 1.0535, Test Loss: 1.3208\n",
      "Epoch [7/50] - Train Loss: 1.1472, Test Loss: 1.1824\n",
      "Epoch [8/50] - Train Loss: 1.0865, Test Loss: 1.1953\n",
      "Epoch [9/50] - Train Loss: 1.0547, Test Loss: 1.2463\n",
      "Epoch [10/50] - Train Loss: 1.0518, Test Loss: 1.3016\n",
      "Epoch [11/50] - Train Loss: 1.0504, Test Loss: 1.2929\n",
      "Epoch [12/50] - Train Loss: 1.0485, Test Loss: 1.2703\n",
      "Epoch [13/50] - Train Loss: 1.0484, Test Loss: 1.2670\n",
      "Epoch [14/50] - Train Loss: 1.0480, Test Loss: 1.2750\n",
      "Epoch [15/50] - Train Loss: 1.0479, Test Loss: 1.2801\n",
      "Epoch [16/50] - Train Loss: 1.0478, Test Loss: 1.2781\n",
      "Epoch [17/50] - Train Loss: 1.0477, Test Loss: 1.2753\n",
      "Epoch [18/50] - Train Loss: 1.0476, Test Loss: 1.2754\n",
      "Epoch [19/50] - Train Loss: 1.0475, Test Loss: 1.2767\n",
      "Epoch [20/50] - Train Loss: 1.0475, Test Loss: 1.2767\n",
      "Epoch [21/50] - Train Loss: 1.0474, Test Loss: 1.2760\n",
      "Epoch [22/50] - Train Loss: 1.0474, Test Loss: 1.2757\n",
      "Epoch [23/50] - Train Loss: 1.0473, Test Loss: 1.2757\n",
      "Epoch [24/50] - Train Loss: 1.0473, Test Loss: 1.2756\n",
      "Epoch [25/50] - Train Loss: 1.0472, Test Loss: 1.2753\n",
      "Epoch [26/50] - Train Loss: 1.0472, Test Loss: 1.2750\n",
      "Epoch [27/50] - Train Loss: 1.0471, Test Loss: 1.2749\n",
      "Epoch [28/50] - Train Loss: 1.0471, Test Loss: 1.2749\n",
      "Epoch [29/50] - Train Loss: 1.0470, Test Loss: 1.2749\n",
      "Epoch [30/50] - Train Loss: 1.0469, Test Loss: 1.2746\n",
      "Epoch [31/50] - Train Loss: 1.0468, Test Loss: 1.2753\n",
      "Epoch [32/50] - Train Loss: 1.0459, Test Loss: 1.2706\n",
      "Epoch [33/50] - Train Loss: 1.0756, Test Loss: 1.2577\n",
      "Epoch [34/50] - Train Loss: 1.0485, Test Loss: 1.2568\n",
      "Epoch [35/50] - Train Loss: 1.0541, Test Loss: 1.2614\n",
      "Epoch [36/50] - Train Loss: 1.0692, Test Loss: 1.3108\n",
      "Epoch [37/50] - Train Loss: 1.0665, Test Loss: 1.1974\n",
      "Epoch [38/50] - Train Loss: 1.0423, Test Loss: 1.2569\n",
      "Epoch [39/50] - Train Loss: 1.0506, Test Loss: 1.2755\n",
      "Epoch [40/50] - Train Loss: 1.0440, Test Loss: 1.2514\n",
      "Epoch [41/50] - Train Loss: 1.0418, Test Loss: 1.2545\n",
      "Epoch [42/50] - Train Loss: 1.0394, Test Loss: 1.2616\n",
      "Epoch [43/50] - Train Loss: 1.0396, Test Loss: 1.2615\n",
      "Epoch [44/50] - Train Loss: 1.0393, Test Loss: 1.2492\n",
      "Epoch [45/50] - Train Loss: 1.0415, Test Loss: 1.2543\n",
      "Epoch [46/50] - Train Loss: 1.0385, Test Loss: 1.2566\n",
      "Epoch [47/50] - Train Loss: 1.0401, Test Loss: 1.2530\n",
      "Epoch [48/50] - Train Loss: 1.0388, Test Loss: 1.2547\n",
      "Epoch [49/50] - Train Loss: 1.0386, Test Loss: 1.2595\n",
      "Epoch [50/50] - Train Loss: 1.0385, Test Loss: 1.2502\n",
      "Avg Test Loss: 1.2502\n",
      "Testing combination: (64, 2, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5450, Test Loss: 1.7309\n",
      "Epoch [2/50] - Train Loss: 1.4832, Test Loss: 1.7382\n",
      "Epoch [3/50] - Train Loss: 1.4775, Test Loss: 1.7741\n",
      "Epoch [4/50] - Train Loss: 1.4469, Test Loss: 2.0411\n",
      "Epoch [5/50] - Train Loss: 1.8498, Test Loss: 1.7985\n",
      "Epoch [6/50] - Train Loss: 1.4771, Test Loss: 1.7496\n",
      "Epoch [7/50] - Train Loss: 1.4838, Test Loss: 1.7448\n",
      "Epoch [8/50] - Train Loss: 1.4781, Test Loss: 1.7443\n",
      "Epoch [9/50] - Train Loss: 1.4683, Test Loss: 1.7492\n",
      "Epoch [10/50] - Train Loss: 1.4547, Test Loss: 1.7674\n",
      "Epoch [11/50] - Train Loss: 1.4384, Test Loss: 1.8253\n",
      "Epoch [12/50] - Train Loss: 1.4305, Test Loss: 1.9189\n",
      "Epoch [13/50] - Train Loss: 1.4291, Test Loss: 1.9655\n",
      "Epoch [14/50] - Train Loss: 1.4205, Test Loss: 1.9570\n",
      "Epoch [15/50] - Train Loss: 1.4173, Test Loss: 1.9538\n",
      "Epoch [16/50] - Train Loss: 1.4193, Test Loss: 1.9488\n",
      "Epoch [17/50] - Train Loss: 1.4199, Test Loss: 1.9489\n",
      "Epoch [18/50] - Train Loss: 1.4211, Test Loss: 1.9422\n",
      "Epoch [19/50] - Train Loss: 1.4180, Test Loss: 1.9320\n",
      "Epoch [20/50] - Train Loss: 1.4159, Test Loss: 1.9235\n",
      "Epoch [21/50] - Train Loss: 1.4160, Test Loss: 1.9415\n",
      "Epoch [22/50] - Train Loss: 1.4155, Test Loss: 1.9209\n",
      "Epoch [23/50] - Train Loss: 1.4092, Test Loss: 1.9154\n",
      "Epoch [24/50] - Train Loss: 1.4110, Test Loss: 1.9147\n",
      "Epoch [25/50] - Train Loss: 1.4111, Test Loss: 1.9485\n",
      "Epoch [26/50] - Train Loss: 1.4122, Test Loss: 1.9113\n",
      "Epoch [27/50] - Train Loss: 1.4077, Test Loss: 1.9069\n",
      "Epoch [28/50] - Train Loss: 1.4111, Test Loss: 1.9067\n",
      "Epoch [29/50] - Train Loss: 1.4106, Test Loss: 1.9264\n",
      "Epoch [30/50] - Train Loss: 1.4092, Test Loss: 1.9744\n",
      "Epoch [31/50] - Train Loss: 1.4074, Test Loss: 1.9041\n",
      "Epoch [32/50] - Train Loss: 1.4061, Test Loss: 1.8966\n",
      "Epoch [33/50] - Train Loss: 1.4105, Test Loss: 1.8963\n",
      "Epoch [34/50] - Train Loss: 1.4096, Test Loss: 1.9244\n",
      "Epoch [35/50] - Train Loss: 1.4058, Test Loss: 1.9922\n",
      "Epoch [36/50] - Train Loss: 1.4038, Test Loss: 1.8980\n",
      "Epoch [37/50] - Train Loss: 1.4047, Test Loss: 1.8832\n",
      "Epoch [38/50] - Train Loss: 1.4108, Test Loss: 1.8759\n",
      "Epoch [39/50] - Train Loss: 1.4086, Test Loss: 1.9162\n",
      "Epoch [40/50] - Train Loss: 1.4016, Test Loss: 2.0209\n",
      "Epoch [41/50] - Train Loss: 1.3946, Test Loss: 1.9020\n",
      "Epoch [42/50] - Train Loss: 1.4078, Test Loss: 1.9116\n",
      "Epoch [43/50] - Train Loss: 1.4157, Test Loss: 1.9131\n",
      "Epoch [44/50] - Train Loss: 1.4147, Test Loss: 1.9083\n",
      "Epoch [45/50] - Train Loss: 1.4142, Test Loss: 1.8994\n",
      "Epoch [46/50] - Train Loss: 1.4128, Test Loss: 1.8897\n",
      "Epoch [47/50] - Train Loss: 1.4082, Test Loss: 1.9254\n",
      "Epoch [48/50] - Train Loss: 1.4004, Test Loss: 2.0636\n",
      "Epoch [49/50] - Train Loss: 1.3896, Test Loss: 1.9358\n",
      "Epoch [50/50] - Train Loss: 1.3979, Test Loss: 1.9356\n",
      "Avg Test Loss: 1.9356\n",
      "Testing combination: (64, 2, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1230, Test Loss: 1.0951\n",
      "Epoch [2/50] - Train Loss: 1.1176, Test Loss: 1.0928\n",
      "Epoch [3/50] - Train Loss: 1.1165, Test Loss: 1.0917\n",
      "Epoch [4/50] - Train Loss: 1.1157, Test Loss: 1.0928\n",
      "Epoch [5/50] - Train Loss: 1.1141, Test Loss: 1.0979\n",
      "Epoch [6/50] - Train Loss: 1.1085, Test Loss: 1.1111\n",
      "Epoch [7/50] - Train Loss: 1.0902, Test Loss: 1.1462\n",
      "Epoch [8/50] - Train Loss: 1.0719, Test Loss: 1.2146\n",
      "Epoch [9/50] - Train Loss: 1.0931, Test Loss: 1.1846\n",
      "Epoch [10/50] - Train Loss: 1.0777, Test Loss: 1.1983\n",
      "Epoch [11/50] - Train Loss: 1.0724, Test Loss: 1.2398\n",
      "Epoch [12/50] - Train Loss: 1.0717, Test Loss: 1.2687\n",
      "Epoch [13/50] - Train Loss: 1.0719, Test Loss: 1.2561\n",
      "Epoch [14/50] - Train Loss: 1.0710, Test Loss: 1.2442\n",
      "Epoch [15/50] - Train Loss: 1.0703, Test Loss: 1.2459\n",
      "Epoch [16/50] - Train Loss: 1.0700, Test Loss: 1.2510\n",
      "Epoch [17/50] - Train Loss: 1.0697, Test Loss: 1.2520\n",
      "Epoch [18/50] - Train Loss: 1.0694, Test Loss: 1.2518\n",
      "Epoch [19/50] - Train Loss: 1.0688, Test Loss: 1.2538\n",
      "Epoch [20/50] - Train Loss: 1.0683, Test Loss: 1.2574\n",
      "Epoch [21/50] - Train Loss: 1.0677, Test Loss: 1.2613\n",
      "Epoch [22/50] - Train Loss: 1.0668, Test Loss: 1.2662\n",
      "Epoch [23/50] - Train Loss: 1.0656, Test Loss: 1.2697\n",
      "Epoch [24/50] - Train Loss: 1.0635, Test Loss: 1.2718\n",
      "Epoch [25/50] - Train Loss: 1.0589, Test Loss: 1.2604\n",
      "Epoch [26/50] - Train Loss: 1.0508, Test Loss: 1.2127\n",
      "Epoch [27/50] - Train Loss: 1.0975, Test Loss: 1.1273\n",
      "Epoch [28/50] - Train Loss: 1.1339, Test Loss: 1.0781\n",
      "Epoch [29/50] - Train Loss: 1.1206, Test Loss: 1.1042\n",
      "Epoch [30/50] - Train Loss: 1.1014, Test Loss: 1.1149\n",
      "Epoch [31/50] - Train Loss: 1.0888, Test Loss: 1.1332\n",
      "Epoch [32/50] - Train Loss: 1.1164, Test Loss: 1.1360\n",
      "Epoch [33/50] - Train Loss: 1.0513, Test Loss: 1.1798\n",
      "Epoch [34/50] - Train Loss: 1.0960, Test Loss: 1.3065\n",
      "Epoch [35/50] - Train Loss: 1.1012, Test Loss: 1.1798\n",
      "Epoch [36/50] - Train Loss: 1.0643, Test Loss: 1.1894\n",
      "Epoch [37/50] - Train Loss: 1.0655, Test Loss: 1.2192\n",
      "Epoch [38/50] - Train Loss: 1.0649, Test Loss: 1.2374\n",
      "Epoch [39/50] - Train Loss: 1.0612, Test Loss: 1.2405\n",
      "Epoch [40/50] - Train Loss: 1.0594, Test Loss: 1.2427\n",
      "Epoch [41/50] - Train Loss: 1.0563, Test Loss: 1.2305\n",
      "Epoch [42/50] - Train Loss: 1.0556, Test Loss: 1.2338\n",
      "Epoch [43/50] - Train Loss: 1.0520, Test Loss: 1.2116\n",
      "Epoch [44/50] - Train Loss: 1.0826, Test Loss: 1.1974\n",
      "Epoch [45/50] - Train Loss: 1.0719, Test Loss: 1.1654\n",
      "Epoch [46/50] - Train Loss: 1.0804, Test Loss: 1.1882\n",
      "Epoch [47/50] - Train Loss: 1.0658, Test Loss: 1.2139\n",
      "Epoch [48/50] - Train Loss: 1.0470, Test Loss: 1.2309\n",
      "Epoch [49/50] - Train Loss: 1.0139, Test Loss: 1.3334\n",
      "Epoch [50/50] - Train Loss: 1.0391, Test Loss: 1.2370\n",
      "Avg Test Loss: 1.2370\n",
      "Testing combination: (64, 2, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1633, Test Loss: 1.1376\n",
      "Epoch [2/50] - Train Loss: 1.1529, Test Loss: 1.1467\n",
      "Epoch [3/50] - Train Loss: 1.1494, Test Loss: 1.1561\n",
      "Epoch [4/50] - Train Loss: 1.1461, Test Loss: 1.1665\n",
      "Epoch [5/50] - Train Loss: 1.1398, Test Loss: 1.1799\n",
      "Epoch [6/50] - Train Loss: 1.1225, Test Loss: 1.2000\n",
      "Epoch [7/50] - Train Loss: 1.0847, Test Loss: 1.2325\n",
      "Epoch [8/50] - Train Loss: 1.0549, Test Loss: 1.2819\n",
      "Epoch [9/50] - Train Loss: 1.0552, Test Loss: 1.2999\n",
      "Epoch [10/50] - Train Loss: 1.0477, Test Loss: 1.2775\n",
      "Epoch [11/50] - Train Loss: 1.0464, Test Loss: 1.2883\n",
      "Epoch [12/50] - Train Loss: 1.0467, Test Loss: 1.2981\n",
      "Epoch [13/50] - Train Loss: 1.0464, Test Loss: 1.2881\n",
      "Epoch [14/50] - Train Loss: 1.0461, Test Loss: 1.2861\n",
      "Epoch [15/50] - Train Loss: 1.0458, Test Loss: 1.2899\n",
      "Epoch [16/50] - Train Loss: 1.0457, Test Loss: 1.2893\n",
      "Epoch [17/50] - Train Loss: 1.0455, Test Loss: 1.2874\n",
      "Epoch [18/50] - Train Loss: 1.0453, Test Loss: 1.2880\n",
      "Epoch [19/50] - Train Loss: 1.0451, Test Loss: 1.2880\n",
      "Epoch [20/50] - Train Loss: 1.0449, Test Loss: 1.2868\n",
      "Epoch [21/50] - Train Loss: 1.0447, Test Loss: 1.2856\n",
      "Epoch [22/50] - Train Loss: 1.0444, Test Loss: 1.2847\n",
      "Epoch [23/50] - Train Loss: 1.0440, Test Loss: 1.2841\n",
      "Epoch [24/50] - Train Loss: 1.0436, Test Loss: 1.2818\n",
      "Epoch [25/50] - Train Loss: 1.0427, Test Loss: 1.2794\n",
      "Epoch [26/50] - Train Loss: 1.0413, Test Loss: 1.2772\n",
      "Epoch [27/50] - Train Loss: 1.0388, Test Loss: 1.2820\n",
      "Epoch [28/50] - Train Loss: 1.0371, Test Loss: 1.2719\n",
      "Epoch [29/50] - Train Loss: 1.0348, Test Loss: 1.2784\n",
      "Epoch [30/50] - Train Loss: 1.0326, Test Loss: 1.2674\n",
      "Epoch [31/50] - Train Loss: 1.0350, Test Loss: 1.2669\n",
      "Epoch [32/50] - Train Loss: 1.0463, Test Loss: 1.2570\n",
      "Epoch [33/50] - Train Loss: 1.0689, Test Loss: 1.2824\n",
      "Epoch [34/50] - Train Loss: 1.0603, Test Loss: 1.3459\n",
      "Epoch [35/50] - Train Loss: 1.0435, Test Loss: 1.2589\n",
      "Epoch [36/50] - Train Loss: 1.0439, Test Loss: 1.2457\n",
      "Epoch [37/50] - Train Loss: 1.0422, Test Loss: 1.2622\n",
      "Epoch [38/50] - Train Loss: 1.0412, Test Loss: 1.2753\n",
      "Epoch [39/50] - Train Loss: 1.0396, Test Loss: 1.2785\n",
      "Epoch [40/50] - Train Loss: 1.0381, Test Loss: 1.2772\n",
      "Epoch [41/50] - Train Loss: 1.0363, Test Loss: 1.2747\n",
      "Epoch [42/50] - Train Loss: 1.0341, Test Loss: 1.2710\n",
      "Epoch [43/50] - Train Loss: 1.0314, Test Loss: 1.2651\n",
      "Epoch [44/50] - Train Loss: 1.0315, Test Loss: 1.2549\n",
      "Epoch [45/50] - Train Loss: 1.0697, Test Loss: 1.2590\n",
      "Epoch [46/50] - Train Loss: 1.0160, Test Loss: 1.2324\n",
      "Epoch [47/50] - Train Loss: 1.0324, Test Loss: 1.2504\n",
      "Epoch [48/50] - Train Loss: 1.0276, Test Loss: 1.2994\n",
      "Epoch [49/50] - Train Loss: 1.0261, Test Loss: 1.2605\n",
      "Epoch [50/50] - Train Loss: 1.0548, Test Loss: 1.2851\n",
      "Avg Test Loss: 1.2851\n",
      "Testing combination: (64, 2, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.4994, Test Loss: 1.7432\n",
      "Epoch [2/50] - Train Loss: 1.4916, Test Loss: 1.7422\n",
      "Epoch [3/50] - Train Loss: 1.4887, Test Loss: 1.7415\n",
      "Epoch [4/50] - Train Loss: 1.4866, Test Loss: 1.7419\n",
      "Epoch [5/50] - Train Loss: 1.4851, Test Loss: 1.7434\n",
      "Epoch [6/50] - Train Loss: 1.4839, Test Loss: 1.7459\n",
      "Epoch [7/50] - Train Loss: 1.4827, Test Loss: 1.7498\n",
      "Epoch [8/50] - Train Loss: 1.4811, Test Loss: 1.7555\n",
      "Epoch [9/50] - Train Loss: 1.4786, Test Loss: 1.7642\n",
      "Epoch [10/50] - Train Loss: 1.4742, Test Loss: 1.7781\n",
      "Epoch [11/50] - Train Loss: 1.4665, Test Loss: 1.8009\n",
      "Epoch [12/50] - Train Loss: 1.4543, Test Loss: 1.8401\n",
      "Epoch [13/50] - Train Loss: 1.4382, Test Loss: 1.9040\n",
      "Epoch [14/50] - Train Loss: 1.4247, Test Loss: 1.9871\n",
      "Epoch [15/50] - Train Loss: 1.4250, Test Loss: 2.0429\n",
      "Epoch [16/50] - Train Loss: 1.4222, Test Loss: 2.0599\n",
      "Epoch [17/50] - Train Loss: 1.4212, Test Loss: 2.0661\n",
      "Epoch [18/50] - Train Loss: 1.4216, Test Loss: 2.0750\n",
      "Epoch [19/50] - Train Loss: 1.4215, Test Loss: 2.0895\n",
      "Epoch [20/50] - Train Loss: 1.4209, Test Loss: 2.1064\n",
      "Epoch [21/50] - Train Loss: 1.4202, Test Loss: 2.1195\n",
      "Epoch [22/50] - Train Loss: 1.4198, Test Loss: 2.1245\n",
      "Epoch [23/50] - Train Loss: 1.4191, Test Loss: 2.1232\n",
      "Epoch [24/50] - Train Loss: 1.4182, Test Loss: 2.1225\n",
      "Epoch [25/50] - Train Loss: 1.4174, Test Loss: 2.1284\n",
      "Epoch [26/50] - Train Loss: 1.4166, Test Loss: 2.1424\n",
      "Epoch [27/50] - Train Loss: 1.4160, Test Loss: 2.1600\n",
      "Epoch [28/50] - Train Loss: 1.4153, Test Loss: 2.1738\n",
      "Epoch [29/50] - Train Loss: 1.4148, Test Loss: 2.1799\n",
      "Epoch [30/50] - Train Loss: 1.4141, Test Loss: 2.1811\n",
      "Epoch [31/50] - Train Loss: 1.4134, Test Loss: 2.1835\n",
      "Epoch [32/50] - Train Loss: 1.4126, Test Loss: 2.1908\n",
      "Epoch [33/50] - Train Loss: 1.4117, Test Loss: 2.1972\n",
      "Epoch [34/50] - Train Loss: 1.4105, Test Loss: 2.1992\n",
      "Epoch [35/50] - Train Loss: 1.4090, Test Loss: 2.2029\n",
      "Epoch [36/50] - Train Loss: 1.4067, Test Loss: 2.1925\n",
      "Epoch [37/50] - Train Loss: 1.4036, Test Loss: 2.1972\n",
      "Epoch [38/50] - Train Loss: 1.3977, Test Loss: 2.1936\n",
      "Epoch [39/50] - Train Loss: 1.4050, Test Loss: 2.1848\n",
      "Epoch [40/50] - Train Loss: 1.3774, Test Loss: 2.0971\n",
      "Epoch [41/50] - Train Loss: 1.3897, Test Loss: 2.2201\n",
      "Epoch [42/50] - Train Loss: 1.3951, Test Loss: 2.1652\n",
      "Epoch [43/50] - Train Loss: 1.3628, Test Loss: 2.0907\n",
      "Epoch [44/50] - Train Loss: 1.4010, Test Loss: 2.1268\n",
      "Epoch [45/50] - Train Loss: 1.3925, Test Loss: 2.2779\n",
      "Epoch [46/50] - Train Loss: 1.4359, Test Loss: 2.1805\n",
      "Epoch [47/50] - Train Loss: 1.3753, Test Loss: 1.9648\n",
      "Epoch [48/50] - Train Loss: 1.4522, Test Loss: 1.9423\n",
      "Epoch [49/50] - Train Loss: 1.4521, Test Loss: 1.9526\n",
      "Epoch [50/50] - Train Loss: 1.4453, Test Loss: 1.9754\n",
      "Avg Test Loss: 1.9754\n",
      "Testing combination: (64, 2, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1254, Test Loss: 1.0811\n",
      "Epoch [2/50] - Train Loss: 1.1235, Test Loss: 1.0811\n",
      "Epoch [3/50] - Train Loss: 1.1225, Test Loss: 1.0812\n",
      "Epoch [4/50] - Train Loss: 1.1217, Test Loss: 1.0814\n",
      "Epoch [5/50] - Train Loss: 1.1210, Test Loss: 1.0816\n",
      "Epoch [6/50] - Train Loss: 1.1203, Test Loss: 1.0818\n",
      "Epoch [7/50] - Train Loss: 1.1198, Test Loss: 1.0822\n",
      "Epoch [8/50] - Train Loss: 1.1193, Test Loss: 1.0825\n",
      "Epoch [9/50] - Train Loss: 1.1188, Test Loss: 1.0829\n",
      "Epoch [10/50] - Train Loss: 1.1183, Test Loss: 1.0834\n",
      "Epoch [11/50] - Train Loss: 1.1179, Test Loss: 1.0839\n",
      "Epoch [12/50] - Train Loss: 1.1176, Test Loss: 1.0844\n",
      "Epoch [13/50] - Train Loss: 1.1172, Test Loss: 1.0850\n",
      "Epoch [14/50] - Train Loss: 1.1169, Test Loss: 1.0856\n",
      "Epoch [15/50] - Train Loss: 1.1166, Test Loss: 1.0863\n",
      "Epoch [16/50] - Train Loss: 1.1163, Test Loss: 1.0871\n",
      "Epoch [17/50] - Train Loss: 1.1160, Test Loss: 1.0879\n",
      "Epoch [18/50] - Train Loss: 1.1156, Test Loss: 1.0888\n",
      "Epoch [19/50] - Train Loss: 1.1153, Test Loss: 1.0898\n",
      "Epoch [20/50] - Train Loss: 1.1149, Test Loss: 1.0909\n",
      "Epoch [21/50] - Train Loss: 1.1145, Test Loss: 1.0922\n",
      "Epoch [22/50] - Train Loss: 1.1141, Test Loss: 1.0938\n",
      "Epoch [23/50] - Train Loss: 1.1135, Test Loss: 1.0956\n",
      "Epoch [24/50] - Train Loss: 1.1129, Test Loss: 1.0977\n",
      "Epoch [25/50] - Train Loss: 1.1121, Test Loss: 1.1004\n",
      "Epoch [26/50] - Train Loss: 1.1110, Test Loss: 1.1036\n",
      "Epoch [27/50] - Train Loss: 1.1096, Test Loss: 1.1075\n",
      "Epoch [28/50] - Train Loss: 1.1078, Test Loss: 1.1122\n",
      "Epoch [29/50] - Train Loss: 1.1055, Test Loss: 1.1177\n",
      "Epoch [30/50] - Train Loss: 1.1026, Test Loss: 1.1240\n",
      "Epoch [31/50] - Train Loss: 1.0992, Test Loss: 1.1311\n",
      "Epoch [32/50] - Train Loss: 1.0953, Test Loss: 1.1390\n",
      "Epoch [33/50] - Train Loss: 1.0912, Test Loss: 1.1474\n",
      "Epoch [34/50] - Train Loss: 1.0872, Test Loss: 1.1563\n",
      "Epoch [35/50] - Train Loss: 1.0834, Test Loss: 1.1655\n",
      "Epoch [36/50] - Train Loss: 1.0800, Test Loss: 1.1749\n",
      "Epoch [37/50] - Train Loss: 1.0770, Test Loss: 1.1842\n",
      "Epoch [38/50] - Train Loss: 1.0746, Test Loss: 1.1932\n",
      "Epoch [39/50] - Train Loss: 1.0728, Test Loss: 1.2014\n",
      "Epoch [40/50] - Train Loss: 1.0714, Test Loss: 1.2084\n",
      "Epoch [41/50] - Train Loss: 1.0705, Test Loss: 1.2142\n",
      "Epoch [42/50] - Train Loss: 1.0698, Test Loss: 1.2188\n",
      "Epoch [43/50] - Train Loss: 1.0693, Test Loss: 1.2225\n",
      "Epoch [44/50] - Train Loss: 1.0689, Test Loss: 1.2255\n",
      "Epoch [45/50] - Train Loss: 1.0686, Test Loss: 1.2280\n",
      "Epoch [46/50] - Train Loss: 1.0684, Test Loss: 1.2302\n",
      "Epoch [47/50] - Train Loss: 1.0681, Test Loss: 1.2321\n",
      "Epoch [48/50] - Train Loss: 1.0679, Test Loss: 1.2338\n",
      "Epoch [49/50] - Train Loss: 1.0677, Test Loss: 1.2353\n",
      "Epoch [50/50] - Train Loss: 1.0676, Test Loss: 1.2367\n",
      "Avg Test Loss: 1.2367\n",
      "Testing combination: (64, 2, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1498, Test Loss: 1.1686\n",
      "Epoch [2/50] - Train Loss: 1.1490, Test Loss: 1.1685\n",
      "Epoch [3/50] - Train Loss: 1.1489, Test Loss: 1.1684\n",
      "Epoch [4/50] - Train Loss: 1.1488, Test Loss: 1.1684\n",
      "Epoch [5/50] - Train Loss: 1.1487, Test Loss: 1.1685\n",
      "Epoch [6/50] - Train Loss: 1.1486, Test Loss: 1.1685\n",
      "Epoch [7/50] - Train Loss: 1.1485, Test Loss: 1.1685\n",
      "Epoch [8/50] - Train Loss: 1.1485, Test Loss: 1.1686\n",
      "Epoch [9/50] - Train Loss: 1.1484, Test Loss: 1.1686\n",
      "Epoch [10/50] - Train Loss: 1.1483, Test Loss: 1.1687\n",
      "Epoch [11/50] - Train Loss: 1.1482, Test Loss: 1.1688\n",
      "Epoch [12/50] - Train Loss: 1.1481, Test Loss: 1.1688\n",
      "Epoch [13/50] - Train Loss: 1.1480, Test Loss: 1.1690\n",
      "Epoch [14/50] - Train Loss: 1.1478, Test Loss: 1.1691\n",
      "Epoch [15/50] - Train Loss: 1.1477, Test Loss: 1.1692\n",
      "Epoch [16/50] - Train Loss: 1.1475, Test Loss: 1.1694\n",
      "Epoch [17/50] - Train Loss: 1.1473, Test Loss: 1.1696\n",
      "Epoch [18/50] - Train Loss: 1.1471, Test Loss: 1.1698\n",
      "Epoch [19/50] - Train Loss: 1.1468, Test Loss: 1.1701\n",
      "Epoch [20/50] - Train Loss: 1.1465, Test Loss: 1.1704\n",
      "Epoch [21/50] - Train Loss: 1.1462, Test Loss: 1.1708\n",
      "Epoch [22/50] - Train Loss: 1.1457, Test Loss: 1.1712\n",
      "Epoch [23/50] - Train Loss: 1.1452, Test Loss: 1.1718\n",
      "Epoch [24/50] - Train Loss: 1.1446, Test Loss: 1.1725\n",
      "Epoch [25/50] - Train Loss: 1.1438, Test Loss: 1.1733\n",
      "Epoch [26/50] - Train Loss: 1.1429, Test Loss: 1.1744\n",
      "Epoch [27/50] - Train Loss: 1.1418, Test Loss: 1.1756\n",
      "Epoch [28/50] - Train Loss: 1.1403, Test Loss: 1.1772\n",
      "Epoch [29/50] - Train Loss: 1.1385, Test Loss: 1.1793\n",
      "Epoch [30/50] - Train Loss: 1.1362, Test Loss: 1.1818\n",
      "Epoch [31/50] - Train Loss: 1.1333, Test Loss: 1.1850\n",
      "Epoch [32/50] - Train Loss: 1.1295, Test Loss: 1.1891\n",
      "Epoch [33/50] - Train Loss: 1.1246, Test Loss: 1.1941\n",
      "Epoch [34/50] - Train Loss: 1.1185, Test Loss: 1.2003\n",
      "Epoch [35/50] - Train Loss: 1.1109, Test Loss: 1.2076\n",
      "Epoch [36/50] - Train Loss: 1.1020, Test Loss: 1.2160\n",
      "Epoch [37/50] - Train Loss: 1.0923, Test Loss: 1.2252\n",
      "Epoch [38/50] - Train Loss: 1.0825, Test Loss: 1.2351\n",
      "Epoch [39/50] - Train Loss: 1.0735, Test Loss: 1.2454\n",
      "Epoch [40/50] - Train Loss: 1.0657, Test Loss: 1.2560\n",
      "Epoch [41/50] - Train Loss: 1.0593, Test Loss: 1.2665\n",
      "Epoch [42/50] - Train Loss: 1.0545, Test Loss: 1.2767\n",
      "Epoch [43/50] - Train Loss: 1.0511, Test Loss: 1.2860\n",
      "Epoch [44/50] - Train Loss: 1.0489, Test Loss: 1.2938\n",
      "Epoch [45/50] - Train Loss: 1.0475, Test Loss: 1.2999\n",
      "Epoch [46/50] - Train Loss: 1.0466, Test Loss: 1.3039\n",
      "Epoch [47/50] - Train Loss: 1.0460, Test Loss: 1.3063\n",
      "Epoch [48/50] - Train Loss: 1.0455, Test Loss: 1.3074\n",
      "Epoch [49/50] - Train Loss: 1.0451, Test Loss: 1.3077\n",
      "Epoch [50/50] - Train Loss: 1.0447, Test Loss: 1.3077\n",
      "Avg Test Loss: 1.3077\n",
      "Testing combination: (64, 2, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5317, Test Loss: 1.7937\n",
      "Epoch [2/50] - Train Loss: 1.5293, Test Loss: 1.7909\n",
      "Epoch [3/50] - Train Loss: 1.5271, Test Loss: 1.7880\n",
      "Epoch [4/50] - Train Loss: 1.5250, Test Loss: 1.7852\n",
      "Epoch [5/50] - Train Loss: 1.5229, Test Loss: 1.7825\n",
      "Epoch [6/50] - Train Loss: 1.5209, Test Loss: 1.7799\n",
      "Epoch [7/50] - Train Loss: 1.5190, Test Loss: 1.7775\n",
      "Epoch [8/50] - Train Loss: 1.5171, Test Loss: 1.7751\n",
      "Epoch [9/50] - Train Loss: 1.5154, Test Loss: 1.7729\n",
      "Epoch [10/50] - Train Loss: 1.5137, Test Loss: 1.7708\n",
      "Epoch [11/50] - Train Loss: 1.5120, Test Loss: 1.7688\n",
      "Epoch [12/50] - Train Loss: 1.5104, Test Loss: 1.7670\n",
      "Epoch [13/50] - Train Loss: 1.5089, Test Loss: 1.7652\n",
      "Epoch [14/50] - Train Loss: 1.5075, Test Loss: 1.7636\n",
      "Epoch [15/50] - Train Loss: 1.5061, Test Loss: 1.7620\n",
      "Epoch [16/50] - Train Loss: 1.5047, Test Loss: 1.7606\n",
      "Epoch [17/50] - Train Loss: 1.5034, Test Loss: 1.7592\n",
      "Epoch [18/50] - Train Loss: 1.5022, Test Loss: 1.7580\n",
      "Epoch [19/50] - Train Loss: 1.5010, Test Loss: 1.7569\n",
      "Epoch [20/50] - Train Loss: 1.4998, Test Loss: 1.7558\n",
      "Epoch [21/50] - Train Loss: 1.4987, Test Loss: 1.7549\n",
      "Epoch [22/50] - Train Loss: 1.4977, Test Loss: 1.7540\n",
      "Epoch [23/50] - Train Loss: 1.4966, Test Loss: 1.7532\n",
      "Epoch [24/50] - Train Loss: 1.4957, Test Loss: 1.7526\n",
      "Epoch [25/50] - Train Loss: 1.4947, Test Loss: 1.7520\n",
      "Epoch [26/50] - Train Loss: 1.4938, Test Loss: 1.7515\n",
      "Epoch [27/50] - Train Loss: 1.4930, Test Loss: 1.7511\n",
      "Epoch [28/50] - Train Loss: 1.4922, Test Loss: 1.7508\n",
      "Epoch [29/50] - Train Loss: 1.4914, Test Loss: 1.7506\n",
      "Epoch [30/50] - Train Loss: 1.4906, Test Loss: 1.7505\n",
      "Epoch [31/50] - Train Loss: 1.4899, Test Loss: 1.7505\n",
      "Epoch [32/50] - Train Loss: 1.4892, Test Loss: 1.7506\n",
      "Epoch [33/50] - Train Loss: 1.4885, Test Loss: 1.7508\n",
      "Epoch [34/50] - Train Loss: 1.4879, Test Loss: 1.7511\n",
      "Epoch [35/50] - Train Loss: 1.4873, Test Loss: 1.7515\n",
      "Epoch [36/50] - Train Loss: 1.4867, Test Loss: 1.7520\n",
      "Epoch [37/50] - Train Loss: 1.4861, Test Loss: 1.7526\n",
      "Epoch [38/50] - Train Loss: 1.4856, Test Loss: 1.7533\n",
      "Epoch [39/50] - Train Loss: 1.4851, Test Loss: 1.7541\n",
      "Epoch [40/50] - Train Loss: 1.4845, Test Loss: 1.7550\n",
      "Epoch [41/50] - Train Loss: 1.4840, Test Loss: 1.7560\n",
      "Epoch [42/50] - Train Loss: 1.4835, Test Loss: 1.7570\n",
      "Epoch [43/50] - Train Loss: 1.4831, Test Loss: 1.7582\n",
      "Epoch [44/50] - Train Loss: 1.4826, Test Loss: 1.7595\n",
      "Epoch [45/50] - Train Loss: 1.4821, Test Loss: 1.7609\n",
      "Epoch [46/50] - Train Loss: 1.4816, Test Loss: 1.7623\n",
      "Epoch [47/50] - Train Loss: 1.4812, Test Loss: 1.7639\n",
      "Epoch [48/50] - Train Loss: 1.4807, Test Loss: 1.7656\n",
      "Epoch [49/50] - Train Loss: 1.4802, Test Loss: 1.7673\n",
      "Epoch [50/50] - Train Loss: 1.4797, Test Loss: 1.7692\n",
      "Avg Test Loss: 1.7692\n",
      "Testing combination: (64, 3, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.3471, Test Loss: 1.1001\n",
      "Epoch [2/50] - Train Loss: 1.1189, Test Loss: 1.0877\n",
      "Epoch [3/50] - Train Loss: 1.1183, Test Loss: 1.0865\n",
      "Epoch [4/50] - Train Loss: 1.1166, Test Loss: 1.0888\n",
      "Epoch [5/50] - Train Loss: 1.1036, Test Loss: 1.1441\n",
      "Epoch [6/50] - Train Loss: 1.1222, Test Loss: 1.1015\n",
      "Epoch [7/50] - Train Loss: 1.0973, Test Loss: 1.1152\n",
      "Epoch [8/50] - Train Loss: 1.0819, Test Loss: 1.2042\n",
      "Epoch [9/50] - Train Loss: 1.2511, Test Loss: 1.1024\n",
      "Epoch [10/50] - Train Loss: 1.1124, Test Loss: 1.0962\n",
      "Epoch [11/50] - Train Loss: 1.1046, Test Loss: 1.0990\n",
      "Epoch [12/50] - Train Loss: 1.0901, Test Loss: 1.1196\n",
      "Epoch [13/50] - Train Loss: 1.0768, Test Loss: 1.1957\n",
      "Epoch [14/50] - Train Loss: 1.0813, Test Loss: 1.1478\n",
      "Epoch [15/50] - Train Loss: 1.0741, Test Loss: 1.1687\n",
      "Epoch [16/50] - Train Loss: 1.0748, Test Loss: 1.1709\n",
      "Epoch [17/50] - Train Loss: 1.0746, Test Loss: 1.1684\n",
      "Epoch [18/50] - Train Loss: 1.0741, Test Loss: 1.1750\n",
      "Epoch [19/50] - Train Loss: 1.0739, Test Loss: 1.1719\n",
      "Epoch [20/50] - Train Loss: 1.0735, Test Loss: 1.1766\n",
      "Epoch [21/50] - Train Loss: 1.0727, Test Loss: 1.1782\n",
      "Epoch [22/50] - Train Loss: 1.0674, Test Loss: 1.1840\n",
      "Epoch [23/50] - Train Loss: 1.0744, Test Loss: 1.1841\n",
      "Epoch [24/50] - Train Loss: 1.2410, Test Loss: 1.1939\n",
      "Epoch [25/50] - Train Loss: 1.1464, Test Loss: 1.1049\n",
      "Epoch [26/50] - Train Loss: 1.2869, Test Loss: 1.0840\n",
      "Epoch [27/50] - Train Loss: 1.1114, Test Loss: 1.1774\n",
      "Epoch [28/50] - Train Loss: 1.0893, Test Loss: 1.2424\n",
      "Epoch [29/50] - Train Loss: 1.0501, Test Loss: 1.3381\n",
      "Epoch [30/50] - Train Loss: 1.0793, Test Loss: 1.2457\n",
      "Epoch [31/50] - Train Loss: 1.1136, Test Loss: 1.2304\n",
      "Epoch [32/50] - Train Loss: 1.0777, Test Loss: 1.2319\n",
      "Epoch [33/50] - Train Loss: 1.0737, Test Loss: 1.2252\n",
      "Epoch [34/50] - Train Loss: 1.0703, Test Loss: 1.2239\n",
      "Epoch [35/50] - Train Loss: 1.0663, Test Loss: 1.2023\n",
      "Epoch [36/50] - Train Loss: 1.0639, Test Loss: 1.1934\n",
      "Epoch [37/50] - Train Loss: 1.0647, Test Loss: 1.1796\n",
      "Epoch [38/50] - Train Loss: 1.0644, Test Loss: 1.1876\n",
      "Epoch [39/50] - Train Loss: 1.0617, Test Loss: 1.1813\n",
      "Epoch [40/50] - Train Loss: 1.0621, Test Loss: 1.2255\n",
      "Epoch [41/50] - Train Loss: 1.0637, Test Loss: 1.2658\n",
      "Epoch [42/50] - Train Loss: 1.0633, Test Loss: 1.1984\n",
      "Epoch [43/50] - Train Loss: 1.0601, Test Loss: 1.2190\n",
      "Epoch [44/50] - Train Loss: 1.0595, Test Loss: 1.2220\n",
      "Epoch [45/50] - Train Loss: 1.0601, Test Loss: 1.1970\n",
      "Epoch [46/50] - Train Loss: 1.0595, Test Loss: 1.2155\n",
      "Epoch [47/50] - Train Loss: 1.0649, Test Loss: 1.2210\n",
      "Epoch [48/50] - Train Loss: 1.0587, Test Loss: 1.2091\n",
      "Epoch [49/50] - Train Loss: 1.0682, Test Loss: 1.1775\n",
      "Epoch [50/50] - Train Loss: 1.0627, Test Loss: 1.2082\n",
      "Avg Test Loss: 1.2082\n",
      "Testing combination: (64, 3, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.5966, Test Loss: 1.1328\n",
      "Epoch [2/50] - Train Loss: 1.1539, Test Loss: 1.1444\n",
      "Epoch [3/50] - Train Loss: 1.1321, Test Loss: 1.1677\n",
      "Epoch [4/50] - Train Loss: 1.0710, Test Loss: 1.2345\n",
      "Epoch [5/50] - Train Loss: 1.4824, Test Loss: 1.1395\n",
      "Epoch [6/50] - Train Loss: 1.1515, Test Loss: 1.1345\n",
      "Epoch [7/50] - Train Loss: 1.1355, Test Loss: 1.1431\n",
      "Epoch [8/50] - Train Loss: 1.1061, Test Loss: 1.1673\n",
      "Epoch [9/50] - Train Loss: 1.0662, Test Loss: 1.2036\n",
      "Epoch [10/50] - Train Loss: 1.0629, Test Loss: 1.2354\n",
      "Epoch [11/50] - Train Loss: 1.0502, Test Loss: 1.2590\n",
      "Epoch [12/50] - Train Loss: 1.0506, Test Loss: 1.2457\n",
      "Epoch [13/50] - Train Loss: 1.0755, Test Loss: 1.2248\n",
      "Epoch [14/50] - Train Loss: 1.0480, Test Loss: 1.2446\n",
      "Epoch [15/50] - Train Loss: 1.0497, Test Loss: 1.2376\n",
      "Epoch [16/50] - Train Loss: 1.0462, Test Loss: 1.2412\n",
      "Epoch [17/50] - Train Loss: 1.0432, Test Loss: 1.2441\n",
      "Epoch [18/50] - Train Loss: 1.0413, Test Loss: 1.2384\n",
      "Epoch [19/50] - Train Loss: 1.0400, Test Loss: 1.2397\n",
      "Epoch [20/50] - Train Loss: 1.0392, Test Loss: 1.2399\n",
      "Epoch [21/50] - Train Loss: 1.0386, Test Loss: 1.2396\n",
      "Epoch [22/50] - Train Loss: 1.0383, Test Loss: 1.2403\n",
      "Epoch [23/50] - Train Loss: 1.0379, Test Loss: 1.2410\n",
      "Epoch [24/50] - Train Loss: 1.0378, Test Loss: 1.2407\n",
      "Epoch [25/50] - Train Loss: 1.0374, Test Loss: 1.2413\n",
      "Epoch [26/50] - Train Loss: 1.0376, Test Loss: 1.2410\n",
      "Epoch [27/50] - Train Loss: 1.0370, Test Loss: 1.2423\n",
      "Epoch [28/50] - Train Loss: 1.0378, Test Loss: 1.2407\n",
      "Epoch [29/50] - Train Loss: 1.0370, Test Loss: 1.2441\n",
      "Epoch [30/50] - Train Loss: 1.0418, Test Loss: 1.2310\n",
      "Epoch [31/50] - Train Loss: 1.0457, Test Loss: 1.2439\n",
      "Epoch [32/50] - Train Loss: 1.0421, Test Loss: 1.2739\n",
      "Epoch [33/50] - Train Loss: 1.0409, Test Loss: 1.2557\n",
      "Epoch [34/50] - Train Loss: 1.0424, Test Loss: 1.2583\n",
      "Epoch [35/50] - Train Loss: 1.0390, Test Loss: 1.2593\n",
      "Epoch [36/50] - Train Loss: 1.0387, Test Loss: 1.2563\n",
      "Epoch [37/50] - Train Loss: 1.0391, Test Loss: 1.2535\n",
      "Epoch [38/50] - Train Loss: 1.0390, Test Loss: 1.2500\n",
      "Epoch [39/50] - Train Loss: 1.0370, Test Loss: 1.2547\n",
      "Epoch [40/50] - Train Loss: 1.0392, Test Loss: 1.2468\n",
      "Epoch [41/50] - Train Loss: 1.0369, Test Loss: 1.2569\n",
      "Epoch [42/50] - Train Loss: 1.0383, Test Loss: 1.2492\n",
      "Epoch [43/50] - Train Loss: 1.0443, Test Loss: 1.2546\n",
      "Epoch [44/50] - Train Loss: 1.0382, Test Loss: 1.2522\n",
      "Epoch [45/50] - Train Loss: 1.0374, Test Loss: 1.2453\n",
      "Epoch [46/50] - Train Loss: 1.0370, Test Loss: 1.2596\n",
      "Epoch [47/50] - Train Loss: 1.0360, Test Loss: 1.2443\n",
      "Epoch [48/50] - Train Loss: 1.0365, Test Loss: 1.2451\n",
      "Epoch [49/50] - Train Loss: 1.0351, Test Loss: 1.2596\n",
      "Epoch [50/50] - Train Loss: 1.0353, Test Loss: 1.2373\n",
      "Avg Test Loss: 1.2373\n",
      "Testing combination: (64, 3, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5558, Test Loss: 1.7342\n",
      "Epoch [2/50] - Train Loss: 1.4853, Test Loss: 1.7379\n",
      "Epoch [3/50] - Train Loss: 1.4842, Test Loss: 1.7466\n",
      "Epoch [4/50] - Train Loss: 1.4655, Test Loss: 1.8599\n",
      "Epoch [5/50] - Train Loss: 1.6864, Test Loss: 1.7691\n",
      "Epoch [6/50] - Train Loss: 1.4820, Test Loss: 1.7500\n",
      "Epoch [7/50] - Train Loss: 1.4848, Test Loss: 1.7495\n",
      "Epoch [8/50] - Train Loss: 1.4818, Test Loss: 1.7532\n",
      "Epoch [9/50] - Train Loss: 1.4739, Test Loss: 1.7672\n",
      "Epoch [10/50] - Train Loss: 1.4577, Test Loss: 1.8146\n",
      "Epoch [11/50] - Train Loss: 1.4319, Test Loss: 1.9646\n",
      "Epoch [12/50] - Train Loss: 1.6400, Test Loss: 1.8377\n",
      "Epoch [13/50] - Train Loss: 1.4602, Test Loss: 1.7924\n",
      "Epoch [14/50] - Train Loss: 1.4657, Test Loss: 1.7826\n",
      "Epoch [15/50] - Train Loss: 1.4613, Test Loss: 1.7931\n",
      "Epoch [16/50] - Train Loss: 1.4505, Test Loss: 1.8418\n",
      "Epoch [17/50] - Train Loss: 1.4403, Test Loss: 1.8930\n",
      "Epoch [18/50] - Train Loss: 1.4328, Test Loss: 1.9607\n",
      "Epoch [19/50] - Train Loss: 1.4297, Test Loss: 2.0352\n",
      "Epoch [20/50] - Train Loss: 1.4302, Test Loss: 2.0866\n",
      "Epoch [21/50] - Train Loss: 1.4277, Test Loss: 2.0984\n",
      "Epoch [22/50] - Train Loss: 1.4229, Test Loss: 2.0840\n",
      "Epoch [23/50] - Train Loss: 1.4200, Test Loss: 2.0559\n",
      "Epoch [24/50] - Train Loss: 1.4175, Test Loss: 2.0304\n",
      "Epoch [25/50] - Train Loss: 1.4161, Test Loss: 2.0347\n",
      "Epoch [26/50] - Train Loss: 1.4163, Test Loss: 2.0303\n",
      "Epoch [27/50] - Train Loss: 1.4119, Test Loss: 2.0412\n",
      "Epoch [28/50] - Train Loss: 1.4130, Test Loss: 2.0584\n",
      "Epoch [29/50] - Train Loss: 1.4134, Test Loss: 2.0958\n",
      "Epoch [30/50] - Train Loss: 1.4140, Test Loss: 2.0596\n",
      "Epoch [31/50] - Train Loss: 1.4136, Test Loss: 2.0598\n",
      "Epoch [32/50] - Train Loss: 1.4182, Test Loss: 2.0603\n",
      "Epoch [33/50] - Train Loss: 1.4171, Test Loss: 2.0674\n",
      "Epoch [34/50] - Train Loss: 1.4141, Test Loss: 2.0608\n",
      "Epoch [35/50] - Train Loss: 1.4129, Test Loss: 2.0642\n",
      "Epoch [36/50] - Train Loss: 1.4118, Test Loss: 2.0684\n",
      "Epoch [37/50] - Train Loss: 1.4110, Test Loss: 2.0589\n",
      "Epoch [38/50] - Train Loss: 1.4081, Test Loss: 2.0870\n",
      "Epoch [39/50] - Train Loss: 1.4049, Test Loss: 2.0365\n",
      "Epoch [40/50] - Train Loss: 1.4023, Test Loss: 2.0400\n",
      "Epoch [41/50] - Train Loss: 1.4054, Test Loss: 2.0955\n",
      "Epoch [42/50] - Train Loss: 1.4048, Test Loss: 2.0910\n",
      "Epoch [43/50] - Train Loss: 1.3983, Test Loss: 2.0923\n",
      "Epoch [44/50] - Train Loss: 1.4000, Test Loss: 2.1221\n",
      "Epoch [45/50] - Train Loss: 1.3989, Test Loss: 2.0670\n",
      "Epoch [46/50] - Train Loss: 1.3984, Test Loss: 2.1079\n",
      "Epoch [47/50] - Train Loss: 1.3957, Test Loss: 2.1102\n",
      "Epoch [48/50] - Train Loss: 1.3901, Test Loss: 2.1503\n",
      "Epoch [49/50] - Train Loss: 1.3729, Test Loss: 1.9920\n",
      "Epoch [50/50] - Train Loss: 1.5226, Test Loss: 1.7425\n",
      "Avg Test Loss: 1.7425\n",
      "Testing combination: (64, 3, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1307, Test Loss: 1.1083\n",
      "Epoch [2/50] - Train Loss: 1.1201, Test Loss: 1.0976\n",
      "Epoch [3/50] - Train Loss: 1.1174, Test Loss: 1.0920\n",
      "Epoch [4/50] - Train Loss: 1.1166, Test Loss: 1.0896\n",
      "Epoch [5/50] - Train Loss: 1.1161, Test Loss: 1.0895\n",
      "Epoch [6/50] - Train Loss: 1.1147, Test Loss: 1.0920\n",
      "Epoch [7/50] - Train Loss: 1.1089, Test Loss: 1.1002\n",
      "Epoch [8/50] - Train Loss: 1.0871, Test Loss: 1.1423\n",
      "Epoch [9/50] - Train Loss: 1.1683, Test Loss: 1.1089\n",
      "Epoch [10/50] - Train Loss: 1.1024, Test Loss: 1.1037\n",
      "Epoch [11/50] - Train Loss: 1.1011, Test Loss: 1.1073\n",
      "Epoch [12/50] - Train Loss: 1.0965, Test Loss: 1.1145\n",
      "Epoch [13/50] - Train Loss: 1.0899, Test Loss: 1.1262\n",
      "Epoch [14/50] - Train Loss: 1.0820, Test Loss: 1.1456\n",
      "Epoch [15/50] - Train Loss: 1.0745, Test Loss: 1.1770\n",
      "Epoch [16/50] - Train Loss: 1.0717, Test Loss: 1.2135\n",
      "Epoch [17/50] - Train Loss: 1.0726, Test Loss: 1.2271\n",
      "Epoch [18/50] - Train Loss: 1.0706, Test Loss: 1.2271\n",
      "Epoch [19/50] - Train Loss: 1.0688, Test Loss: 1.2325\n",
      "Epoch [20/50] - Train Loss: 1.0677, Test Loss: 1.2401\n",
      "Epoch [21/50] - Train Loss: 1.0670, Test Loss: 1.2426\n",
      "Epoch [22/50] - Train Loss: 1.0662, Test Loss: 1.2433\n",
      "Epoch [23/50] - Train Loss: 1.0654, Test Loss: 1.2465\n",
      "Epoch [24/50] - Train Loss: 1.0647, Test Loss: 1.2492\n",
      "Epoch [25/50] - Train Loss: 1.0639, Test Loss: 1.2507\n",
      "Epoch [26/50] - Train Loss: 1.0627, Test Loss: 1.2535\n",
      "Epoch [27/50] - Train Loss: 1.0599, Test Loss: 1.2514\n",
      "Epoch [28/50] - Train Loss: 1.0610, Test Loss: 1.2750\n",
      "Epoch [29/50] - Train Loss: 1.0767, Test Loss: 1.1969\n",
      "Epoch [30/50] - Train Loss: 1.1151, Test Loss: 1.0788\n",
      "Epoch [31/50] - Train Loss: 1.1253, Test Loss: 1.0805\n",
      "Epoch [32/50] - Train Loss: 1.1200, Test Loss: 1.0840\n",
      "Epoch [33/50] - Train Loss: 1.1180, Test Loss: 1.0866\n",
      "Epoch [34/50] - Train Loss: 1.1173, Test Loss: 1.0881\n",
      "Epoch [35/50] - Train Loss: 1.1168, Test Loss: 1.0889\n",
      "Epoch [36/50] - Train Loss: 1.1164, Test Loss: 1.0894\n",
      "Epoch [37/50] - Train Loss: 1.1159, Test Loss: 1.0900\n",
      "Epoch [38/50] - Train Loss: 1.1153, Test Loss: 1.0908\n",
      "Epoch [39/50] - Train Loss: 1.1142, Test Loss: 1.0921\n",
      "Epoch [40/50] - Train Loss: 1.1123, Test Loss: 1.0942\n",
      "Epoch [41/50] - Train Loss: 1.1089, Test Loss: 1.0978\n",
      "Epoch [42/50] - Train Loss: 1.1028, Test Loss: 1.1046\n",
      "Epoch [43/50] - Train Loss: 1.0926, Test Loss: 1.1188\n",
      "Epoch [44/50] - Train Loss: 1.0774, Test Loss: 1.1486\n",
      "Epoch [45/50] - Train Loss: 1.0691, Test Loss: 1.1861\n",
      "Epoch [46/50] - Train Loss: 1.0722, Test Loss: 1.1942\n",
      "Epoch [47/50] - Train Loss: 1.0662, Test Loss: 1.2110\n",
      "Epoch [48/50] - Train Loss: 1.0637, Test Loss: 1.2318\n",
      "Epoch [49/50] - Train Loss: 1.0585, Test Loss: 1.2346\n",
      "Epoch [50/50] - Train Loss: 1.0652, Test Loss: 1.2030\n",
      "Avg Test Loss: 1.2030\n",
      "Testing combination: (64, 3, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1599, Test Loss: 1.1445\n",
      "Epoch [2/50] - Train Loss: 1.1516, Test Loss: 1.1502\n",
      "Epoch [3/50] - Train Loss: 1.1498, Test Loss: 1.1561\n",
      "Epoch [4/50] - Train Loss: 1.1481, Test Loss: 1.1618\n",
      "Epoch [5/50] - Train Loss: 1.1452, Test Loss: 1.1683\n",
      "Epoch [6/50] - Train Loss: 1.1360, Test Loss: 1.1789\n",
      "Epoch [7/50] - Train Loss: 1.1085, Test Loss: 1.2007\n",
      "Epoch [8/50] - Train Loss: 1.0685, Test Loss: 1.2392\n",
      "Epoch [9/50] - Train Loss: 1.0600, Test Loss: 1.2627\n",
      "Epoch [10/50] - Train Loss: 1.0497, Test Loss: 1.2827\n",
      "Epoch [11/50] - Train Loss: 1.0471, Test Loss: 1.3028\n",
      "Epoch [12/50] - Train Loss: 1.0471, Test Loss: 1.3090\n",
      "Epoch [13/50] - Train Loss: 1.0468, Test Loss: 1.3120\n",
      "Epoch [14/50] - Train Loss: 1.0465, Test Loss: 1.3128\n",
      "Epoch [15/50] - Train Loss: 1.0462, Test Loss: 1.3111\n",
      "Epoch [16/50] - Train Loss: 1.0461, Test Loss: 1.3114\n",
      "Epoch [17/50] - Train Loss: 1.0460, Test Loss: 1.3051\n",
      "Epoch [18/50] - Train Loss: 1.0461, Test Loss: 1.3114\n",
      "Epoch [19/50] - Train Loss: 1.0475, Test Loss: 1.2868\n",
      "Epoch [20/50] - Train Loss: 1.0467, Test Loss: 1.3096\n",
      "Epoch [21/50] - Train Loss: 1.0472, Test Loss: 1.2699\n",
      "Epoch [22/50] - Train Loss: 1.0441, Test Loss: 1.2833\n",
      "Epoch [23/50] - Train Loss: 1.0443, Test Loss: 1.2888\n",
      "Epoch [24/50] - Train Loss: 1.0431, Test Loss: 1.2833\n",
      "Epoch [25/50] - Train Loss: 1.0411, Test Loss: 1.2886\n",
      "Epoch [26/50] - Train Loss: 1.0388, Test Loss: 1.2807\n",
      "Epoch [27/50] - Train Loss: 1.0349, Test Loss: 1.2765\n",
      "Epoch [28/50] - Train Loss: 1.0378, Test Loss: 1.2604\n",
      "Epoch [29/50] - Train Loss: 1.0293, Test Loss: 1.2846\n",
      "Epoch [30/50] - Train Loss: 1.1823, Test Loss: 1.1232\n",
      "Epoch [31/50] - Train Loss: 1.1683, Test Loss: 1.1277\n",
      "Epoch [32/50] - Train Loss: 1.1587, Test Loss: 1.1353\n",
      "Epoch [33/50] - Train Loss: 1.1513, Test Loss: 1.1438\n",
      "Epoch [34/50] - Train Loss: 1.1450, Test Loss: 1.1528\n",
      "Epoch [35/50] - Train Loss: 1.1367, Test Loss: 1.1631\n",
      "Epoch [36/50] - Train Loss: 1.1213, Test Loss: 1.1774\n",
      "Epoch [37/50] - Train Loss: 1.0921, Test Loss: 1.2039\n",
      "Epoch [38/50] - Train Loss: 1.0546, Test Loss: 1.2580\n",
      "Epoch [39/50] - Train Loss: 1.0563, Test Loss: 1.2772\n",
      "Epoch [40/50] - Train Loss: 1.0457, Test Loss: 1.2722\n",
      "Epoch [41/50] - Train Loss: 1.0448, Test Loss: 1.2796\n",
      "Epoch [42/50] - Train Loss: 1.0441, Test Loss: 1.2834\n",
      "Epoch [43/50] - Train Loss: 1.0417, Test Loss: 1.2756\n",
      "Epoch [44/50] - Train Loss: 1.0396, Test Loss: 1.2680\n",
      "Epoch [45/50] - Train Loss: 1.0373, Test Loss: 1.2629\n",
      "Epoch [46/50] - Train Loss: 1.0354, Test Loss: 1.2624\n",
      "Epoch [47/50] - Train Loss: 1.0353, Test Loss: 1.2533\n",
      "Epoch [48/50] - Train Loss: 1.0334, Test Loss: 1.2483\n",
      "Epoch [49/50] - Train Loss: 1.0355, Test Loss: 1.2793\n",
      "Epoch [50/50] - Train Loss: 1.0421, Test Loss: 1.2339\n",
      "Avg Test Loss: 1.2339\n",
      "Testing combination: (64, 3, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5305, Test Loss: 1.7787\n",
      "Epoch [2/50] - Train Loss: 1.5112, Test Loss: 1.7605\n",
      "Epoch [3/50] - Train Loss: 1.4988, Test Loss: 1.7477\n",
      "Epoch [4/50] - Train Loss: 1.4904, Test Loss: 1.7403\n",
      "Epoch [5/50] - Train Loss: 1.4855, Test Loss: 1.7376\n",
      "Epoch [6/50] - Train Loss: 1.4833, Test Loss: 1.7387\n",
      "Epoch [7/50] - Train Loss: 1.4829, Test Loss: 1.7419\n",
      "Epoch [8/50] - Train Loss: 1.4830, Test Loss: 1.7462\n",
      "Epoch [9/50] - Train Loss: 1.4827, Test Loss: 1.7510\n",
      "Epoch [10/50] - Train Loss: 1.4814, Test Loss: 1.7566\n",
      "Epoch [11/50] - Train Loss: 1.4788, Test Loss: 1.7634\n",
      "Epoch [12/50] - Train Loss: 1.4744, Test Loss: 1.7729\n",
      "Epoch [13/50] - Train Loss: 1.4674, Test Loss: 1.7875\n",
      "Epoch [14/50] - Train Loss: 1.4569, Test Loss: 1.8110\n",
      "Epoch [15/50] - Train Loss: 1.4431, Test Loss: 1.8495\n",
      "Epoch [16/50] - Train Loss: 1.4298, Test Loss: 1.9084\n",
      "Epoch [17/50] - Train Loss: 1.4272, Test Loss: 1.9553\n",
      "Epoch [18/50] - Train Loss: 1.4221, Test Loss: 1.9874\n",
      "Epoch [19/50] - Train Loss: 1.4233, Test Loss: 2.0156\n",
      "Epoch [20/50] - Train Loss: 1.4241, Test Loss: 2.0416\n",
      "Epoch [21/50] - Train Loss: 1.4239, Test Loss: 2.0640\n",
      "Epoch [22/50] - Train Loss: 1.4231, Test Loss: 2.0789\n",
      "Epoch [23/50] - Train Loss: 1.4222, Test Loss: 2.0847\n",
      "Epoch [24/50] - Train Loss: 1.4210, Test Loss: 2.0853\n",
      "Epoch [25/50] - Train Loss: 1.4197, Test Loss: 2.0872\n",
      "Epoch [26/50] - Train Loss: 1.4185, Test Loss: 2.0945\n",
      "Epoch [27/50] - Train Loss: 1.4174, Test Loss: 2.1067\n",
      "Epoch [28/50] - Train Loss: 1.4165, Test Loss: 2.1198\n",
      "Epoch [29/50] - Train Loss: 1.4157, Test Loss: 2.1303\n",
      "Epoch [30/50] - Train Loss: 1.4150, Test Loss: 2.1388\n",
      "Epoch [31/50] - Train Loss: 1.4142, Test Loss: 2.1493\n",
      "Epoch [32/50] - Train Loss: 1.4135, Test Loss: 2.1592\n",
      "Epoch [33/50] - Train Loss: 1.4127, Test Loss: 2.1649\n",
      "Epoch [34/50] - Train Loss: 1.4118, Test Loss: 2.1701\n",
      "Epoch [35/50] - Train Loss: 1.4107, Test Loss: 2.1738\n",
      "Epoch [36/50] - Train Loss: 1.4093, Test Loss: 2.1763\n",
      "Epoch [37/50] - Train Loss: 1.4077, Test Loss: 2.1777\n",
      "Epoch [38/50] - Train Loss: 1.4057, Test Loss: 2.1799\n",
      "Epoch [39/50] - Train Loss: 1.4002, Test Loss: 2.1524\n",
      "Epoch [40/50] - Train Loss: 1.3970, Test Loss: 2.1603\n",
      "Epoch [41/50] - Train Loss: 1.3845, Test Loss: 2.1199\n",
      "Epoch [42/50] - Train Loss: 1.3848, Test Loss: 2.0860\n",
      "Epoch [43/50] - Train Loss: 1.3601, Test Loss: 2.0867\n",
      "Epoch [44/50] - Train Loss: 1.6923, Test Loss: 2.1743\n",
      "Epoch [45/50] - Train Loss: 1.3314, Test Loss: 1.9234\n",
      "Epoch [46/50] - Train Loss: 1.4043, Test Loss: 1.8774\n",
      "Epoch [47/50] - Train Loss: 1.4160, Test Loss: 1.9001\n",
      "Epoch [48/50] - Train Loss: 1.4011, Test Loss: 1.9303\n",
      "Epoch [49/50] - Train Loss: 1.4083, Test Loss: 1.9403\n",
      "Epoch [50/50] - Train Loss: 1.3362, Test Loss: 1.9865\n",
      "Avg Test Loss: 1.9865\n",
      "Testing combination: (64, 3, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1272, Test Loss: 1.0811\n",
      "Epoch [2/50] - Train Loss: 1.1250, Test Loss: 1.0809\n",
      "Epoch [3/50] - Train Loss: 1.1239, Test Loss: 1.0809\n",
      "Epoch [4/50] - Train Loss: 1.1229, Test Loss: 1.0809\n",
      "Epoch [5/50] - Train Loss: 1.1220, Test Loss: 1.0809\n",
      "Epoch [6/50] - Train Loss: 1.1212, Test Loss: 1.0811\n",
      "Epoch [7/50] - Train Loss: 1.1205, Test Loss: 1.0813\n",
      "Epoch [8/50] - Train Loss: 1.1199, Test Loss: 1.0816\n",
      "Epoch [9/50] - Train Loss: 1.1193, Test Loss: 1.0819\n",
      "Epoch [10/50] - Train Loss: 1.1188, Test Loss: 1.0822\n",
      "Epoch [11/50] - Train Loss: 1.1183, Test Loss: 1.0827\n",
      "Epoch [12/50] - Train Loss: 1.1178, Test Loss: 1.0831\n",
      "Epoch [13/50] - Train Loss: 1.1174, Test Loss: 1.0837\n",
      "Epoch [14/50] - Train Loss: 1.1169, Test Loss: 1.0843\n",
      "Epoch [15/50] - Train Loss: 1.1165, Test Loss: 1.0849\n",
      "Epoch [16/50] - Train Loss: 1.1161, Test Loss: 1.0857\n",
      "Epoch [17/50] - Train Loss: 1.1156, Test Loss: 1.0865\n",
      "Epoch [18/50] - Train Loss: 1.1151, Test Loss: 1.0875\n",
      "Epoch [19/50] - Train Loss: 1.1146, Test Loss: 1.0886\n",
      "Epoch [20/50] - Train Loss: 1.1139, Test Loss: 1.0900\n",
      "Epoch [21/50] - Train Loss: 1.1131, Test Loss: 1.0916\n",
      "Epoch [22/50] - Train Loss: 1.1121, Test Loss: 1.0936\n",
      "Epoch [23/50] - Train Loss: 1.1108, Test Loss: 1.0962\n",
      "Epoch [24/50] - Train Loss: 1.1091, Test Loss: 1.0994\n",
      "Epoch [25/50] - Train Loss: 1.1069, Test Loss: 1.1036\n",
      "Epoch [26/50] - Train Loss: 1.1040, Test Loss: 1.1090\n",
      "Epoch [27/50] - Train Loss: 1.1003, Test Loss: 1.1160\n",
      "Epoch [28/50] - Train Loss: 1.0958, Test Loss: 1.1247\n",
      "Epoch [29/50] - Train Loss: 1.0907, Test Loss: 1.1349\n",
      "Epoch [30/50] - Train Loss: 1.0856, Test Loss: 1.1462\n",
      "Epoch [31/50] - Train Loss: 1.0810, Test Loss: 1.1578\n",
      "Epoch [32/50] - Train Loss: 1.0773, Test Loss: 1.1688\n",
      "Epoch [33/50] - Train Loss: 1.0747, Test Loss: 1.1785\n",
      "Epoch [34/50] - Train Loss: 1.0729, Test Loss: 1.1864\n",
      "Epoch [35/50] - Train Loss: 1.0718, Test Loss: 1.1924\n",
      "Epoch [36/50] - Train Loss: 1.0710, Test Loss: 1.1969\n",
      "Epoch [37/50] - Train Loss: 1.0704, Test Loss: 1.2006\n",
      "Epoch [38/50] - Train Loss: 1.0700, Test Loss: 1.2037\n",
      "Epoch [39/50] - Train Loss: 1.0696, Test Loss: 1.2066\n",
      "Epoch [40/50] - Train Loss: 1.0693, Test Loss: 1.2092\n",
      "Epoch [41/50] - Train Loss: 1.0690, Test Loss: 1.2116\n",
      "Epoch [42/50] - Train Loss: 1.0688, Test Loss: 1.2138\n",
      "Epoch [43/50] - Train Loss: 1.0686, Test Loss: 1.2157\n",
      "Epoch [44/50] - Train Loss: 1.0684, Test Loss: 1.2175\n",
      "Epoch [45/50] - Train Loss: 1.0683, Test Loss: 1.2191\n",
      "Epoch [46/50] - Train Loss: 1.0681, Test Loss: 1.2205\n",
      "Epoch [47/50] - Train Loss: 1.0680, Test Loss: 1.2218\n",
      "Epoch [48/50] - Train Loss: 1.0678, Test Loss: 1.2230\n",
      "Epoch [49/50] - Train Loss: 1.0676, Test Loss: 1.2241\n",
      "Epoch [50/50] - Train Loss: 1.0674, Test Loss: 1.2251\n",
      "Avg Test Loss: 1.2251\n",
      "Testing combination: (64, 3, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1553, Test Loss: 1.1372\n",
      "Epoch [2/50] - Train Loss: 1.1544, Test Loss: 1.1380\n",
      "Epoch [3/50] - Train Loss: 1.1539, Test Loss: 1.1388\n",
      "Epoch [4/50] - Train Loss: 1.1535, Test Loss: 1.1396\n",
      "Epoch [5/50] - Train Loss: 1.1531, Test Loss: 1.1404\n",
      "Epoch [6/50] - Train Loss: 1.1527, Test Loss: 1.1412\n",
      "Epoch [7/50] - Train Loss: 1.1524, Test Loss: 1.1419\n",
      "Epoch [8/50] - Train Loss: 1.1520, Test Loss: 1.1427\n",
      "Epoch [9/50] - Train Loss: 1.1517, Test Loss: 1.1435\n",
      "Epoch [10/50] - Train Loss: 1.1514, Test Loss: 1.1442\n",
      "Epoch [11/50] - Train Loss: 1.1511, Test Loss: 1.1450\n",
      "Epoch [12/50] - Train Loss: 1.1508, Test Loss: 1.1458\n",
      "Epoch [13/50] - Train Loss: 1.1505, Test Loss: 1.1465\n",
      "Epoch [14/50] - Train Loss: 1.1502, Test Loss: 1.1473\n",
      "Epoch [15/50] - Train Loss: 1.1499, Test Loss: 1.1481\n",
      "Epoch [16/50] - Train Loss: 1.1496, Test Loss: 1.1489\n",
      "Epoch [17/50] - Train Loss: 1.1493, Test Loss: 1.1497\n",
      "Epoch [18/50] - Train Loss: 1.1490, Test Loss: 1.1506\n",
      "Epoch [19/50] - Train Loss: 1.1486, Test Loss: 1.1515\n",
      "Epoch [20/50] - Train Loss: 1.1482, Test Loss: 1.1524\n",
      "Epoch [21/50] - Train Loss: 1.1477, Test Loss: 1.1534\n",
      "Epoch [22/50] - Train Loss: 1.1471, Test Loss: 1.1545\n",
      "Epoch [23/50] - Train Loss: 1.1465, Test Loss: 1.1556\n",
      "Epoch [24/50] - Train Loss: 1.1456, Test Loss: 1.1569\n",
      "Epoch [25/50] - Train Loss: 1.1446, Test Loss: 1.1584\n",
      "Epoch [26/50] - Train Loss: 1.1433, Test Loss: 1.1601\n",
      "Epoch [27/50] - Train Loss: 1.1416, Test Loss: 1.1621\n",
      "Epoch [28/50] - Train Loss: 1.1393, Test Loss: 1.1646\n",
      "Epoch [29/50] - Train Loss: 1.1363, Test Loss: 1.1676\n",
      "Epoch [30/50] - Train Loss: 1.1323, Test Loss: 1.1713\n",
      "Epoch [31/50] - Train Loss: 1.1272, Test Loss: 1.1758\n",
      "Epoch [32/50] - Train Loss: 1.1207, Test Loss: 1.1814\n",
      "Epoch [33/50] - Train Loss: 1.1128, Test Loss: 1.1881\n",
      "Epoch [34/50] - Train Loss: 1.1039, Test Loss: 1.1960\n",
      "Epoch [35/50] - Train Loss: 1.0944, Test Loss: 1.2051\n",
      "Epoch [36/50] - Train Loss: 1.0848, Test Loss: 1.2152\n",
      "Epoch [37/50] - Train Loss: 1.0757, Test Loss: 1.2257\n",
      "Epoch [38/50] - Train Loss: 1.0679, Test Loss: 1.2363\n",
      "Epoch [39/50] - Train Loss: 1.0617, Test Loss: 1.2464\n",
      "Epoch [40/50] - Train Loss: 1.0572, Test Loss: 1.2555\n",
      "Epoch [41/50] - Train Loss: 1.0540, Test Loss: 1.2633\n",
      "Epoch [42/50] - Train Loss: 1.0518, Test Loss: 1.2695\n",
      "Epoch [43/50] - Train Loss: 1.0502, Test Loss: 1.2742\n",
      "Epoch [44/50] - Train Loss: 1.0489, Test Loss: 1.2777\n",
      "Epoch [45/50] - Train Loss: 1.0479, Test Loss: 1.2803\n",
      "Epoch [46/50] - Train Loss: 1.0471, Test Loss: 1.2822\n",
      "Epoch [47/50] - Train Loss: 1.0464, Test Loss: 1.2838\n",
      "Epoch [48/50] - Train Loss: 1.0459, Test Loss: 1.2851\n",
      "Epoch [49/50] - Train Loss: 1.0455, Test Loss: 1.2862\n",
      "Epoch [50/50] - Train Loss: 1.0452, Test Loss: 1.2872\n",
      "Avg Test Loss: 1.2872\n",
      "Testing combination: (64, 3, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.4880, Test Loss: 1.7336\n",
      "Epoch [2/50] - Train Loss: 1.4872, Test Loss: 1.7337\n",
      "Epoch [3/50] - Train Loss: 1.4870, Test Loss: 1.7337\n",
      "Epoch [4/50] - Train Loss: 1.4868, Test Loss: 1.7337\n",
      "Epoch [5/50] - Train Loss: 1.4867, Test Loss: 1.7338\n",
      "Epoch [6/50] - Train Loss: 1.4866, Test Loss: 1.7338\n",
      "Epoch [7/50] - Train Loss: 1.4865, Test Loss: 1.7338\n",
      "Epoch [8/50] - Train Loss: 1.4864, Test Loss: 1.7338\n",
      "Epoch [9/50] - Train Loss: 1.4863, Test Loss: 1.7338\n",
      "Epoch [10/50] - Train Loss: 1.4862, Test Loss: 1.7339\n",
      "Epoch [11/50] - Train Loss: 1.4861, Test Loss: 1.7339\n",
      "Epoch [12/50] - Train Loss: 1.4860, Test Loss: 1.7340\n",
      "Epoch [13/50] - Train Loss: 1.4860, Test Loss: 1.7340\n",
      "Epoch [14/50] - Train Loss: 1.4859, Test Loss: 1.7341\n",
      "Epoch [15/50] - Train Loss: 1.4858, Test Loss: 1.7342\n",
      "Epoch [16/50] - Train Loss: 1.4857, Test Loss: 1.7342\n",
      "Epoch [17/50] - Train Loss: 1.4857, Test Loss: 1.7343\n",
      "Epoch [18/50] - Train Loss: 1.4856, Test Loss: 1.7344\n",
      "Epoch [19/50] - Train Loss: 1.4855, Test Loss: 1.7346\n",
      "Epoch [20/50] - Train Loss: 1.4855, Test Loss: 1.7347\n",
      "Epoch [21/50] - Train Loss: 1.4854, Test Loss: 1.7348\n",
      "Epoch [22/50] - Train Loss: 1.4853, Test Loss: 1.7350\n",
      "Epoch [23/50] - Train Loss: 1.4852, Test Loss: 1.7352\n",
      "Epoch [24/50] - Train Loss: 1.4852, Test Loss: 1.7354\n",
      "Epoch [25/50] - Train Loss: 1.4851, Test Loss: 1.7356\n",
      "Epoch [26/50] - Train Loss: 1.4850, Test Loss: 1.7358\n",
      "Epoch [27/50] - Train Loss: 1.4849, Test Loss: 1.7361\n",
      "Epoch [28/50] - Train Loss: 1.4848, Test Loss: 1.7364\n",
      "Epoch [29/50] - Train Loss: 1.4847, Test Loss: 1.7367\n",
      "Epoch [30/50] - Train Loss: 1.4846, Test Loss: 1.7371\n",
      "Epoch [31/50] - Train Loss: 1.4844, Test Loss: 1.7375\n",
      "Epoch [32/50] - Train Loss: 1.4843, Test Loss: 1.7379\n",
      "Epoch [33/50] - Train Loss: 1.4841, Test Loss: 1.7384\n",
      "Epoch [34/50] - Train Loss: 1.4840, Test Loss: 1.7389\n",
      "Epoch [35/50] - Train Loss: 1.4838, Test Loss: 1.7395\n",
      "Epoch [36/50] - Train Loss: 1.4836, Test Loss: 1.7402\n",
      "Epoch [37/50] - Train Loss: 1.4833, Test Loss: 1.7409\n",
      "Epoch [38/50] - Train Loss: 1.4830, Test Loss: 1.7418\n",
      "Epoch [39/50] - Train Loss: 1.4827, Test Loss: 1.7427\n",
      "Epoch [40/50] - Train Loss: 1.4823, Test Loss: 1.7437\n",
      "Epoch [41/50] - Train Loss: 1.4819, Test Loss: 1.7448\n",
      "Epoch [42/50] - Train Loss: 1.4814, Test Loss: 1.7460\n",
      "Epoch [43/50] - Train Loss: 1.4808, Test Loss: 1.7474\n",
      "Epoch [44/50] - Train Loss: 1.4802, Test Loss: 1.7489\n",
      "Epoch [45/50] - Train Loss: 1.4794, Test Loss: 1.7507\n",
      "Epoch [46/50] - Train Loss: 1.4786, Test Loss: 1.7526\n",
      "Epoch [47/50] - Train Loss: 1.4776, Test Loss: 1.7547\n",
      "Epoch [48/50] - Train Loss: 1.4765, Test Loss: 1.7571\n",
      "Epoch [49/50] - Train Loss: 1.4752, Test Loss: 1.7598\n",
      "Epoch [50/50] - Train Loss: 1.4737, Test Loss: 1.7629\n",
      "Avg Test Loss: 1.7629\n",
      "Testing combination: (64, 4, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.2791, Test Loss: 1.0914\n",
      "Epoch [2/50] - Train Loss: 1.1188, Test Loss: 1.1538\n",
      "Epoch [3/50] - Train Loss: 1.1881, Test Loss: 1.1173\n",
      "Epoch [4/50] - Train Loss: 1.1226, Test Loss: 1.0807\n",
      "Epoch [5/50] - Train Loss: 1.1282, Test Loss: 1.0859\n",
      "Epoch [6/50] - Train Loss: 1.1243, Test Loss: 1.0902\n",
      "Epoch [7/50] - Train Loss: 1.1212, Test Loss: 1.0862\n",
      "Epoch [8/50] - Train Loss: 1.1209, Test Loss: 1.0854\n",
      "Epoch [9/50] - Train Loss: 1.1204, Test Loss: 1.0865\n",
      "Epoch [10/50] - Train Loss: 1.1192, Test Loss: 1.0876\n",
      "Epoch [11/50] - Train Loss: 1.1174, Test Loss: 1.0853\n",
      "Epoch [12/50] - Train Loss: 1.1209, Test Loss: 1.0881\n",
      "Epoch [13/50] - Train Loss: 1.1159, Test Loss: 1.0861\n",
      "Epoch [14/50] - Train Loss: 1.1140, Test Loss: 1.0871\n",
      "Epoch [15/50] - Train Loss: 1.1109, Test Loss: 1.0969\n",
      "Epoch [16/50] - Train Loss: 1.1084, Test Loss: 1.0851\n",
      "Epoch [17/50] - Train Loss: 1.1072, Test Loss: 1.1033\n",
      "Epoch [18/50] - Train Loss: 1.0956, Test Loss: 1.0912\n",
      "Epoch [19/50] - Train Loss: 1.0942, Test Loss: 1.0980\n",
      "Epoch [20/50] - Train Loss: 1.0893, Test Loss: 1.0843\n",
      "Epoch [21/50] - Train Loss: 1.0957, Test Loss: 1.0877\n",
      "Epoch [22/50] - Train Loss: 1.0805, Test Loss: 1.0924\n",
      "Epoch [23/50] - Train Loss: 1.0757, Test Loss: 1.0965\n",
      "Epoch [24/50] - Train Loss: 1.0655, Test Loss: 1.0953\n",
      "Epoch [25/50] - Train Loss: 1.0619, Test Loss: 1.0810\n",
      "Epoch [26/50] - Train Loss: 1.0708, Test Loss: 1.0915\n",
      "Epoch [27/50] - Train Loss: 1.0671, Test Loss: 1.0871\n",
      "Epoch [28/50] - Train Loss: 1.0839, Test Loss: 1.0973\n",
      "Epoch [29/50] - Train Loss: 1.1182, Test Loss: 1.1051\n",
      "Epoch [30/50] - Train Loss: 1.0740, Test Loss: 1.1116\n",
      "Epoch [31/50] - Train Loss: 1.0824, Test Loss: 1.1241\n",
      "Epoch [32/50] - Train Loss: 1.0665, Test Loss: 1.1105\n",
      "Epoch [33/50] - Train Loss: 1.0615, Test Loss: 1.1111\n",
      "Epoch [34/50] - Train Loss: 1.0593, Test Loss: 1.1113\n",
      "Epoch [35/50] - Train Loss: 1.0509, Test Loss: 1.1097\n",
      "Epoch [36/50] - Train Loss: 1.0703, Test Loss: 1.1461\n",
      "Epoch [37/50] - Train Loss: 1.1157, Test Loss: 1.1378\n",
      "Epoch [38/50] - Train Loss: 1.0730, Test Loss: 1.1200\n",
      "Epoch [39/50] - Train Loss: 1.0638, Test Loss: 1.1151\n",
      "Epoch [40/50] - Train Loss: 1.0669, Test Loss: 1.1230\n",
      "Epoch [41/50] - Train Loss: 1.0683, Test Loss: 1.1174\n",
      "Epoch [42/50] - Train Loss: 1.0578, Test Loss: 1.1108\n",
      "Epoch [43/50] - Train Loss: 1.0491, Test Loss: 1.1107\n",
      "Epoch [44/50] - Train Loss: 1.0332, Test Loss: 1.1093\n",
      "Epoch [45/50] - Train Loss: 1.0983, Test Loss: 1.1456\n",
      "Epoch [46/50] - Train Loss: 1.0965, Test Loss: 1.1086\n",
      "Epoch [47/50] - Train Loss: 1.0674, Test Loss: 1.1106\n",
      "Epoch [48/50] - Train Loss: 1.0711, Test Loss: 1.1107\n",
      "Epoch [49/50] - Train Loss: 1.0668, Test Loss: 1.1106\n",
      "Epoch [50/50] - Train Loss: 1.0647, Test Loss: 1.1099\n",
      "Avg Test Loss: 1.1099\n",
      "Testing combination: (64, 4, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.2240, Test Loss: 1.1488\n",
      "Epoch [2/50] - Train Loss: 1.1548, Test Loss: 1.1568\n",
      "Epoch [3/50] - Train Loss: 1.1498, Test Loss: 1.1609\n",
      "Epoch [4/50] - Train Loss: 1.1389, Test Loss: 1.1757\n",
      "Epoch [5/50] - Train Loss: 1.2142, Test Loss: 1.1540\n",
      "Epoch [6/50] - Train Loss: 1.1452, Test Loss: 1.1520\n",
      "Epoch [7/50] - Train Loss: 1.1241, Test Loss: 1.1578\n",
      "Epoch [8/50] - Train Loss: 1.0532, Test Loss: 1.4522\n",
      "Epoch [9/50] - Train Loss: 1.1514, Test Loss: 1.1645\n",
      "Epoch [10/50] - Train Loss: 1.1094, Test Loss: 1.1747\n",
      "Epoch [11/50] - Train Loss: 1.0670, Test Loss: 1.2203\n",
      "Epoch [12/50] - Train Loss: 1.0644, Test Loss: 1.3106\n",
      "Epoch [13/50] - Train Loss: 1.0563, Test Loss: 1.2221\n",
      "Epoch [14/50] - Train Loss: 1.0483, Test Loss: 1.2342\n",
      "Epoch [15/50] - Train Loss: 1.0466, Test Loss: 1.2709\n",
      "Epoch [16/50] - Train Loss: 1.0457, Test Loss: 1.2747\n",
      "Epoch [17/50] - Train Loss: 1.0436, Test Loss: 1.2580\n",
      "Epoch [18/50] - Train Loss: 1.0424, Test Loss: 1.2511\n",
      "Epoch [19/50] - Train Loss: 1.0425, Test Loss: 1.2548\n",
      "Epoch [20/50] - Train Loss: 1.0410, Test Loss: 1.2582\n",
      "Epoch [21/50] - Train Loss: 1.0409, Test Loss: 1.2574\n",
      "Epoch [22/50] - Train Loss: 1.0409, Test Loss: 1.2559\n",
      "Epoch [23/50] - Train Loss: 1.0401, Test Loss: 1.2558\n",
      "Epoch [24/50] - Train Loss: 1.0405, Test Loss: 1.2561\n",
      "Epoch [25/50] - Train Loss: 1.0399, Test Loss: 1.2556\n",
      "Epoch [26/50] - Train Loss: 1.0403, Test Loss: 1.2549\n",
      "Epoch [27/50] - Train Loss: 1.0395, Test Loss: 1.2547\n",
      "Epoch [28/50] - Train Loss: 1.0404, Test Loss: 1.2543\n",
      "Epoch [29/50] - Train Loss: 1.0389, Test Loss: 1.2545\n",
      "Epoch [30/50] - Train Loss: 1.0404, Test Loss: 1.2539\n",
      "Epoch [31/50] - Train Loss: 1.0382, Test Loss: 1.2580\n",
      "Epoch [32/50] - Train Loss: 1.0394, Test Loss: 1.2526\n",
      "Epoch [33/50] - Train Loss: 1.0398, Test Loss: 1.2561\n",
      "Epoch [34/50] - Train Loss: 1.0399, Test Loss: 1.2563\n",
      "Epoch [35/50] - Train Loss: 1.0387, Test Loss: 1.2682\n",
      "Epoch [36/50] - Train Loss: 1.0347, Test Loss: 1.2456\n",
      "Epoch [37/50] - Train Loss: 1.0359, Test Loss: 1.3014\n",
      "Epoch [38/50] - Train Loss: 1.0290, Test Loss: 1.2516\n",
      "Epoch [39/50] - Train Loss: 1.0255, Test Loss: 1.3931\n",
      "Epoch [40/50] - Train Loss: 1.0989, Test Loss: 1.1950\n",
      "Epoch [41/50] - Train Loss: 1.0610, Test Loss: 1.1849\n",
      "Epoch [42/50] - Train Loss: 1.0598, Test Loss: 1.2920\n",
      "Epoch [43/50] - Train Loss: 1.0498, Test Loss: 1.2502\n",
      "Epoch [44/50] - Train Loss: 1.0579, Test Loss: 1.2389\n",
      "Epoch [45/50] - Train Loss: 1.0626, Test Loss: 1.2526\n",
      "Epoch [46/50] - Train Loss: 1.0489, Test Loss: 1.2858\n",
      "Epoch [47/50] - Train Loss: 1.0490, Test Loss: 1.2818\n",
      "Epoch [48/50] - Train Loss: 1.0466, Test Loss: 1.2670\n",
      "Epoch [49/50] - Train Loss: 1.0502, Test Loss: 1.2531\n",
      "Epoch [50/50] - Train Loss: 1.0454, Test Loss: 1.2483\n",
      "Avg Test Loss: 1.2483\n",
      "Testing combination: (64, 4, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5568, Test Loss: 1.7352\n",
      "Epoch [2/50] - Train Loss: 1.4845, Test Loss: 1.7342\n",
      "Epoch [3/50] - Train Loss: 1.4856, Test Loss: 1.7361\n",
      "Epoch [4/50] - Train Loss: 1.4849, Test Loss: 1.7421\n",
      "Epoch [5/50] - Train Loss: 1.4769, Test Loss: 1.8107\n",
      "Epoch [6/50] - Train Loss: 1.4791, Test Loss: 1.8410\n",
      "Epoch [7/50] - Train Loss: 1.4357, Test Loss: 2.1562\n",
      "Epoch [8/50] - Train Loss: 1.4653, Test Loss: 2.0213\n",
      "Epoch [9/50] - Train Loss: 1.4429, Test Loss: 1.9253\n",
      "Epoch [10/50] - Train Loss: 1.4397, Test Loss: 1.9722\n",
      "Epoch [11/50] - Train Loss: 1.4302, Test Loss: 2.0580\n",
      "Epoch [12/50] - Train Loss: 1.4280, Test Loss: 2.1255\n",
      "Epoch [13/50] - Train Loss: 1.4342, Test Loss: 2.0933\n",
      "Epoch [14/50] - Train Loss: 1.4249, Test Loss: 2.0518\n",
      "Epoch [15/50] - Train Loss: 1.4187, Test Loss: 2.0782\n",
      "Epoch [16/50] - Train Loss: 1.4532, Test Loss: 2.0649\n",
      "Epoch [17/50] - Train Loss: 1.4262, Test Loss: 2.0696\n",
      "Epoch [18/50] - Train Loss: 1.4291, Test Loss: 2.0904\n",
      "Epoch [19/50] - Train Loss: 1.4283, Test Loss: 2.0977\n",
      "Epoch [20/50] - Train Loss: 1.4243, Test Loss: 2.0867\n",
      "Epoch [21/50] - Train Loss: 1.4200, Test Loss: 2.0666\n",
      "Epoch [22/50] - Train Loss: 1.4216, Test Loss: 2.0450\n",
      "Epoch [23/50] - Train Loss: 1.4170, Test Loss: 2.0371\n",
      "Epoch [24/50] - Train Loss: 1.4155, Test Loss: 2.0711\n",
      "Epoch [25/50] - Train Loss: 1.4161, Test Loss: 2.0987\n",
      "Epoch [26/50] - Train Loss: 1.4154, Test Loss: 2.1170\n",
      "Epoch [27/50] - Train Loss: 1.4154, Test Loss: 2.1127\n",
      "Epoch [28/50] - Train Loss: 1.4137, Test Loss: 2.0896\n",
      "Epoch [29/50] - Train Loss: 1.4128, Test Loss: 2.0732\n",
      "Epoch [30/50] - Train Loss: 1.4140, Test Loss: 2.1256\n",
      "Epoch [31/50] - Train Loss: 1.4120, Test Loss: 2.0581\n",
      "Epoch [32/50] - Train Loss: 1.4110, Test Loss: 2.0859\n",
      "Epoch [33/50] - Train Loss: 1.4160, Test Loss: 2.1184\n",
      "Epoch [34/50] - Train Loss: 1.4154, Test Loss: 2.1331\n",
      "Epoch [35/50] - Train Loss: 1.4140, Test Loss: 2.1113\n",
      "Epoch [36/50] - Train Loss: 1.4123, Test Loss: 2.0740\n",
      "Epoch [37/50] - Train Loss: 1.4108, Test Loss: 2.0478\n",
      "Epoch [38/50] - Train Loss: 1.4085, Test Loss: 2.0788\n",
      "Epoch [39/50] - Train Loss: 1.4048, Test Loss: 2.1841\n",
      "Epoch [40/50] - Train Loss: 1.3799, Test Loss: 2.0481\n",
      "Epoch [41/50] - Train Loss: 1.4652, Test Loss: 1.7469\n",
      "Epoch [42/50] - Train Loss: 1.4958, Test Loss: 1.7424\n",
      "Epoch [43/50] - Train Loss: 1.4940, Test Loss: 1.7371\n",
      "Epoch [44/50] - Train Loss: 1.4916, Test Loss: 1.7341\n",
      "Epoch [45/50] - Train Loss: 1.4900, Test Loss: 1.7332\n",
      "Epoch [46/50] - Train Loss: 1.4888, Test Loss: 1.7333\n",
      "Epoch [47/50] - Train Loss: 1.4876, Test Loss: 1.7337\n",
      "Epoch [48/50] - Train Loss: 1.4863, Test Loss: 1.7346\n",
      "Epoch [49/50] - Train Loss: 1.4845, Test Loss: 1.7380\n",
      "Epoch [50/50] - Train Loss: 1.4755, Test Loss: 1.8120\n",
      "Avg Test Loss: 1.8120\n",
      "Testing combination: (64, 4, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1389, Test Loss: 1.0828\n",
      "Epoch [2/50] - Train Loss: 1.1200, Test Loss: 1.0878\n",
      "Epoch [3/50] - Train Loss: 1.1179, Test Loss: 1.0894\n",
      "Epoch [4/50] - Train Loss: 1.1167, Test Loss: 1.0898\n",
      "Epoch [5/50] - Train Loss: 1.1148, Test Loss: 1.0918\n",
      "Epoch [6/50] - Train Loss: 1.1087, Test Loss: 1.1000\n",
      "Epoch [7/50] - Train Loss: 1.0913, Test Loss: 1.1299\n",
      "Epoch [8/50] - Train Loss: 1.1179, Test Loss: 1.1109\n",
      "Epoch [9/50] - Train Loss: 1.0926, Test Loss: 1.1192\n",
      "Epoch [10/50] - Train Loss: 1.0825, Test Loss: 1.1490\n",
      "Epoch [11/50] - Train Loss: 1.0732, Test Loss: 1.1986\n",
      "Epoch [12/50] - Train Loss: 1.0754, Test Loss: 1.2188\n",
      "Epoch [13/50] - Train Loss: 1.0723, Test Loss: 1.2175\n",
      "Epoch [14/50] - Train Loss: 1.0716, Test Loss: 1.2272\n",
      "Epoch [15/50] - Train Loss: 1.0714, Test Loss: 1.2343\n",
      "Epoch [16/50] - Train Loss: 1.0710, Test Loss: 1.2284\n",
      "Epoch [17/50] - Train Loss: 1.0703, Test Loss: 1.2283\n",
      "Epoch [18/50] - Train Loss: 1.0695, Test Loss: 1.2292\n",
      "Epoch [19/50] - Train Loss: 1.0686, Test Loss: 1.2280\n",
      "Epoch [20/50] - Train Loss: 1.0677, Test Loss: 1.2331\n",
      "Epoch [21/50] - Train Loss: 1.0667, Test Loss: 1.2345\n",
      "Epoch [22/50] - Train Loss: 1.0662, Test Loss: 1.2442\n",
      "Epoch [23/50] - Train Loss: 1.0687, Test Loss: 1.2050\n",
      "Epoch [24/50] - Train Loss: 1.0672, Test Loss: 1.2494\n",
      "Epoch [25/50] - Train Loss: 1.0633, Test Loss: 1.2016\n",
      "Epoch [26/50] - Train Loss: 1.0628, Test Loss: 1.2207\n",
      "Epoch [27/50] - Train Loss: 1.0589, Test Loss: 1.2276\n",
      "Epoch [28/50] - Train Loss: 1.0621, Test Loss: 1.2170\n",
      "Epoch [29/50] - Train Loss: 1.0649, Test Loss: 1.2135\n",
      "Epoch [30/50] - Train Loss: 1.0540, Test Loss: 1.2128\n",
      "Epoch [31/50] - Train Loss: 1.1169, Test Loss: 1.0797\n",
      "Epoch [32/50] - Train Loss: 1.1262, Test Loss: 1.0808\n",
      "Epoch [33/50] - Train Loss: 1.1206, Test Loss: 1.0851\n",
      "Epoch [34/50] - Train Loss: 1.1176, Test Loss: 1.0894\n",
      "Epoch [35/50] - Train Loss: 1.1134, Test Loss: 1.0966\n",
      "Epoch [36/50] - Train Loss: 1.0963, Test Loss: 1.1220\n",
      "Epoch [37/50] - Train Loss: 1.0695, Test Loss: 1.2245\n",
      "Epoch [38/50] - Train Loss: 1.0715, Test Loss: 1.1941\n",
      "Epoch [39/50] - Train Loss: 1.1119, Test Loss: 1.0874\n",
      "Epoch [40/50] - Train Loss: 1.1226, Test Loss: 1.0868\n",
      "Epoch [41/50] - Train Loss: 1.1159, Test Loss: 1.0917\n",
      "Epoch [42/50] - Train Loss: 1.1084, Test Loss: 1.0996\n",
      "Epoch [43/50] - Train Loss: 1.0984, Test Loss: 1.1106\n",
      "Epoch [44/50] - Train Loss: 1.0863, Test Loss: 1.1316\n",
      "Epoch [45/50] - Train Loss: 1.0726, Test Loss: 1.1716\n",
      "Epoch [46/50] - Train Loss: 1.0724, Test Loss: 1.1977\n",
      "Epoch [47/50] - Train Loss: 1.0697, Test Loss: 1.2086\n",
      "Epoch [48/50] - Train Loss: 1.0660, Test Loss: 1.2192\n",
      "Epoch [49/50] - Train Loss: 1.0629, Test Loss: 1.2229\n",
      "Epoch [50/50] - Train Loss: 1.0586, Test Loss: 1.2213\n",
      "Avg Test Loss: 1.2213\n",
      "Testing combination: (64, 4, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1581, Test Loss: 1.1562\n",
      "Epoch [2/50] - Train Loss: 1.1507, Test Loss: 1.1576\n",
      "Epoch [3/50] - Train Loss: 1.1499, Test Loss: 1.1596\n",
      "Epoch [4/50] - Train Loss: 1.1493, Test Loss: 1.1617\n",
      "Epoch [5/50] - Train Loss: 1.1483, Test Loss: 1.1638\n",
      "Epoch [6/50] - Train Loss: 1.1451, Test Loss: 1.1670\n",
      "Epoch [7/50] - Train Loss: 1.1325, Test Loss: 1.1740\n",
      "Epoch [8/50] - Train Loss: 1.0943, Test Loss: 1.2002\n",
      "Epoch [9/50] - Train Loss: 1.0884, Test Loss: 1.2151\n",
      "Epoch [10/50] - Train Loss: 1.0476, Test Loss: 1.2813\n",
      "Epoch [11/50] - Train Loss: 1.0578, Test Loss: 1.3327\n",
      "Epoch [12/50] - Train Loss: 1.0698, Test Loss: 1.2560\n",
      "Epoch [13/50] - Train Loss: 1.0464, Test Loss: 1.2773\n",
      "Epoch [14/50] - Train Loss: 1.0518, Test Loss: 1.2636\n",
      "Epoch [15/50] - Train Loss: 1.0520, Test Loss: 1.2522\n",
      "Epoch [16/50] - Train Loss: 1.0492, Test Loss: 1.2555\n",
      "Epoch [17/50] - Train Loss: 1.0471, Test Loss: 1.2679\n",
      "Epoch [18/50] - Train Loss: 1.0465, Test Loss: 1.2785\n",
      "Epoch [19/50] - Train Loss: 1.0463, Test Loss: 1.2808\n",
      "Epoch [20/50] - Train Loss: 1.0461, Test Loss: 1.2795\n",
      "Epoch [21/50] - Train Loss: 1.0459, Test Loss: 1.2798\n",
      "Epoch [22/50] - Train Loss: 1.0457, Test Loss: 1.2811\n",
      "Epoch [23/50] - Train Loss: 1.0456, Test Loss: 1.2811\n",
      "Epoch [24/50] - Train Loss: 1.0453, Test Loss: 1.2799\n",
      "Epoch [25/50] - Train Loss: 1.0451, Test Loss: 1.2788\n",
      "Epoch [26/50] - Train Loss: 1.0448, Test Loss: 1.2777\n",
      "Epoch [27/50] - Train Loss: 1.0444, Test Loss: 1.2767\n",
      "Epoch [28/50] - Train Loss: 1.0438, Test Loss: 1.2757\n",
      "Epoch [29/50] - Train Loss: 1.0433, Test Loss: 1.2745\n",
      "Epoch [30/50] - Train Loss: 1.0426, Test Loss: 1.2740\n",
      "Epoch [31/50] - Train Loss: 1.0417, Test Loss: 1.2738\n",
      "Epoch [32/50] - Train Loss: 1.0405, Test Loss: 1.2735\n",
      "Epoch [33/50] - Train Loss: 1.0382, Test Loss: 1.2720\n",
      "Epoch [34/50] - Train Loss: 1.0347, Test Loss: 1.2680\n",
      "Epoch [35/50] - Train Loss: 1.0347, Test Loss: 1.2489\n",
      "Epoch [36/50] - Train Loss: 1.0180, Test Loss: 1.2415\n",
      "Epoch [37/50] - Train Loss: 0.9527, Test Loss: 1.1762\n",
      "Epoch [38/50] - Train Loss: 1.1924, Test Loss: 1.1306\n",
      "Epoch [39/50] - Train Loss: 1.1916, Test Loss: 1.1253\n",
      "Epoch [40/50] - Train Loss: 1.1553, Test Loss: 1.1415\n",
      "Epoch [41/50] - Train Loss: 1.1460, Test Loss: 1.1535\n",
      "Epoch [42/50] - Train Loss: 1.1346, Test Loss: 1.1657\n",
      "Epoch [43/50] - Train Loss: 1.1167, Test Loss: 1.1850\n",
      "Epoch [44/50] - Train Loss: 1.0878, Test Loss: 1.2026\n",
      "Epoch [45/50] - Train Loss: 1.0525, Test Loss: 1.2383\n",
      "Epoch [46/50] - Train Loss: 1.0435, Test Loss: 1.2768\n",
      "Epoch [47/50] - Train Loss: 1.0412, Test Loss: 1.2879\n",
      "Epoch [48/50] - Train Loss: 1.0414, Test Loss: 1.2816\n",
      "Epoch [49/50] - Train Loss: 1.0401, Test Loss: 1.2790\n",
      "Epoch [50/50] - Train Loss: 1.0391, Test Loss: 1.2770\n",
      "Avg Test Loss: 1.2770\n",
      "Testing combination: (64, 4, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.4958, Test Loss: 1.7333\n",
      "Epoch [2/50] - Train Loss: 1.4879, Test Loss: 1.7335\n",
      "Epoch [3/50] - Train Loss: 1.4867, Test Loss: 1.7338\n",
      "Epoch [4/50] - Train Loss: 1.4861, Test Loss: 1.7342\n",
      "Epoch [5/50] - Train Loss: 1.4857, Test Loss: 1.7349\n",
      "Epoch [6/50] - Train Loss: 1.4852, Test Loss: 1.7359\n",
      "Epoch [7/50] - Train Loss: 1.4844, Test Loss: 1.7376\n",
      "Epoch [8/50] - Train Loss: 1.4831, Test Loss: 1.7401\n",
      "Epoch [9/50] - Train Loss: 1.4805, Test Loss: 1.7445\n",
      "Epoch [10/50] - Train Loss: 1.4756, Test Loss: 1.7536\n",
      "Epoch [11/50] - Train Loss: 1.4650, Test Loss: 1.7784\n",
      "Epoch [12/50] - Train Loss: 1.4478, Test Loss: 1.8249\n",
      "Epoch [13/50] - Train Loss: 1.4277, Test Loss: 1.8964\n",
      "Epoch [14/50] - Train Loss: 1.4238, Test Loss: 1.9517\n",
      "Epoch [15/50] - Train Loss: 1.4261, Test Loss: 1.9698\n",
      "Epoch [16/50] - Train Loss: 1.4260, Test Loss: 1.9782\n",
      "Epoch [17/50] - Train Loss: 1.4247, Test Loss: 1.9865\n",
      "Epoch [18/50] - Train Loss: 1.4235, Test Loss: 1.9904\n",
      "Epoch [19/50] - Train Loss: 1.4229, Test Loss: 1.9879\n",
      "Epoch [20/50] - Train Loss: 1.4217, Test Loss: 1.9852\n",
      "Epoch [21/50] - Train Loss: 1.4199, Test Loss: 1.9902\n",
      "Epoch [22/50] - Train Loss: 1.4180, Test Loss: 2.0061\n",
      "Epoch [23/50] - Train Loss: 1.4161, Test Loss: 2.0293\n",
      "Epoch [24/50] - Train Loss: 1.4139, Test Loss: 2.0548\n",
      "Epoch [25/50] - Train Loss: 1.4112, Test Loss: 2.0822\n",
      "Epoch [26/50] - Train Loss: 1.4083, Test Loss: 2.1136\n",
      "Epoch [27/50] - Train Loss: 1.4064, Test Loss: 2.1460\n",
      "Epoch [28/50] - Train Loss: 1.4009, Test Loss: 2.1280\n",
      "Epoch [29/50] - Train Loss: 1.3972, Test Loss: 2.1427\n",
      "Epoch [30/50] - Train Loss: 1.4093, Test Loss: 2.1412\n",
      "Epoch [31/50] - Train Loss: 1.4049, Test Loss: 1.8763\n",
      "Epoch [32/50] - Train Loss: 1.4185, Test Loss: 2.1231\n",
      "Epoch [33/50] - Train Loss: 1.4062, Test Loss: 2.2165\n",
      "Epoch [34/50] - Train Loss: 1.4029, Test Loss: 2.1613\n",
      "Epoch [35/50] - Train Loss: 1.3863, Test Loss: 2.0435\n",
      "Epoch [36/50] - Train Loss: 1.3799, Test Loss: 2.0839\n",
      "Epoch [37/50] - Train Loss: 1.4182, Test Loss: 2.1118\n",
      "Epoch [38/50] - Train Loss: 1.3580, Test Loss: 1.9682\n",
      "Epoch [39/50] - Train Loss: 1.3854, Test Loss: 2.0092\n",
      "Epoch [40/50] - Train Loss: 1.3869, Test Loss: 2.0954\n",
      "Epoch [41/50] - Train Loss: 1.3774, Test Loss: 2.2699\n",
      "Epoch [42/50] - Train Loss: 1.3714, Test Loss: 2.2028\n",
      "Epoch [43/50] - Train Loss: 1.3579, Test Loss: 2.1237\n",
      "Epoch [44/50] - Train Loss: 1.3561, Test Loss: 2.1599\n",
      "Epoch [45/50] - Train Loss: 1.4558, Test Loss: 2.1251\n",
      "Epoch [46/50] - Train Loss: 1.2899, Test Loss: 1.9688\n",
      "Epoch [47/50] - Train Loss: 1.3079, Test Loss: 1.9489\n",
      "Epoch [48/50] - Train Loss: 1.3585, Test Loss: 1.9723\n",
      "Epoch [49/50] - Train Loss: 1.2087, Test Loss: 2.0073\n",
      "Epoch [50/50] - Train Loss: 1.3246, Test Loss: 2.0124\n",
      "Avg Test Loss: 2.0124\n",
      "Testing combination: (64, 4, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1218, Test Loss: 1.0808\n",
      "Epoch [2/50] - Train Loss: 1.1202, Test Loss: 1.0810\n",
      "Epoch [3/50] - Train Loss: 1.1195, Test Loss: 1.0812\n",
      "Epoch [4/50] - Train Loss: 1.1190, Test Loss: 1.0815\n",
      "Epoch [5/50] - Train Loss: 1.1186, Test Loss: 1.0817\n",
      "Epoch [6/50] - Train Loss: 1.1182, Test Loss: 1.0820\n",
      "Epoch [7/50] - Train Loss: 1.1179, Test Loss: 1.0823\n",
      "Epoch [8/50] - Train Loss: 1.1176, Test Loss: 1.0826\n",
      "Epoch [9/50] - Train Loss: 1.1174, Test Loss: 1.0829\n",
      "Epoch [10/50] - Train Loss: 1.1172, Test Loss: 1.0832\n",
      "Epoch [11/50] - Train Loss: 1.1170, Test Loss: 1.0835\n",
      "Epoch [12/50] - Train Loss: 1.1168, Test Loss: 1.0838\n",
      "Epoch [13/50] - Train Loss: 1.1166, Test Loss: 1.0842\n",
      "Epoch [14/50] - Train Loss: 1.1165, Test Loss: 1.0845\n",
      "Epoch [15/50] - Train Loss: 1.1163, Test Loss: 1.0848\n",
      "Epoch [16/50] - Train Loss: 1.1161, Test Loss: 1.0852\n",
      "Epoch [17/50] - Train Loss: 1.1160, Test Loss: 1.0856\n",
      "Epoch [18/50] - Train Loss: 1.1158, Test Loss: 1.0860\n",
      "Epoch [19/50] - Train Loss: 1.1155, Test Loss: 1.0865\n",
      "Epoch [20/50] - Train Loss: 1.1153, Test Loss: 1.0871\n",
      "Epoch [21/50] - Train Loss: 1.1149, Test Loss: 1.0877\n",
      "Epoch [22/50] - Train Loss: 1.1144, Test Loss: 1.0885\n",
      "Epoch [23/50] - Train Loss: 1.1138, Test Loss: 1.0895\n",
      "Epoch [24/50] - Train Loss: 1.1129, Test Loss: 1.0907\n",
      "Epoch [25/50] - Train Loss: 1.1117, Test Loss: 1.0921\n",
      "Epoch [26/50] - Train Loss: 1.1102, Test Loss: 1.0939\n",
      "Epoch [27/50] - Train Loss: 1.1082, Test Loss: 1.0960\n",
      "Epoch [28/50] - Train Loss: 1.1058, Test Loss: 1.0986\n",
      "Epoch [29/50] - Train Loss: 1.1029, Test Loss: 1.1017\n",
      "Epoch [30/50] - Train Loss: 1.0995, Test Loss: 1.1056\n",
      "Epoch [31/50] - Train Loss: 1.0955, Test Loss: 1.1106\n",
      "Epoch [32/50] - Train Loss: 1.0910, Test Loss: 1.1169\n",
      "Epoch [33/50] - Train Loss: 1.0865, Test Loss: 1.1244\n",
      "Epoch [34/50] - Train Loss: 1.0824, Test Loss: 1.1317\n",
      "Epoch [35/50] - Train Loss: 1.0789, Test Loss: 1.1387\n",
      "Epoch [36/50] - Train Loss: 1.0763, Test Loss: 1.1452\n",
      "Epoch [37/50] - Train Loss: 1.0745, Test Loss: 1.1513\n",
      "Epoch [38/50] - Train Loss: 1.0733, Test Loss: 1.1567\n",
      "Epoch [39/50] - Train Loss: 1.0725, Test Loss: 1.1613\n",
      "Epoch [40/50] - Train Loss: 1.0719, Test Loss: 1.1652\n",
      "Epoch [41/50] - Train Loss: 1.0714, Test Loss: 1.1686\n",
      "Epoch [42/50] - Train Loss: 1.0710, Test Loss: 1.1717\n",
      "Epoch [43/50] - Train Loss: 1.0707, Test Loss: 1.1745\n",
      "Epoch [44/50] - Train Loss: 1.0704, Test Loss: 1.1772\n",
      "Epoch [45/50] - Train Loss: 1.0701, Test Loss: 1.1796\n",
      "Epoch [46/50] - Train Loss: 1.0698, Test Loss: 1.1819\n",
      "Epoch [47/50] - Train Loss: 1.0695, Test Loss: 1.1841\n",
      "Epoch [48/50] - Train Loss: 1.0693, Test Loss: 1.1863\n",
      "Epoch [49/50] - Train Loss: 1.0690, Test Loss: 1.1884\n",
      "Epoch [50/50] - Train Loss: 1.0687, Test Loss: 1.1904\n",
      "Avg Test Loss: 1.1904\n",
      "Testing combination: (64, 4, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1500, Test Loss: 1.1546\n",
      "Epoch [2/50] - Train Loss: 1.1493, Test Loss: 1.1549\n",
      "Epoch [3/50] - Train Loss: 1.1492, Test Loss: 1.1552\n",
      "Epoch [4/50] - Train Loss: 1.1492, Test Loss: 1.1556\n",
      "Epoch [5/50] - Train Loss: 1.1491, Test Loss: 1.1560\n",
      "Epoch [6/50] - Train Loss: 1.1490, Test Loss: 1.1563\n",
      "Epoch [7/50] - Train Loss: 1.1490, Test Loss: 1.1567\n",
      "Epoch [8/50] - Train Loss: 1.1489, Test Loss: 1.1570\n",
      "Epoch [9/50] - Train Loss: 1.1489, Test Loss: 1.1573\n",
      "Epoch [10/50] - Train Loss: 1.1489, Test Loss: 1.1577\n",
      "Epoch [11/50] - Train Loss: 1.1488, Test Loss: 1.1580\n",
      "Epoch [12/50] - Train Loss: 1.1487, Test Loss: 1.1583\n",
      "Epoch [13/50] - Train Loss: 1.1487, Test Loss: 1.1586\n",
      "Epoch [14/50] - Train Loss: 1.1486, Test Loss: 1.1589\n",
      "Epoch [15/50] - Train Loss: 1.1486, Test Loss: 1.1592\n",
      "Epoch [16/50] - Train Loss: 1.1485, Test Loss: 1.1595\n",
      "Epoch [17/50] - Train Loss: 1.1484, Test Loss: 1.1598\n",
      "Epoch [18/50] - Train Loss: 1.1483, Test Loss: 1.1601\n",
      "Epoch [19/50] - Train Loss: 1.1481, Test Loss: 1.1604\n",
      "Epoch [20/50] - Train Loss: 1.1480, Test Loss: 1.1607\n",
      "Epoch [21/50] - Train Loss: 1.1478, Test Loss: 1.1611\n",
      "Epoch [22/50] - Train Loss: 1.1475, Test Loss: 1.1615\n",
      "Epoch [23/50] - Train Loss: 1.1471, Test Loss: 1.1619\n",
      "Epoch [24/50] - Train Loss: 1.1467, Test Loss: 1.1624\n",
      "Epoch [25/50] - Train Loss: 1.1460, Test Loss: 1.1630\n",
      "Epoch [26/50] - Train Loss: 1.1452, Test Loss: 1.1637\n",
      "Epoch [27/50] - Train Loss: 1.1440, Test Loss: 1.1646\n",
      "Epoch [28/50] - Train Loss: 1.1424, Test Loss: 1.1657\n",
      "Epoch [29/50] - Train Loss: 1.1401, Test Loss: 1.1672\n",
      "Epoch [30/50] - Train Loss: 1.1368, Test Loss: 1.1692\n",
      "Epoch [31/50] - Train Loss: 1.1322, Test Loss: 1.1719\n",
      "Epoch [32/50] - Train Loss: 1.1258, Test Loss: 1.1756\n",
      "Epoch [33/50] - Train Loss: 1.1173, Test Loss: 1.1805\n",
      "Epoch [34/50] - Train Loss: 1.1067, Test Loss: 1.1869\n",
      "Epoch [35/50] - Train Loss: 1.0946, Test Loss: 1.1952\n",
      "Epoch [36/50] - Train Loss: 1.0821, Test Loss: 1.2052\n",
      "Epoch [37/50] - Train Loss: 1.0712, Test Loss: 1.2160\n",
      "Epoch [38/50] - Train Loss: 1.0633, Test Loss: 1.2262\n",
      "Epoch [39/50] - Train Loss: 1.0584, Test Loss: 1.2345\n",
      "Epoch [40/50] - Train Loss: 1.0553, Test Loss: 1.2407\n",
      "Epoch [41/50] - Train Loss: 1.0529, Test Loss: 1.2455\n",
      "Epoch [42/50] - Train Loss: 1.0510, Test Loss: 1.2494\n",
      "Epoch [43/50] - Train Loss: 1.0494, Test Loss: 1.2529\n",
      "Epoch [44/50] - Train Loss: 1.0481, Test Loss: 1.2562\n",
      "Epoch [45/50] - Train Loss: 1.0471, Test Loss: 1.2593\n",
      "Epoch [46/50] - Train Loss: 1.0462, Test Loss: 1.2622\n",
      "Epoch [47/50] - Train Loss: 1.0456, Test Loss: 1.2648\n",
      "Epoch [48/50] - Train Loss: 1.0451, Test Loss: 1.2671\n",
      "Epoch [49/50] - Train Loss: 1.0446, Test Loss: 1.2691\n",
      "Epoch [50/50] - Train Loss: 1.0443, Test Loss: 1.2708\n",
      "Avg Test Loss: 1.2708\n",
      "Testing combination: (64, 4, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5409, Test Loss: 1.8060\n",
      "Epoch [2/50] - Train Loss: 1.5378, Test Loss: 1.8020\n",
      "Epoch [3/50] - Train Loss: 1.5349, Test Loss: 1.7980\n",
      "Epoch [4/50] - Train Loss: 1.5320, Test Loss: 1.7941\n",
      "Epoch [5/50] - Train Loss: 1.5293, Test Loss: 1.7904\n",
      "Epoch [6/50] - Train Loss: 1.5267, Test Loss: 1.7868\n",
      "Epoch [7/50] - Train Loss: 1.5242, Test Loss: 1.7834\n",
      "Epoch [8/50] - Train Loss: 1.5218, Test Loss: 1.7802\n",
      "Epoch [9/50] - Train Loss: 1.5195, Test Loss: 1.7771\n",
      "Epoch [10/50] - Train Loss: 1.5173, Test Loss: 1.7741\n",
      "Epoch [11/50] - Train Loss: 1.5152, Test Loss: 1.7713\n",
      "Epoch [12/50] - Train Loss: 1.5132, Test Loss: 1.7686\n",
      "Epoch [13/50] - Train Loss: 1.5113, Test Loss: 1.7661\n",
      "Epoch [14/50] - Train Loss: 1.5094, Test Loss: 1.7636\n",
      "Epoch [15/50] - Train Loss: 1.5076, Test Loss: 1.7613\n",
      "Epoch [16/50] - Train Loss: 1.5059, Test Loss: 1.7591\n",
      "Epoch [17/50] - Train Loss: 1.5042, Test Loss: 1.7570\n",
      "Epoch [18/50] - Train Loss: 1.5026, Test Loss: 1.7551\n",
      "Epoch [19/50] - Train Loss: 1.5011, Test Loss: 1.7532\n",
      "Epoch [20/50] - Train Loss: 1.4997, Test Loss: 1.7515\n",
      "Epoch [21/50] - Train Loss: 1.4983, Test Loss: 1.7499\n",
      "Epoch [22/50] - Train Loss: 1.4970, Test Loss: 1.7485\n",
      "Epoch [23/50] - Train Loss: 1.4957, Test Loss: 1.7471\n",
      "Epoch [24/50] - Train Loss: 1.4945, Test Loss: 1.7459\n",
      "Epoch [25/50] - Train Loss: 1.4934, Test Loss: 1.7448\n",
      "Epoch [26/50] - Train Loss: 1.4923, Test Loss: 1.7439\n",
      "Epoch [27/50] - Train Loss: 1.4913, Test Loss: 1.7430\n",
      "Epoch [28/50] - Train Loss: 1.4903, Test Loss: 1.7423\n",
      "Epoch [29/50] - Train Loss: 1.4894, Test Loss: 1.7418\n",
      "Epoch [30/50] - Train Loss: 1.4886, Test Loss: 1.7413\n",
      "Epoch [31/50] - Train Loss: 1.4878, Test Loss: 1.7410\n",
      "Epoch [32/50] - Train Loss: 1.4870, Test Loss: 1.7409\n",
      "Epoch [33/50] - Train Loss: 1.4863, Test Loss: 1.7408\n",
      "Epoch [34/50] - Train Loss: 1.4856, Test Loss: 1.7409\n",
      "Epoch [35/50] - Train Loss: 1.4849, Test Loss: 1.7411\n",
      "Epoch [36/50] - Train Loss: 1.4843, Test Loss: 1.7415\n",
      "Epoch [37/50] - Train Loss: 1.4837, Test Loss: 1.7419\n",
      "Epoch [38/50] - Train Loss: 1.4831, Test Loss: 1.7425\n",
      "Epoch [39/50] - Train Loss: 1.4825, Test Loss: 1.7431\n",
      "Epoch [40/50] - Train Loss: 1.4819, Test Loss: 1.7439\n",
      "Epoch [41/50] - Train Loss: 1.4813, Test Loss: 1.7447\n",
      "Epoch [42/50] - Train Loss: 1.4806, Test Loss: 1.7457\n",
      "Epoch [43/50] - Train Loss: 1.4800, Test Loss: 1.7467\n",
      "Epoch [44/50] - Train Loss: 1.4793, Test Loss: 1.7479\n",
      "Epoch [45/50] - Train Loss: 1.4786, Test Loss: 1.7491\n",
      "Epoch [46/50] - Train Loss: 1.4779, Test Loss: 1.7504\n",
      "Epoch [47/50] - Train Loss: 1.4771, Test Loss: 1.7517\n",
      "Epoch [48/50] - Train Loss: 1.4763, Test Loss: 1.7532\n",
      "Epoch [49/50] - Train Loss: 1.4754, Test Loss: 1.7547\n",
      "Epoch [50/50] - Train Loss: 1.4745, Test Loss: 1.7562\n",
      "Avg Test Loss: 1.7562\n",
      "Best Hyperparameters: (32, 4, 0.01, 6)\n",
      "Best Loss: 1.0815\n"
     ]
    }
   ],
   "source": [
    "# Hyperparametre tuning\n",
    "\n",
    "# Define the hyperparameter space\n",
    "hyperparameter_space2 = {\n",
    "    'hidden_size': [4, 8, 16, 32, 64],\n",
    "    'num_layers': [1, 2, 3, 4],\n",
    "    'learning_rate': [0.01, 0.001, 0.0001],\n",
    "    \"batch_size\": [6, 8, 16]\n",
    "}\n",
    "\n",
    "hyperparameter_combinations = list(itertools.product(\n",
    "    hyperparameter_space2['hidden_size'],\n",
    "    hyperparameter_space2['num_layers'],\n",
    "    hyperparameter_space2['learning_rate'],\n",
    "    hyperparameter_space2['batch_size']\n",
    "))\n",
    "\n",
    "# Store results\n",
    "best_params = None\n",
    "best_loss = float('inf')\n",
    "all_train_losses = []\n",
    "all_test_losses = []\n",
    "num_epochs = 50\n",
    "\n",
    "# Hyperparameter tuning\n",
    "for params in hyperparameter_combinations:\n",
    "    params_dict = {\n",
    "        'hidden_size': params[0],\n",
    "        'num_layers': params[1],\n",
    "        'learning_rate': params[2],\n",
    "        'batch_size': params[3],\n",
    "    }\n",
    "    print(f\"Testing combination: {params}\")\n",
    "\n",
    "    train_losses, test_losses, avg_loss = train_and_evaluate(params_dict, train_X_new, train_y_new, test_X_new, test_y_new, num_epochs)\n",
    "    all_train_losses.append(train_losses)\n",
    "    all_test_losses.append(test_losses)\n",
    "\n",
    "    print(f\"Avg Test Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        best_params = params\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Loss: {best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500] - Train Loss: 1.1371, Test Loss: 1.0923\n",
      "Epoch [2/500] - Train Loss: 1.1194, Test Loss: 1.0901\n",
      "Epoch [3/500] - Train Loss: 1.1176, Test Loss: 1.0879\n",
      "Epoch [4/500] - Train Loss: 1.1172, Test Loss: 1.0884\n",
      "Epoch [5/500] - Train Loss: 1.1158, Test Loss: 1.0910\n",
      "Epoch [6/500] - Train Loss: 1.1120, Test Loss: 1.0945\n",
      "Epoch [7/500] - Train Loss: 1.1057, Test Loss: 1.0991\n",
      "Epoch [8/500] - Train Loss: 1.0939, Test Loss: 1.1186\n",
      "Epoch [9/500] - Train Loss: 1.1414, Test Loss: 1.0981\n",
      "Epoch [10/500] - Train Loss: 1.0988, Test Loss: 1.0995\n",
      "Epoch [11/500] - Train Loss: 1.0965, Test Loss: 1.1063\n",
      "Epoch [12/500] - Train Loss: 1.0899, Test Loss: 1.1166\n",
      "Epoch [13/500] - Train Loss: 1.0835, Test Loss: 1.1254\n",
      "Epoch [14/500] - Train Loss: 1.0778, Test Loss: 1.1304\n",
      "Epoch [15/500] - Train Loss: 1.0752, Test Loss: 1.1346\n",
      "Epoch [16/500] - Train Loss: 1.0738, Test Loss: 1.1399\n",
      "Epoch [17/500] - Train Loss: 1.0745, Test Loss: 1.1449\n",
      "Epoch [18/500] - Train Loss: 1.0715, Test Loss: 1.1498\n",
      "Epoch [19/500] - Train Loss: 1.0710, Test Loss: 1.1552\n",
      "Epoch [20/500] - Train Loss: 1.0685, Test Loss: 1.1613\n",
      "Epoch [21/500] - Train Loss: 1.0683, Test Loss: 1.1682\n",
      "Epoch [22/500] - Train Loss: 1.0660, Test Loss: 1.1737\n",
      "Epoch [23/500] - Train Loss: 1.0682, Test Loss: 1.1804\n",
      "Epoch [24/500] - Train Loss: 1.0666, Test Loss: 1.1861\n",
      "Epoch [25/500] - Train Loss: 1.0653, Test Loss: 1.1875\n",
      "Epoch [26/500] - Train Loss: 1.0693, Test Loss: 1.1907\n",
      "Epoch [27/500] - Train Loss: 1.0668, Test Loss: 1.1973\n",
      "Epoch [28/500] - Train Loss: 1.0653, Test Loss: 1.1985\n",
      "Epoch [29/500] - Train Loss: 1.0643, Test Loss: 1.1993\n",
      "Epoch [30/500] - Train Loss: 1.0646, Test Loss: 1.2017\n",
      "Epoch [31/500] - Train Loss: 1.0612, Test Loss: 1.1972\n",
      "Epoch [32/500] - Train Loss: 1.0735, Test Loss: 1.2049\n",
      "Epoch [33/500] - Train Loss: 1.0707, Test Loss: 1.2032\n",
      "Epoch [34/500] - Train Loss: 1.0673, Test Loss: 1.2074\n",
      "Epoch [35/500] - Train Loss: 1.0647, Test Loss: 1.2033\n",
      "Epoch [36/500] - Train Loss: 1.0633, Test Loss: 1.2018\n",
      "Epoch [37/500] - Train Loss: 1.0586, Test Loss: 1.1991\n",
      "Epoch [38/500] - Train Loss: 1.0596, Test Loss: 1.1934\n",
      "Epoch [39/500] - Train Loss: 1.0573, Test Loss: 1.1880\n",
      "Epoch [40/500] - Train Loss: 1.0561, Test Loss: 1.2208\n",
      "Epoch [41/500] - Train Loss: 1.0523, Test Loss: 1.1988\n",
      "Epoch [42/500] - Train Loss: 1.0445, Test Loss: 1.2301\n",
      "Epoch [43/500] - Train Loss: 1.0431, Test Loss: 1.2032\n",
      "Epoch [44/500] - Train Loss: 1.0425, Test Loss: 1.2374\n",
      "Epoch [45/500] - Train Loss: 1.0526, Test Loss: 1.2010\n",
      "Epoch [46/500] - Train Loss: 1.0362, Test Loss: 1.1930\n",
      "Epoch [47/500] - Train Loss: 1.0895, Test Loss: 1.2542\n",
      "Epoch [48/500] - Train Loss: 1.0257, Test Loss: 1.1764\n",
      "Epoch [49/500] - Train Loss: 1.0775, Test Loss: 1.2981\n",
      "Epoch [50/500] - Train Loss: 1.0068, Test Loss: 1.2514\n",
      "Epoch [51/500] - Train Loss: 0.9998, Test Loss: 1.2746\n",
      "Epoch [52/500] - Train Loss: 0.9154, Test Loss: 1.2538\n",
      "Epoch [53/500] - Train Loss: 0.9836, Test Loss: 1.2741\n",
      "Epoch [54/500] - Train Loss: 1.0025, Test Loss: 1.1816\n",
      "Epoch [55/500] - Train Loss: 0.8295, Test Loss: 1.3070\n",
      "Epoch [56/500] - Train Loss: 0.8973, Test Loss: 1.4161\n",
      "Epoch [57/500] - Train Loss: 0.9561, Test Loss: 1.1238\n",
      "Epoch [58/500] - Train Loss: 0.8902, Test Loss: 1.1687\n",
      "Epoch [59/500] - Train Loss: 0.8882, Test Loss: 1.3076\n",
      "Epoch [60/500] - Train Loss: 1.2460, Test Loss: 1.3303\n",
      "Epoch [61/500] - Train Loss: 1.1188, Test Loss: 1.0854\n",
      "Epoch [62/500] - Train Loss: 1.1181, Test Loss: 1.0819\n",
      "Epoch [63/500] - Train Loss: 1.1234, Test Loss: 1.0822\n",
      "Epoch [64/500] - Train Loss: 1.1177, Test Loss: 1.0878\n",
      "Epoch [65/500] - Train Loss: 1.1152, Test Loss: 1.0916\n",
      "Epoch [66/500] - Train Loss: 1.1139, Test Loss: 1.0910\n",
      "Epoch [67/500] - Train Loss: 1.1131, Test Loss: 1.0896\n",
      "Epoch [68/500] - Train Loss: 1.1128, Test Loss: 1.0891\n",
      "Epoch [69/500] - Train Loss: 1.1126, Test Loss: 1.0893\n",
      "Epoch [70/500] - Train Loss: 1.1122, Test Loss: 1.0898\n",
      "Epoch [71/500] - Train Loss: 1.1118, Test Loss: 1.0904\n",
      "Epoch [72/500] - Train Loss: 1.1113, Test Loss: 1.0909\n",
      "Epoch [73/500] - Train Loss: 1.1108, Test Loss: 1.0913\n",
      "Epoch [74/500] - Train Loss: 1.1102, Test Loss: 1.0918\n",
      "Epoch [75/500] - Train Loss: 1.1096, Test Loss: 1.0924\n",
      "Epoch [76/500] - Train Loss: 1.1089, Test Loss: 1.0931\n",
      "Epoch [77/500] - Train Loss: 1.1081, Test Loss: 1.0940\n",
      "Epoch [78/500] - Train Loss: 1.1072, Test Loss: 1.0952\n",
      "Epoch [79/500] - Train Loss: 1.1060, Test Loss: 1.0966\n",
      "Epoch [80/500] - Train Loss: 1.1046, Test Loss: 1.0984\n",
      "Epoch [81/500] - Train Loss: 1.1029, Test Loss: 1.1009\n",
      "Epoch [82/500] - Train Loss: 1.1007, Test Loss: 1.1041\n",
      "Epoch [83/500] - Train Loss: 1.0978, Test Loss: 1.1084\n",
      "Epoch [84/500] - Train Loss: 1.0943, Test Loss: 1.1132\n",
      "Epoch [85/500] - Train Loss: 1.0910, Test Loss: 1.1182\n",
      "Epoch [86/500] - Train Loss: 1.0883, Test Loss: 1.1236\n",
      "Epoch [87/500] - Train Loss: 1.0860, Test Loss: 1.1299\n",
      "Epoch [88/500] - Train Loss: 1.0840, Test Loss: 1.1368\n",
      "Epoch [89/500] - Train Loss: 1.0822, Test Loss: 1.1438\n",
      "Epoch [90/500] - Train Loss: 1.0805, Test Loss: 1.1506\n",
      "Epoch [91/500] - Train Loss: 1.0791, Test Loss: 1.1568\n",
      "Epoch [92/500] - Train Loss: 1.0781, Test Loss: 1.1625\n",
      "Epoch [93/500] - Train Loss: 1.0774, Test Loss: 1.1677\n",
      "Epoch [94/500] - Train Loss: 1.0768, Test Loss: 1.1723\n",
      "Epoch [95/500] - Train Loss: 1.0764, Test Loss: 1.1764\n",
      "Epoch [96/500] - Train Loss: 1.0760, Test Loss: 1.1800\n",
      "Epoch [97/500] - Train Loss: 1.0757, Test Loss: 1.1831\n",
      "Epoch [98/500] - Train Loss: 1.0755, Test Loss: 1.1859\n",
      "Epoch [99/500] - Train Loss: 1.0753, Test Loss: 1.1883\n",
      "Epoch [100/500] - Train Loss: 1.0751, Test Loss: 1.1904\n",
      "Epoch [101/500] - Train Loss: 1.0750, Test Loss: 1.1922\n",
      "Epoch [102/500] - Train Loss: 1.0749, Test Loss: 1.1938\n",
      "Epoch [103/500] - Train Loss: 1.0747, Test Loss: 1.1952\n",
      "Epoch [104/500] - Train Loss: 1.0746, Test Loss: 1.1964\n",
      "Epoch [105/500] - Train Loss: 1.0746, Test Loss: 1.1975\n",
      "Epoch [106/500] - Train Loss: 1.0745, Test Loss: 1.1984\n",
      "Epoch [107/500] - Train Loss: 1.0744, Test Loss: 1.1993\n",
      "Epoch [108/500] - Train Loss: 1.0743, Test Loss: 1.2000\n",
      "Epoch [109/500] - Train Loss: 1.0743, Test Loss: 1.2006\n",
      "Epoch [110/500] - Train Loss: 1.0742, Test Loss: 1.2012\n",
      "Epoch [111/500] - Train Loss: 1.0742, Test Loss: 1.2017\n",
      "Epoch [112/500] - Train Loss: 1.0741, Test Loss: 1.2022\n",
      "Epoch [113/500] - Train Loss: 1.0741, Test Loss: 1.2026\n",
      "Epoch [114/500] - Train Loss: 1.0740, Test Loss: 1.2029\n",
      "Epoch [115/500] - Train Loss: 1.0740, Test Loss: 1.2033\n",
      "Epoch [116/500] - Train Loss: 1.0739, Test Loss: 1.2035\n",
      "Epoch [117/500] - Train Loss: 1.0739, Test Loss: 1.2038\n",
      "Epoch [118/500] - Train Loss: 1.0738, Test Loss: 1.2040\n",
      "Epoch [119/500] - Train Loss: 1.0738, Test Loss: 1.2043\n",
      "Epoch [120/500] - Train Loss: 1.0738, Test Loss: 1.2045\n",
      "Epoch [121/500] - Train Loss: 1.0737, Test Loss: 1.2046\n",
      "Epoch [122/500] - Train Loss: 1.0737, Test Loss: 1.2048\n",
      "Epoch [123/500] - Train Loss: 1.0737, Test Loss: 1.2050\n",
      "Epoch [124/500] - Train Loss: 1.0736, Test Loss: 1.2051\n",
      "Epoch [125/500] - Train Loss: 1.0736, Test Loss: 1.2052\n",
      "Epoch [126/500] - Train Loss: 1.0736, Test Loss: 1.2053\n",
      "Epoch [127/500] - Train Loss: 1.0735, Test Loss: 1.2054\n",
      "Epoch [128/500] - Train Loss: 1.0735, Test Loss: 1.2055\n",
      "Epoch [129/500] - Train Loss: 1.0735, Test Loss: 1.2056\n",
      "Epoch [130/500] - Train Loss: 1.0735, Test Loss: 1.2057\n",
      "Epoch [131/500] - Train Loss: 1.0734, Test Loss: 1.2058\n",
      "Epoch [132/500] - Train Loss: 1.0734, Test Loss: 1.2059\n",
      "Epoch [133/500] - Train Loss: 1.0734, Test Loss: 1.2059\n",
      "Epoch [134/500] - Train Loss: 1.0734, Test Loss: 1.2060\n",
      "Epoch [135/500] - Train Loss: 1.0734, Test Loss: 1.2061\n",
      "Epoch [136/500] - Train Loss: 1.0733, Test Loss: 1.2062\n",
      "Epoch [137/500] - Train Loss: 1.0733, Test Loss: 1.2063\n",
      "Epoch [138/500] - Train Loss: 1.0733, Test Loss: 1.2064\n",
      "Epoch [139/500] - Train Loss: 1.0733, Test Loss: 1.2065\n",
      "Epoch [140/500] - Train Loss: 1.0733, Test Loss: 1.2066\n",
      "Epoch [141/500] - Train Loss: 1.0733, Test Loss: 1.2068\n",
      "Epoch [142/500] - Train Loss: 1.0732, Test Loss: 1.2069\n",
      "Epoch [143/500] - Train Loss: 1.0732, Test Loss: 1.2070\n",
      "Epoch [144/500] - Train Loss: 1.0732, Test Loss: 1.2072\n",
      "Epoch [145/500] - Train Loss: 1.0732, Test Loss: 1.2073\n",
      "Epoch [146/500] - Train Loss: 1.0732, Test Loss: 1.2074\n",
      "Epoch [147/500] - Train Loss: 1.0732, Test Loss: 1.2076\n",
      "Epoch [148/500] - Train Loss: 1.0732, Test Loss: 1.2077\n",
      "Epoch [149/500] - Train Loss: 1.0732, Test Loss: 1.2078\n",
      "Epoch [150/500] - Train Loss: 1.0731, Test Loss: 1.2079\n",
      "Epoch [151/500] - Train Loss: 1.0731, Test Loss: 1.2081\n",
      "Epoch [152/500] - Train Loss: 1.0731, Test Loss: 1.2082\n",
      "Epoch [153/500] - Train Loss: 1.0731, Test Loss: 1.2083\n",
      "Epoch [154/500] - Train Loss: 1.0731, Test Loss: 1.2084\n",
      "Epoch [155/500] - Train Loss: 1.0731, Test Loss: 1.2085\n",
      "Epoch [156/500] - Train Loss: 1.0731, Test Loss: 1.2086\n",
      "Epoch [157/500] - Train Loss: 1.0731, Test Loss: 1.2087\n",
      "Epoch [158/500] - Train Loss: 1.0730, Test Loss: 1.2088\n",
      "Epoch [159/500] - Train Loss: 1.0730, Test Loss: 1.2089\n",
      "Epoch [160/500] - Train Loss: 1.0730, Test Loss: 1.2090\n",
      "Epoch [161/500] - Train Loss: 1.0730, Test Loss: 1.2091\n",
      "Epoch [162/500] - Train Loss: 1.0730, Test Loss: 1.2092\n",
      "Epoch [163/500] - Train Loss: 1.0730, Test Loss: 1.2093\n",
      "Epoch [164/500] - Train Loss: 1.0730, Test Loss: 1.2094\n",
      "Epoch [165/500] - Train Loss: 1.0730, Test Loss: 1.2095\n",
      "Epoch [166/500] - Train Loss: 1.0729, Test Loss: 1.2096\n",
      "Epoch [167/500] - Train Loss: 1.0729, Test Loss: 1.2096\n",
      "Epoch [168/500] - Train Loss: 1.0729, Test Loss: 1.2097\n",
      "Epoch [169/500] - Train Loss: 1.0729, Test Loss: 1.2098\n",
      "Epoch [170/500] - Train Loss: 1.0728, Test Loss: 1.2100\n",
      "Epoch [171/500] - Train Loss: 1.0727, Test Loss: 1.2102\n",
      "Epoch [172/500] - Train Loss: 1.0726, Test Loss: 1.2104\n",
      "Epoch [173/500] - Train Loss: 1.0724, Test Loss: 1.2105\n",
      "Epoch [174/500] - Train Loss: 1.0720, Test Loss: 1.2105\n",
      "Epoch [175/500] - Train Loss: 1.0717, Test Loss: 1.2105\n",
      "Epoch [176/500] - Train Loss: 1.0716, Test Loss: 1.2102\n",
      "Epoch [177/500] - Train Loss: 1.0704, Test Loss: 1.2101\n",
      "Epoch [178/500] - Train Loss: 1.0918, Test Loss: 1.1102\n",
      "Epoch [179/500] - Train Loss: 1.0845, Test Loss: 1.1223\n",
      "Epoch [180/500] - Train Loss: 1.0763, Test Loss: 1.1515\n",
      "Epoch [181/500] - Train Loss: 1.0736, Test Loss: 1.1985\n",
      "Epoch [182/500] - Train Loss: 1.0733, Test Loss: 1.2081\n",
      "Epoch [183/500] - Train Loss: 1.0732, Test Loss: 1.2035\n",
      "Epoch [184/500] - Train Loss: 1.0734, Test Loss: 1.1962\n",
      "Epoch [185/500] - Train Loss: 1.0735, Test Loss: 1.1899\n",
      "Epoch [186/500] - Train Loss: 1.0735, Test Loss: 1.1859\n",
      "Epoch [187/500] - Train Loss: 1.0734, Test Loss: 1.1841\n",
      "Epoch [188/500] - Train Loss: 1.0734, Test Loss: 1.1839\n",
      "Epoch [189/500] - Train Loss: 1.0733, Test Loss: 1.1842\n",
      "Epoch [190/500] - Train Loss: 1.0733, Test Loss: 1.1846\n",
      "Epoch [191/500] - Train Loss: 1.0733, Test Loss: 1.1848\n",
      "Epoch [192/500] - Train Loss: 1.0732, Test Loss: 1.1849\n",
      "Epoch [193/500] - Train Loss: 1.0732, Test Loss: 1.1849\n",
      "Epoch [194/500] - Train Loss: 1.0732, Test Loss: 1.1849\n",
      "Epoch [195/500] - Train Loss: 1.0732, Test Loss: 1.1848\n",
      "Epoch [196/500] - Train Loss: 1.0732, Test Loss: 1.1848\n",
      "Epoch [197/500] - Train Loss: 1.0731, Test Loss: 1.1848\n",
      "Epoch [198/500] - Train Loss: 1.0731, Test Loss: 1.1848\n",
      "Epoch [199/500] - Train Loss: 1.0731, Test Loss: 1.1847\n",
      "Epoch [200/500] - Train Loss: 1.0731, Test Loss: 1.1847\n",
      "Epoch [201/500] - Train Loss: 1.0730, Test Loss: 1.1847\n",
      "Epoch [202/500] - Train Loss: 1.0730, Test Loss: 1.1846\n",
      "Epoch [203/500] - Train Loss: 1.0729, Test Loss: 1.1846\n",
      "Epoch [204/500] - Train Loss: 1.0729, Test Loss: 1.1846\n",
      "Epoch [205/500] - Train Loss: 1.0728, Test Loss: 1.1845\n",
      "Epoch [206/500] - Train Loss: 1.0728, Test Loss: 1.1845\n",
      "Epoch [207/500] - Train Loss: 1.0727, Test Loss: 1.1843\n",
      "Epoch [208/500] - Train Loss: 1.0727, Test Loss: 1.1840\n",
      "Epoch [209/500] - Train Loss: 1.0726, Test Loss: 1.1832\n",
      "Epoch [210/500] - Train Loss: 1.0727, Test Loss: 1.1822\n",
      "Epoch [211/500] - Train Loss: 1.0726, Test Loss: 1.1817\n",
      "Epoch [212/500] - Train Loss: 1.0726, Test Loss: 1.1819\n",
      "Epoch [213/500] - Train Loss: 1.0726, Test Loss: 1.1822\n",
      "Epoch [214/500] - Train Loss: 1.0726, Test Loss: 1.1824\n",
      "Epoch [215/500] - Train Loss: 1.0726, Test Loss: 1.1825\n",
      "Epoch [216/500] - Train Loss: 1.0726, Test Loss: 1.1826\n",
      "Epoch [217/500] - Train Loss: 1.0726, Test Loss: 1.1826\n",
      "Epoch [218/500] - Train Loss: 1.0725, Test Loss: 1.1827\n",
      "Epoch [219/500] - Train Loss: 1.0725, Test Loss: 1.1828\n",
      "Epoch [220/500] - Train Loss: 1.0725, Test Loss: 1.1829\n",
      "Epoch [221/500] - Train Loss: 1.0725, Test Loss: 1.1830\n",
      "Epoch [222/500] - Train Loss: 1.0725, Test Loss: 1.1830\n",
      "Epoch [223/500] - Train Loss: 1.0725, Test Loss: 1.1831\n",
      "Epoch [224/500] - Train Loss: 1.0725, Test Loss: 1.1832\n",
      "Epoch [225/500] - Train Loss: 1.0724, Test Loss: 1.1833\n",
      "Epoch [226/500] - Train Loss: 1.0724, Test Loss: 1.1834\n",
      "Epoch [227/500] - Train Loss: 1.0724, Test Loss: 1.1835\n",
      "Epoch [228/500] - Train Loss: 1.0724, Test Loss: 1.1835\n",
      "Epoch [229/500] - Train Loss: 1.0724, Test Loss: 1.1836\n",
      "Epoch [230/500] - Train Loss: 1.0723, Test Loss: 1.1837\n",
      "Epoch [231/500] - Train Loss: 1.0723, Test Loss: 1.1838\n",
      "Epoch [232/500] - Train Loss: 1.0723, Test Loss: 1.1839\n",
      "Epoch [233/500] - Train Loss: 1.0723, Test Loss: 1.1840\n",
      "Epoch [234/500] - Train Loss: 1.0722, Test Loss: 1.1841\n",
      "Epoch [235/500] - Train Loss: 1.0722, Test Loss: 1.1841\n",
      "Epoch [236/500] - Train Loss: 1.0722, Test Loss: 1.1842\n",
      "Epoch [237/500] - Train Loss: 1.0721, Test Loss: 1.1843\n",
      "Epoch [238/500] - Train Loss: 1.0721, Test Loss: 1.1844\n",
      "Epoch [239/500] - Train Loss: 1.0720, Test Loss: 1.1845\n",
      "Epoch [240/500] - Train Loss: 1.0720, Test Loss: 1.1845\n",
      "Epoch [241/500] - Train Loss: 1.0719, Test Loss: 1.1846\n",
      "Epoch [242/500] - Train Loss: 1.0719, Test Loss: 1.1847\n",
      "Epoch [243/500] - Train Loss: 1.0718, Test Loss: 1.1847\n",
      "Epoch [244/500] - Train Loss: 1.0717, Test Loss: 1.1848\n",
      "Epoch [245/500] - Train Loss: 1.0716, Test Loss: 1.1848\n",
      "Epoch [246/500] - Train Loss: 1.0715, Test Loss: 1.1848\n",
      "Epoch [247/500] - Train Loss: 1.0713, Test Loss: 1.1849\n",
      "Epoch [248/500] - Train Loss: 1.0713, Test Loss: 1.1845\n",
      "Epoch [249/500] - Train Loss: 1.0703, Test Loss: 1.1864\n",
      "Epoch [250/500] - Train Loss: 1.1179, Test Loss: 1.1438\n",
      "Epoch [251/500] - Train Loss: 1.0794, Test Loss: 1.1440\n",
      "Epoch [252/500] - Train Loss: 1.0758, Test Loss: 1.1638\n",
      "Epoch [253/500] - Train Loss: 1.0733, Test Loss: 1.1858\n",
      "Epoch [254/500] - Train Loss: 1.0725, Test Loss: 1.2000\n",
      "Epoch [255/500] - Train Loss: 1.0723, Test Loss: 1.2052\n",
      "Epoch [256/500] - Train Loss: 1.0723, Test Loss: 1.2053\n",
      "Epoch [257/500] - Train Loss: 1.0723, Test Loss: 1.2038\n",
      "Epoch [258/500] - Train Loss: 1.0722, Test Loss: 1.2025\n",
      "Epoch [259/500] - Train Loss: 1.0720, Test Loss: 1.2019\n",
      "Epoch [260/500] - Train Loss: 1.0716, Test Loss: 1.2020\n",
      "Epoch [261/500] - Train Loss: 1.0709, Test Loss: 1.2023\n",
      "Epoch [262/500] - Train Loss: 1.0713, Test Loss: 1.2006\n",
      "Epoch [263/500] - Train Loss: 1.0705, Test Loss: 1.2006\n",
      "Epoch [264/500] - Train Loss: 1.0706, Test Loss: 1.2003\n",
      "Epoch [265/500] - Train Loss: 1.0699, Test Loss: 1.2009\n",
      "Epoch [266/500] - Train Loss: 1.0714, Test Loss: 1.1987\n",
      "Epoch [267/500] - Train Loss: 1.0704, Test Loss: 1.2002\n",
      "Epoch [268/500] - Train Loss: 1.0679, Test Loss: 1.2038\n",
      "Epoch [269/500] - Train Loss: 1.0837, Test Loss: 1.1811\n",
      "Epoch [270/500] - Train Loss: 1.1082, Test Loss: 1.1790\n",
      "Epoch [271/500] - Train Loss: 1.0797, Test Loss: 1.1915\n",
      "Epoch [272/500] - Train Loss: 1.0720, Test Loss: 1.2152\n",
      "Epoch [273/500] - Train Loss: 1.0714, Test Loss: 1.2213\n",
      "Epoch [274/500] - Train Loss: 1.0704, Test Loss: 1.2190\n",
      "Epoch [275/500] - Train Loss: 1.0695, Test Loss: 1.2142\n",
      "Epoch [276/500] - Train Loss: 1.0720, Test Loss: 1.2063\n",
      "Epoch [277/500] - Train Loss: 1.0706, Test Loss: 1.2054\n",
      "Epoch [278/500] - Train Loss: 1.0699, Test Loss: 1.2088\n",
      "Epoch [279/500] - Train Loss: 1.0671, Test Loss: 1.2123\n",
      "Epoch [280/500] - Train Loss: 1.0735, Test Loss: 1.2032\n",
      "Epoch [281/500] - Train Loss: 1.0707, Test Loss: 1.2030\n",
      "Epoch [282/500] - Train Loss: 1.0707, Test Loss: 1.2088\n",
      "Epoch [283/500] - Train Loss: 1.0693, Test Loss: 1.2147\n",
      "Epoch [284/500] - Train Loss: 1.0657, Test Loss: 1.2186\n",
      "Epoch [285/500] - Train Loss: 1.0609, Test Loss: 1.2153\n",
      "Epoch [286/500] - Train Loss: 1.0606, Test Loss: 1.2108\n",
      "Epoch [287/500] - Train Loss: 1.0584, Test Loss: 1.2102\n",
      "Epoch [288/500] - Train Loss: 1.0581, Test Loss: 1.2104\n",
      "Epoch [289/500] - Train Loss: 1.0580, Test Loss: 1.2112\n",
      "Epoch [290/500] - Train Loss: 1.0578, Test Loss: 1.2105\n",
      "Epoch [291/500] - Train Loss: 1.0606, Test Loss: 1.2118\n",
      "Epoch [292/500] - Train Loss: 1.0598, Test Loss: 1.2082\n",
      "Epoch [293/500] - Train Loss: 1.0655, Test Loss: 1.2069\n",
      "Epoch [294/500] - Train Loss: 1.0644, Test Loss: 1.2182\n",
      "Epoch [295/500] - Train Loss: 1.0580, Test Loss: 1.2182\n",
      "Epoch [296/500] - Train Loss: 1.0545, Test Loss: 1.2151\n",
      "Epoch [297/500] - Train Loss: 1.0562, Test Loss: 1.2155\n",
      "Epoch [298/500] - Train Loss: 1.0543, Test Loss: 1.2194\n",
      "Epoch [299/500] - Train Loss: 1.0539, Test Loss: 1.2255\n",
      "Epoch [300/500] - Train Loss: 1.0469, Test Loss: 1.2300\n",
      "Epoch [301/500] - Train Loss: 1.0741, Test Loss: 1.2274\n",
      "Epoch [302/500] - Train Loss: 1.0439, Test Loss: 1.1981\n",
      "Epoch [303/500] - Train Loss: 1.0642, Test Loss: 1.2021\n",
      "Epoch [304/500] - Train Loss: 1.0605, Test Loss: 1.2064\n",
      "Epoch [305/500] - Train Loss: 1.0591, Test Loss: 1.2093\n",
      "Epoch [306/500] - Train Loss: 1.0581, Test Loss: 1.2116\n",
      "Epoch [307/500] - Train Loss: 1.0486, Test Loss: 1.2296\n",
      "Epoch [308/500] - Train Loss: 1.0494, Test Loss: 1.2393\n",
      "Epoch [309/500] - Train Loss: 1.0250, Test Loss: 1.2357\n",
      "Epoch [310/500] - Train Loss: 1.0379, Test Loss: 1.2484\n",
      "Epoch [311/500] - Train Loss: 1.0285, Test Loss: 1.2137\n",
      "Epoch [312/500] - Train Loss: 1.0541, Test Loss: 1.3067\n",
      "Epoch [313/500] - Train Loss: 0.9740, Test Loss: 1.2798\n",
      "Epoch [314/500] - Train Loss: 0.9600, Test Loss: 1.2881\n",
      "Epoch [315/500] - Train Loss: 0.9486, Test Loss: 1.3275\n",
      "Epoch [316/500] - Train Loss: 0.9234, Test Loss: 1.3652\n",
      "Epoch [317/500] - Train Loss: 0.8942, Test Loss: 1.3883\n",
      "Epoch [318/500] - Train Loss: 0.8975, Test Loss: 1.4370\n",
      "Epoch [319/500] - Train Loss: 0.9308, Test Loss: 1.3944\n",
      "Epoch [320/500] - Train Loss: 0.9780, Test Loss: 1.3664\n",
      "Epoch [321/500] - Train Loss: 0.8563, Test Loss: 1.4114\n",
      "Epoch [322/500] - Train Loss: 0.8499, Test Loss: 1.3575\n",
      "Epoch [323/500] - Train Loss: 0.8247, Test Loss: 1.3954\n",
      "Epoch [324/500] - Train Loss: 0.8193, Test Loss: 1.4910\n",
      "Epoch [325/500] - Train Loss: 0.7796, Test Loss: 1.5475\n",
      "Epoch [326/500] - Train Loss: 0.7888, Test Loss: 1.4761\n",
      "Epoch [327/500] - Train Loss: 0.7698, Test Loss: 1.4580\n",
      "Epoch [328/500] - Train Loss: 0.7666, Test Loss: 1.4794\n",
      "Epoch [329/500] - Train Loss: 0.7291, Test Loss: 1.5246\n",
      "Epoch [330/500] - Train Loss: 0.7141, Test Loss: 1.5474\n",
      "Epoch [331/500] - Train Loss: 0.6856, Test Loss: 1.6628\n",
      "Epoch [332/500] - Train Loss: 0.6511, Test Loss: 2.0251\n",
      "Epoch [333/500] - Train Loss: 0.7528, Test Loss: 1.7552\n",
      "Epoch [334/500] - Train Loss: 0.7479, Test Loss: 1.4628\n",
      "Epoch [335/500] - Train Loss: 0.6392, Test Loss: 1.5602\n",
      "Epoch [336/500] - Train Loss: 0.6096, Test Loss: 1.7527\n",
      "Epoch [337/500] - Train Loss: 0.6174, Test Loss: 1.9655\n",
      "Epoch [338/500] - Train Loss: 0.7033, Test Loss: 1.7636\n",
      "Epoch [339/500] - Train Loss: 0.6325, Test Loss: 1.6697\n",
      "Epoch [340/500] - Train Loss: 0.5792, Test Loss: 1.7466\n",
      "Epoch [341/500] - Train Loss: 0.5635, Test Loss: 1.8767\n",
      "Epoch [342/500] - Train Loss: 0.5563, Test Loss: 2.0381\n",
      "Epoch [343/500] - Train Loss: 0.6106, Test Loss: 1.9722\n",
      "Epoch [344/500] - Train Loss: 0.6188, Test Loss: 1.7526\n",
      "Epoch [345/500] - Train Loss: 0.5620, Test Loss: 1.6961\n",
      "Epoch [346/500] - Train Loss: 0.5631, Test Loss: 1.8235\n",
      "Epoch [347/500] - Train Loss: 0.5227, Test Loss: 2.0034\n",
      "Epoch [348/500] - Train Loss: 0.5302, Test Loss: 2.0416\n",
      "Epoch [349/500] - Train Loss: 0.5230, Test Loss: 1.9825\n",
      "Epoch [350/500] - Train Loss: 0.5082, Test Loss: 1.9452\n",
      "Epoch [351/500] - Train Loss: 0.5041, Test Loss: 1.9859\n",
      "Epoch [352/500] - Train Loss: 0.4960, Test Loss: 2.0689\n",
      "Epoch [353/500] - Train Loss: 0.4920, Test Loss: 2.1251\n",
      "Epoch [354/500] - Train Loss: 0.4997, Test Loss: 2.1162\n",
      "Epoch [355/500] - Train Loss: 0.5042, Test Loss: 2.0156\n",
      "Epoch [356/500] - Train Loss: 0.4925, Test Loss: 1.9254\n",
      "Epoch [357/500] - Train Loss: 0.5090, Test Loss: 1.8952\n",
      "Epoch [358/500] - Train Loss: 0.5112, Test Loss: 2.1140\n",
      "Epoch [359/500] - Train Loss: 0.4911, Test Loss: 2.1956\n",
      "Epoch [360/500] - Train Loss: 0.4987, Test Loss: 2.0853\n",
      "Epoch [361/500] - Train Loss: 0.4720, Test Loss: 1.9709\n",
      "Epoch [362/500] - Train Loss: 0.4831, Test Loss: 2.0011\n",
      "Epoch [363/500] - Train Loss: 0.4670, Test Loss: 2.1322\n",
      "Epoch [364/500] - Train Loss: 0.4578, Test Loss: 2.1847\n",
      "Epoch [365/500] - Train Loss: 0.4570, Test Loss: 2.1474\n",
      "Epoch [366/500] - Train Loss: 0.4425, Test Loss: 2.1264\n",
      "Epoch [367/500] - Train Loss: 0.4348, Test Loss: 2.1415\n",
      "Epoch [368/500] - Train Loss: 0.4286, Test Loss: 2.1937\n",
      "Epoch [369/500] - Train Loss: 0.4237, Test Loss: 2.2659\n",
      "Epoch [370/500] - Train Loss: 0.4245, Test Loss: 2.3200\n",
      "Epoch [371/500] - Train Loss: 0.4292, Test Loss: 2.3511\n",
      "Epoch [372/500] - Train Loss: 0.4387, Test Loss: 2.3343\n",
      "Epoch [373/500] - Train Loss: 0.4328, Test Loss: 2.2703\n",
      "Epoch [374/500] - Train Loss: 0.4114, Test Loss: 2.2157\n",
      "Epoch [375/500] - Train Loss: 0.3939, Test Loss: 2.1747\n",
      "Epoch [376/500] - Train Loss: 0.3899, Test Loss: 2.1918\n",
      "Epoch [377/500] - Train Loss: 0.3871, Test Loss: 2.2663\n",
      "Epoch [378/500] - Train Loss: 0.3690, Test Loss: 2.4278\n",
      "Epoch [379/500] - Train Loss: 0.3593, Test Loss: 2.6463\n",
      "Epoch [380/500] - Train Loss: 0.3832, Test Loss: 2.7703\n",
      "Epoch [381/500] - Train Loss: 0.4306, Test Loss: 2.6771\n",
      "Epoch [382/500] - Train Loss: 0.4350, Test Loss: 2.5634\n",
      "Epoch [383/500] - Train Loss: 0.4598, Test Loss: 2.3919\n",
      "Epoch [384/500] - Train Loss: 0.4283, Test Loss: 2.1697\n",
      "Epoch [385/500] - Train Loss: 0.3644, Test Loss: 2.1420\n",
      "Epoch [386/500] - Train Loss: 0.4098, Test Loss: 2.4079\n",
      "Epoch [387/500] - Train Loss: 0.3585, Test Loss: 2.6882\n",
      "Epoch [388/500] - Train Loss: 0.3959, Test Loss: 2.6540\n",
      "Epoch [389/500] - Train Loss: 0.3144, Test Loss: 2.7224\n",
      "Epoch [390/500] - Train Loss: 0.2565, Test Loss: 2.9778\n",
      "Epoch [391/500] - Train Loss: 0.2454, Test Loss: 3.2770\n",
      "Epoch [392/500] - Train Loss: 0.2307, Test Loss: 3.5261\n",
      "Epoch [393/500] - Train Loss: 0.2222, Test Loss: 3.7038\n",
      "Epoch [394/500] - Train Loss: 0.2178, Test Loss: 3.7721\n",
      "Epoch [395/500] - Train Loss: 0.2110, Test Loss: 3.8952\n",
      "Epoch [396/500] - Train Loss: 0.2085, Test Loss: 3.9348\n",
      "Epoch [397/500] - Train Loss: 0.2015, Test Loss: 4.0189\n",
      "Epoch [398/500] - Train Loss: 0.2075, Test Loss: 4.0265\n",
      "Epoch [399/500] - Train Loss: 0.2284, Test Loss: 4.1538\n",
      "Epoch [400/500] - Train Loss: 0.2374, Test Loss: 4.0274\n",
      "Epoch [401/500] - Train Loss: 0.2254, Test Loss: 3.9069\n",
      "Epoch [402/500] - Train Loss: 0.2635, Test Loss: 3.7923\n",
      "Epoch [403/500] - Train Loss: 0.2595, Test Loss: 3.4663\n",
      "Epoch [404/500] - Train Loss: 0.2932, Test Loss: 2.9175\n",
      "Epoch [405/500] - Train Loss: 0.4646, Test Loss: 2.4201\n",
      "Epoch [406/500] - Train Loss: 0.5787, Test Loss: 2.7179\n",
      "Epoch [407/500] - Train Loss: 0.3431, Test Loss: 2.6389\n",
      "Epoch [408/500] - Train Loss: 0.2795, Test Loss: 3.2655\n",
      "Epoch [409/500] - Train Loss: 0.2692, Test Loss: 3.3056\n",
      "Epoch [410/500] - Train Loss: 0.2307, Test Loss: 3.2080\n",
      "Epoch [411/500] - Train Loss: 0.2007, Test Loss: 3.3234\n",
      "Epoch [412/500] - Train Loss: 0.2161, Test Loss: 3.5736\n",
      "Epoch [413/500] - Train Loss: 0.1978, Test Loss: 3.7201\n",
      "Epoch [414/500] - Train Loss: 0.1876, Test Loss: 3.6875\n",
      "Epoch [415/500] - Train Loss: 0.1814, Test Loss: 3.6456\n",
      "Epoch [416/500] - Train Loss: 0.1834, Test Loss: 3.6824\n",
      "Epoch [417/500] - Train Loss: 0.1819, Test Loss: 3.7935\n",
      "Epoch [418/500] - Train Loss: 0.1756, Test Loss: 3.8945\n",
      "Epoch [419/500] - Train Loss: 0.1708, Test Loss: 3.9528\n",
      "Epoch [420/500] - Train Loss: 0.1679, Test Loss: 3.9881\n",
      "Epoch [421/500] - Train Loss: 0.1661, Test Loss: 4.0283\n",
      "Epoch [422/500] - Train Loss: 0.1644, Test Loss: 4.0733\n",
      "Epoch [423/500] - Train Loss: 0.1626, Test Loss: 4.1143\n",
      "Epoch [424/500] - Train Loss: 0.1607, Test Loss: 4.1493\n",
      "Epoch [425/500] - Train Loss: 0.1590, Test Loss: 4.1766\n",
      "Epoch [426/500] - Train Loss: 0.1574, Test Loss: 4.1972\n",
      "Epoch [427/500] - Train Loss: 0.1559, Test Loss: 4.2139\n",
      "Epoch [428/500] - Train Loss: 0.1545, Test Loss: 4.2256\n",
      "Epoch [429/500] - Train Loss: 0.1532, Test Loss: 4.2338\n",
      "Epoch [430/500] - Train Loss: 0.1521, Test Loss: 4.2405\n",
      "Epoch [431/500] - Train Loss: 0.1511, Test Loss: 4.2459\n",
      "Epoch [432/500] - Train Loss: 0.1502, Test Loss: 4.2518\n",
      "Epoch [433/500] - Train Loss: 0.1492, Test Loss: 4.2611\n",
      "Epoch [434/500] - Train Loss: 0.1484, Test Loss: 4.2787\n",
      "Epoch [435/500] - Train Loss: 0.1477, Test Loss: 4.3030\n",
      "Epoch [436/500] - Train Loss: 0.1476, Test Loss: 4.3388\n",
      "Epoch [437/500] - Train Loss: 0.1484, Test Loss: 4.3753\n",
      "Epoch [438/500] - Train Loss: 0.1508, Test Loss: 4.4273\n",
      "Epoch [439/500] - Train Loss: 0.1560, Test Loss: 4.4527\n",
      "Epoch [440/500] - Train Loss: 0.1610, Test Loss: 4.5075\n",
      "Epoch [441/500] - Train Loss: 0.1710, Test Loss: 4.4725\n",
      "Epoch [442/500] - Train Loss: 0.1700, Test Loss: 4.5127\n",
      "Epoch [443/500] - Train Loss: 0.1789, Test Loss: 4.4890\n",
      "Epoch [444/500] - Train Loss: 0.1777, Test Loss: 4.5542\n",
      "Epoch [445/500] - Train Loss: 0.1908, Test Loss: 4.5625\n",
      "Epoch [446/500] - Train Loss: 0.2089, Test Loss: 4.5026\n",
      "Epoch [447/500] - Train Loss: 1.8324, Test Loss: 1.8493\n",
      "Epoch [448/500] - Train Loss: 0.8759, Test Loss: 1.1845\n",
      "Epoch [449/500] - Train Loss: 1.1492, Test Loss: 1.4357\n",
      "Epoch [450/500] - Train Loss: 1.3282, Test Loss: 1.0902\n",
      "Epoch [451/500] - Train Loss: 1.1385, Test Loss: 1.1095\n",
      "Epoch [452/500] - Train Loss: 1.1306, Test Loss: 1.1080\n",
      "Epoch [453/500] - Train Loss: 1.1186, Test Loss: 1.0880\n",
      "Epoch [454/500] - Train Loss: 1.1176, Test Loss: 1.0837\n",
      "Epoch [455/500] - Train Loss: 1.1194, Test Loss: 1.0844\n",
      "Epoch [456/500] - Train Loss: 1.1194, Test Loss: 1.0864\n",
      "Epoch [457/500] - Train Loss: 1.1190, Test Loss: 1.0876\n",
      "Epoch [458/500] - Train Loss: 1.1186, Test Loss: 1.0875\n",
      "Epoch [459/500] - Train Loss: 1.1185, Test Loss: 1.0871\n",
      "Epoch [460/500] - Train Loss: 1.1184, Test Loss: 1.0869\n",
      "Epoch [461/500] - Train Loss: 1.1185, Test Loss: 1.0868\n",
      "Epoch [462/500] - Train Loss: 1.1184, Test Loss: 1.0869\n",
      "Epoch [463/500] - Train Loss: 1.1184, Test Loss: 1.0870\n",
      "Epoch [464/500] - Train Loss: 1.1184, Test Loss: 1.0870\n",
      "Epoch [465/500] - Train Loss: 1.1183, Test Loss: 1.0870\n",
      "Epoch [466/500] - Train Loss: 1.1183, Test Loss: 1.0870\n",
      "Epoch [467/500] - Train Loss: 1.1183, Test Loss: 1.0870\n",
      "Epoch [468/500] - Train Loss: 1.1183, Test Loss: 1.0870\n",
      "Epoch [469/500] - Train Loss: 1.1182, Test Loss: 1.0870\n",
      "Epoch [470/500] - Train Loss: 1.1182, Test Loss: 1.0870\n",
      "Epoch [471/500] - Train Loss: 1.1182, Test Loss: 1.0870\n",
      "Epoch [472/500] - Train Loss: 1.1182, Test Loss: 1.0870\n",
      "Epoch [473/500] - Train Loss: 1.1182, Test Loss: 1.0870\n",
      "Epoch [474/500] - Train Loss: 1.1181, Test Loss: 1.0871\n",
      "Epoch [475/500] - Train Loss: 1.1181, Test Loss: 1.0871\n",
      "Epoch [476/500] - Train Loss: 1.1181, Test Loss: 1.0871\n",
      "Epoch [477/500] - Train Loss: 1.1181, Test Loss: 1.0871\n",
      "Epoch [478/500] - Train Loss: 1.1181, Test Loss: 1.0871\n",
      "Epoch [479/500] - Train Loss: 1.1181, Test Loss: 1.0871\n",
      "Epoch [480/500] - Train Loss: 1.1180, Test Loss: 1.0871\n",
      "Epoch [481/500] - Train Loss: 1.1180, Test Loss: 1.0871\n",
      "Epoch [482/500] - Train Loss: 1.1180, Test Loss: 1.0871\n",
      "Epoch [483/500] - Train Loss: 1.1180, Test Loss: 1.0871\n",
      "Epoch [484/500] - Train Loss: 1.1180, Test Loss: 1.0871\n",
      "Epoch [485/500] - Train Loss: 1.1180, Test Loss: 1.0871\n",
      "Epoch [486/500] - Train Loss: 1.1180, Test Loss: 1.0871\n",
      "Epoch [487/500] - Train Loss: 1.1179, Test Loss: 1.0871\n",
      "Epoch [488/500] - Train Loss: 1.1179, Test Loss: 1.0871\n",
      "Epoch [489/500] - Train Loss: 1.1179, Test Loss: 1.0871\n",
      "Epoch [490/500] - Train Loss: 1.1179, Test Loss: 1.0871\n",
      "Epoch [491/500] - Train Loss: 1.1179, Test Loss: 1.0871\n",
      "Epoch [492/500] - Train Loss: 1.1179, Test Loss: 1.0871\n",
      "Epoch [493/500] - Train Loss: 1.1179, Test Loss: 1.0871\n",
      "Epoch [494/500] - Train Loss: 1.1179, Test Loss: 1.0871\n",
      "Epoch [495/500] - Train Loss: 1.1179, Test Loss: 1.0871\n",
      "Epoch [496/500] - Train Loss: 1.1178, Test Loss: 1.0872\n",
      "Epoch [497/500] - Train Loss: 1.1178, Test Loss: 1.0872\n",
      "Epoch [498/500] - Train Loss: 1.1178, Test Loss: 1.0872\n",
      "Epoch [499/500] - Train Loss: 1.1178, Test Loss: 1.0872\n",
      "Epoch [500/500] - Train Loss: 1.1178, Test Loss: 1.0872\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_size = 8\n",
    "num_layers = 2\n",
    "learning_rate = 0.01\n",
    "batch_size = 6\n",
    "num_epochs = 500\n",
    "\n",
    "params = {\n",
    "        'hidden_size': hidden_size,\n",
    "        'num_layers': num_layers,\n",
    "        'learning_rate': learning_rate,\n",
    "        'batch_size': batch_size,\n",
    "    }\n",
    "\n",
    "train_losses, test_losses, avg_loss = train_and_evaluate(params, \n",
    "                                                         train_X_new, \n",
    "                                                         train_y_new, \n",
    "                                                         test_X_new, \n",
    "                                                         test_y_new, \n",
    "                                                         num_epochs)\n",
    "\n",
    "# Plotting the training and testing losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, len(test_losses) + 1), test_losses, label='Testing Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Testing Loss over Epochs (CNN-LSTM)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
