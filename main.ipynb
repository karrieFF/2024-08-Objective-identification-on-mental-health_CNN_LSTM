{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "# from missingpy import MissForest #impute missing value\n",
    "from sklearn.preprocessing import MinMaxScaler #standardized data\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#deep learning package\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitbit_survey2 = pd.read_csv('fitbit_survey.csv')\n",
    "select_survey = pd.read_csv('select_survey.csv')\n",
    "\n",
    "fitbit_survey2.drop(columns = ['Unnamed: 0'], inplace = True)\n",
    "select_survey.drop(columns = ['Unnamed: 0'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mental_health1 =  select_survey['mental_health_1'].values\n",
    "mental_health2 =  select_survey['mental_health_2'].values\n",
    "\n",
    "ids = fitbit_survey2['Id'].unique()\n",
    "max_short_day = 0\n",
    "max_long_day = 0\n",
    "for id in ids:\n",
    "    individual_data_short = fitbit_survey2[(fitbit_survey2['Id'] == id) & (fitbit_survey2['survey_date'] < 2)]\n",
    "    individual_data_long = fitbit_survey2[(fitbit_survey2['Id'] == id) & (fitbit_survey2['survey_date'] < 4)]\n",
    "    if len(individual_data_short) > max_short_day:\n",
    "        max_short_day = len(individual_data_short)\n",
    "\n",
    "    if len(individual_data_long) > max_long_day:\n",
    "        max_long_day = len(individual_data_long)\n",
    "\n",
    "# List to store padded matrices for each ID\n",
    "padded_matrices = []\n",
    "\n",
    "for id_val in ids:\n",
    "    # Filter data for the current `id_val` and specified condition\n",
    "    id_data = fitbit_survey2[(fitbit_survey2['Id'] == id_val) & (fitbit_survey2['survey_date'] < 2)]\n",
    "\n",
    "    max_rows = max_short_day\n",
    "    col = id_data.shape[1]\n",
    "    \n",
    "    # Convert to matrix (numpy array) without 'Id' and 'survey_date' columns\n",
    "    id_matrix = id_data.drop(columns=['Id', 'survey_date']).values\n",
    "    \n",
    "    # Pad each matrix to the target shape (max_rows, max_cols)\n",
    "    padded_id_matrix = np.pad(id_matrix, ((0, max_rows - id_matrix.shape[0]), (0, col - id_matrix.shape[1])), mode='constant', constant_values=0) \n",
    "    #pad the dataset with the same length with 0 and the padding value will be ignored by masking\n",
    "    \n",
    "    # Append the padded matrix to the list\n",
    "    padded_matrices.append(padded_id_matrix) #add 2D matrix to 3D\n",
    "\n",
    "# Stack all matrices into a single 3D array (number of IDs, max_rows, max_cols)\n",
    "final_padded_matrix = np.stack(padded_matrices, axis=0) \n",
    "\n",
    "\n",
    "# List to store padded matrices for each ID\n",
    "padded_matrices2 = []\n",
    "\n",
    "for id_val in ids:\n",
    "    # Filter data for the current `id_val` and specified condition\n",
    "    id_data = fitbit_survey2[(fitbit_survey2['Id'] == id_val) & (fitbit_survey2['survey_date'] < 4)]\n",
    "\n",
    "    max_rows = max_long_day\n",
    "    col = id_data.shape[1]\n",
    "    \n",
    "    # Convert to matrix (numpy array) without 'Id' and 'survey_date' columns\n",
    "    id_matrix = id_data.drop(columns=['Id', 'survey_date']).values\n",
    "    \n",
    "    # Pad each matrix to the target shape (max_rows, max_cols)\n",
    "    padded_id_matrix = np.pad(id_matrix, ((0, max_rows - id_matrix.shape[0]), (0, col - id_matrix.shape[1])), mode='constant', constant_values=0) \n",
    "    #pad the dataset with the same length with 0 and the padding value will be ignored by masking\n",
    "    \n",
    "    # Append the padded matrix to the list\n",
    "    padded_matrices2.append(padded_id_matrix) #add 2D matrix to 3D\n",
    "\n",
    "# Stack all matrices into a single 3D array (number of IDs, max_rows, max_cols)\n",
    "final_padded_matrix2 = np.stack(padded_matrices2, axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_short_data = final_padded_matrix.copy()\n",
    "X_long_data = final_padded_matrix2.copy()\n",
    "y_short_data = mental_health1.copy()\n",
    "y_long_data = mental_health2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize the data\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_reshpaed = X_short_data.reshape(-1, X_short_data.shape[2])\n",
    "X_standardized = scaler.fit_transform(X_reshpaed)\n",
    "X_short_standardized = X_standardized.reshape(X_short_data.shape)\n",
    "\n",
    "X_reshpaed2 = X_long_data.reshape(-1, X_long_data.shape[2])\n",
    "X_standardized2 = scaler.fit_transform(X_reshpaed2)\n",
    "X_short_standardized2 = X_standardized2.reshape(X_long_data.shape) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataX, datay, shuffle = True, train_percentage = 0.7):\n",
    "    if shuffle:\n",
    "        random_indices = np.arange(len(dataX))\n",
    "        np.random.shuffle(random_indices)\n",
    "        dataX = dataX[random_indices]\n",
    "        datay = datay[random_indices]\n",
    "    \n",
    "    # Compute split indices\n",
    "    train_end = int(len(dataX) * train_percentage)\n",
    "\n",
    "    # Split the data\n",
    "    train_X, train_y = dataX[:train_end], datay[:train_end]\n",
    "    test_X, test_y = dataX[train_end:], datay[train_end:]\n",
    "    \n",
    "    return train_X, train_y, test_X, test_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data to training and validating\n",
    "train_X_data, train_y_data, test_X_data, test_y_data = train_test_split(X_short_standardized, y_short_data) \n",
    "train_y_data = train_y_data.reshape(-1, 1)\n",
    "test_y_data = test_y_data.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize y in order to decrease the value of loss function\n",
    "train_y_mean = train_y_data.mean()\n",
    "train_y_std = train_y_data.std()\n",
    "\n",
    "train_y = (train_y_data - train_y_mean) / train_y_std\n",
    "test_y = (test_y_data - train_y_mean) / train_y_std\n",
    "\n",
    "train_X_new = torch.tensor(train_X_data, dtype=torch.float32) # torch.Size([58, 109, 39])\n",
    "train_y_new = torch.tensor(train_y, dtype=torch.float32) # torch.Size([58, 1]) \n",
    "test_X_new = torch.tensor(test_X_data, dtype=torch.float32)  # torch.Size([14, 109, 39])\n",
    "test_y_new = torch.tensor(test_y, dtype=torch.float32) # torch.Size([14, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-RNN Model (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(CNN_RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # 1D Convolution\n",
    "        self.conv = nn.Conv1d(in_channels=input_size, out_channels=hidden_size, kernel_size=2)\n",
    "        \n",
    "        # RNN\n",
    "        self.rnn = nn.RNN(input_size=hidden_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Input shape: (batch_size, seq_len, features)\n",
    "        # Permute to (batch_size, features, seq_len) for Conv1d\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv(x)  # Apply convolution\n",
    "        x = x.permute(0, 2, 1)  # Permute back to (batch_size, seq_len, features)\n",
    "\n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # RNN forward pass\n",
    "        out, _ = self.rnn(x, h0)\n",
    "\n",
    "        # Extract the output at the last time step\n",
    "        last_outputs = out[:, -1, :]  # (batch_size, hidden_size)\n",
    "\n",
    "        # Fully connected layer\n",
    "        out = self.fc(last_outputs)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Modified training function to return training and testing losses\n",
    "def train_and_evaluate(model, train_X, train_y, test_X, test_y, criterion, optimizer, num_epochs):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass on training data\n",
    "        outputs = model(train_X)\n",
    "        train_loss = criterion(outputs, train_y)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store the training loss\n",
    "        train_losses.append(train_loss.item())\n",
    "\n",
    "        # Evaluate on the test data\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(test_X)\n",
    "            test_loss = criterion(test_outputs, test_y).item()\n",
    "            test_losses.append(test_loss)\n",
    "\n",
    "        # Print loss every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Training Loss: {train_loss.item():.4f}, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune CNN-RNN Model (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing hyperparameters: {'hidden_size': 16, 'learning_rate': 0.01, 'num_layers': 1}\n",
      "Epoch [10/50], Training Loss: 0.9952, Test Loss: 1.1482\n",
      "Epoch [20/50], Training Loss: 0.9930, Test Loss: 1.1445\n",
      "Epoch [30/50], Training Loss: 0.9930, Test Loss: 1.1404\n",
      "Epoch [40/50], Training Loss: 0.9929, Test Loss: 1.1433\n",
      "Epoch [50/50], Training Loss: 0.9929, Test Loss: 1.1421\n",
      "Test Loss: 1.0687\n",
      "Testing hyperparameters: {'hidden_size': 16, 'learning_rate': 0.01, 'num_layers': 2}\n",
      "Epoch [10/50], Training Loss: 0.9941, Test Loss: 1.1372\n",
      "Epoch [20/50], Training Loss: 0.9933, Test Loss: 1.1434\n",
      "Epoch [30/50], Training Loss: 0.9931, Test Loss: 1.1455\n",
      "Epoch [40/50], Training Loss: 0.9908, Test Loss: 1.1431\n",
      "Epoch [50/50], Training Loss: 0.9933, Test Loss: 1.1406\n",
      "Test Loss: 1.0694\n",
      "Testing hyperparameters: {'hidden_size': 16, 'learning_rate': 0.01, 'num_layers': 3}\n",
      "Epoch [10/50], Training Loss: 0.9987, Test Loss: 1.1421\n",
      "Epoch [20/50], Training Loss: 0.9943, Test Loss: 1.1424\n",
      "Epoch [30/50], Training Loss: 1.0934, Test Loss: 1.1473\n",
      "Epoch [40/50], Training Loss: 0.9933, Test Loss: 1.1399\n",
      "Epoch [50/50], Training Loss: 0.9929, Test Loss: 1.1415\n",
      "Test Loss: 1.0722\n",
      "Testing hyperparameters: {'hidden_size': 16, 'learning_rate': 0.001, 'num_layers': 1}\n",
      "Epoch [10/50], Training Loss: 1.0002, Test Loss: 1.1521\n",
      "Epoch [20/50], Training Loss: 0.9954, Test Loss: 1.1367\n",
      "Epoch [30/50], Training Loss: 0.9935, Test Loss: 1.1396\n",
      "Epoch [40/50], Training Loss: 0.9931, Test Loss: 1.1448\n",
      "Epoch [50/50], Training Loss: 0.9929, Test Loss: 1.1433\n",
      "Test Loss: 1.0738\n",
      "Testing hyperparameters: {'hidden_size': 16, 'learning_rate': 0.001, 'num_layers': 2}\n",
      "Epoch [10/50], Training Loss: 1.0012, Test Loss: 1.1514\n",
      "Epoch [20/50], Training Loss: 0.9963, Test Loss: 1.1369\n",
      "Epoch [30/50], Training Loss: 0.9937, Test Loss: 1.1471\n",
      "Epoch [40/50], Training Loss: 0.9930, Test Loss: 1.1406\n",
      "Epoch [50/50], Training Loss: 0.9929, Test Loss: 1.1425\n",
      "Test Loss: 1.0710\n",
      "Testing hyperparameters: {'hidden_size': 16, 'learning_rate': 0.001, 'num_layers': 3}\n",
      "Epoch [10/50], Training Loss: 1.0016, Test Loss: 1.1595\n",
      "Epoch [20/50], Training Loss: 0.9955, Test Loss: 1.1416\n",
      "Epoch [30/50], Training Loss: 0.9949, Test Loss: 1.1386\n",
      "Epoch [40/50], Training Loss: 0.9935, Test Loss: 1.1458\n",
      "Epoch [50/50], Training Loss: 0.9930, Test Loss: 1.1407\n",
      "Test Loss: 1.0719\n",
      "Testing hyperparameters: {'hidden_size': 16, 'learning_rate': 0.0001, 'num_layers': 1}\n",
      "Epoch [10/50], Training Loss: 1.0346, Test Loss: 1.2018\n",
      "Epoch [20/50], Training Loss: 1.0272, Test Loss: 1.1925\n",
      "Epoch [30/50], Training Loss: 1.0208, Test Loss: 1.1843\n",
      "Epoch [40/50], Training Loss: 1.0153, Test Loss: 1.1770\n",
      "Epoch [50/50], Training Loss: 1.0107, Test Loss: 1.1708\n",
      "Test Loss: 1.1067\n",
      "Testing hyperparameters: {'hidden_size': 16, 'learning_rate': 0.0001, 'num_layers': 2}\n",
      "Epoch [10/50], Training Loss: 1.0049, Test Loss: 1.1400\n",
      "Epoch [20/50], Training Loss: 1.0032, Test Loss: 1.1402\n",
      "Epoch [30/50], Training Loss: 1.0019, Test Loss: 1.1406\n",
      "Epoch [40/50], Training Loss: 1.0009, Test Loss: 1.1405\n",
      "Epoch [50/50], Training Loss: 1.0000, Test Loss: 1.1406\n",
      "Test Loss: 1.0716\n",
      "Testing hyperparameters: {'hidden_size': 16, 'learning_rate': 0.0001, 'num_layers': 3}\n",
      "Epoch [10/50], Training Loss: 1.0281, Test Loss: 1.1901\n",
      "Epoch [20/50], Training Loss: 1.0185, Test Loss: 1.1766\n",
      "Epoch [30/50], Training Loss: 1.0110, Test Loss: 1.1656\n",
      "Epoch [40/50], Training Loss: 1.0055, Test Loss: 1.1567\n",
      "Epoch [50/50], Training Loss: 1.0020, Test Loss: 1.1501\n",
      "Test Loss: 1.0945\n",
      "Testing hyperparameters: {'hidden_size': 32, 'learning_rate': 0.01, 'num_layers': 1}\n",
      "Epoch [10/50], Training Loss: 0.9956, Test Loss: 1.1374\n",
      "Epoch [20/50], Training Loss: 0.9927, Test Loss: 1.1403\n",
      "Epoch [30/50], Training Loss: 0.9929, Test Loss: 1.1442\n",
      "Epoch [40/50], Training Loss: 0.9930, Test Loss: 1.1403\n",
      "Epoch [50/50], Training Loss: 0.9923, Test Loss: 1.1432\n",
      "Test Loss: 1.0697\n",
      "Testing hyperparameters: {'hidden_size': 32, 'learning_rate': 0.01, 'num_layers': 2}\n",
      "Epoch [10/50], Training Loss: 0.9963, Test Loss: 1.1359\n",
      "Epoch [20/50], Training Loss: 1.0923, Test Loss: 1.1360\n",
      "Epoch [30/50], Training Loss: 0.8879, Test Loss: 1.2702\n",
      "Epoch [40/50], Training Loss: 0.9883, Test Loss: 1.2591\n",
      "Epoch [50/50], Training Loss: 1.0585, Test Loss: 1.1633\n",
      "Test Loss: 1.1018\n",
      "Testing hyperparameters: {'hidden_size': 32, 'learning_rate': 0.01, 'num_layers': 3}\n",
      "Epoch [10/50], Training Loss: 0.9986, Test Loss: 1.1557\n",
      "Epoch [20/50], Training Loss: 0.9928, Test Loss: 1.1419\n",
      "Epoch [30/50], Training Loss: 0.9922, Test Loss: 1.1386\n",
      "Epoch [40/50], Training Loss: 0.9917, Test Loss: 1.1432\n",
      "Epoch [50/50], Training Loss: 0.9883, Test Loss: 1.1394\n",
      "Test Loss: 1.0761\n",
      "Testing hyperparameters: {'hidden_size': 32, 'learning_rate': 0.001, 'num_layers': 1}\n",
      "Epoch [10/50], Training Loss: 0.9974, Test Loss: 1.1362\n",
      "Epoch [20/50], Training Loss: 0.9939, Test Loss: 1.1491\n",
      "Epoch [30/50], Training Loss: 0.9929, Test Loss: 1.1407\n",
      "Epoch [40/50], Training Loss: 0.9929, Test Loss: 1.1419\n",
      "Epoch [50/50], Training Loss: 0.9929, Test Loss: 1.1429\n",
      "Test Loss: 1.0689\n",
      "Testing hyperparameters: {'hidden_size': 32, 'learning_rate': 0.001, 'num_layers': 2}\n",
      "Epoch [10/50], Training Loss: 0.9940, Test Loss: 1.1391\n",
      "Epoch [20/50], Training Loss: 0.9930, Test Loss: 1.1399\n",
      "Epoch [30/50], Training Loss: 0.9931, Test Loss: 1.1409\n",
      "Epoch [40/50], Training Loss: 0.9929, Test Loss: 1.1418\n",
      "Epoch [50/50], Training Loss: 0.9929, Test Loss: 1.1423\n",
      "Test Loss: 1.0681\n",
      "Testing hyperparameters: {'hidden_size': 32, 'learning_rate': 0.001, 'num_layers': 3}\n",
      "Epoch [10/50], Training Loss: 1.0052, Test Loss: 1.1551\n",
      "Epoch [20/50], Training Loss: 0.9978, Test Loss: 1.1368\n",
      "Epoch [30/50], Training Loss: 0.9942, Test Loss: 1.1475\n",
      "Epoch [40/50], Training Loss: 0.9932, Test Loss: 1.1398\n",
      "Epoch [50/50], Training Loss: 0.9929, Test Loss: 1.1432\n",
      "Test Loss: 1.0718\n",
      "Testing hyperparameters: {'hidden_size': 32, 'learning_rate': 0.0001, 'num_layers': 1}\n",
      "Epoch [10/50], Training Loss: 0.9994, Test Loss: 1.1432\n",
      "Epoch [20/50], Training Loss: 0.9975, Test Loss: 1.1397\n",
      "Epoch [30/50], Training Loss: 0.9964, Test Loss: 1.1395\n",
      "Epoch [40/50], Training Loss: 0.9953, Test Loss: 1.1407\n",
      "Epoch [50/50], Training Loss: 0.9945, Test Loss: 1.1417\n",
      "Test Loss: 1.0695\n",
      "Testing hyperparameters: {'hidden_size': 32, 'learning_rate': 0.0001, 'num_layers': 2}\n",
      "Epoch [10/50], Training Loss: 0.9998, Test Loss: 1.1418\n",
      "Epoch [20/50], Training Loss: 0.9988, Test Loss: 1.1395\n",
      "Epoch [30/50], Training Loss: 0.9977, Test Loss: 1.1404\n",
      "Epoch [40/50], Training Loss: 0.9966, Test Loss: 1.1417\n",
      "Epoch [50/50], Training Loss: 0.9955, Test Loss: 1.1416\n",
      "Test Loss: 1.0699\n",
      "Testing hyperparameters: {'hidden_size': 32, 'learning_rate': 0.0001, 'num_layers': 3}\n",
      "Epoch [10/50], Training Loss: 0.9993, Test Loss: 1.1415\n",
      "Epoch [20/50], Training Loss: 0.9983, Test Loss: 1.1403\n",
      "Epoch [30/50], Training Loss: 0.9972, Test Loss: 1.1412\n",
      "Epoch [40/50], Training Loss: 0.9960, Test Loss: 1.1412\n",
      "Epoch [50/50], Training Loss: 0.9948, Test Loss: 1.1414\n",
      "Test Loss: 1.0693\n",
      "Testing hyperparameters: {'hidden_size': 64, 'learning_rate': 0.01, 'num_layers': 1}\n",
      "Epoch [10/50], Training Loss: 0.9977, Test Loss: 1.1375\n",
      "Epoch [20/50], Training Loss: 1.0107, Test Loss: 1.2390\n",
      "Epoch [30/50], Training Loss: 0.9347, Test Loss: 1.1242\n",
      "Epoch [40/50], Training Loss: 0.9878, Test Loss: 1.2091\n",
      "Epoch [50/50], Training Loss: 0.9986, Test Loss: 1.2391\n",
      "Test Loss: 1.0853\n",
      "Testing hyperparameters: {'hidden_size': 64, 'learning_rate': 0.01, 'num_layers': 2}\n",
      "Epoch [10/50], Training Loss: 0.9610, Test Loss: 1.6533\n",
      "Epoch [20/50], Training Loss: 1.0461, Test Loss: 1.1677\n",
      "Epoch [30/50], Training Loss: 1.0054, Test Loss: 1.1704\n",
      "Epoch [40/50], Training Loss: 0.9838, Test Loss: 0.9737\n",
      "Epoch [50/50], Training Loss: 0.9829, Test Loss: 1.0179\n",
      "Test Loss: 1.1187\n",
      "Testing hyperparameters: {'hidden_size': 64, 'learning_rate': 0.01, 'num_layers': 3}\n",
      "Epoch [10/50], Training Loss: 1.0135, Test Loss: 1.1400\n",
      "Epoch [20/50], Training Loss: 1.0168, Test Loss: 1.1452\n",
      "Epoch [30/50], Training Loss: 1.0060, Test Loss: 1.1359\n",
      "Epoch [40/50], Training Loss: 0.9974, Test Loss: 1.1385\n",
      "Epoch [50/50], Training Loss: 0.9939, Test Loss: 1.1483\n",
      "Test Loss: 1.1113\n",
      "Testing hyperparameters: {'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 1}\n",
      "Epoch [10/50], Training Loss: 0.9933, Test Loss: 1.1383\n",
      "Epoch [20/50], Training Loss: 0.9933, Test Loss: 1.1464\n",
      "Epoch [30/50], Training Loss: 0.9931, Test Loss: 1.1402\n",
      "Epoch [40/50], Training Loss: 0.9929, Test Loss: 1.1434\n",
      "Epoch [50/50], Training Loss: 0.9929, Test Loss: 1.1419\n",
      "Test Loss: 1.0685\n",
      "Testing hyperparameters: {'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 2}\n",
      "Epoch [10/50], Training Loss: 0.9929, Test Loss: 1.1391\n",
      "Epoch [20/50], Training Loss: 0.9928, Test Loss: 1.1407\n",
      "Epoch [30/50], Training Loss: 0.9929, Test Loss: 1.1429\n",
      "Epoch [40/50], Training Loss: 0.9928, Test Loss: 1.1432\n",
      "Epoch [50/50], Training Loss: 0.9924, Test Loss: 1.1428\n",
      "Test Loss: 1.0680\n",
      "Testing hyperparameters: {'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 3}\n",
      "Epoch [10/50], Training Loss: 0.9958, Test Loss: 1.1508\n",
      "Epoch [20/50], Training Loss: 0.9930, Test Loss: 1.1463\n",
      "Epoch [30/50], Training Loss: 0.9930, Test Loss: 1.1408\n",
      "Epoch [40/50], Training Loss: 0.9926, Test Loss: 1.1412\n",
      "Epoch [50/50], Training Loss: 0.9915, Test Loss: 1.1421\n",
      "Test Loss: 1.0685\n",
      "Testing hyperparameters: {'hidden_size': 64, 'learning_rate': 0.0001, 'num_layers': 1}\n",
      "Epoch [10/50], Training Loss: 0.9972, Test Loss: 1.1400\n",
      "Epoch [20/50], Training Loss: 0.9948, Test Loss: 1.1420\n",
      "Epoch [30/50], Training Loss: 0.9934, Test Loss: 1.1415\n",
      "Epoch [40/50], Training Loss: 0.9929, Test Loss: 1.1423\n",
      "Epoch [50/50], Training Loss: 0.9929, Test Loss: 1.1421\n",
      "Test Loss: 1.0682\n",
      "Testing hyperparameters: {'hidden_size': 64, 'learning_rate': 0.0001, 'num_layers': 2}\n",
      "Epoch [10/50], Training Loss: 0.9992, Test Loss: 1.1392\n",
      "Epoch [20/50], Training Loss: 0.9971, Test Loss: 1.1424\n",
      "Epoch [30/50], Training Loss: 0.9953, Test Loss: 1.1408\n",
      "Epoch [40/50], Training Loss: 0.9939, Test Loss: 1.1422\n",
      "Epoch [50/50], Training Loss: 0.9930, Test Loss: 1.1423\n",
      "Test Loss: 1.0689\n",
      "Testing hyperparameters: {'hidden_size': 64, 'learning_rate': 0.0001, 'num_layers': 3}\n",
      "Epoch [10/50], Training Loss: 0.9989, Test Loss: 1.1380\n",
      "Epoch [20/50], Training Loss: 0.9968, Test Loss: 1.1427\n",
      "Epoch [30/50], Training Loss: 0.9950, Test Loss: 1.1405\n",
      "Epoch [40/50], Training Loss: 0.9936, Test Loss: 1.1426\n",
      "Epoch [50/50], Training Loss: 0.9929, Test Loss: 1.1418\n",
      "Test Loss: 1.0687\n",
      "Best Hyperparameters: {'hidden_size': 64, 'learning_rate': 0.001, 'num_layers': 2}\n",
      "Best Loss: 1.0680\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters tuning\n",
    "input_size = train_X_new.shape[2]  # Feature size\n",
    "output_size = 1\n",
    "# Define the hyperparameter space\n",
    "hyperparameter_space = {\n",
    "    'hidden_size': [16, 32, 64],\n",
    "    'num_layers': [1, 2, 3],\n",
    "    'learning_rate': [0.01, 0.001, 0.0001],\n",
    "}\n",
    "\n",
    "param_grid = ParameterGrid(hyperparameter_space)\n",
    "\n",
    "# Track the best hyperparameters\n",
    "best_params = None\n",
    "best_loss = float('inf')\n",
    "\n",
    "for params in param_grid:\n",
    "    print(f\"Testing hyperparameters: {params}\")\n",
    "\n",
    "    # Extract hyperparameters\n",
    "    hidden_size = params['hidden_size']\n",
    "    num_layers = params['num_layers']\n",
    "    learning_rate = params['learning_rate']\n",
    "\n",
    "    # Initialize the model, criterion, and optimizer\n",
    "    model = CNN_RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, output_size=output_size)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    test_loss = train_and_evaluate(\n",
    "        model,\n",
    "        train_X_new,\n",
    "        train_y_new,\n",
    "        test_X_new,\n",
    "        test_y_new,\n",
    "        criterion,\n",
    "        optimizer,\n",
    "        num_epochs=50\n",
    "    )\n",
    "    mean_loss = np.mean(test_loss)\n",
    "    print(f\"Test Loss: {mean_loss:.4f}\")\n",
    "\n",
    "    # Check if this is the best model so far\n",
    "    if mean_loss < best_loss:\n",
    "        best_loss = mean_loss\n",
    "        best_params = params\n",
    "\n",
    "# Print the best hyperparameters and loss\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Loss: {best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train_and_evaluate() got multiple values for argument 'num_epochs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[296], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()  \u001b[38;5;66;03m# Mean Squared Error for continuous variables\u001b[39;00m\n\u001b[0;32m     11\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[1;32m---> 13\u001b[0m train_losses, test_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_X_new\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_y_new\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_X_new\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_y_new\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Plot the training and testing losses\u001b[39;00m\n\u001b[0;32m     25\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[1;31mTypeError\u001b[0m: train_and_evaluate() got multiple values for argument 'num_epochs'"
     ]
    }
   ],
   "source": [
    "input_size = train_X_new.shape[2]  # Feature size\n",
    "output_size = 1  # Continuous output variable\n",
    "hidden_size = 64 # Number of hidden units\n",
    "num_layers = 2 # Number of RNN layers\n",
    "learning_rate = 0.001\n",
    "num_epochs = 500\n",
    "\n",
    "# Initialize the model, criterion, and optimizer\n",
    "model = CNN_RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, output_size=output_size)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for continuous variables\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_losses, test_losses = train_and_evaluate(\n",
    "    model,\n",
    "    train_X_new,\n",
    "    train_y_new,\n",
    "    test_X_new,\n",
    "    test_y_new,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    num_epochs=num_epochs\n",
    ")\n",
    "\n",
    "# Plot the training and testing losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, len(test_losses) + 1), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Testing Loss over Epochs (CNN-RNN)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN-LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self, input_size, seq_len, hidden_size, num_layers, output_size):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Convolutional layer\n",
    "        self.conv1d = nn.Conv1d(in_channels=input_size, out_channels=hidden_size, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Rearrange dimensions for Conv1D\n",
    "        x = x.permute(0, 2, 1)  # (batch_size, input_size, seq_len)\n",
    "        \n",
    "        # Pass through Conv1D\n",
    "        x = self.conv1d(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  # (batch_size, hidden_size, reduced_seq_len)\n",
    "        \n",
    "        # Rearrange dimensions for LSTM\n",
    "        x = x.permute(0, 2, 1)  # (batch_size, reduced_seq_len, hidden_size)\n",
    "\n",
    "        # Pass through LSTM\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))  # (batch_size, reduced_seq_len, hidden_size)\n",
    "\n",
    "        # Take the last time step\n",
    "        out = out[:, -1, :]  # (batch_size, hidden_size)\n",
    "\n",
    "        # Fully connected layer\n",
    "        out = self.fc(out)  # (batch_size, output_size)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(params, train_X, train_y, test_X, test_y, num_epochs):\n",
    "    hidden_size = params['hidden_size']\n",
    "    num_layers = params['num_layers']\n",
    "    learning_rate = params['learning_rate']\n",
    "    batch_size = params['batch_size']\n",
    "    \n",
    "    # Model instantiation\n",
    "    model = CNN_LSTM(\n",
    "        input_size=train_X.shape[2],\n",
    "        seq_len=train_X.shape[1],\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers,\n",
    "        output_size=1\n",
    "    )\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Initialize lists to track losses\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for i in range(0, len(train_X), batch_size):\n",
    "            batch_X = train_X[i:i + batch_size]\n",
    "            batch_y = train_y[i:i + batch_size]\n",
    "\n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Average training loss for the epoch\n",
    "        avg_train_loss = total_train_loss / (len(train_X) // batch_size)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Evaluation loop\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            total_test_loss = 0\n",
    "            for i in range(0, len(test_X), batch_size):\n",
    "                batch_X = test_X[i:i + batch_size]\n",
    "                batch_y = test_y[i:i + batch_size]\n",
    "\n",
    "                outputs = model(batch_X)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                total_test_loss += loss.item()\n",
    "\n",
    "        # Average testing loss for the epoch\n",
    "        avg_test_loss = total_test_loss / (len(test_X) // batch_size)\n",
    "        test_losses.append(avg_test_loss)\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}] - Train Loss: {avg_train_loss:.4f}, Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "    return train_losses, test_losses, avg_test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing combination: (4, 1, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1094, Test Loss: 1.5075\n",
      "Epoch [2/50] - Train Loss: 1.0885, Test Loss: 1.4887\n",
      "Epoch [3/50] - Train Loss: 1.0841, Test Loss: 1.4807\n",
      "Epoch [4/50] - Train Loss: 1.0852, Test Loss: 1.4795\n",
      "Epoch [5/50] - Train Loss: 1.0856, Test Loss: 1.4807\n",
      "Epoch [6/50] - Train Loss: 1.0851, Test Loss: 1.4819\n",
      "Epoch [7/50] - Train Loss: 1.0846, Test Loss: 1.4824\n",
      "Epoch [8/50] - Train Loss: 1.0841, Test Loss: 1.4824\n",
      "Epoch [9/50] - Train Loss: 1.0837, Test Loss: 1.4822\n",
      "Epoch [10/50] - Train Loss: 1.0831, Test Loss: 1.4821\n",
      "Epoch [11/50] - Train Loss: 1.0822, Test Loss: 1.4823\n",
      "Epoch [12/50] - Train Loss: 1.0813, Test Loss: 1.4828\n",
      "Epoch [13/50] - Train Loss: 1.0802, Test Loss: 1.4834\n",
      "Epoch [14/50] - Train Loss: 1.0788, Test Loss: 1.4841\n",
      "Epoch [15/50] - Train Loss: 1.0769, Test Loss: 1.4850\n",
      "Epoch [16/50] - Train Loss: 1.0740, Test Loss: 1.4877\n",
      "Epoch [17/50] - Train Loss: 1.0706, Test Loss: 1.4912\n",
      "Epoch [18/50] - Train Loss: 1.0660, Test Loss: 1.4899\n",
      "Epoch [19/50] - Train Loss: 1.0636, Test Loss: 1.4904\n",
      "Epoch [20/50] - Train Loss: 1.0619, Test Loss: 1.4916\n",
      "Epoch [21/50] - Train Loss: 1.0604, Test Loss: 1.4919\n",
      "Epoch [22/50] - Train Loss: 1.0595, Test Loss: 1.4925\n",
      "Epoch [23/50] - Train Loss: 1.0591, Test Loss: 1.4927\n",
      "Epoch [24/50] - Train Loss: 1.0593, Test Loss: 1.4951\n",
      "Epoch [25/50] - Train Loss: 1.0573, Test Loss: 1.4932\n",
      "Epoch [26/50] - Train Loss: 1.0566, Test Loss: 1.4927\n",
      "Epoch [27/50] - Train Loss: 1.0554, Test Loss: 1.4952\n",
      "Epoch [28/50] - Train Loss: 1.0493, Test Loss: 1.4937\n",
      "Epoch [29/50] - Train Loss: 1.0558, Test Loss: 1.4802\n",
      "Epoch [30/50] - Train Loss: 1.0968, Test Loss: 1.4860\n",
      "Epoch [31/50] - Train Loss: 1.0874, Test Loss: 1.4799\n",
      "Epoch [32/50] - Train Loss: 1.0940, Test Loss: 1.4797\n",
      "Epoch [33/50] - Train Loss: 1.0881, Test Loss: 1.4803\n",
      "Epoch [34/50] - Train Loss: 1.0880, Test Loss: 1.4812\n",
      "Epoch [35/50] - Train Loss: 1.0852, Test Loss: 1.4821\n",
      "Epoch [36/50] - Train Loss: 1.0849, Test Loss: 1.4819\n",
      "Epoch [37/50] - Train Loss: 1.0843, Test Loss: 1.4814\n",
      "Epoch [38/50] - Train Loss: 1.0837, Test Loss: 1.4814\n",
      "Epoch [39/50] - Train Loss: 1.0860, Test Loss: 1.4814\n",
      "Epoch [40/50] - Train Loss: 1.0749, Test Loss: 1.4810\n",
      "Epoch [41/50] - Train Loss: 1.0612, Test Loss: 1.4791\n",
      "Epoch [42/50] - Train Loss: 1.0559, Test Loss: 1.4855\n",
      "Epoch [43/50] - Train Loss: 1.0508, Test Loss: 1.5024\n",
      "Epoch [44/50] - Train Loss: 1.0429, Test Loss: 1.5100\n",
      "Epoch [45/50] - Train Loss: 1.0336, Test Loss: 1.5095\n",
      "Epoch [46/50] - Train Loss: 1.0488, Test Loss: 1.4872\n",
      "Epoch [47/50] - Train Loss: 1.0538, Test Loss: 1.4819\n",
      "Epoch [48/50] - Train Loss: 1.0529, Test Loss: 1.5167\n",
      "Epoch [49/50] - Train Loss: 1.0496, Test Loss: 1.5136\n",
      "Epoch [50/50] - Train Loss: 1.0431, Test Loss: 1.5110\n",
      "Avg Test Loss: 1.5110\n",
      "Testing combination: (4, 1, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.2064, Test Loss: 1.5737\n",
      "Epoch [2/50] - Train Loss: 1.1263, Test Loss: 1.6145\n",
      "Epoch [3/50] - Train Loss: 1.1179, Test Loss: 1.6370\n",
      "Epoch [4/50] - Train Loss: 1.1101, Test Loss: 1.6088\n",
      "Epoch [5/50] - Train Loss: 1.1081, Test Loss: 1.5972\n",
      "Epoch [6/50] - Train Loss: 1.1091, Test Loss: 1.5983\n",
      "Epoch [7/50] - Train Loss: 1.1092, Test Loss: 1.6033\n",
      "Epoch [8/50] - Train Loss: 1.1090, Test Loss: 1.6059\n",
      "Epoch [9/50] - Train Loss: 1.1087, Test Loss: 1.6051\n",
      "Epoch [10/50] - Train Loss: 1.1086, Test Loss: 1.6035\n",
      "Epoch [11/50] - Train Loss: 1.1086, Test Loss: 1.6029\n",
      "Epoch [12/50] - Train Loss: 1.1087, Test Loss: 1.6033\n",
      "Epoch [13/50] - Train Loss: 1.1087, Test Loss: 1.6038\n",
      "Epoch [14/50] - Train Loss: 1.1086, Test Loss: 1.6040\n",
      "Epoch [15/50] - Train Loss: 1.1086, Test Loss: 1.6039\n",
      "Epoch [16/50] - Train Loss: 1.1086, Test Loss: 1.6038\n",
      "Epoch [17/50] - Train Loss: 1.1086, Test Loss: 1.6037\n",
      "Epoch [18/50] - Train Loss: 1.1085, Test Loss: 1.6038\n",
      "Epoch [19/50] - Train Loss: 1.1085, Test Loss: 1.6038\n",
      "Epoch [20/50] - Train Loss: 1.1085, Test Loss: 1.6038\n",
      "Epoch [21/50] - Train Loss: 1.1085, Test Loss: 1.6038\n",
      "Epoch [22/50] - Train Loss: 1.1085, Test Loss: 1.6038\n",
      "Epoch [23/50] - Train Loss: 1.1085, Test Loss: 1.6038\n",
      "Epoch [24/50] - Train Loss: 1.1085, Test Loss: 1.6038\n",
      "Epoch [25/50] - Train Loss: 1.1085, Test Loss: 1.6038\n",
      "Epoch [26/50] - Train Loss: 1.1084, Test Loss: 1.6038\n",
      "Epoch [27/50] - Train Loss: 1.1084, Test Loss: 1.6038\n",
      "Epoch [28/50] - Train Loss: 1.1084, Test Loss: 1.6038\n",
      "Epoch [29/50] - Train Loss: 1.1084, Test Loss: 1.6038\n",
      "Epoch [30/50] - Train Loss: 1.1084, Test Loss: 1.6039\n",
      "Epoch [31/50] - Train Loss: 1.1084, Test Loss: 1.6039\n",
      "Epoch [32/50] - Train Loss: 1.1084, Test Loss: 1.6039\n",
      "Epoch [33/50] - Train Loss: 1.1083, Test Loss: 1.6039\n",
      "Epoch [34/50] - Train Loss: 1.1083, Test Loss: 1.6039\n",
      "Epoch [35/50] - Train Loss: 1.1083, Test Loss: 1.6039\n",
      "Epoch [36/50] - Train Loss: 1.1082, Test Loss: 1.6039\n",
      "Epoch [37/50] - Train Loss: 1.1080, Test Loss: 1.6040\n",
      "Epoch [38/50] - Train Loss: 1.1076, Test Loss: 1.6041\n",
      "Epoch [39/50] - Train Loss: 1.1065, Test Loss: 1.6050\n",
      "Epoch [40/50] - Train Loss: 1.1041, Test Loss: 1.6087\n",
      "Epoch [41/50] - Train Loss: 1.1010, Test Loss: 1.6133\n",
      "Epoch [42/50] - Train Loss: 1.0975, Test Loss: 1.6131\n",
      "Epoch [43/50] - Train Loss: 1.0943, Test Loss: 1.6113\n",
      "Epoch [44/50] - Train Loss: 1.0919, Test Loss: 1.6117\n",
      "Epoch [45/50] - Train Loss: 1.0896, Test Loss: 1.6126\n",
      "Epoch [46/50] - Train Loss: 1.0877, Test Loss: 1.6126\n",
      "Epoch [47/50] - Train Loss: 1.0862, Test Loss: 1.6124\n",
      "Epoch [48/50] - Train Loss: 1.0849, Test Loss: 1.6126\n",
      "Epoch [49/50] - Train Loss: 1.0838, Test Loss: 1.6127\n",
      "Epoch [50/50] - Train Loss: 1.0829, Test Loss: 1.6127\n",
      "Avg Test Loss: 1.6127\n",
      "Testing combination: (4, 1, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3071, Test Loss: 2.6801\n",
      "Epoch [2/50] - Train Loss: 1.3028, Test Loss: 2.6707\n",
      "Epoch [3/50] - Train Loss: 1.3021, Test Loss: 2.6645\n",
      "Epoch [4/50] - Train Loss: 1.3020, Test Loss: 2.6610\n",
      "Epoch [5/50] - Train Loss: 1.3021, Test Loss: 2.6596\n",
      "Epoch [6/50] - Train Loss: 1.3021, Test Loss: 2.6595\n",
      "Epoch [7/50] - Train Loss: 1.3021, Test Loss: 2.6602\n",
      "Epoch [8/50] - Train Loss: 1.3021, Test Loss: 2.6612\n",
      "Epoch [9/50] - Train Loss: 1.3020, Test Loss: 2.6623\n",
      "Epoch [10/50] - Train Loss: 1.3020, Test Loss: 2.6632\n",
      "Epoch [11/50] - Train Loss: 1.3020, Test Loss: 2.6637\n",
      "Epoch [12/50] - Train Loss: 1.3020, Test Loss: 2.6640\n",
      "Epoch [13/50] - Train Loss: 1.3020, Test Loss: 2.6640\n",
      "Epoch [14/50] - Train Loss: 1.3020, Test Loss: 2.6639\n",
      "Epoch [15/50] - Train Loss: 1.3019, Test Loss: 2.6636\n",
      "Epoch [16/50] - Train Loss: 1.3019, Test Loss: 2.6634\n",
      "Epoch [17/50] - Train Loss: 1.3019, Test Loss: 2.6632\n",
      "Epoch [18/50] - Train Loss: 1.3019, Test Loss: 2.6631\n",
      "Epoch [19/50] - Train Loss: 1.3019, Test Loss: 2.6630\n",
      "Epoch [20/50] - Train Loss: 1.3020, Test Loss: 2.6630\n",
      "Epoch [21/50] - Train Loss: 1.3020, Test Loss: 2.6630\n",
      "Epoch [22/50] - Train Loss: 1.3020, Test Loss: 2.6630\n",
      "Epoch [23/50] - Train Loss: 1.3020, Test Loss: 2.6631\n",
      "Epoch [24/50] - Train Loss: 1.3020, Test Loss: 2.6631\n",
      "Epoch [25/50] - Train Loss: 1.3019, Test Loss: 2.6632\n",
      "Epoch [26/50] - Train Loss: 1.3019, Test Loss: 2.6632\n",
      "Epoch [27/50] - Train Loss: 1.3019, Test Loss: 2.6632\n",
      "Epoch [28/50] - Train Loss: 1.3019, Test Loss: 2.6632\n",
      "Epoch [29/50] - Train Loss: 1.3019, Test Loss: 2.6632\n",
      "Epoch [30/50] - Train Loss: 1.3019, Test Loss: 2.6632\n",
      "Epoch [31/50] - Train Loss: 1.3019, Test Loss: 2.6632\n",
      "Epoch [32/50] - Train Loss: 1.3019, Test Loss: 2.6631\n",
      "Epoch [33/50] - Train Loss: 1.3019, Test Loss: 2.6631\n",
      "Epoch [34/50] - Train Loss: 1.3019, Test Loss: 2.6631\n",
      "Epoch [35/50] - Train Loss: 1.3019, Test Loss: 2.6631\n",
      "Epoch [36/50] - Train Loss: 1.3019, Test Loss: 2.6631\n",
      "Epoch [37/50] - Train Loss: 1.3019, Test Loss: 2.6631\n",
      "Epoch [38/50] - Train Loss: 1.3019, Test Loss: 2.6631\n",
      "Epoch [39/50] - Train Loss: 1.3019, Test Loss: 2.6631\n",
      "Epoch [40/50] - Train Loss: 1.3019, Test Loss: 2.6631\n",
      "Epoch [41/50] - Train Loss: 1.3019, Test Loss: 2.6631\n",
      "Epoch [42/50] - Train Loss: 1.3019, Test Loss: 2.6631\n",
      "Epoch [43/50] - Train Loss: 1.3019, Test Loss: 2.6631\n",
      "Epoch [44/50] - Train Loss: 1.3019, Test Loss: 2.6631\n",
      "Epoch [45/50] - Train Loss: 1.3019, Test Loss: 2.6631\n",
      "Epoch [46/50] - Train Loss: 1.3019, Test Loss: 2.6631\n",
      "Epoch [47/50] - Train Loss: 1.3019, Test Loss: 2.6631\n",
      "Epoch [48/50] - Train Loss: 1.3019, Test Loss: 2.6631\n",
      "Epoch [49/50] - Train Loss: 1.3019, Test Loss: 2.6631\n",
      "Epoch [50/50] - Train Loss: 1.3019, Test Loss: 2.6631\n",
      "Avg Test Loss: 2.6631\n",
      "Testing combination: (4, 1, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.0994, Test Loss: 1.5085\n",
      "Epoch [2/50] - Train Loss: 1.0966, Test Loss: 1.5058\n",
      "Epoch [3/50] - Train Loss: 1.0952, Test Loss: 1.5033\n",
      "Epoch [4/50] - Train Loss: 1.0940, Test Loss: 1.5012\n",
      "Epoch [5/50] - Train Loss: 1.0930, Test Loss: 1.4993\n",
      "Epoch [6/50] - Train Loss: 1.0922, Test Loss: 1.4977\n",
      "Epoch [7/50] - Train Loss: 1.0914, Test Loss: 1.4963\n",
      "Epoch [8/50] - Train Loss: 1.0908, Test Loss: 1.4950\n",
      "Epoch [9/50] - Train Loss: 1.0902, Test Loss: 1.4940\n",
      "Epoch [10/50] - Train Loss: 1.0896, Test Loss: 1.4930\n",
      "Epoch [11/50] - Train Loss: 1.0891, Test Loss: 1.4921\n",
      "Epoch [12/50] - Train Loss: 1.0886, Test Loss: 1.4915\n",
      "Epoch [13/50] - Train Loss: 1.0882, Test Loss: 1.4908\n",
      "Epoch [14/50] - Train Loss: 1.0878, Test Loss: 1.4903\n",
      "Epoch [15/50] - Train Loss: 1.0874, Test Loss: 1.4898\n",
      "Epoch [16/50] - Train Loss: 1.0871, Test Loss: 1.4893\n",
      "Epoch [17/50] - Train Loss: 1.0867, Test Loss: 1.4889\n",
      "Epoch [18/50] - Train Loss: 1.0864, Test Loss: 1.4885\n",
      "Epoch [19/50] - Train Loss: 1.0861, Test Loss: 1.4881\n",
      "Epoch [20/50] - Train Loss: 1.0859, Test Loss: 1.4878\n",
      "Epoch [21/50] - Train Loss: 1.0856, Test Loss: 1.4874\n",
      "Epoch [22/50] - Train Loss: 1.0854, Test Loss: 1.4871\n",
      "Epoch [23/50] - Train Loss: 1.0851, Test Loss: 1.4869\n",
      "Epoch [24/50] - Train Loss: 1.0849, Test Loss: 1.4866\n",
      "Epoch [25/50] - Train Loss: 1.0847, Test Loss: 1.4864\n",
      "Epoch [26/50] - Train Loss: 1.0845, Test Loss: 1.4861\n",
      "Epoch [27/50] - Train Loss: 1.0843, Test Loss: 1.4859\n",
      "Epoch [28/50] - Train Loss: 1.0841, Test Loss: 1.4857\n",
      "Epoch [29/50] - Train Loss: 1.0839, Test Loss: 1.4855\n",
      "Epoch [30/50] - Train Loss: 1.0838, Test Loss: 1.4854\n",
      "Epoch [31/50] - Train Loss: 1.0836, Test Loss: 1.4852\n",
      "Epoch [32/50] - Train Loss: 1.0835, Test Loss: 1.4851\n",
      "Epoch [33/50] - Train Loss: 1.0834, Test Loss: 1.4849\n",
      "Epoch [34/50] - Train Loss: 1.0832, Test Loss: 1.4847\n",
      "Epoch [35/50] - Train Loss: 1.0831, Test Loss: 1.4846\n",
      "Epoch [36/50] - Train Loss: 1.0830, Test Loss: 1.4844\n",
      "Epoch [37/50] - Train Loss: 1.0829, Test Loss: 1.4843\n",
      "Epoch [38/50] - Train Loss: 1.0828, Test Loss: 1.4842\n",
      "Epoch [39/50] - Train Loss: 1.0827, Test Loss: 1.4841\n",
      "Epoch [40/50] - Train Loss: 1.0826, Test Loss: 1.4840\n",
      "Epoch [41/50] - Train Loss: 1.0825, Test Loss: 1.4838\n",
      "Epoch [42/50] - Train Loss: 1.0825, Test Loss: 1.4837\n",
      "Epoch [43/50] - Train Loss: 1.0824, Test Loss: 1.4836\n",
      "Epoch [44/50] - Train Loss: 1.0823, Test Loss: 1.4835\n",
      "Epoch [45/50] - Train Loss: 1.0823, Test Loss: 1.4835\n",
      "Epoch [46/50] - Train Loss: 1.0823, Test Loss: 1.4834\n",
      "Epoch [47/50] - Train Loss: 1.0822, Test Loss: 1.4833\n",
      "Epoch [48/50] - Train Loss: 1.0822, Test Loss: 1.4832\n",
      "Epoch [49/50] - Train Loss: 1.0822, Test Loss: 1.4831\n",
      "Epoch [50/50] - Train Loss: 1.0821, Test Loss: 1.4831\n",
      "Avg Test Loss: 1.4831\n",
      "Testing combination: (4, 1, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.2233, Test Loss: 1.5970\n",
      "Epoch [2/50] - Train Loss: 1.2097, Test Loss: 1.5909\n",
      "Epoch [3/50] - Train Loss: 1.1968, Test Loss: 1.5855\n",
      "Epoch [4/50] - Train Loss: 1.1845, Test Loss: 1.5810\n",
      "Epoch [5/50] - Train Loss: 1.1727, Test Loss: 1.5775\n",
      "Epoch [6/50] - Train Loss: 1.1618, Test Loss: 1.5750\n",
      "Epoch [7/50] - Train Loss: 1.1517, Test Loss: 1.5738\n",
      "Epoch [8/50] - Train Loss: 1.1424, Test Loss: 1.5738\n",
      "Epoch [9/50] - Train Loss: 1.1337, Test Loss: 1.5754\n",
      "Epoch [10/50] - Train Loss: 1.1265, Test Loss: 1.5784\n",
      "Epoch [11/50] - Train Loss: 1.1209, Test Loss: 1.5825\n",
      "Epoch [12/50] - Train Loss: 1.1168, Test Loss: 1.5871\n",
      "Epoch [13/50] - Train Loss: 1.1141, Test Loss: 1.5918\n",
      "Epoch [14/50] - Train Loss: 1.1124, Test Loss: 1.5959\n",
      "Epoch [15/50] - Train Loss: 1.1114, Test Loss: 1.5994\n",
      "Epoch [16/50] - Train Loss: 1.1108, Test Loss: 1.6019\n",
      "Epoch [17/50] - Train Loss: 1.1105, Test Loss: 1.6038\n",
      "Epoch [18/50] - Train Loss: 1.1103, Test Loss: 1.6050\n",
      "Epoch [19/50] - Train Loss: 1.1102, Test Loss: 1.6057\n",
      "Epoch [20/50] - Train Loss: 1.1101, Test Loss: 1.6062\n",
      "Epoch [21/50] - Train Loss: 1.1100, Test Loss: 1.6064\n",
      "Epoch [22/50] - Train Loss: 1.1099, Test Loss: 1.6065\n",
      "Epoch [23/50] - Train Loss: 1.1099, Test Loss: 1.6065\n",
      "Epoch [24/50] - Train Loss: 1.1098, Test Loss: 1.6065\n",
      "Epoch [25/50] - Train Loss: 1.1098, Test Loss: 1.6064\n",
      "Epoch [26/50] - Train Loss: 1.1097, Test Loss: 1.6064\n",
      "Epoch [27/50] - Train Loss: 1.1097, Test Loss: 1.6063\n",
      "Epoch [28/50] - Train Loss: 1.1096, Test Loss: 1.6063\n",
      "Epoch [29/50] - Train Loss: 1.1096, Test Loss: 1.6063\n",
      "Epoch [30/50] - Train Loss: 1.1095, Test Loss: 1.6062\n",
      "Epoch [31/50] - Train Loss: 1.1095, Test Loss: 1.6062\n",
      "Epoch [32/50] - Train Loss: 1.1095, Test Loss: 1.6062\n",
      "Epoch [33/50] - Train Loss: 1.1094, Test Loss: 1.6062\n",
      "Epoch [34/50] - Train Loss: 1.1094, Test Loss: 1.6062\n",
      "Epoch [35/50] - Train Loss: 1.1093, Test Loss: 1.6062\n",
      "Epoch [36/50] - Train Loss: 1.1093, Test Loss: 1.6061\n",
      "Epoch [37/50] - Train Loss: 1.1093, Test Loss: 1.6061\n",
      "Epoch [38/50] - Train Loss: 1.1092, Test Loss: 1.6061\n",
      "Epoch [39/50] - Train Loss: 1.1092, Test Loss: 1.6061\n",
      "Epoch [40/50] - Train Loss: 1.1092, Test Loss: 1.6061\n",
      "Epoch [41/50] - Train Loss: 1.1091, Test Loss: 1.6061\n",
      "Epoch [42/50] - Train Loss: 1.1091, Test Loss: 1.6061\n",
      "Epoch [43/50] - Train Loss: 1.1090, Test Loss: 1.6061\n",
      "Epoch [44/50] - Train Loss: 1.1090, Test Loss: 1.6061\n",
      "Epoch [45/50] - Train Loss: 1.1090, Test Loss: 1.6060\n",
      "Epoch [46/50] - Train Loss: 1.1089, Test Loss: 1.6060\n",
      "Epoch [47/50] - Train Loss: 1.1089, Test Loss: 1.6060\n",
      "Epoch [48/50] - Train Loss: 1.1089, Test Loss: 1.6060\n",
      "Epoch [49/50] - Train Loss: 1.1088, Test Loss: 1.6060\n",
      "Epoch [50/50] - Train Loss: 1.1088, Test Loss: 1.6060\n",
      "Avg Test Loss: 1.6060\n",
      "Testing combination: (4, 1, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3021, Test Loss: 2.6548\n",
      "Epoch [2/50] - Train Loss: 1.3011, Test Loss: 2.6559\n",
      "Epoch [3/50] - Train Loss: 1.3003, Test Loss: 2.6568\n",
      "Epoch [4/50] - Train Loss: 1.2997, Test Loss: 2.6576\n",
      "Epoch [5/50] - Train Loss: 1.2991, Test Loss: 2.6584\n",
      "Epoch [6/50] - Train Loss: 1.2985, Test Loss: 2.6592\n",
      "Epoch [7/50] - Train Loss: 1.2979, Test Loss: 2.6598\n",
      "Epoch [8/50] - Train Loss: 1.2973, Test Loss: 2.6605\n",
      "Epoch [9/50] - Train Loss: 1.2968, Test Loss: 2.6611\n",
      "Epoch [10/50] - Train Loss: 1.2962, Test Loss: 2.6616\n",
      "Epoch [11/50] - Train Loss: 1.2957, Test Loss: 2.6622\n",
      "Epoch [12/50] - Train Loss: 1.2952, Test Loss: 2.6627\n",
      "Epoch [13/50] - Train Loss: 1.2946, Test Loss: 2.6632\n",
      "Epoch [14/50] - Train Loss: 1.2941, Test Loss: 2.6636\n",
      "Epoch [15/50] - Train Loss: 1.2936, Test Loss: 2.6641\n",
      "Epoch [16/50] - Train Loss: 1.2932, Test Loss: 2.6645\n",
      "Epoch [17/50] - Train Loss: 1.2927, Test Loss: 2.6649\n",
      "Epoch [18/50] - Train Loss: 1.2923, Test Loss: 2.6654\n",
      "Epoch [19/50] - Train Loss: 1.2919, Test Loss: 2.6658\n",
      "Epoch [20/50] - Train Loss: 1.2916, Test Loss: 2.6661\n",
      "Epoch [21/50] - Train Loss: 1.2913, Test Loss: 2.6665\n",
      "Epoch [22/50] - Train Loss: 1.2910, Test Loss: 2.6669\n",
      "Epoch [23/50] - Train Loss: 1.2907, Test Loss: 2.6672\n",
      "Epoch [24/50] - Train Loss: 1.2905, Test Loss: 2.6676\n",
      "Epoch [25/50] - Train Loss: 1.2904, Test Loss: 2.6679\n",
      "Epoch [26/50] - Train Loss: 1.2902, Test Loss: 2.6682\n",
      "Epoch [27/50] - Train Loss: 1.2901, Test Loss: 2.6685\n",
      "Epoch [28/50] - Train Loss: 1.2900, Test Loss: 2.6688\n",
      "Epoch [29/50] - Train Loss: 1.2899, Test Loss: 2.6690\n",
      "Epoch [30/50] - Train Loss: 1.2898, Test Loss: 2.6692\n",
      "Epoch [31/50] - Train Loss: 1.2897, Test Loss: 2.6695\n",
      "Epoch [32/50] - Train Loss: 1.2896, Test Loss: 2.6696\n",
      "Epoch [33/50] - Train Loss: 1.2896, Test Loss: 2.6698\n",
      "Epoch [34/50] - Train Loss: 1.2895, Test Loss: 2.6700\n",
      "Epoch [35/50] - Train Loss: 1.2895, Test Loss: 2.6701\n",
      "Epoch [36/50] - Train Loss: 1.2894, Test Loss: 2.6702\n",
      "Epoch [37/50] - Train Loss: 1.2894, Test Loss: 2.6703\n",
      "Epoch [38/50] - Train Loss: 1.2894, Test Loss: 2.6704\n",
      "Epoch [39/50] - Train Loss: 1.2893, Test Loss: 2.6705\n",
      "Epoch [40/50] - Train Loss: 1.2893, Test Loss: 2.6706\n",
      "Epoch [41/50] - Train Loss: 1.2893, Test Loss: 2.6706\n",
      "Epoch [42/50] - Train Loss: 1.2893, Test Loss: 2.6707\n",
      "Epoch [43/50] - Train Loss: 1.2892, Test Loss: 2.6707\n",
      "Epoch [44/50] - Train Loss: 1.2892, Test Loss: 2.6708\n",
      "Epoch [45/50] - Train Loss: 1.2892, Test Loss: 2.6708\n",
      "Epoch [46/50] - Train Loss: 1.2892, Test Loss: 2.6709\n",
      "Epoch [47/50] - Train Loss: 1.2892, Test Loss: 2.6709\n",
      "Epoch [48/50] - Train Loss: 1.2892, Test Loss: 2.6709\n",
      "Epoch [49/50] - Train Loss: 1.2891, Test Loss: 2.6709\n",
      "Epoch [50/50] - Train Loss: 1.2891, Test Loss: 2.6709\n",
      "Avg Test Loss: 2.6709\n",
      "Testing combination: (4, 1, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.2180, Test Loss: 1.7089\n",
      "Epoch [2/50] - Train Loss: 1.2162, Test Loss: 1.7065\n",
      "Epoch [3/50] - Train Loss: 1.2145, Test Loss: 1.7041\n",
      "Epoch [4/50] - Train Loss: 1.2129, Test Loss: 1.7018\n",
      "Epoch [5/50] - Train Loss: 1.2112, Test Loss: 1.6994\n",
      "Epoch [6/50] - Train Loss: 1.2096, Test Loss: 1.6971\n",
      "Epoch [7/50] - Train Loss: 1.2079, Test Loss: 1.6949\n",
      "Epoch [8/50] - Train Loss: 1.2063, Test Loss: 1.6926\n",
      "Epoch [9/50] - Train Loss: 1.2048, Test Loss: 1.6904\n",
      "Epoch [10/50] - Train Loss: 1.2032, Test Loss: 1.6882\n",
      "Epoch [11/50] - Train Loss: 1.2016, Test Loss: 1.6860\n",
      "Epoch [12/50] - Train Loss: 1.2001, Test Loss: 1.6838\n",
      "Epoch [13/50] - Train Loss: 1.1986, Test Loss: 1.6817\n",
      "Epoch [14/50] - Train Loss: 1.1970, Test Loss: 1.6795\n",
      "Epoch [15/50] - Train Loss: 1.1955, Test Loss: 1.6774\n",
      "Epoch [16/50] - Train Loss: 1.1941, Test Loss: 1.6753\n",
      "Epoch [17/50] - Train Loss: 1.1926, Test Loss: 1.6731\n",
      "Epoch [18/50] - Train Loss: 1.1911, Test Loss: 1.6710\n",
      "Epoch [19/50] - Train Loss: 1.1896, Test Loss: 1.6689\n",
      "Epoch [20/50] - Train Loss: 1.1882, Test Loss: 1.6668\n",
      "Epoch [21/50] - Train Loss: 1.1867, Test Loss: 1.6647\n",
      "Epoch [22/50] - Train Loss: 1.1853, Test Loss: 1.6627\n",
      "Epoch [23/50] - Train Loss: 1.1838, Test Loss: 1.6606\n",
      "Epoch [24/50] - Train Loss: 1.1824, Test Loss: 1.6585\n",
      "Epoch [25/50] - Train Loss: 1.1810, Test Loss: 1.6564\n",
      "Epoch [26/50] - Train Loss: 1.1796, Test Loss: 1.6543\n",
      "Epoch [27/50] - Train Loss: 1.1781, Test Loss: 1.6523\n",
      "Epoch [28/50] - Train Loss: 1.1767, Test Loss: 1.6502\n",
      "Epoch [29/50] - Train Loss: 1.1753, Test Loss: 1.6481\n",
      "Epoch [30/50] - Train Loss: 1.1739, Test Loss: 1.6461\n",
      "Epoch [31/50] - Train Loss: 1.1725, Test Loss: 1.6440\n",
      "Epoch [32/50] - Train Loss: 1.1712, Test Loss: 1.6421\n",
      "Epoch [33/50] - Train Loss: 1.1699, Test Loss: 1.6402\n",
      "Epoch [34/50] - Train Loss: 1.1686, Test Loss: 1.6382\n",
      "Epoch [35/50] - Train Loss: 1.1673, Test Loss: 1.6363\n",
      "Epoch [36/50] - Train Loss: 1.1660, Test Loss: 1.6344\n",
      "Epoch [37/50] - Train Loss: 1.1647, Test Loss: 1.6325\n",
      "Epoch [38/50] - Train Loss: 1.1635, Test Loss: 1.6306\n",
      "Epoch [39/50] - Train Loss: 1.1622, Test Loss: 1.6287\n",
      "Epoch [40/50] - Train Loss: 1.1609, Test Loss: 1.6269\n",
      "Epoch [41/50] - Train Loss: 1.1597, Test Loss: 1.6250\n",
      "Epoch [42/50] - Train Loss: 1.1584, Test Loss: 1.6231\n",
      "Epoch [43/50] - Train Loss: 1.1572, Test Loss: 1.6212\n",
      "Epoch [44/50] - Train Loss: 1.1559, Test Loss: 1.6194\n",
      "Epoch [45/50] - Train Loss: 1.1547, Test Loss: 1.6175\n",
      "Epoch [46/50] - Train Loss: 1.1535, Test Loss: 1.6157\n",
      "Epoch [47/50] - Train Loss: 1.1523, Test Loss: 1.6139\n",
      "Epoch [48/50] - Train Loss: 1.1511, Test Loss: 1.6120\n",
      "Epoch [49/50] - Train Loss: 1.1499, Test Loss: 1.6102\n",
      "Epoch [50/50] - Train Loss: 1.1487, Test Loss: 1.6084\n",
      "Avg Test Loss: 1.6084\n",
      "Testing combination: (4, 1, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.2731, Test Loss: 1.6299\n",
      "Epoch [2/50] - Train Loss: 1.2717, Test Loss: 1.6290\n",
      "Epoch [3/50] - Train Loss: 1.2703, Test Loss: 1.6282\n",
      "Epoch [4/50] - Train Loss: 1.2689, Test Loss: 1.6273\n",
      "Epoch [5/50] - Train Loss: 1.2675, Test Loss: 1.6265\n",
      "Epoch [6/50] - Train Loss: 1.2662, Test Loss: 1.6257\n",
      "Epoch [7/50] - Train Loss: 1.2648, Test Loss: 1.6248\n",
      "Epoch [8/50] - Train Loss: 1.2635, Test Loss: 1.6240\n",
      "Epoch [9/50] - Train Loss: 1.2622, Test Loss: 1.6232\n",
      "Epoch [10/50] - Train Loss: 1.2608, Test Loss: 1.6224\n",
      "Epoch [11/50] - Train Loss: 1.2595, Test Loss: 1.6217\n",
      "Epoch [12/50] - Train Loss: 1.2582, Test Loss: 1.6209\n",
      "Epoch [13/50] - Train Loss: 1.2570, Test Loss: 1.6201\n",
      "Epoch [14/50] - Train Loss: 1.2557, Test Loss: 1.6194\n",
      "Epoch [15/50] - Train Loss: 1.2544, Test Loss: 1.6186\n",
      "Epoch [16/50] - Train Loss: 1.2532, Test Loss: 1.6179\n",
      "Epoch [17/50] - Train Loss: 1.2519, Test Loss: 1.6172\n",
      "Epoch [18/50] - Train Loss: 1.2507, Test Loss: 1.6165\n",
      "Epoch [19/50] - Train Loss: 1.2495, Test Loss: 1.6158\n",
      "Epoch [20/50] - Train Loss: 1.2483, Test Loss: 1.6151\n",
      "Epoch [21/50] - Train Loss: 1.2471, Test Loss: 1.6144\n",
      "Epoch [22/50] - Train Loss: 1.2459, Test Loss: 1.6137\n",
      "Epoch [23/50] - Train Loss: 1.2447, Test Loss: 1.6130\n",
      "Epoch [24/50] - Train Loss: 1.2435, Test Loss: 1.6123\n",
      "Epoch [25/50] - Train Loss: 1.2424, Test Loss: 1.6117\n",
      "Epoch [26/50] - Train Loss: 1.2413, Test Loss: 1.6111\n",
      "Epoch [27/50] - Train Loss: 1.2402, Test Loss: 1.6105\n",
      "Epoch [28/50] - Train Loss: 1.2392, Test Loss: 1.6099\n",
      "Epoch [29/50] - Train Loss: 1.2381, Test Loss: 1.6093\n",
      "Epoch [30/50] - Train Loss: 1.2371, Test Loss: 1.6087\n",
      "Epoch [31/50] - Train Loss: 1.2360, Test Loss: 1.6082\n",
      "Epoch [32/50] - Train Loss: 1.2350, Test Loss: 1.6075\n",
      "Epoch [33/50] - Train Loss: 1.2339, Test Loss: 1.6069\n",
      "Epoch [34/50] - Train Loss: 1.2328, Test Loss: 1.6063\n",
      "Epoch [35/50] - Train Loss: 1.2317, Test Loss: 1.6057\n",
      "Epoch [36/50] - Train Loss: 1.2306, Test Loss: 1.6051\n",
      "Epoch [37/50] - Train Loss: 1.2295, Test Loss: 1.6045\n",
      "Epoch [38/50] - Train Loss: 1.2284, Test Loss: 1.6039\n",
      "Epoch [39/50] - Train Loss: 1.2274, Test Loss: 1.6034\n",
      "Epoch [40/50] - Train Loss: 1.2263, Test Loss: 1.6028\n",
      "Epoch [41/50] - Train Loss: 1.2253, Test Loss: 1.6023\n",
      "Epoch [42/50] - Train Loss: 1.2242, Test Loss: 1.6017\n",
      "Epoch [43/50] - Train Loss: 1.2232, Test Loss: 1.6012\n",
      "Epoch [44/50] - Train Loss: 1.2222, Test Loss: 1.6006\n",
      "Epoch [45/50] - Train Loss: 1.2212, Test Loss: 1.6001\n",
      "Epoch [46/50] - Train Loss: 1.2202, Test Loss: 1.5996\n",
      "Epoch [47/50] - Train Loss: 1.2192, Test Loss: 1.5990\n",
      "Epoch [48/50] - Train Loss: 1.2181, Test Loss: 1.5985\n",
      "Epoch [49/50] - Train Loss: 1.2171, Test Loss: 1.5980\n",
      "Epoch [50/50] - Train Loss: 1.2162, Test Loss: 1.5975\n",
      "Avg Test Loss: 1.5975\n",
      "Testing combination: (4, 1, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3338, Test Loss: 2.6292\n",
      "Epoch [2/50] - Train Loss: 1.3335, Test Loss: 2.6292\n",
      "Epoch [3/50] - Train Loss: 1.3332, Test Loss: 2.6291\n",
      "Epoch [4/50] - Train Loss: 1.3329, Test Loss: 2.6290\n",
      "Epoch [5/50] - Train Loss: 1.3326, Test Loss: 2.6290\n",
      "Epoch [6/50] - Train Loss: 1.3323, Test Loss: 2.6289\n",
      "Epoch [7/50] - Train Loss: 1.3319, Test Loss: 2.6289\n",
      "Epoch [8/50] - Train Loss: 1.3316, Test Loss: 2.6288\n",
      "Epoch [9/50] - Train Loss: 1.3313, Test Loss: 2.6288\n",
      "Epoch [10/50] - Train Loss: 1.3310, Test Loss: 2.6287\n",
      "Epoch [11/50] - Train Loss: 1.3308, Test Loss: 2.6287\n",
      "Epoch [12/50] - Train Loss: 1.3305, Test Loss: 2.6286\n",
      "Epoch [13/50] - Train Loss: 1.3302, Test Loss: 2.6286\n",
      "Epoch [14/50] - Train Loss: 1.3299, Test Loss: 2.6285\n",
      "Epoch [15/50] - Train Loss: 1.3296, Test Loss: 2.6285\n",
      "Epoch [16/50] - Train Loss: 1.3293, Test Loss: 2.6285\n",
      "Epoch [17/50] - Train Loss: 1.3290, Test Loss: 2.6284\n",
      "Epoch [18/50] - Train Loss: 1.3287, Test Loss: 2.6284\n",
      "Epoch [19/50] - Train Loss: 1.3284, Test Loss: 2.6284\n",
      "Epoch [20/50] - Train Loss: 1.3281, Test Loss: 2.6283\n",
      "Epoch [21/50] - Train Loss: 1.3279, Test Loss: 2.6283\n",
      "Epoch [22/50] - Train Loss: 1.3276, Test Loss: 2.6283\n",
      "Epoch [23/50] - Train Loss: 1.3273, Test Loss: 2.6283\n",
      "Epoch [24/50] - Train Loss: 1.3270, Test Loss: 2.6282\n",
      "Epoch [25/50] - Train Loss: 1.3267, Test Loss: 2.6282\n",
      "Epoch [26/50] - Train Loss: 1.3265, Test Loss: 2.6282\n",
      "Epoch [27/50] - Train Loss: 1.3262, Test Loss: 2.6282\n",
      "Epoch [28/50] - Train Loss: 1.3259, Test Loss: 2.6282\n",
      "Epoch [29/50] - Train Loss: 1.3256, Test Loss: 2.6282\n",
      "Epoch [30/50] - Train Loss: 1.3253, Test Loss: 2.6281\n",
      "Epoch [31/50] - Train Loss: 1.3251, Test Loss: 2.6281\n",
      "Epoch [32/50] - Train Loss: 1.3248, Test Loss: 2.6281\n",
      "Epoch [33/50] - Train Loss: 1.3245, Test Loss: 2.6281\n",
      "Epoch [34/50] - Train Loss: 1.3242, Test Loss: 2.6281\n",
      "Epoch [35/50] - Train Loss: 1.3240, Test Loss: 2.6281\n",
      "Epoch [36/50] - Train Loss: 1.3237, Test Loss: 2.6281\n",
      "Epoch [37/50] - Train Loss: 1.3234, Test Loss: 2.6281\n",
      "Epoch [38/50] - Train Loss: 1.3231, Test Loss: 2.6281\n",
      "Epoch [39/50] - Train Loss: 1.3229, Test Loss: 2.6282\n",
      "Epoch [40/50] - Train Loss: 1.3226, Test Loss: 2.6282\n",
      "Epoch [41/50] - Train Loss: 1.3223, Test Loss: 2.6282\n",
      "Epoch [42/50] - Train Loss: 1.3221, Test Loss: 2.6282\n",
      "Epoch [43/50] - Train Loss: 1.3218, Test Loss: 2.6282\n",
      "Epoch [44/50] - Train Loss: 1.3215, Test Loss: 2.6282\n",
      "Epoch [45/50] - Train Loss: 1.3212, Test Loss: 2.6282\n",
      "Epoch [46/50] - Train Loss: 1.3210, Test Loss: 2.6283\n",
      "Epoch [47/50] - Train Loss: 1.3207, Test Loss: 2.6283\n",
      "Epoch [48/50] - Train Loss: 1.3204, Test Loss: 2.6283\n",
      "Epoch [49/50] - Train Loss: 1.3202, Test Loss: 2.6283\n",
      "Epoch [50/50] - Train Loss: 1.3199, Test Loss: 2.6284\n",
      "Avg Test Loss: 2.6284\n",
      "Testing combination: (4, 2, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1721, Test Loss: 1.5605\n",
      "Epoch [2/50] - Train Loss: 1.1020, Test Loss: 1.4935\n",
      "Epoch [3/50] - Train Loss: 1.0878, Test Loss: 1.4793\n",
      "Epoch [4/50] - Train Loss: 1.0895, Test Loss: 1.4784\n",
      "Epoch [5/50] - Train Loss: 1.0897, Test Loss: 1.4805\n",
      "Epoch [6/50] - Train Loss: 1.0887, Test Loss: 1.4824\n",
      "Epoch [7/50] - Train Loss: 1.0878, Test Loss: 1.4830\n",
      "Epoch [8/50] - Train Loss: 1.0871, Test Loss: 1.4828\n",
      "Epoch [9/50] - Train Loss: 1.0865, Test Loss: 1.4824\n",
      "Epoch [10/50] - Train Loss: 1.0861, Test Loss: 1.4821\n",
      "Epoch [11/50] - Train Loss: 1.0857, Test Loss: 1.4820\n",
      "Epoch [12/50] - Train Loss: 1.0852, Test Loss: 1.4820\n",
      "Epoch [13/50] - Train Loss: 1.0847, Test Loss: 1.4820\n",
      "Epoch [14/50] - Train Loss: 1.0839, Test Loss: 1.4821\n",
      "Epoch [15/50] - Train Loss: 1.0828, Test Loss: 1.4823\n",
      "Epoch [16/50] - Train Loss: 1.0815, Test Loss: 1.4829\n",
      "Epoch [17/50] - Train Loss: 1.0798, Test Loss: 1.4835\n",
      "Epoch [18/50] - Train Loss: 1.0779, Test Loss: 1.4840\n",
      "Epoch [19/50] - Train Loss: 1.0756, Test Loss: 1.4843\n",
      "Epoch [20/50] - Train Loss: 1.0734, Test Loss: 1.4847\n",
      "Epoch [21/50] - Train Loss: 1.0713, Test Loss: 1.4851\n",
      "Epoch [22/50] - Train Loss: 1.0687, Test Loss: 1.4851\n",
      "Epoch [23/50] - Train Loss: 1.0658, Test Loss: 1.4835\n",
      "Epoch [24/50] - Train Loss: 1.0631, Test Loss: 1.4844\n",
      "Epoch [25/50] - Train Loss: 1.0652, Test Loss: 1.4865\n",
      "Epoch [26/50] - Train Loss: 1.0661, Test Loss: 1.5023\n",
      "Epoch [27/50] - Train Loss: 1.0745, Test Loss: 1.4829\n",
      "Epoch [28/50] - Train Loss: 1.0593, Test Loss: 1.4863\n",
      "Epoch [29/50] - Train Loss: 1.0545, Test Loss: 1.4767\n",
      "Epoch [30/50] - Train Loss: 1.0612, Test Loss: 1.5800\n",
      "Epoch [31/50] - Train Loss: 1.0524, Test Loss: 1.4826\n",
      "Epoch [32/50] - Train Loss: 1.0494, Test Loss: 1.4796\n",
      "Epoch [33/50] - Train Loss: 1.0528, Test Loss: 1.4795\n",
      "Epoch [34/50] - Train Loss: 1.0487, Test Loss: 1.4783\n",
      "Epoch [35/50] - Train Loss: 1.0464, Test Loss: 1.4797\n",
      "Epoch [36/50] - Train Loss: 1.0447, Test Loss: 1.4870\n",
      "Epoch [37/50] - Train Loss: 1.0405, Test Loss: 1.4974\n",
      "Epoch [38/50] - Train Loss: 1.0412, Test Loss: 1.5689\n",
      "Epoch [39/50] - Train Loss: 1.0364, Test Loss: 1.4166\n",
      "Epoch [40/50] - Train Loss: 1.0484, Test Loss: 1.6744\n",
      "Epoch [41/50] - Train Loss: 1.0326, Test Loss: 1.4340\n",
      "Epoch [42/50] - Train Loss: 1.0694, Test Loss: 1.4889\n",
      "Epoch [43/50] - Train Loss: 1.0609, Test Loss: 1.4995\n",
      "Epoch [44/50] - Train Loss: 1.0544, Test Loss: 1.4931\n",
      "Epoch [45/50] - Train Loss: 1.0498, Test Loss: 1.4782\n",
      "Epoch [46/50] - Train Loss: 1.0466, Test Loss: 1.4594\n",
      "Epoch [47/50] - Train Loss: 1.0440, Test Loss: 1.4510\n",
      "Epoch [48/50] - Train Loss: 1.0363, Test Loss: 1.4797\n",
      "Epoch [49/50] - Train Loss: 1.0286, Test Loss: 1.5651\n",
      "Epoch [50/50] - Train Loss: 1.0135, Test Loss: 1.6010\n",
      "Avg Test Loss: 1.6010\n",
      "Testing combination: (4, 2, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1607, Test Loss: 1.5829\n",
      "Epoch [2/50] - Train Loss: 1.1196, Test Loss: 1.6126\n",
      "Epoch [3/50] - Train Loss: 1.1163, Test Loss: 1.6242\n",
      "Epoch [4/50] - Train Loss: 1.1156, Test Loss: 1.6204\n",
      "Epoch [5/50] - Train Loss: 1.1145, Test Loss: 1.6136\n",
      "Epoch [6/50] - Train Loss: 1.1140, Test Loss: 1.6090\n",
      "Epoch [7/50] - Train Loss: 1.1138, Test Loss: 1.6070\n",
      "Epoch [8/50] - Train Loss: 1.1137, Test Loss: 1.6068\n",
      "Epoch [9/50] - Train Loss: 1.1136, Test Loss: 1.6074\n",
      "Epoch [10/50] - Train Loss: 1.1133, Test Loss: 1.6080\n",
      "Epoch [11/50] - Train Loss: 1.1130, Test Loss: 1.6082\n",
      "Epoch [12/50] - Train Loss: 1.1126, Test Loss: 1.6080\n",
      "Epoch [13/50] - Train Loss: 1.1121, Test Loss: 1.6077\n",
      "Epoch [14/50] - Train Loss: 1.1114, Test Loss: 1.6077\n",
      "Epoch [15/50] - Train Loss: 1.1106, Test Loss: 1.6080\n",
      "Epoch [16/50] - Train Loss: 1.1096, Test Loss: 1.6087\n",
      "Epoch [17/50] - Train Loss: 1.1083, Test Loss: 1.6094\n",
      "Epoch [18/50] - Train Loss: 1.1068, Test Loss: 1.6100\n",
      "Epoch [19/50] - Train Loss: 1.1052, Test Loss: 1.6104\n",
      "Epoch [20/50] - Train Loss: 1.1036, Test Loss: 1.6107\n",
      "Epoch [21/50] - Train Loss: 1.1020, Test Loss: 1.6107\n",
      "Epoch [22/50] - Train Loss: 1.1003, Test Loss: 1.6107\n",
      "Epoch [23/50] - Train Loss: 1.0984, Test Loss: 1.6106\n",
      "Epoch [24/50] - Train Loss: 1.0963, Test Loss: 1.6107\n",
      "Epoch [25/50] - Train Loss: 1.0939, Test Loss: 1.6108\n",
      "Epoch [26/50] - Train Loss: 1.0914, Test Loss: 1.6109\n",
      "Epoch [27/50] - Train Loss: 1.0889, Test Loss: 1.6111\n",
      "Epoch [28/50] - Train Loss: 1.0864, Test Loss: 1.6112\n",
      "Epoch [29/50] - Train Loss: 1.0845, Test Loss: 1.6112\n",
      "Epoch [30/50] - Train Loss: 1.0826, Test Loss: 1.6109\n",
      "Epoch [31/50] - Train Loss: 1.0814, Test Loss: 1.6114\n",
      "Epoch [32/50] - Train Loss: 1.0806, Test Loss: 1.6117\n",
      "Epoch [33/50] - Train Loss: 1.0802, Test Loss: 1.6117\n",
      "Epoch [34/50] - Train Loss: 1.0799, Test Loss: 1.6117\n",
      "Epoch [35/50] - Train Loss: 1.0798, Test Loss: 1.6119\n",
      "Epoch [36/50] - Train Loss: 1.0796, Test Loss: 1.6121\n",
      "Epoch [37/50] - Train Loss: 1.0795, Test Loss: 1.6122\n",
      "Epoch [38/50] - Train Loss: 1.0794, Test Loss: 1.6123\n",
      "Epoch [39/50] - Train Loss: 1.0793, Test Loss: 1.6124\n",
      "Epoch [40/50] - Train Loss: 1.0792, Test Loss: 1.6125\n",
      "Epoch [41/50] - Train Loss: 1.0792, Test Loss: 1.6126\n",
      "Epoch [42/50] - Train Loss: 1.0791, Test Loss: 1.6126\n",
      "Epoch [43/50] - Train Loss: 1.0791, Test Loss: 1.6127\n",
      "Epoch [44/50] - Train Loss: 1.0790, Test Loss: 1.6127\n",
      "Epoch [45/50] - Train Loss: 1.0790, Test Loss: 1.6128\n",
      "Epoch [46/50] - Train Loss: 1.0789, Test Loss: 1.6128\n",
      "Epoch [47/50] - Train Loss: 1.0789, Test Loss: 1.6128\n",
      "Epoch [48/50] - Train Loss: 1.0789, Test Loss: 1.6129\n",
      "Epoch [49/50] - Train Loss: 1.0788, Test Loss: 1.6129\n",
      "Epoch [50/50] - Train Loss: 1.0788, Test Loss: 1.6129\n",
      "Avg Test Loss: 1.6129\n",
      "Testing combination: (4, 2, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3801, Test Loss: 2.6281\n",
      "Epoch [2/50] - Train Loss: 1.3156, Test Loss: 2.6767\n",
      "Epoch [3/50] - Train Loss: 1.3082, Test Loss: 2.7232\n",
      "Epoch [4/50] - Train Loss: 1.3096, Test Loss: 2.7021\n",
      "Epoch [5/50] - Train Loss: 1.3034, Test Loss: 2.6720\n",
      "Epoch [6/50] - Train Loss: 1.3010, Test Loss: 2.6554\n",
      "Epoch [7/50] - Train Loss: 1.3018, Test Loss: 2.6497\n",
      "Epoch [8/50] - Train Loss: 1.3024, Test Loss: 2.6508\n",
      "Epoch [9/50] - Train Loss: 1.3019, Test Loss: 2.6561\n",
      "Epoch [10/50] - Train Loss: 1.3012, Test Loss: 2.6632\n",
      "Epoch [11/50] - Train Loss: 1.3007, Test Loss: 2.6690\n",
      "Epoch [12/50] - Train Loss: 1.3005, Test Loss: 2.6715\n",
      "Epoch [13/50] - Train Loss: 1.3003, Test Loss: 2.6706\n",
      "Epoch [14/50] - Train Loss: 1.3000, Test Loss: 2.6679\n",
      "Epoch [15/50] - Train Loss: 1.2997, Test Loss: 2.6654\n",
      "Epoch [16/50] - Train Loss: 1.2996, Test Loss: 2.6640\n",
      "Epoch [17/50] - Train Loss: 1.2994, Test Loss: 2.6640\n",
      "Epoch [18/50] - Train Loss: 1.2992, Test Loss: 2.6651\n",
      "Epoch [19/50] - Train Loss: 1.2990, Test Loss: 2.6665\n",
      "Epoch [20/50] - Train Loss: 1.2987, Test Loss: 2.6677\n",
      "Epoch [21/50] - Train Loss: 1.2984, Test Loss: 2.6683\n",
      "Epoch [22/50] - Train Loss: 1.2980, Test Loss: 2.6684\n",
      "Epoch [23/50] - Train Loss: 1.2976, Test Loss: 2.6682\n",
      "Epoch [24/50] - Train Loss: 1.2971, Test Loss: 2.6680\n",
      "Epoch [25/50] - Train Loss: 1.2966, Test Loss: 2.6682\n",
      "Epoch [26/50] - Train Loss: 1.2960, Test Loss: 2.6686\n",
      "Epoch [27/50] - Train Loss: 1.2954, Test Loss: 2.6692\n",
      "Epoch [28/50] - Train Loss: 1.2948, Test Loss: 2.6699\n",
      "Epoch [29/50] - Train Loss: 1.2941, Test Loss: 2.6704\n",
      "Epoch [30/50] - Train Loss: 1.2935, Test Loss: 2.6707\n",
      "Epoch [31/50] - Train Loss: 1.2929, Test Loss: 2.6709\n",
      "Epoch [32/50] - Train Loss: 1.2923, Test Loss: 2.6710\n",
      "Epoch [33/50] - Train Loss: 1.2919, Test Loss: 2.6711\n",
      "Epoch [34/50] - Train Loss: 1.2916, Test Loss: 2.6711\n",
      "Epoch [35/50] - Train Loss: 1.2913, Test Loss: 2.6712\n",
      "Epoch [36/50] - Train Loss: 1.2911, Test Loss: 2.6712\n",
      "Epoch [37/50] - Train Loss: 1.2909, Test Loss: 2.6712\n",
      "Epoch [38/50] - Train Loss: 1.2907, Test Loss: 2.6713\n",
      "Epoch [39/50] - Train Loss: 1.2905, Test Loss: 2.6714\n",
      "Epoch [40/50] - Train Loss: 1.2904, Test Loss: 2.6715\n",
      "Epoch [41/50] - Train Loss: 1.2902, Test Loss: 2.6716\n",
      "Epoch [42/50] - Train Loss: 1.2901, Test Loss: 2.6717\n",
      "Epoch [43/50] - Train Loss: 1.2900, Test Loss: 2.6717\n",
      "Epoch [44/50] - Train Loss: 1.2899, Test Loss: 2.6718\n",
      "Epoch [45/50] - Train Loss: 1.2898, Test Loss: 2.6718\n",
      "Epoch [46/50] - Train Loss: 1.2898, Test Loss: 2.6718\n",
      "Epoch [47/50] - Train Loss: 1.2897, Test Loss: 2.6718\n",
      "Epoch [48/50] - Train Loss: 1.2896, Test Loss: 2.6719\n",
      "Epoch [49/50] - Train Loss: 1.2896, Test Loss: 2.6719\n",
      "Epoch [50/50] - Train Loss: 1.2895, Test Loss: 2.6719\n",
      "Avg Test Loss: 2.6719\n",
      "Testing combination: (4, 2, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.2839, Test Loss: 1.7789\n",
      "Epoch [2/50] - Train Loss: 1.2510, Test Loss: 1.7354\n",
      "Epoch [3/50] - Train Loss: 1.2222, Test Loss: 1.6965\n",
      "Epoch [4/50] - Train Loss: 1.1973, Test Loss: 1.6624\n",
      "Epoch [5/50] - Train Loss: 1.1762, Test Loss: 1.6332\n",
      "Epoch [6/50] - Train Loss: 1.1589, Test Loss: 1.6087\n",
      "Epoch [7/50] - Train Loss: 1.1450, Test Loss: 1.5885\n",
      "Epoch [8/50] - Train Loss: 1.1339, Test Loss: 1.5720\n",
      "Epoch [9/50] - Train Loss: 1.1251, Test Loss: 1.5584\n",
      "Epoch [10/50] - Train Loss: 1.1181, Test Loss: 1.5472\n",
      "Epoch [11/50] - Train Loss: 1.1125, Test Loss: 1.5380\n",
      "Epoch [12/50] - Train Loss: 1.1080, Test Loss: 1.5303\n",
      "Epoch [13/50] - Train Loss: 1.1041, Test Loss: 1.5239\n",
      "Epoch [14/50] - Train Loss: 1.1008, Test Loss: 1.5184\n",
      "Epoch [15/50] - Train Loss: 1.0980, Test Loss: 1.5138\n",
      "Epoch [16/50] - Train Loss: 1.0957, Test Loss: 1.5098\n",
      "Epoch [17/50] - Train Loss: 1.0939, Test Loss: 1.5063\n",
      "Epoch [18/50] - Train Loss: 1.0924, Test Loss: 1.5033\n",
      "Epoch [19/50] - Train Loss: 1.0911, Test Loss: 1.5008\n",
      "Epoch [20/50] - Train Loss: 1.0901, Test Loss: 1.4985\n",
      "Epoch [21/50] - Train Loss: 1.0892, Test Loss: 1.4966\n",
      "Epoch [22/50] - Train Loss: 1.0885, Test Loss: 1.4949\n",
      "Epoch [23/50] - Train Loss: 1.0878, Test Loss: 1.4934\n",
      "Epoch [24/50] - Train Loss: 1.0874, Test Loss: 1.4921\n",
      "Epoch [25/50] - Train Loss: 1.0868, Test Loss: 1.4910\n",
      "Epoch [26/50] - Train Loss: 1.0864, Test Loss: 1.4900\n",
      "Epoch [27/50] - Train Loss: 1.0860, Test Loss: 1.4891\n",
      "Epoch [28/50] - Train Loss: 1.0857, Test Loss: 1.4884\n",
      "Epoch [29/50] - Train Loss: 1.0854, Test Loss: 1.4877\n",
      "Epoch [30/50] - Train Loss: 1.0851, Test Loss: 1.4871\n",
      "Epoch [31/50] - Train Loss: 1.0848, Test Loss: 1.4865\n",
      "Epoch [32/50] - Train Loss: 1.0846, Test Loss: 1.4861\n",
      "Epoch [33/50] - Train Loss: 1.0843, Test Loss: 1.4856\n",
      "Epoch [34/50] - Train Loss: 1.0841, Test Loss: 1.4853\n",
      "Epoch [35/50] - Train Loss: 1.0839, Test Loss: 1.4849\n",
      "Epoch [36/50] - Train Loss: 1.0837, Test Loss: 1.4846\n",
      "Epoch [37/50] - Train Loss: 1.0835, Test Loss: 1.4844\n",
      "Epoch [38/50] - Train Loss: 1.0833, Test Loss: 1.4841\n",
      "Epoch [39/50] - Train Loss: 1.0830, Test Loss: 1.4839\n",
      "Epoch [40/50] - Train Loss: 1.0828, Test Loss: 1.4837\n",
      "Epoch [41/50] - Train Loss: 1.0825, Test Loss: 1.4836\n",
      "Epoch [42/50] - Train Loss: 1.0822, Test Loss: 1.4834\n",
      "Epoch [43/50] - Train Loss: 1.0820, Test Loss: 1.4833\n",
      "Epoch [44/50] - Train Loss: 1.0819, Test Loss: 1.4832\n",
      "Epoch [45/50] - Train Loss: 1.0819, Test Loss: 1.4831\n",
      "Epoch [46/50] - Train Loss: 1.0818, Test Loss: 1.4830\n",
      "Epoch [47/50] - Train Loss: 1.0817, Test Loss: 1.4829\n",
      "Epoch [48/50] - Train Loss: 1.0817, Test Loss: 1.4828\n",
      "Epoch [49/50] - Train Loss: 1.0817, Test Loss: 1.4828\n",
      "Epoch [50/50] - Train Loss: 1.0816, Test Loss: 1.4827\n",
      "Avg Test Loss: 1.4827\n",
      "Testing combination: (4, 2, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1556, Test Loss: 1.7312\n",
      "Epoch [2/50] - Train Loss: 1.1469, Test Loss: 1.7134\n",
      "Epoch [3/50] - Train Loss: 1.1398, Test Loss: 1.6981\n",
      "Epoch [4/50] - Train Loss: 1.1342, Test Loss: 1.6848\n",
      "Epoch [5/50] - Train Loss: 1.1296, Test Loss: 1.6733\n",
      "Epoch [6/50] - Train Loss: 1.1259, Test Loss: 1.6632\n",
      "Epoch [7/50] - Train Loss: 1.1230, Test Loss: 1.6545\n",
      "Epoch [8/50] - Train Loss: 1.1207, Test Loss: 1.6468\n",
      "Epoch [9/50] - Train Loss: 1.1189, Test Loss: 1.6403\n",
      "Epoch [10/50] - Train Loss: 1.1175, Test Loss: 1.6346\n",
      "Epoch [11/50] - Train Loss: 1.1165, Test Loss: 1.6298\n",
      "Epoch [12/50] - Train Loss: 1.1157, Test Loss: 1.6258\n",
      "Epoch [13/50] - Train Loss: 1.1152, Test Loss: 1.6225\n",
      "Epoch [14/50] - Train Loss: 1.1149, Test Loss: 1.6199\n",
      "Epoch [15/50] - Train Loss: 1.1146, Test Loss: 1.6177\n",
      "Epoch [16/50] - Train Loss: 1.1145, Test Loss: 1.6160\n",
      "Epoch [17/50] - Train Loss: 1.1144, Test Loss: 1.6146\n",
      "Epoch [18/50] - Train Loss: 1.1144, Test Loss: 1.6135\n",
      "Epoch [19/50] - Train Loss: 1.1143, Test Loss: 1.6127\n",
      "Epoch [20/50] - Train Loss: 1.1143, Test Loss: 1.6120\n",
      "Epoch [21/50] - Train Loss: 1.1143, Test Loss: 1.6115\n",
      "Epoch [22/50] - Train Loss: 1.1143, Test Loss: 1.6111\n",
      "Epoch [23/50] - Train Loss: 1.1143, Test Loss: 1.6108\n",
      "Epoch [24/50] - Train Loss: 1.1143, Test Loss: 1.6106\n",
      "Epoch [25/50] - Train Loss: 1.1143, Test Loss: 1.6104\n",
      "Epoch [26/50] - Train Loss: 1.1142, Test Loss: 1.6103\n",
      "Epoch [27/50] - Train Loss: 1.1142, Test Loss: 1.6102\n",
      "Epoch [28/50] - Train Loss: 1.1142, Test Loss: 1.6101\n",
      "Epoch [29/50] - Train Loss: 1.1142, Test Loss: 1.6100\n",
      "Epoch [30/50] - Train Loss: 1.1142, Test Loss: 1.6100\n",
      "Epoch [31/50] - Train Loss: 1.1142, Test Loss: 1.6099\n",
      "Epoch [32/50] - Train Loss: 1.1142, Test Loss: 1.6099\n",
      "Epoch [33/50] - Train Loss: 1.1142, Test Loss: 1.6099\n",
      "Epoch [34/50] - Train Loss: 1.1142, Test Loss: 1.6099\n",
      "Epoch [35/50] - Train Loss: 1.1142, Test Loss: 1.6098\n",
      "Epoch [36/50] - Train Loss: 1.1142, Test Loss: 1.6098\n",
      "Epoch [37/50] - Train Loss: 1.1142, Test Loss: 1.6098\n",
      "Epoch [38/50] - Train Loss: 1.1142, Test Loss: 1.6098\n",
      "Epoch [39/50] - Train Loss: 1.1142, Test Loss: 1.6098\n",
      "Epoch [40/50] - Train Loss: 1.1142, Test Loss: 1.6098\n",
      "Epoch [41/50] - Train Loss: 1.1141, Test Loss: 1.6098\n",
      "Epoch [42/50] - Train Loss: 1.1141, Test Loss: 1.6098\n",
      "Epoch [43/50] - Train Loss: 1.1141, Test Loss: 1.6098\n",
      "Epoch [44/50] - Train Loss: 1.1141, Test Loss: 1.6098\n",
      "Epoch [45/50] - Train Loss: 1.1141, Test Loss: 1.6098\n",
      "Epoch [46/50] - Train Loss: 1.1141, Test Loss: 1.6098\n",
      "Epoch [47/50] - Train Loss: 1.1141, Test Loss: 1.6098\n",
      "Epoch [48/50] - Train Loss: 1.1141, Test Loss: 1.6098\n",
      "Epoch [49/50] - Train Loss: 1.1141, Test Loss: 1.6098\n",
      "Epoch [50/50] - Train Loss: 1.1141, Test Loss: 1.6098\n",
      "Avg Test Loss: 1.6098\n",
      "Testing combination: (4, 2, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3687, Test Loss: 2.8713\n",
      "Epoch [2/50] - Train Loss: 1.3622, Test Loss: 2.8568\n",
      "Epoch [3/50] - Train Loss: 1.3562, Test Loss: 2.8431\n",
      "Epoch [4/50] - Train Loss: 1.3507, Test Loss: 2.8300\n",
      "Epoch [5/50] - Train Loss: 1.3456, Test Loss: 2.8177\n",
      "Epoch [6/50] - Train Loss: 1.3409, Test Loss: 2.8060\n",
      "Epoch [7/50] - Train Loss: 1.3366, Test Loss: 2.7949\n",
      "Epoch [8/50] - Train Loss: 1.3326, Test Loss: 2.7843\n",
      "Epoch [9/50] - Train Loss: 1.3288, Test Loss: 2.7743\n",
      "Epoch [10/50] - Train Loss: 1.3254, Test Loss: 2.7649\n",
      "Epoch [11/50] - Train Loss: 1.3223, Test Loss: 2.7560\n",
      "Epoch [12/50] - Train Loss: 1.3195, Test Loss: 2.7475\n",
      "Epoch [13/50] - Train Loss: 1.3169, Test Loss: 2.7397\n",
      "Epoch [14/50] - Train Loss: 1.3146, Test Loss: 2.7323\n",
      "Epoch [15/50] - Train Loss: 1.3126, Test Loss: 2.7254\n",
      "Epoch [16/50] - Train Loss: 1.3108, Test Loss: 2.7191\n",
      "Epoch [17/50] - Train Loss: 1.3092, Test Loss: 2.7132\n",
      "Epoch [18/50] - Train Loss: 1.3078, Test Loss: 2.7078\n",
      "Epoch [19/50] - Train Loss: 1.3067, Test Loss: 2.7029\n",
      "Epoch [20/50] - Train Loss: 1.3057, Test Loss: 2.6984\n",
      "Epoch [21/50] - Train Loss: 1.3048, Test Loss: 2.6944\n",
      "Epoch [22/50] - Train Loss: 1.3041, Test Loss: 2.6907\n",
      "Epoch [23/50] - Train Loss: 1.3035, Test Loss: 2.6875\n",
      "Epoch [24/50] - Train Loss: 1.3030, Test Loss: 2.6845\n",
      "Epoch [25/50] - Train Loss: 1.3026, Test Loss: 2.6819\n",
      "Epoch [26/50] - Train Loss: 1.3023, Test Loss: 2.6796\n",
      "Epoch [27/50] - Train Loss: 1.3021, Test Loss: 2.6775\n",
      "Epoch [28/50] - Train Loss: 1.3018, Test Loss: 2.6757\n",
      "Epoch [29/50] - Train Loss: 1.3017, Test Loss: 2.6741\n",
      "Epoch [30/50] - Train Loss: 1.3016, Test Loss: 2.6728\n",
      "Epoch [31/50] - Train Loss: 1.3014, Test Loss: 2.6715\n",
      "Epoch [32/50] - Train Loss: 1.3014, Test Loss: 2.6705\n",
      "Epoch [33/50] - Train Loss: 1.3013, Test Loss: 2.6696\n",
      "Epoch [34/50] - Train Loss: 1.3013, Test Loss: 2.6688\n",
      "Epoch [35/50] - Train Loss: 1.3012, Test Loss: 2.6681\n",
      "Epoch [36/50] - Train Loss: 1.3012, Test Loss: 2.6675\n",
      "Epoch [37/50] - Train Loss: 1.3012, Test Loss: 2.6669\n",
      "Epoch [38/50] - Train Loss: 1.3011, Test Loss: 2.6665\n",
      "Epoch [39/50] - Train Loss: 1.3011, Test Loss: 2.6661\n",
      "Epoch [40/50] - Train Loss: 1.3011, Test Loss: 2.6658\n",
      "Epoch [41/50] - Train Loss: 1.3011, Test Loss: 2.6655\n",
      "Epoch [42/50] - Train Loss: 1.3011, Test Loss: 2.6653\n",
      "Epoch [43/50] - Train Loss: 1.3010, Test Loss: 2.6651\n",
      "Epoch [44/50] - Train Loss: 1.3010, Test Loss: 2.6649\n",
      "Epoch [45/50] - Train Loss: 1.3010, Test Loss: 2.6648\n",
      "Epoch [46/50] - Train Loss: 1.3010, Test Loss: 2.6647\n",
      "Epoch [47/50] - Train Loss: 1.3010, Test Loss: 2.6646\n",
      "Epoch [48/50] - Train Loss: 1.3010, Test Loss: 2.6645\n",
      "Epoch [49/50] - Train Loss: 1.3010, Test Loss: 2.6644\n",
      "Epoch [50/50] - Train Loss: 1.3009, Test Loss: 2.6644\n",
      "Avg Test Loss: 2.6644\n",
      "Testing combination: (4, 2, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.3723, Test Loss: 1.9220\n",
      "Epoch [2/50] - Train Loss: 1.3680, Test Loss: 1.9163\n",
      "Epoch [3/50] - Train Loss: 1.3639, Test Loss: 1.9108\n",
      "Epoch [4/50] - Train Loss: 1.3599, Test Loss: 1.9054\n",
      "Epoch [5/50] - Train Loss: 1.3559, Test Loss: 1.9000\n",
      "Epoch [6/50] - Train Loss: 1.3520, Test Loss: 1.8948\n",
      "Epoch [7/50] - Train Loss: 1.3481, Test Loss: 1.8896\n",
      "Epoch [8/50] - Train Loss: 1.3444, Test Loss: 1.8845\n",
      "Epoch [9/50] - Train Loss: 1.3406, Test Loss: 1.8794\n",
      "Epoch [10/50] - Train Loss: 1.3370, Test Loss: 1.8745\n",
      "Epoch [11/50] - Train Loss: 1.3333, Test Loss: 1.8695\n",
      "Epoch [12/50] - Train Loss: 1.3298, Test Loss: 1.8647\n",
      "Epoch [13/50] - Train Loss: 1.3262, Test Loss: 1.8599\n",
      "Epoch [14/50] - Train Loss: 1.3228, Test Loss: 1.8552\n",
      "Epoch [15/50] - Train Loss: 1.3193, Test Loss: 1.8505\n",
      "Epoch [16/50] - Train Loss: 1.3159, Test Loss: 1.8459\n",
      "Epoch [17/50] - Train Loss: 1.3126, Test Loss: 1.8413\n",
      "Epoch [18/50] - Train Loss: 1.3093, Test Loss: 1.8368\n",
      "Epoch [19/50] - Train Loss: 1.3060, Test Loss: 1.8323\n",
      "Epoch [20/50] - Train Loss: 1.3028, Test Loss: 1.8279\n",
      "Epoch [21/50] - Train Loss: 1.2996, Test Loss: 1.8235\n",
      "Epoch [22/50] - Train Loss: 1.2965, Test Loss: 1.8192\n",
      "Epoch [23/50] - Train Loss: 1.2934, Test Loss: 1.8149\n",
      "Epoch [24/50] - Train Loss: 1.2903, Test Loss: 1.8106\n",
      "Epoch [25/50] - Train Loss: 1.2873, Test Loss: 1.8064\n",
      "Epoch [26/50] - Train Loss: 1.2843, Test Loss: 1.8023\n",
      "Epoch [27/50] - Train Loss: 1.2813, Test Loss: 1.7981\n",
      "Epoch [28/50] - Train Loss: 1.2784, Test Loss: 1.7941\n",
      "Epoch [29/50] - Train Loss: 1.2755, Test Loss: 1.7900\n",
      "Epoch [30/50] - Train Loss: 1.2726, Test Loss: 1.7860\n",
      "Epoch [31/50] - Train Loss: 1.2698, Test Loss: 1.7820\n",
      "Epoch [32/50] - Train Loss: 1.2670, Test Loss: 1.7781\n",
      "Epoch [33/50] - Train Loss: 1.2642, Test Loss: 1.7742\n",
      "Epoch [34/50] - Train Loss: 1.2614, Test Loss: 1.7704\n",
      "Epoch [35/50] - Train Loss: 1.2587, Test Loss: 1.7665\n",
      "Epoch [36/50] - Train Loss: 1.2560, Test Loss: 1.7627\n",
      "Epoch [37/50] - Train Loss: 1.2533, Test Loss: 1.7590\n",
      "Epoch [38/50] - Train Loss: 1.2507, Test Loss: 1.7553\n",
      "Epoch [39/50] - Train Loss: 1.2481, Test Loss: 1.7516\n",
      "Epoch [40/50] - Train Loss: 1.2455, Test Loss: 1.7479\n",
      "Epoch [41/50] - Train Loss: 1.2430, Test Loss: 1.7443\n",
      "Epoch [42/50] - Train Loss: 1.2405, Test Loss: 1.7407\n",
      "Epoch [43/50] - Train Loss: 1.2380, Test Loss: 1.7372\n",
      "Epoch [44/50] - Train Loss: 1.2355, Test Loss: 1.7337\n",
      "Epoch [45/50] - Train Loss: 1.2330, Test Loss: 1.7302\n",
      "Epoch [46/50] - Train Loss: 1.2306, Test Loss: 1.7267\n",
      "Epoch [47/50] - Train Loss: 1.2282, Test Loss: 1.7233\n",
      "Epoch [48/50] - Train Loss: 1.2259, Test Loss: 1.7199\n",
      "Epoch [49/50] - Train Loss: 1.2235, Test Loss: 1.7166\n",
      "Epoch [50/50] - Train Loss: 1.2212, Test Loss: 1.7132\n",
      "Avg Test Loss: 1.7132\n",
      "Testing combination: (4, 2, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1459, Test Loss: 1.5736\n",
      "Epoch [2/50] - Train Loss: 1.1454, Test Loss: 1.5736\n",
      "Epoch [3/50] - Train Loss: 1.1450, Test Loss: 1.5736\n",
      "Epoch [4/50] - Train Loss: 1.1446, Test Loss: 1.5736\n",
      "Epoch [5/50] - Train Loss: 1.1442, Test Loss: 1.5736\n",
      "Epoch [6/50] - Train Loss: 1.1438, Test Loss: 1.5736\n",
      "Epoch [7/50] - Train Loss: 1.1435, Test Loss: 1.5736\n",
      "Epoch [8/50] - Train Loss: 1.1431, Test Loss: 1.5737\n",
      "Epoch [9/50] - Train Loss: 1.1427, Test Loss: 1.5737\n",
      "Epoch [10/50] - Train Loss: 1.1423, Test Loss: 1.5737\n",
      "Epoch [11/50] - Train Loss: 1.1420, Test Loss: 1.5737\n",
      "Epoch [12/50] - Train Loss: 1.1416, Test Loss: 1.5738\n",
      "Epoch [13/50] - Train Loss: 1.1412, Test Loss: 1.5738\n",
      "Epoch [14/50] - Train Loss: 1.1409, Test Loss: 1.5738\n",
      "Epoch [15/50] - Train Loss: 1.1405, Test Loss: 1.5739\n",
      "Epoch [16/50] - Train Loss: 1.1402, Test Loss: 1.5739\n",
      "Epoch [17/50] - Train Loss: 1.1398, Test Loss: 1.5740\n",
      "Epoch [18/50] - Train Loss: 1.1395, Test Loss: 1.5740\n",
      "Epoch [19/50] - Train Loss: 1.1391, Test Loss: 1.5740\n",
      "Epoch [20/50] - Train Loss: 1.1388, Test Loss: 1.5741\n",
      "Epoch [21/50] - Train Loss: 1.1384, Test Loss: 1.5741\n",
      "Epoch [22/50] - Train Loss: 1.1381, Test Loss: 1.5742\n",
      "Epoch [23/50] - Train Loss: 1.1378, Test Loss: 1.5743\n",
      "Epoch [24/50] - Train Loss: 1.1374, Test Loss: 1.5743\n",
      "Epoch [25/50] - Train Loss: 1.1371, Test Loss: 1.5744\n",
      "Epoch [26/50] - Train Loss: 1.1368, Test Loss: 1.5744\n",
      "Epoch [27/50] - Train Loss: 1.1365, Test Loss: 1.5745\n",
      "Epoch [28/50] - Train Loss: 1.1362, Test Loss: 1.5746\n",
      "Epoch [29/50] - Train Loss: 1.1358, Test Loss: 1.5747\n",
      "Epoch [30/50] - Train Loss: 1.1355, Test Loss: 1.5747\n",
      "Epoch [31/50] - Train Loss: 1.1352, Test Loss: 1.5748\n",
      "Epoch [32/50] - Train Loss: 1.1349, Test Loss: 1.5749\n",
      "Epoch [33/50] - Train Loss: 1.1346, Test Loss: 1.5750\n",
      "Epoch [34/50] - Train Loss: 1.1343, Test Loss: 1.5751\n",
      "Epoch [35/50] - Train Loss: 1.1340, Test Loss: 1.5751\n",
      "Epoch [36/50] - Train Loss: 1.1337, Test Loss: 1.5752\n",
      "Epoch [37/50] - Train Loss: 1.1334, Test Loss: 1.5753\n",
      "Epoch [38/50] - Train Loss: 1.1332, Test Loss: 1.5754\n",
      "Epoch [39/50] - Train Loss: 1.1329, Test Loss: 1.5755\n",
      "Epoch [40/50] - Train Loss: 1.1326, Test Loss: 1.5756\n",
      "Epoch [41/50] - Train Loss: 1.1323, Test Loss: 1.5757\n",
      "Epoch [42/50] - Train Loss: 1.1320, Test Loss: 1.5758\n",
      "Epoch [43/50] - Train Loss: 1.1318, Test Loss: 1.5759\n",
      "Epoch [44/50] - Train Loss: 1.1315, Test Loss: 1.5760\n",
      "Epoch [45/50] - Train Loss: 1.1312, Test Loss: 1.5761\n",
      "Epoch [46/50] - Train Loss: 1.1309, Test Loss: 1.5762\n",
      "Epoch [47/50] - Train Loss: 1.1307, Test Loss: 1.5763\n",
      "Epoch [48/50] - Train Loss: 1.1304, Test Loss: 1.5764\n",
      "Epoch [49/50] - Train Loss: 1.1302, Test Loss: 1.5766\n",
      "Epoch [50/50] - Train Loss: 1.1299, Test Loss: 1.5767\n",
      "Avg Test Loss: 1.5767\n",
      "Testing combination: (4, 2, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3284, Test Loss: 2.6283\n",
      "Epoch [2/50] - Train Loss: 1.3281, Test Loss: 2.6283\n",
      "Epoch [3/50] - Train Loss: 1.3277, Test Loss: 2.6283\n",
      "Epoch [4/50] - Train Loss: 1.3274, Test Loss: 2.6282\n",
      "Epoch [5/50] - Train Loss: 1.3271, Test Loss: 2.6282\n",
      "Epoch [6/50] - Train Loss: 1.3268, Test Loss: 2.6282\n",
      "Epoch [7/50] - Train Loss: 1.3265, Test Loss: 2.6282\n",
      "Epoch [8/50] - Train Loss: 1.3262, Test Loss: 2.6282\n",
      "Epoch [9/50] - Train Loss: 1.3259, Test Loss: 2.6282\n",
      "Epoch [10/50] - Train Loss: 1.3256, Test Loss: 2.6281\n",
      "Epoch [11/50] - Train Loss: 1.3253, Test Loss: 2.6281\n",
      "Epoch [12/50] - Train Loss: 1.3251, Test Loss: 2.6281\n",
      "Epoch [13/50] - Train Loss: 1.3248, Test Loss: 2.6281\n",
      "Epoch [14/50] - Train Loss: 1.3245, Test Loss: 2.6281\n",
      "Epoch [15/50] - Train Loss: 1.3242, Test Loss: 2.6281\n",
      "Epoch [16/50] - Train Loss: 1.3240, Test Loss: 2.6281\n",
      "Epoch [17/50] - Train Loss: 1.3237, Test Loss: 2.6281\n",
      "Epoch [18/50] - Train Loss: 1.3234, Test Loss: 2.6282\n",
      "Epoch [19/50] - Train Loss: 1.3232, Test Loss: 2.6282\n",
      "Epoch [20/50] - Train Loss: 1.3229, Test Loss: 2.6282\n",
      "Epoch [21/50] - Train Loss: 1.3226, Test Loss: 2.6282\n",
      "Epoch [22/50] - Train Loss: 1.3224, Test Loss: 2.6282\n",
      "Epoch [23/50] - Train Loss: 1.3221, Test Loss: 2.6282\n",
      "Epoch [24/50] - Train Loss: 1.3219, Test Loss: 2.6282\n",
      "Epoch [25/50] - Train Loss: 1.3216, Test Loss: 2.6283\n",
      "Epoch [26/50] - Train Loss: 1.3214, Test Loss: 2.6283\n",
      "Epoch [27/50] - Train Loss: 1.3211, Test Loss: 2.6283\n",
      "Epoch [28/50] - Train Loss: 1.3209, Test Loss: 2.6284\n",
      "Epoch [29/50] - Train Loss: 1.3207, Test Loss: 2.6284\n",
      "Epoch [30/50] - Train Loss: 1.3204, Test Loss: 2.6284\n",
      "Epoch [31/50] - Train Loss: 1.3202, Test Loss: 2.6284\n",
      "Epoch [32/50] - Train Loss: 1.3200, Test Loss: 2.6285\n",
      "Epoch [33/50] - Train Loss: 1.3198, Test Loss: 2.6285\n",
      "Epoch [34/50] - Train Loss: 1.3195, Test Loss: 2.6286\n",
      "Epoch [35/50] - Train Loss: 1.3193, Test Loss: 2.6286\n",
      "Epoch [36/50] - Train Loss: 1.3191, Test Loss: 2.6286\n",
      "Epoch [37/50] - Train Loss: 1.3189, Test Loss: 2.6287\n",
      "Epoch [38/50] - Train Loss: 1.3187, Test Loss: 2.6287\n",
      "Epoch [39/50] - Train Loss: 1.3185, Test Loss: 2.6288\n",
      "Epoch [40/50] - Train Loss: 1.3183, Test Loss: 2.6288\n",
      "Epoch [41/50] - Train Loss: 1.3180, Test Loss: 2.6289\n",
      "Epoch [42/50] - Train Loss: 1.3178, Test Loss: 2.6289\n",
      "Epoch [43/50] - Train Loss: 1.3176, Test Loss: 2.6290\n",
      "Epoch [44/50] - Train Loss: 1.3174, Test Loss: 2.6290\n",
      "Epoch [45/50] - Train Loss: 1.3172, Test Loss: 2.6291\n",
      "Epoch [46/50] - Train Loss: 1.3170, Test Loss: 2.6292\n",
      "Epoch [47/50] - Train Loss: 1.3168, Test Loss: 2.6292\n",
      "Epoch [48/50] - Train Loss: 1.3166, Test Loss: 2.6293\n",
      "Epoch [49/50] - Train Loss: 1.3165, Test Loss: 2.6293\n",
      "Epoch [50/50] - Train Loss: 1.3163, Test Loss: 2.6294\n",
      "Avg Test Loss: 2.6294\n",
      "Testing combination: (4, 3, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.2009, Test Loss: 1.5627\n",
      "Epoch [2/50] - Train Loss: 1.0996, Test Loss: 1.4819\n",
      "Epoch [3/50] - Train Loss: 1.0970, Test Loss: 1.4768\n",
      "Epoch [4/50] - Train Loss: 1.0986, Test Loss: 1.4810\n",
      "Epoch [5/50] - Train Loss: 1.0969, Test Loss: 1.4855\n",
      "Epoch [6/50] - Train Loss: 1.0958, Test Loss: 1.4869\n",
      "Epoch [7/50] - Train Loss: 1.0951, Test Loss: 1.4862\n",
      "Epoch [8/50] - Train Loss: 1.0947, Test Loss: 1.4850\n",
      "Epoch [9/50] - Train Loss: 1.0944, Test Loss: 1.4843\n",
      "Epoch [10/50] - Train Loss: 1.0941, Test Loss: 1.4841\n",
      "Epoch [11/50] - Train Loss: 1.0937, Test Loss: 1.4840\n",
      "Epoch [12/50] - Train Loss: 1.0932, Test Loss: 1.4838\n",
      "Epoch [13/50] - Train Loss: 1.0927, Test Loss: 1.4836\n",
      "Epoch [14/50] - Train Loss: 1.0921, Test Loss: 1.4833\n",
      "Epoch [15/50] - Train Loss: 1.0914, Test Loss: 1.4831\n",
      "Epoch [16/50] - Train Loss: 1.0905, Test Loss: 1.4829\n",
      "Epoch [17/50] - Train Loss: 1.0897, Test Loss: 1.4827\n",
      "Epoch [18/50] - Train Loss: 1.0890, Test Loss: 1.4825\n",
      "Epoch [19/50] - Train Loss: 1.0880, Test Loss: 1.4824\n",
      "Epoch [20/50] - Train Loss: 1.0874, Test Loss: 1.4823\n",
      "Epoch [21/50] - Train Loss: 1.0869, Test Loss: 1.4822\n",
      "Epoch [22/50] - Train Loss: 1.0863, Test Loss: 1.4821\n",
      "Epoch [23/50] - Train Loss: 1.0858, Test Loss: 1.4820\n",
      "Epoch [24/50] - Train Loss: 1.0854, Test Loss: 1.4820\n",
      "Epoch [25/50] - Train Loss: 1.0851, Test Loss: 1.4819\n",
      "Epoch [26/50] - Train Loss: 1.0849, Test Loss: 1.4819\n",
      "Epoch [27/50] - Train Loss: 1.0847, Test Loss: 1.4819\n",
      "Epoch [28/50] - Train Loss: 1.0845, Test Loss: 1.4818\n",
      "Epoch [29/50] - Train Loss: 1.0844, Test Loss: 1.4818\n",
      "Epoch [30/50] - Train Loss: 1.0844, Test Loss: 1.4818\n",
      "Epoch [31/50] - Train Loss: 1.0843, Test Loss: 1.4818\n",
      "Epoch [32/50] - Train Loss: 1.0843, Test Loss: 1.4818\n",
      "Epoch [33/50] - Train Loss: 1.0843, Test Loss: 1.4818\n",
      "Epoch [34/50] - Train Loss: 1.0843, Test Loss: 1.4818\n",
      "Epoch [35/50] - Train Loss: 1.0842, Test Loss: 1.4818\n",
      "Epoch [36/50] - Train Loss: 1.0842, Test Loss: 1.4818\n",
      "Epoch [37/50] - Train Loss: 1.0842, Test Loss: 1.4818\n",
      "Epoch [38/50] - Train Loss: 1.0842, Test Loss: 1.4818\n",
      "Epoch [39/50] - Train Loss: 1.0842, Test Loss: 1.4818\n",
      "Epoch [40/50] - Train Loss: 1.0841, Test Loss: 1.4818\n",
      "Epoch [41/50] - Train Loss: 1.0841, Test Loss: 1.4818\n",
      "Epoch [42/50] - Train Loss: 1.0841, Test Loss: 1.4818\n",
      "Epoch [43/50] - Train Loss: 1.0841, Test Loss: 1.4818\n",
      "Epoch [44/50] - Train Loss: 1.0841, Test Loss: 1.4818\n",
      "Epoch [45/50] - Train Loss: 1.0841, Test Loss: 1.4818\n",
      "Epoch [46/50] - Train Loss: 1.0840, Test Loss: 1.4818\n",
      "Epoch [47/50] - Train Loss: 1.0840, Test Loss: 1.4818\n",
      "Epoch [48/50] - Train Loss: 1.0840, Test Loss: 1.4818\n",
      "Epoch [49/50] - Train Loss: 1.0840, Test Loss: 1.4818\n",
      "Epoch [50/50] - Train Loss: 1.0840, Test Loss: 1.4818\n",
      "Avg Test Loss: 1.4818\n",
      "Testing combination: (4, 3, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1468, Test Loss: 1.6405\n",
      "Epoch [2/50] - Train Loss: 1.1150, Test Loss: 1.5935\n",
      "Epoch [3/50] - Train Loss: 1.1181, Test Loss: 1.5962\n",
      "Epoch [4/50] - Train Loss: 1.1171, Test Loss: 1.6083\n",
      "Epoch [5/50] - Train Loss: 1.1162, Test Loss: 1.6145\n",
      "Epoch [6/50] - Train Loss: 1.1158, Test Loss: 1.6135\n",
      "Epoch [7/50] - Train Loss: 1.1155, Test Loss: 1.6102\n",
      "Epoch [8/50] - Train Loss: 1.1155, Test Loss: 1.6082\n",
      "Epoch [9/50] - Train Loss: 1.1156, Test Loss: 1.6081\n",
      "Epoch [10/50] - Train Loss: 1.1157, Test Loss: 1.6089\n",
      "Epoch [11/50] - Train Loss: 1.1157, Test Loss: 1.6096\n",
      "Epoch [12/50] - Train Loss: 1.1156, Test Loss: 1.6097\n",
      "Epoch [13/50] - Train Loss: 1.1156, Test Loss: 1.6095\n",
      "Epoch [14/50] - Train Loss: 1.1156, Test Loss: 1.6093\n",
      "Epoch [15/50] - Train Loss: 1.1156, Test Loss: 1.6093\n",
      "Epoch [16/50] - Train Loss: 1.1156, Test Loss: 1.6093\n",
      "Epoch [17/50] - Train Loss: 1.1156, Test Loss: 1.6094\n",
      "Epoch [18/50] - Train Loss: 1.1156, Test Loss: 1.6094\n",
      "Epoch [19/50] - Train Loss: 1.1156, Test Loss: 1.6094\n",
      "Epoch [20/50] - Train Loss: 1.1156, Test Loss: 1.6094\n",
      "Epoch [21/50] - Train Loss: 1.1156, Test Loss: 1.6094\n",
      "Epoch [22/50] - Train Loss: 1.1156, Test Loss: 1.6094\n",
      "Epoch [23/50] - Train Loss: 1.1155, Test Loss: 1.6094\n",
      "Epoch [24/50] - Train Loss: 1.1155, Test Loss: 1.6094\n",
      "Epoch [25/50] - Train Loss: 1.1155, Test Loss: 1.6094\n",
      "Epoch [26/50] - Train Loss: 1.1155, Test Loss: 1.6094\n",
      "Epoch [27/50] - Train Loss: 1.1155, Test Loss: 1.6094\n",
      "Epoch [28/50] - Train Loss: 1.1155, Test Loss: 1.6094\n",
      "Epoch [29/50] - Train Loss: 1.1155, Test Loss: 1.6094\n",
      "Epoch [30/50] - Train Loss: 1.1155, Test Loss: 1.6094\n",
      "Epoch [31/50] - Train Loss: 1.1155, Test Loss: 1.6094\n",
      "Epoch [32/50] - Train Loss: 1.1155, Test Loss: 1.6094\n",
      "Epoch [33/50] - Train Loss: 1.1155, Test Loss: 1.6094\n",
      "Epoch [34/50] - Train Loss: 1.1155, Test Loss: 1.6094\n",
      "Epoch [35/50] - Train Loss: 1.1155, Test Loss: 1.6094\n",
      "Epoch [36/50] - Train Loss: 1.1155, Test Loss: 1.6094\n",
      "Epoch [37/50] - Train Loss: 1.1155, Test Loss: 1.6094\n",
      "Epoch [38/50] - Train Loss: 1.1155, Test Loss: 1.6094\n",
      "Epoch [39/50] - Train Loss: 1.1155, Test Loss: 1.6094\n",
      "Epoch [40/50] - Train Loss: 1.1155, Test Loss: 1.6094\n",
      "Epoch [41/50] - Train Loss: 1.1155, Test Loss: 1.6094\n",
      "Epoch [42/50] - Train Loss: 1.1155, Test Loss: 1.6094\n",
      "Epoch [43/50] - Train Loss: 1.1155, Test Loss: 1.6094\n",
      "Epoch [44/50] - Train Loss: 1.1154, Test Loss: 1.6094\n",
      "Epoch [45/50] - Train Loss: 1.1154, Test Loss: 1.6094\n",
      "Epoch [46/50] - Train Loss: 1.1154, Test Loss: 1.6094\n",
      "Epoch [47/50] - Train Loss: 1.1154, Test Loss: 1.6094\n",
      "Epoch [48/50] - Train Loss: 1.1154, Test Loss: 1.6094\n",
      "Epoch [49/50] - Train Loss: 1.1154, Test Loss: 1.6094\n",
      "Epoch [50/50] - Train Loss: 1.1154, Test Loss: 1.6094\n",
      "Avg Test Loss: 1.6094\n",
      "Testing combination: (4, 3, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.4725, Test Loss: 2.6764\n",
      "Epoch [2/50] - Train Loss: 1.3863, Test Loss: 2.6323\n",
      "Epoch [3/50] - Train Loss: 1.3291, Test Loss: 2.6399\n",
      "Epoch [4/50] - Train Loss: 1.3048, Test Loss: 2.6926\n",
      "Epoch [5/50] - Train Loss: 1.3064, Test Loss: 2.7185\n",
      "Epoch [6/50] - Train Loss: 1.3067, Test Loss: 2.7031\n",
      "Epoch [7/50] - Train Loss: 1.3021, Test Loss: 2.6780\n",
      "Epoch [8/50] - Train Loss: 1.2995, Test Loss: 2.6611\n",
      "Epoch [9/50] - Train Loss: 1.2996, Test Loss: 2.6538\n",
      "Epoch [10/50] - Train Loss: 1.3001, Test Loss: 2.6532\n",
      "Epoch [11/50] - Train Loss: 1.2997, Test Loss: 2.6571\n",
      "Epoch [12/50] - Train Loss: 1.2988, Test Loss: 2.6633\n",
      "Epoch [13/50] - Train Loss: 1.2982, Test Loss: 2.6692\n",
      "Epoch [14/50] - Train Loss: 1.2978, Test Loss: 2.6728\n",
      "Epoch [15/50] - Train Loss: 1.2974, Test Loss: 2.6732\n",
      "Epoch [16/50] - Train Loss: 1.2970, Test Loss: 2.6714\n",
      "Epoch [17/50] - Train Loss: 1.2966, Test Loss: 2.6691\n",
      "Epoch [18/50] - Train Loss: 1.2963, Test Loss: 2.6674\n",
      "Epoch [19/50] - Train Loss: 1.2960, Test Loss: 2.6668\n",
      "Epoch [20/50] - Train Loss: 1.2957, Test Loss: 2.6673\n",
      "Epoch [21/50] - Train Loss: 1.2953, Test Loss: 2.6685\n",
      "Epoch [22/50] - Train Loss: 1.2949, Test Loss: 2.6697\n",
      "Epoch [23/50] - Train Loss: 1.2945, Test Loss: 2.6706\n",
      "Epoch [24/50] - Train Loss: 1.2940, Test Loss: 2.6710\n",
      "Epoch [25/50] - Train Loss: 1.2935, Test Loss: 2.6710\n",
      "Epoch [26/50] - Train Loss: 1.2930, Test Loss: 2.6709\n",
      "Epoch [27/50] - Train Loss: 1.2925, Test Loss: 2.6709\n",
      "Epoch [28/50] - Train Loss: 1.2921, Test Loss: 2.6710\n",
      "Epoch [29/50] - Train Loss: 1.2916, Test Loss: 2.6711\n",
      "Epoch [30/50] - Train Loss: 1.2912, Test Loss: 2.6710\n",
      "Epoch [31/50] - Train Loss: 1.2908, Test Loss: 2.6708\n",
      "Epoch [32/50] - Train Loss: 1.2904, Test Loss: 2.6704\n",
      "Epoch [33/50] - Train Loss: 1.2900, Test Loss: 2.6699\n",
      "Epoch [34/50] - Train Loss: 1.2896, Test Loss: 2.6695\n",
      "Epoch [35/50] - Train Loss: 1.2891, Test Loss: 2.6690\n",
      "Epoch [36/50] - Train Loss: 1.2886, Test Loss: 2.6682\n",
      "Epoch [37/50] - Train Loss: 1.2881, Test Loss: 2.6673\n",
      "Epoch [38/50] - Train Loss: 1.2874, Test Loss: 2.6664\n",
      "Epoch [39/50] - Train Loss: 1.2867, Test Loss: 2.6661\n",
      "Epoch [40/50] - Train Loss: 1.2858, Test Loss: 2.6662\n",
      "Epoch [41/50] - Train Loss: 1.2846, Test Loss: 2.6658\n",
      "Epoch [42/50] - Train Loss: 1.2843, Test Loss: 2.6671\n",
      "Epoch [43/50] - Train Loss: 1.3053, Test Loss: 2.6656\n",
      "Epoch [44/50] - Train Loss: 1.3023, Test Loss: 2.6525\n",
      "Epoch [45/50] - Train Loss: 1.3046, Test Loss: 2.6393\n",
      "Epoch [46/50] - Train Loss: 1.2927, Test Loss: 2.6488\n",
      "Epoch [47/50] - Train Loss: 1.2931, Test Loss: 2.6412\n",
      "Epoch [48/50] - Train Loss: 1.2930, Test Loss: 2.6332\n",
      "Epoch [49/50] - Train Loss: 1.2918, Test Loss: 2.6297\n",
      "Epoch [50/50] - Train Loss: 1.2905, Test Loss: 2.6268\n",
      "Avg Test Loss: 2.6268\n",
      "Testing combination: (4, 3, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.0946, Test Loss: 1.4839\n",
      "Epoch [2/50] - Train Loss: 1.0937, Test Loss: 1.4842\n",
      "Epoch [3/50] - Train Loss: 1.0935, Test Loss: 1.4844\n",
      "Epoch [4/50] - Train Loss: 1.0935, Test Loss: 1.4846\n",
      "Epoch [5/50] - Train Loss: 1.0934, Test Loss: 1.4847\n",
      "Epoch [6/50] - Train Loss: 1.0934, Test Loss: 1.4848\n",
      "Epoch [7/50] - Train Loss: 1.0933, Test Loss: 1.4849\n",
      "Epoch [8/50] - Train Loss: 1.0933, Test Loss: 1.4850\n",
      "Epoch [9/50] - Train Loss: 1.0933, Test Loss: 1.4851\n",
      "Epoch [10/50] - Train Loss: 1.0932, Test Loss: 1.4852\n",
      "Epoch [11/50] - Train Loss: 1.0932, Test Loss: 1.4852\n",
      "Epoch [12/50] - Train Loss: 1.0932, Test Loss: 1.4853\n",
      "Epoch [13/50] - Train Loss: 1.0931, Test Loss: 1.4853\n",
      "Epoch [14/50] - Train Loss: 1.0931, Test Loss: 1.4854\n",
      "Epoch [15/50] - Train Loss: 1.0931, Test Loss: 1.4854\n",
      "Epoch [16/50] - Train Loss: 1.0931, Test Loss: 1.4854\n",
      "Epoch [17/50] - Train Loss: 1.0930, Test Loss: 1.4855\n",
      "Epoch [18/50] - Train Loss: 1.0930, Test Loss: 1.4855\n",
      "Epoch [19/50] - Train Loss: 1.0930, Test Loss: 1.4855\n",
      "Epoch [20/50] - Train Loss: 1.0930, Test Loss: 1.4855\n",
      "Epoch [21/50] - Train Loss: 1.0929, Test Loss: 1.4855\n",
      "Epoch [22/50] - Train Loss: 1.0929, Test Loss: 1.4856\n",
      "Epoch [23/50] - Train Loss: 1.0929, Test Loss: 1.4856\n",
      "Epoch [24/50] - Train Loss: 1.0929, Test Loss: 1.4856\n",
      "Epoch [25/50] - Train Loss: 1.0928, Test Loss: 1.4856\n",
      "Epoch [26/50] - Train Loss: 1.0928, Test Loss: 1.4856\n",
      "Epoch [27/50] - Train Loss: 1.0928, Test Loss: 1.4856\n",
      "Epoch [28/50] - Train Loss: 1.0927, Test Loss: 1.4856\n",
      "Epoch [29/50] - Train Loss: 1.0927, Test Loss: 1.4856\n",
      "Epoch [30/50] - Train Loss: 1.0927, Test Loss: 1.4856\n",
      "Epoch [31/50] - Train Loss: 1.0926, Test Loss: 1.4856\n",
      "Epoch [32/50] - Train Loss: 1.0926, Test Loss: 1.4856\n",
      "Epoch [33/50] - Train Loss: 1.0925, Test Loss: 1.4856\n",
      "Epoch [34/50] - Train Loss: 1.0925, Test Loss: 1.4856\n",
      "Epoch [35/50] - Train Loss: 1.0924, Test Loss: 1.4856\n",
      "Epoch [36/50] - Train Loss: 1.0924, Test Loss: 1.4856\n",
      "Epoch [37/50] - Train Loss: 1.0923, Test Loss: 1.4856\n",
      "Epoch [38/50] - Train Loss: 1.0922, Test Loss: 1.4856\n",
      "Epoch [39/50] - Train Loss: 1.0921, Test Loss: 1.4856\n",
      "Epoch [40/50] - Train Loss: 1.0921, Test Loss: 1.4856\n",
      "Epoch [41/50] - Train Loss: 1.0920, Test Loss: 1.4856\n",
      "Epoch [42/50] - Train Loss: 1.0919, Test Loss: 1.4856\n",
      "Epoch [43/50] - Train Loss: 1.0918, Test Loss: 1.4856\n",
      "Epoch [44/50] - Train Loss: 1.0917, Test Loss: 1.4856\n",
      "Epoch [45/50] - Train Loss: 1.0916, Test Loss: 1.4855\n",
      "Epoch [46/50] - Train Loss: 1.0915, Test Loss: 1.4855\n",
      "Epoch [47/50] - Train Loss: 1.0914, Test Loss: 1.4855\n",
      "Epoch [48/50] - Train Loss: 1.0913, Test Loss: 1.4855\n",
      "Epoch [49/50] - Train Loss: 1.0912, Test Loss: 1.4855\n",
      "Epoch [50/50] - Train Loss: 1.0910, Test Loss: 1.4854\n",
      "Avg Test Loss: 1.4854\n",
      "Testing combination: (4, 3, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1514, Test Loss: 1.5736\n",
      "Epoch [2/50] - Train Loss: 1.1440, Test Loss: 1.5739\n",
      "Epoch [3/50] - Train Loss: 1.1382, Test Loss: 1.5749\n",
      "Epoch [4/50] - Train Loss: 1.1333, Test Loss: 1.5764\n",
      "Epoch [5/50] - Train Loss: 1.1294, Test Loss: 1.5783\n",
      "Epoch [6/50] - Train Loss: 1.1262, Test Loss: 1.5805\n",
      "Epoch [7/50] - Train Loss: 1.1236, Test Loss: 1.5829\n",
      "Epoch [8/50] - Train Loss: 1.1215, Test Loss: 1.5853\n",
      "Epoch [9/50] - Train Loss: 1.1198, Test Loss: 1.5877\n",
      "Epoch [10/50] - Train Loss: 1.1185, Test Loss: 1.5902\n",
      "Epoch [11/50] - Train Loss: 1.1175, Test Loss: 1.5925\n",
      "Epoch [12/50] - Train Loss: 1.1167, Test Loss: 1.5947\n",
      "Epoch [13/50] - Train Loss: 1.1161, Test Loss: 1.5968\n",
      "Epoch [14/50] - Train Loss: 1.1156, Test Loss: 1.5987\n",
      "Epoch [15/50] - Train Loss: 1.1153, Test Loss: 1.6004\n",
      "Epoch [16/50] - Train Loss: 1.1151, Test Loss: 1.6019\n",
      "Epoch [17/50] - Train Loss: 1.1149, Test Loss: 1.6033\n",
      "Epoch [18/50] - Train Loss: 1.1147, Test Loss: 1.6044\n",
      "Epoch [19/50] - Train Loss: 1.1146, Test Loss: 1.6054\n",
      "Epoch [20/50] - Train Loss: 1.1146, Test Loss: 1.6062\n",
      "Epoch [21/50] - Train Loss: 1.1145, Test Loss: 1.6069\n",
      "Epoch [22/50] - Train Loss: 1.1145, Test Loss: 1.6075\n",
      "Epoch [23/50] - Train Loss: 1.1145, Test Loss: 1.6079\n",
      "Epoch [24/50] - Train Loss: 1.1144, Test Loss: 1.6083\n",
      "Epoch [25/50] - Train Loss: 1.1144, Test Loss: 1.6086\n",
      "Epoch [26/50] - Train Loss: 1.1144, Test Loss: 1.6089\n",
      "Epoch [27/50] - Train Loss: 1.1144, Test Loss: 1.6091\n",
      "Epoch [28/50] - Train Loss: 1.1144, Test Loss: 1.6093\n",
      "Epoch [29/50] - Train Loss: 1.1144, Test Loss: 1.6094\n",
      "Epoch [30/50] - Train Loss: 1.1144, Test Loss: 1.6096\n",
      "Epoch [31/50] - Train Loss: 1.1144, Test Loss: 1.6097\n",
      "Epoch [32/50] - Train Loss: 1.1143, Test Loss: 1.6097\n",
      "Epoch [33/50] - Train Loss: 1.1143, Test Loss: 1.6098\n",
      "Epoch [34/50] - Train Loss: 1.1143, Test Loss: 1.6099\n",
      "Epoch [35/50] - Train Loss: 1.1143, Test Loss: 1.6099\n",
      "Epoch [36/50] - Train Loss: 1.1143, Test Loss: 1.6100\n",
      "Epoch [37/50] - Train Loss: 1.1143, Test Loss: 1.6100\n",
      "Epoch [38/50] - Train Loss: 1.1142, Test Loss: 1.6101\n",
      "Epoch [39/50] - Train Loss: 1.1142, Test Loss: 1.6101\n",
      "Epoch [40/50] - Train Loss: 1.1142, Test Loss: 1.6101\n",
      "Epoch [41/50] - Train Loss: 1.1142, Test Loss: 1.6102\n",
      "Epoch [42/50] - Train Loss: 1.1141, Test Loss: 1.6102\n",
      "Epoch [43/50] - Train Loss: 1.1141, Test Loss: 1.6103\n",
      "Epoch [44/50] - Train Loss: 1.1140, Test Loss: 1.6103\n",
      "Epoch [45/50] - Train Loss: 1.1140, Test Loss: 1.6104\n",
      "Epoch [46/50] - Train Loss: 1.1139, Test Loss: 1.6105\n",
      "Epoch [47/50] - Train Loss: 1.1138, Test Loss: 1.6106\n",
      "Epoch [48/50] - Train Loss: 1.1137, Test Loss: 1.6107\n",
      "Epoch [49/50] - Train Loss: 1.1136, Test Loss: 1.6108\n",
      "Epoch [50/50] - Train Loss: 1.1135, Test Loss: 1.6109\n",
      "Avg Test Loss: 1.6109\n",
      "Testing combination: (4, 3, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3021, Test Loss: 2.6604\n",
      "Epoch [2/50] - Train Loss: 1.3018, Test Loss: 2.6608\n",
      "Epoch [3/50] - Train Loss: 1.3018, Test Loss: 2.6611\n",
      "Epoch [4/50] - Train Loss: 1.3017, Test Loss: 2.6614\n",
      "Epoch [5/50] - Train Loss: 1.3017, Test Loss: 2.6616\n",
      "Epoch [6/50] - Train Loss: 1.3017, Test Loss: 2.6618\n",
      "Epoch [7/50] - Train Loss: 1.3017, Test Loss: 2.6620\n",
      "Epoch [8/50] - Train Loss: 1.3017, Test Loss: 2.6621\n",
      "Epoch [9/50] - Train Loss: 1.3017, Test Loss: 2.6623\n",
      "Epoch [10/50] - Train Loss: 1.3017, Test Loss: 2.6623\n",
      "Epoch [11/50] - Train Loss: 1.3017, Test Loss: 2.6624\n",
      "Epoch [12/50] - Train Loss: 1.3017, Test Loss: 2.6625\n",
      "Epoch [13/50] - Train Loss: 1.3017, Test Loss: 2.6625\n",
      "Epoch [14/50] - Train Loss: 1.3017, Test Loss: 2.6626\n",
      "Epoch [15/50] - Train Loss: 1.3017, Test Loss: 2.6626\n",
      "Epoch [16/50] - Train Loss: 1.3017, Test Loss: 2.6626\n",
      "Epoch [17/50] - Train Loss: 1.3017, Test Loss: 2.6627\n",
      "Epoch [18/50] - Train Loss: 1.3017, Test Loss: 2.6627\n",
      "Epoch [19/50] - Train Loss: 1.3017, Test Loss: 2.6627\n",
      "Epoch [20/50] - Train Loss: 1.3017, Test Loss: 2.6627\n",
      "Epoch [21/50] - Train Loss: 1.3017, Test Loss: 2.6627\n",
      "Epoch [22/50] - Train Loss: 1.3017, Test Loss: 2.6627\n",
      "Epoch [23/50] - Train Loss: 1.3017, Test Loss: 2.6627\n",
      "Epoch [24/50] - Train Loss: 1.3017, Test Loss: 2.6627\n",
      "Epoch [25/50] - Train Loss: 1.3017, Test Loss: 2.6627\n",
      "Epoch [26/50] - Train Loss: 1.3017, Test Loss: 2.6627\n",
      "Epoch [27/50] - Train Loss: 1.3017, Test Loss: 2.6627\n",
      "Epoch [28/50] - Train Loss: 1.3017, Test Loss: 2.6627\n",
      "Epoch [29/50] - Train Loss: 1.3017, Test Loss: 2.6627\n",
      "Epoch [30/50] - Train Loss: 1.3016, Test Loss: 2.6627\n",
      "Epoch [31/50] - Train Loss: 1.3016, Test Loss: 2.6627\n",
      "Epoch [32/50] - Train Loss: 1.3016, Test Loss: 2.6627\n",
      "Epoch [33/50] - Train Loss: 1.3016, Test Loss: 2.6627\n",
      "Epoch [34/50] - Train Loss: 1.3016, Test Loss: 2.6627\n",
      "Epoch [35/50] - Train Loss: 1.3016, Test Loss: 2.6627\n",
      "Epoch [36/50] - Train Loss: 1.3016, Test Loss: 2.6626\n",
      "Epoch [37/50] - Train Loss: 1.3016, Test Loss: 2.6626\n",
      "Epoch [38/50] - Train Loss: 1.3016, Test Loss: 2.6626\n",
      "Epoch [39/50] - Train Loss: 1.3016, Test Loss: 2.6626\n",
      "Epoch [40/50] - Train Loss: 1.3016, Test Loss: 2.6626\n",
      "Epoch [41/50] - Train Loss: 1.3016, Test Loss: 2.6626\n",
      "Epoch [42/50] - Train Loss: 1.3016, Test Loss: 2.6626\n",
      "Epoch [43/50] - Train Loss: 1.3016, Test Loss: 2.6625\n",
      "Epoch [44/50] - Train Loss: 1.3016, Test Loss: 2.6625\n",
      "Epoch [45/50] - Train Loss: 1.3016, Test Loss: 2.6625\n",
      "Epoch [46/50] - Train Loss: 1.3016, Test Loss: 2.6625\n",
      "Epoch [47/50] - Train Loss: 1.3016, Test Loss: 2.6625\n",
      "Epoch [48/50] - Train Loss: 1.3016, Test Loss: 2.6624\n",
      "Epoch [49/50] - Train Loss: 1.3016, Test Loss: 2.6624\n",
      "Epoch [50/50] - Train Loss: 1.3016, Test Loss: 2.6624\n",
      "Avg Test Loss: 2.6624\n",
      "Testing combination: (4, 3, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.2800, Test Loss: 1.5918\n",
      "Epoch [2/50] - Train Loss: 1.2767, Test Loss: 1.5891\n",
      "Epoch [3/50] - Train Loss: 1.2736, Test Loss: 1.5865\n",
      "Epoch [4/50] - Train Loss: 1.2706, Test Loss: 1.5840\n",
      "Epoch [5/50] - Train Loss: 1.2676, Test Loss: 1.5815\n",
      "Epoch [6/50] - Train Loss: 1.2646, Test Loss: 1.5791\n",
      "Epoch [7/50] - Train Loss: 1.2617, Test Loss: 1.5767\n",
      "Epoch [8/50] - Train Loss: 1.2589, Test Loss: 1.5744\n",
      "Epoch [9/50] - Train Loss: 1.2561, Test Loss: 1.5721\n",
      "Epoch [10/50] - Train Loss: 1.2534, Test Loss: 1.5698\n",
      "Epoch [11/50] - Train Loss: 1.2507, Test Loss: 1.5676\n",
      "Epoch [12/50] - Train Loss: 1.2480, Test Loss: 1.5655\n",
      "Epoch [13/50] - Train Loss: 1.2454, Test Loss: 1.5633\n",
      "Epoch [14/50] - Train Loss: 1.2428, Test Loss: 1.5613\n",
      "Epoch [15/50] - Train Loss: 1.2403, Test Loss: 1.5592\n",
      "Epoch [16/50] - Train Loss: 1.2378, Test Loss: 1.5572\n",
      "Epoch [17/50] - Train Loss: 1.2354, Test Loss: 1.5553\n",
      "Epoch [18/50] - Train Loss: 1.2330, Test Loss: 1.5534\n",
      "Epoch [19/50] - Train Loss: 1.2306, Test Loss: 1.5515\n",
      "Epoch [20/50] - Train Loss: 1.2283, Test Loss: 1.5497\n",
      "Epoch [21/50] - Train Loss: 1.2260, Test Loss: 1.5478\n",
      "Epoch [22/50] - Train Loss: 1.2238, Test Loss: 1.5461\n",
      "Epoch [23/50] - Train Loss: 1.2216, Test Loss: 1.5443\n",
      "Epoch [24/50] - Train Loss: 1.2194, Test Loss: 1.5426\n",
      "Epoch [25/50] - Train Loss: 1.2172, Test Loss: 1.5410\n",
      "Epoch [26/50] - Train Loss: 1.2151, Test Loss: 1.5393\n",
      "Epoch [27/50] - Train Loss: 1.2131, Test Loss: 1.5377\n",
      "Epoch [28/50] - Train Loss: 1.2110, Test Loss: 1.5361\n",
      "Epoch [29/50] - Train Loss: 1.2090, Test Loss: 1.5346\n",
      "Epoch [30/50] - Train Loss: 1.2070, Test Loss: 1.5331\n",
      "Epoch [31/50] - Train Loss: 1.2051, Test Loss: 1.5316\n",
      "Epoch [32/50] - Train Loss: 1.2032, Test Loss: 1.5301\n",
      "Epoch [33/50] - Train Loss: 1.2013, Test Loss: 1.5287\n",
      "Epoch [34/50] - Train Loss: 1.1994, Test Loss: 1.5273\n",
      "Epoch [35/50] - Train Loss: 1.1976, Test Loss: 1.5259\n",
      "Epoch [36/50] - Train Loss: 1.1958, Test Loss: 1.5246\n",
      "Epoch [37/50] - Train Loss: 1.1940, Test Loss: 1.5232\n",
      "Epoch [38/50] - Train Loss: 1.1922, Test Loss: 1.5220\n",
      "Epoch [39/50] - Train Loss: 1.1905, Test Loss: 1.5207\n",
      "Epoch [40/50] - Train Loss: 1.1888, Test Loss: 1.5194\n",
      "Epoch [41/50] - Train Loss: 1.1872, Test Loss: 1.5182\n",
      "Epoch [42/50] - Train Loss: 1.1855, Test Loss: 1.5170\n",
      "Epoch [43/50] - Train Loss: 1.1839, Test Loss: 1.5159\n",
      "Epoch [44/50] - Train Loss: 1.1823, Test Loss: 1.5147\n",
      "Epoch [45/50] - Train Loss: 1.1807, Test Loss: 1.5136\n",
      "Epoch [46/50] - Train Loss: 1.1792, Test Loss: 1.5125\n",
      "Epoch [47/50] - Train Loss: 1.1777, Test Loss: 1.5114\n",
      "Epoch [48/50] - Train Loss: 1.1762, Test Loss: 1.5104\n",
      "Epoch [49/50] - Train Loss: 1.1747, Test Loss: 1.5093\n",
      "Epoch [50/50] - Train Loss: 1.1733, Test Loss: 1.5083\n",
      "Avg Test Loss: 1.5083\n",
      "Testing combination: (4, 3, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1161, Test Loss: 1.6295\n",
      "Epoch [2/50] - Train Loss: 1.1161, Test Loss: 1.6292\n",
      "Epoch [3/50] - Train Loss: 1.1160, Test Loss: 1.6289\n",
      "Epoch [4/50] - Train Loss: 1.1160, Test Loss: 1.6287\n",
      "Epoch [5/50] - Train Loss: 1.1159, Test Loss: 1.6284\n",
      "Epoch [6/50] - Train Loss: 1.1159, Test Loss: 1.6281\n",
      "Epoch [7/50] - Train Loss: 1.1158, Test Loss: 1.6278\n",
      "Epoch [8/50] - Train Loss: 1.1158, Test Loss: 1.6276\n",
      "Epoch [9/50] - Train Loss: 1.1157, Test Loss: 1.6273\n",
      "Epoch [10/50] - Train Loss: 1.1157, Test Loss: 1.6270\n",
      "Epoch [11/50] - Train Loss: 1.1157, Test Loss: 1.6268\n",
      "Epoch [12/50] - Train Loss: 1.1156, Test Loss: 1.6265\n",
      "Epoch [13/50] - Train Loss: 1.1156, Test Loss: 1.6263\n",
      "Epoch [14/50] - Train Loss: 1.1156, Test Loss: 1.6260\n",
      "Epoch [15/50] - Train Loss: 1.1155, Test Loss: 1.6258\n",
      "Epoch [16/50] - Train Loss: 1.1155, Test Loss: 1.6256\n",
      "Epoch [17/50] - Train Loss: 1.1155, Test Loss: 1.6253\n",
      "Epoch [18/50] - Train Loss: 1.1154, Test Loss: 1.6251\n",
      "Epoch [19/50] - Train Loss: 1.1154, Test Loss: 1.6249\n",
      "Epoch [20/50] - Train Loss: 1.1154, Test Loss: 1.6246\n",
      "Epoch [21/50] - Train Loss: 1.1153, Test Loss: 1.6244\n",
      "Epoch [22/50] - Train Loss: 1.1153, Test Loss: 1.6242\n",
      "Epoch [23/50] - Train Loss: 1.1153, Test Loss: 1.6240\n",
      "Epoch [24/50] - Train Loss: 1.1152, Test Loss: 1.6238\n",
      "Epoch [25/50] - Train Loss: 1.1152, Test Loss: 1.6236\n",
      "Epoch [26/50] - Train Loss: 1.1152, Test Loss: 1.6234\n",
      "Epoch [27/50] - Train Loss: 1.1152, Test Loss: 1.6232\n",
      "Epoch [28/50] - Train Loss: 1.1151, Test Loss: 1.6230\n",
      "Epoch [29/50] - Train Loss: 1.1151, Test Loss: 1.6228\n",
      "Epoch [30/50] - Train Loss: 1.1151, Test Loss: 1.6226\n",
      "Epoch [31/50] - Train Loss: 1.1151, Test Loss: 1.6224\n",
      "Epoch [32/50] - Train Loss: 1.1150, Test Loss: 1.6222\n",
      "Epoch [33/50] - Train Loss: 1.1150, Test Loss: 1.6220\n",
      "Epoch [34/50] - Train Loss: 1.1150, Test Loss: 1.6218\n",
      "Epoch [35/50] - Train Loss: 1.1150, Test Loss: 1.6217\n",
      "Epoch [36/50] - Train Loss: 1.1150, Test Loss: 1.6215\n",
      "Epoch [37/50] - Train Loss: 1.1149, Test Loss: 1.6213\n",
      "Epoch [38/50] - Train Loss: 1.1149, Test Loss: 1.6211\n",
      "Epoch [39/50] - Train Loss: 1.1149, Test Loss: 1.6210\n",
      "Epoch [40/50] - Train Loss: 1.1149, Test Loss: 1.6208\n",
      "Epoch [41/50] - Train Loss: 1.1149, Test Loss: 1.6206\n",
      "Epoch [42/50] - Train Loss: 1.1148, Test Loss: 1.6205\n",
      "Epoch [43/50] - Train Loss: 1.1148, Test Loss: 1.6203\n",
      "Epoch [44/50] - Train Loss: 1.1148, Test Loss: 1.6202\n",
      "Epoch [45/50] - Train Loss: 1.1148, Test Loss: 1.6200\n",
      "Epoch [46/50] - Train Loss: 1.1148, Test Loss: 1.6198\n",
      "Epoch [47/50] - Train Loss: 1.1148, Test Loss: 1.6197\n",
      "Epoch [48/50] - Train Loss: 1.1147, Test Loss: 1.6195\n",
      "Epoch [49/50] - Train Loss: 1.1147, Test Loss: 1.6194\n",
      "Epoch [50/50] - Train Loss: 1.1147, Test Loss: 1.6193\n",
      "Avg Test Loss: 1.6193\n",
      "Testing combination: (4, 3, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3317, Test Loss: 2.7862\n",
      "Epoch [2/50] - Train Loss: 1.3312, Test Loss: 2.7848\n",
      "Epoch [3/50] - Train Loss: 1.3307, Test Loss: 2.7834\n",
      "Epoch [4/50] - Train Loss: 1.3302, Test Loss: 2.7821\n",
      "Epoch [5/50] - Train Loss: 1.3297, Test Loss: 2.7807\n",
      "Epoch [6/50] - Train Loss: 1.3293, Test Loss: 2.7794\n",
      "Epoch [7/50] - Train Loss: 1.3288, Test Loss: 2.7781\n",
      "Epoch [8/50] - Train Loss: 1.3284, Test Loss: 2.7768\n",
      "Epoch [9/50] - Train Loss: 1.3279, Test Loss: 2.7756\n",
      "Epoch [10/50] - Train Loss: 1.3275, Test Loss: 2.7743\n",
      "Epoch [11/50] - Train Loss: 1.3271, Test Loss: 2.7731\n",
      "Epoch [12/50] - Train Loss: 1.3266, Test Loss: 2.7719\n",
      "Epoch [13/50] - Train Loss: 1.3262, Test Loss: 2.7706\n",
      "Epoch [14/50] - Train Loss: 1.3258, Test Loss: 2.7694\n",
      "Epoch [15/50] - Train Loss: 1.3254, Test Loss: 2.7683\n",
      "Epoch [16/50] - Train Loss: 1.3250, Test Loss: 2.7671\n",
      "Epoch [17/50] - Train Loss: 1.3246, Test Loss: 2.7659\n",
      "Epoch [18/50] - Train Loss: 1.3242, Test Loss: 2.7648\n",
      "Epoch [19/50] - Train Loss: 1.3238, Test Loss: 2.7636\n",
      "Epoch [20/50] - Train Loss: 1.3235, Test Loss: 2.7625\n",
      "Epoch [21/50] - Train Loss: 1.3231, Test Loss: 2.7614\n",
      "Epoch [22/50] - Train Loss: 1.3227, Test Loss: 2.7603\n",
      "Epoch [23/50] - Train Loss: 1.3224, Test Loss: 2.7592\n",
      "Epoch [24/50] - Train Loss: 1.3220, Test Loss: 2.7581\n",
      "Epoch [25/50] - Train Loss: 1.3217, Test Loss: 2.7571\n",
      "Epoch [26/50] - Train Loss: 1.3213, Test Loss: 2.7560\n",
      "Epoch [27/50] - Train Loss: 1.3210, Test Loss: 2.7550\n",
      "Epoch [28/50] - Train Loss: 1.3207, Test Loss: 2.7540\n",
      "Epoch [29/50] - Train Loss: 1.3203, Test Loss: 2.7530\n",
      "Epoch [30/50] - Train Loss: 1.3200, Test Loss: 2.7519\n",
      "Epoch [31/50] - Train Loss: 1.3197, Test Loss: 2.7510\n",
      "Epoch [32/50] - Train Loss: 1.3194, Test Loss: 2.7500\n",
      "Epoch [33/50] - Train Loss: 1.3191, Test Loss: 2.7490\n",
      "Epoch [34/50] - Train Loss: 1.3188, Test Loss: 2.7480\n",
      "Epoch [35/50] - Train Loss: 1.3185, Test Loss: 2.7471\n",
      "Epoch [36/50] - Train Loss: 1.3182, Test Loss: 2.7461\n",
      "Epoch [37/50] - Train Loss: 1.3179, Test Loss: 2.7452\n",
      "Epoch [38/50] - Train Loss: 1.3176, Test Loss: 2.7443\n",
      "Epoch [39/50] - Train Loss: 1.3173, Test Loss: 2.7434\n",
      "Epoch [40/50] - Train Loss: 1.3171, Test Loss: 2.7425\n",
      "Epoch [41/50] - Train Loss: 1.3168, Test Loss: 2.7416\n",
      "Epoch [42/50] - Train Loss: 1.3165, Test Loss: 2.7407\n",
      "Epoch [43/50] - Train Loss: 1.3163, Test Loss: 2.7398\n",
      "Epoch [44/50] - Train Loss: 1.3160, Test Loss: 2.7389\n",
      "Epoch [45/50] - Train Loss: 1.3157, Test Loss: 2.7381\n",
      "Epoch [46/50] - Train Loss: 1.3155, Test Loss: 2.7372\n",
      "Epoch [47/50] - Train Loss: 1.3152, Test Loss: 2.7364\n",
      "Epoch [48/50] - Train Loss: 1.3150, Test Loss: 2.7356\n",
      "Epoch [49/50] - Train Loss: 1.3148, Test Loss: 2.7347\n",
      "Epoch [50/50] - Train Loss: 1.3145, Test Loss: 2.7339\n",
      "Avg Test Loss: 2.7339\n",
      "Testing combination: (4, 4, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1218, Test Loss: 1.4747\n",
      "Epoch [2/50] - Train Loss: 1.1013, Test Loss: 1.4828\n",
      "Epoch [3/50] - Train Loss: 1.0977, Test Loss: 1.4872\n",
      "Epoch [4/50] - Train Loss: 1.0963, Test Loss: 1.4866\n",
      "Epoch [5/50] - Train Loss: 1.0957, Test Loss: 1.4851\n",
      "Epoch [6/50] - Train Loss: 1.0956, Test Loss: 1.4841\n",
      "Epoch [7/50] - Train Loss: 1.0956, Test Loss: 1.4839\n",
      "Epoch [8/50] - Train Loss: 1.0957, Test Loss: 1.4840\n",
      "Epoch [9/50] - Train Loss: 1.0957, Test Loss: 1.4842\n",
      "Epoch [10/50] - Train Loss: 1.0957, Test Loss: 1.4843\n",
      "Epoch [11/50] - Train Loss: 1.0956, Test Loss: 1.4844\n",
      "Epoch [12/50] - Train Loss: 1.0956, Test Loss: 1.4844\n",
      "Epoch [13/50] - Train Loss: 1.0956, Test Loss: 1.4844\n",
      "Epoch [14/50] - Train Loss: 1.0955, Test Loss: 1.4844\n",
      "Epoch [15/50] - Train Loss: 1.0955, Test Loss: 1.4844\n",
      "Epoch [16/50] - Train Loss: 1.0955, Test Loss: 1.4844\n",
      "Epoch [17/50] - Train Loss: 1.0955, Test Loss: 1.4844\n",
      "Epoch [18/50] - Train Loss: 1.0955, Test Loss: 1.4844\n",
      "Epoch [19/50] - Train Loss: 1.0954, Test Loss: 1.4844\n",
      "Epoch [20/50] - Train Loss: 1.0954, Test Loss: 1.4844\n",
      "Epoch [21/50] - Train Loss: 1.0954, Test Loss: 1.4845\n",
      "Epoch [22/50] - Train Loss: 1.0954, Test Loss: 1.4845\n",
      "Epoch [23/50] - Train Loss: 1.0954, Test Loss: 1.4845\n",
      "Epoch [24/50] - Train Loss: 1.0953, Test Loss: 1.4845\n",
      "Epoch [25/50] - Train Loss: 1.0953, Test Loss: 1.4845\n",
      "Epoch [26/50] - Train Loss: 1.0953, Test Loss: 1.4845\n",
      "Epoch [27/50] - Train Loss: 1.0953, Test Loss: 1.4845\n",
      "Epoch [28/50] - Train Loss: 1.0953, Test Loss: 1.4845\n",
      "Epoch [29/50] - Train Loss: 1.0953, Test Loss: 1.4846\n",
      "Epoch [30/50] - Train Loss: 1.0953, Test Loss: 1.4846\n",
      "Epoch [31/50] - Train Loss: 1.0952, Test Loss: 1.4846\n",
      "Epoch [32/50] - Train Loss: 1.0952, Test Loss: 1.4846\n",
      "Epoch [33/50] - Train Loss: 1.0952, Test Loss: 1.4846\n",
      "Epoch [34/50] - Train Loss: 1.0952, Test Loss: 1.4846\n",
      "Epoch [35/50] - Train Loss: 1.0952, Test Loss: 1.4846\n",
      "Epoch [36/50] - Train Loss: 1.0952, Test Loss: 1.4846\n",
      "Epoch [37/50] - Train Loss: 1.0952, Test Loss: 1.4846\n",
      "Epoch [38/50] - Train Loss: 1.0952, Test Loss: 1.4846\n",
      "Epoch [39/50] - Train Loss: 1.0951, Test Loss: 1.4846\n",
      "Epoch [40/50] - Train Loss: 1.0951, Test Loss: 1.4847\n",
      "Epoch [41/50] - Train Loss: 1.0951, Test Loss: 1.4847\n",
      "Epoch [42/50] - Train Loss: 1.0951, Test Loss: 1.4847\n",
      "Epoch [43/50] - Train Loss: 1.0951, Test Loss: 1.4847\n",
      "Epoch [44/50] - Train Loss: 1.0951, Test Loss: 1.4847\n",
      "Epoch [45/50] - Train Loss: 1.0951, Test Loss: 1.4847\n",
      "Epoch [46/50] - Train Loss: 1.0951, Test Loss: 1.4847\n",
      "Epoch [47/50] - Train Loss: 1.0951, Test Loss: 1.4847\n",
      "Epoch [48/50] - Train Loss: 1.0951, Test Loss: 1.4847\n",
      "Epoch [49/50] - Train Loss: 1.0950, Test Loss: 1.4847\n",
      "Epoch [50/50] - Train Loss: 1.0950, Test Loss: 1.4847\n",
      "Avg Test Loss: 1.4847\n",
      "Testing combination: (4, 4, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.3070, Test Loss: 1.5769\n",
      "Epoch [2/50] - Train Loss: 1.1384, Test Loss: 1.6329\n",
      "Epoch [3/50] - Train Loss: 1.1268, Test Loss: 1.6519\n",
      "Epoch [4/50] - Train Loss: 1.1181, Test Loss: 1.6160\n",
      "Epoch [5/50] - Train Loss: 1.1148, Test Loss: 1.6004\n",
      "Epoch [6/50] - Train Loss: 1.1160, Test Loss: 1.5998\n",
      "Epoch [7/50] - Train Loss: 1.1162, Test Loss: 1.6052\n",
      "Epoch [8/50] - Train Loss: 1.1160, Test Loss: 1.6101\n",
      "Epoch [9/50] - Train Loss: 1.1158, Test Loss: 1.6111\n",
      "Epoch [10/50] - Train Loss: 1.1156, Test Loss: 1.6096\n",
      "Epoch [11/50] - Train Loss: 1.1156, Test Loss: 1.6081\n",
      "Epoch [12/50] - Train Loss: 1.1156, Test Loss: 1.6077\n",
      "Epoch [13/50] - Train Loss: 1.1157, Test Loss: 1.6080\n",
      "Epoch [14/50] - Train Loss: 1.1157, Test Loss: 1.6084\n",
      "Epoch [15/50] - Train Loss: 1.1157, Test Loss: 1.6085\n",
      "Epoch [16/50] - Train Loss: 1.1157, Test Loss: 1.6085\n",
      "Epoch [17/50] - Train Loss: 1.1157, Test Loss: 1.6083\n",
      "Epoch [18/50] - Train Loss: 1.1157, Test Loss: 1.6083\n",
      "Epoch [19/50] - Train Loss: 1.1156, Test Loss: 1.6083\n",
      "Epoch [20/50] - Train Loss: 1.1156, Test Loss: 1.6083\n",
      "Epoch [21/50] - Train Loss: 1.1156, Test Loss: 1.6084\n",
      "Epoch [22/50] - Train Loss: 1.1156, Test Loss: 1.6084\n",
      "Epoch [23/50] - Train Loss: 1.1156, Test Loss: 1.6084\n",
      "Epoch [24/50] - Train Loss: 1.1156, Test Loss: 1.6084\n",
      "Epoch [25/50] - Train Loss: 1.1155, Test Loss: 1.6084\n",
      "Epoch [26/50] - Train Loss: 1.1155, Test Loss: 1.6084\n",
      "Epoch [27/50] - Train Loss: 1.1155, Test Loss: 1.6085\n",
      "Epoch [28/50] - Train Loss: 1.1154, Test Loss: 1.6085\n",
      "Epoch [29/50] - Train Loss: 1.1154, Test Loss: 1.6085\n",
      "Epoch [30/50] - Train Loss: 1.1153, Test Loss: 1.6086\n",
      "Epoch [31/50] - Train Loss: 1.1152, Test Loss: 1.6087\n",
      "Epoch [32/50] - Train Loss: 1.1150, Test Loss: 1.6087\n",
      "Epoch [33/50] - Train Loss: 1.1147, Test Loss: 1.6089\n",
      "Epoch [34/50] - Train Loss: 1.1143, Test Loss: 1.6106\n",
      "Epoch [35/50] - Train Loss: 1.1133, Test Loss: 1.6125\n",
      "Epoch [36/50] - Train Loss: 1.1121, Test Loss: 1.6149\n",
      "Epoch [37/50] - Train Loss: 1.1095, Test Loss: 1.6147\n",
      "Epoch [38/50] - Train Loss: 1.1109, Test Loss: 1.6122\n",
      "Epoch [39/50] - Train Loss: 1.1077, Test Loss: 1.6113\n",
      "Epoch [40/50] - Train Loss: 1.1096, Test Loss: 1.6716\n",
      "Epoch [41/50] - Train Loss: 1.1080, Test Loss: 1.6145\n",
      "Epoch [42/50] - Train Loss: 1.1026, Test Loss: 1.6147\n",
      "Epoch [43/50] - Train Loss: 1.1047, Test Loss: 1.6092\n",
      "Epoch [44/50] - Train Loss: 1.1034, Test Loss: 1.6119\n",
      "Epoch [45/50] - Train Loss: 1.1102, Test Loss: 1.6134\n",
      "Epoch [46/50] - Train Loss: 1.1020, Test Loss: 1.6039\n",
      "Epoch [47/50] - Train Loss: 1.0950, Test Loss: 1.6256\n",
      "Epoch [48/50] - Train Loss: 1.1032, Test Loss: 1.6421\n",
      "Epoch [49/50] - Train Loss: 1.0918, Test Loss: 1.6254\n",
      "Epoch [50/50] - Train Loss: 1.0933, Test Loss: 1.6112\n",
      "Avg Test Loss: 1.6112\n",
      "Testing combination: (4, 4, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.5380, Test Loss: 2.7071\n",
      "Epoch [2/50] - Train Loss: 1.4046, Test Loss: 2.6295\n",
      "Epoch [3/50] - Train Loss: 1.3198, Test Loss: 2.6753\n",
      "Epoch [4/50] - Train Loss: 1.3094, Test Loss: 2.7350\n",
      "Epoch [5/50] - Train Loss: 1.3149, Test Loss: 2.7246\n",
      "Epoch [6/50] - Train Loss: 1.3082, Test Loss: 2.6881\n",
      "Epoch [7/50] - Train Loss: 1.3025, Test Loss: 2.6612\n",
      "Epoch [8/50] - Train Loss: 1.3023, Test Loss: 2.6493\n",
      "Epoch [9/50] - Train Loss: 1.3037, Test Loss: 2.6470\n",
      "Epoch [10/50] - Train Loss: 1.3039, Test Loss: 2.6504\n",
      "Epoch [11/50] - Train Loss: 1.3032, Test Loss: 2.6569\n",
      "Epoch [12/50] - Train Loss: 1.3026, Test Loss: 2.6639\n",
      "Epoch [13/50] - Train Loss: 1.3025, Test Loss: 2.6686\n",
      "Epoch [14/50] - Train Loss: 1.3025, Test Loss: 2.6697\n",
      "Epoch [15/50] - Train Loss: 1.3024, Test Loss: 2.6680\n",
      "Epoch [16/50] - Train Loss: 1.3022, Test Loss: 2.6651\n",
      "Epoch [17/50] - Train Loss: 1.3022, Test Loss: 2.6626\n",
      "Epoch [18/50] - Train Loss: 1.3022, Test Loss: 2.6611\n",
      "Epoch [19/50] - Train Loss: 1.3023, Test Loss: 2.6608\n",
      "Epoch [20/50] - Train Loss: 1.3023, Test Loss: 2.6614\n",
      "Epoch [21/50] - Train Loss: 1.3023, Test Loss: 2.6624\n",
      "Epoch [22/50] - Train Loss: 1.3023, Test Loss: 2.6632\n",
      "Epoch [23/50] - Train Loss: 1.3023, Test Loss: 2.6638\n",
      "Epoch [24/50] - Train Loss: 1.3023, Test Loss: 2.6638\n",
      "Epoch [25/50] - Train Loss: 1.3023, Test Loss: 2.6636\n",
      "Epoch [26/50] - Train Loss: 1.3023, Test Loss: 2.6633\n",
      "Epoch [27/50] - Train Loss: 1.3023, Test Loss: 2.6629\n",
      "Epoch [28/50] - Train Loss: 1.3023, Test Loss: 2.6628\n",
      "Epoch [29/50] - Train Loss: 1.3023, Test Loss: 2.6628\n",
      "Epoch [30/50] - Train Loss: 1.3023, Test Loss: 2.6629\n",
      "Epoch [31/50] - Train Loss: 1.3023, Test Loss: 2.6630\n",
      "Epoch [32/50] - Train Loss: 1.3023, Test Loss: 2.6631\n",
      "Epoch [33/50] - Train Loss: 1.3023, Test Loss: 2.6631\n",
      "Epoch [34/50] - Train Loss: 1.3023, Test Loss: 2.6631\n",
      "Epoch [35/50] - Train Loss: 1.3023, Test Loss: 2.6631\n",
      "Epoch [36/50] - Train Loss: 1.3023, Test Loss: 2.6631\n",
      "Epoch [37/50] - Train Loss: 1.3023, Test Loss: 2.6630\n",
      "Epoch [38/50] - Train Loss: 1.3023, Test Loss: 2.6630\n",
      "Epoch [39/50] - Train Loss: 1.3023, Test Loss: 2.6630\n",
      "Epoch [40/50] - Train Loss: 1.3023, Test Loss: 2.6630\n",
      "Epoch [41/50] - Train Loss: 1.3023, Test Loss: 2.6630\n",
      "Epoch [42/50] - Train Loss: 1.3023, Test Loss: 2.6631\n",
      "Epoch [43/50] - Train Loss: 1.3023, Test Loss: 2.6631\n",
      "Epoch [44/50] - Train Loss: 1.3023, Test Loss: 2.6631\n",
      "Epoch [45/50] - Train Loss: 1.3023, Test Loss: 2.6631\n",
      "Epoch [46/50] - Train Loss: 1.3023, Test Loss: 2.6630\n",
      "Epoch [47/50] - Train Loss: 1.3023, Test Loss: 2.6630\n",
      "Epoch [48/50] - Train Loss: 1.3023, Test Loss: 2.6630\n",
      "Epoch [49/50] - Train Loss: 1.3023, Test Loss: 2.6630\n",
      "Epoch [50/50] - Train Loss: 1.3023, Test Loss: 2.6630\n",
      "Avg Test Loss: 2.6630\n",
      "Testing combination: (4, 4, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.3606, Test Loss: 1.6424\n",
      "Epoch [2/50] - Train Loss: 1.3196, Test Loss: 1.6077\n",
      "Epoch [3/50] - Train Loss: 1.2807, Test Loss: 1.5755\n",
      "Epoch [4/50] - Train Loss: 1.2441, Test Loss: 1.5469\n",
      "Epoch [5/50] - Train Loss: 1.2109, Test Loss: 1.5229\n",
      "Epoch [6/50] - Train Loss: 1.1822, Test Loss: 1.5042\n",
      "Epoch [7/50] - Train Loss: 1.1586, Test Loss: 1.4907\n",
      "Epoch [8/50] - Train Loss: 1.1400, Test Loss: 1.4818\n",
      "Epoch [9/50] - Train Loss: 1.1260, Test Loss: 1.4765\n",
      "Epoch [10/50] - Train Loss: 1.1157, Test Loss: 1.4740\n",
      "Epoch [11/50] - Train Loss: 1.1085, Test Loss: 1.4733\n",
      "Epoch [12/50] - Train Loss: 1.1035, Test Loss: 1.4738\n",
      "Epoch [13/50] - Train Loss: 1.1001, Test Loss: 1.4750\n",
      "Epoch [14/50] - Train Loss: 1.0979, Test Loss: 1.4764\n",
      "Epoch [15/50] - Train Loss: 1.0964, Test Loss: 1.4778\n",
      "Epoch [16/50] - Train Loss: 1.0955, Test Loss: 1.4792\n",
      "Epoch [17/50] - Train Loss: 1.0948, Test Loss: 1.4804\n",
      "Epoch [18/50] - Train Loss: 1.0944, Test Loss: 1.4814\n",
      "Epoch [19/50] - Train Loss: 1.0942, Test Loss: 1.4822\n",
      "Epoch [20/50] - Train Loss: 1.0940, Test Loss: 1.4829\n",
      "Epoch [21/50] - Train Loss: 1.0939, Test Loss: 1.4835\n",
      "Epoch [22/50] - Train Loss: 1.0938, Test Loss: 1.4839\n",
      "Epoch [23/50] - Train Loss: 1.0938, Test Loss: 1.4843\n",
      "Epoch [24/50] - Train Loss: 1.0937, Test Loss: 1.4846\n",
      "Epoch [25/50] - Train Loss: 1.0937, Test Loss: 1.4848\n",
      "Epoch [26/50] - Train Loss: 1.0937, Test Loss: 1.4850\n",
      "Epoch [27/50] - Train Loss: 1.0936, Test Loss: 1.4851\n",
      "Epoch [28/50] - Train Loss: 1.0936, Test Loss: 1.4852\n",
      "Epoch [29/50] - Train Loss: 1.0936, Test Loss: 1.4853\n",
      "Epoch [30/50] - Train Loss: 1.0936, Test Loss: 1.4854\n",
      "Epoch [31/50] - Train Loss: 1.0936, Test Loss: 1.4854\n",
      "Epoch [32/50] - Train Loss: 1.0935, Test Loss: 1.4855\n",
      "Epoch [33/50] - Train Loss: 1.0935, Test Loss: 1.4855\n",
      "Epoch [34/50] - Train Loss: 1.0935, Test Loss: 1.4856\n",
      "Epoch [35/50] - Train Loss: 1.0934, Test Loss: 1.4856\n",
      "Epoch [36/50] - Train Loss: 1.0934, Test Loss: 1.4856\n",
      "Epoch [37/50] - Train Loss: 1.0933, Test Loss: 1.4857\n",
      "Epoch [38/50] - Train Loss: 1.0933, Test Loss: 1.4857\n",
      "Epoch [39/50] - Train Loss: 1.0933, Test Loss: 1.4857\n",
      "Epoch [40/50] - Train Loss: 1.0932, Test Loss: 1.4857\n",
      "Epoch [41/50] - Train Loss: 1.0932, Test Loss: 1.4857\n",
      "Epoch [42/50] - Train Loss: 1.0931, Test Loss: 1.4858\n",
      "Epoch [43/50] - Train Loss: 1.0931, Test Loss: 1.4858\n",
      "Epoch [44/50] - Train Loss: 1.0931, Test Loss: 1.4858\n",
      "Epoch [45/50] - Train Loss: 1.0930, Test Loss: 1.4858\n",
      "Epoch [46/50] - Train Loss: 1.0930, Test Loss: 1.4858\n",
      "Epoch [47/50] - Train Loss: 1.0929, Test Loss: 1.4859\n",
      "Epoch [48/50] - Train Loss: 1.0929, Test Loss: 1.4859\n",
      "Epoch [49/50] - Train Loss: 1.0928, Test Loss: 1.4859\n",
      "Epoch [50/50] - Train Loss: 1.0927, Test Loss: 1.4859\n",
      "Avg Test Loss: 1.4859\n",
      "Testing combination: (4, 4, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.6550, Test Loss: 1.9059\n",
      "Epoch [2/50] - Train Loss: 1.5954, Test Loss: 1.8582\n",
      "Epoch [3/50] - Train Loss: 1.5436, Test Loss: 1.8176\n",
      "Epoch [4/50] - Train Loss: 1.4987, Test Loss: 1.7832\n",
      "Epoch [5/50] - Train Loss: 1.4598, Test Loss: 1.7540\n",
      "Epoch [6/50] - Train Loss: 1.4260, Test Loss: 1.7292\n",
      "Epoch [7/50] - Train Loss: 1.3965, Test Loss: 1.7080\n",
      "Epoch [8/50] - Train Loss: 1.3707, Test Loss: 1.6898\n",
      "Epoch [9/50] - Train Loss: 1.3479, Test Loss: 1.6742\n",
      "Epoch [10/50] - Train Loss: 1.3277, Test Loss: 1.6606\n",
      "Epoch [11/50] - Train Loss: 1.3098, Test Loss: 1.6489\n",
      "Epoch [12/50] - Train Loss: 1.2937, Test Loss: 1.6387\n",
      "Epoch [13/50] - Train Loss: 1.2792, Test Loss: 1.6297\n",
      "Epoch [14/50] - Train Loss: 1.2660, Test Loss: 1.6217\n",
      "Epoch [15/50] - Train Loss: 1.2538, Test Loss: 1.6145\n",
      "Epoch [16/50] - Train Loss: 1.2425, Test Loss: 1.6081\n",
      "Epoch [17/50] - Train Loss: 1.2317, Test Loss: 1.6021\n",
      "Epoch [18/50] - Train Loss: 1.2213, Test Loss: 1.5967\n",
      "Epoch [19/50] - Train Loss: 1.2111, Test Loss: 1.5916\n",
      "Epoch [20/50] - Train Loss: 1.2009, Test Loss: 1.5869\n",
      "Epoch [21/50] - Train Loss: 1.1905, Test Loss: 1.5825\n",
      "Epoch [22/50] - Train Loss: 1.1797, Test Loss: 1.5786\n",
      "Epoch [23/50] - Train Loss: 1.1686, Test Loss: 1.5755\n",
      "Epoch [24/50] - Train Loss: 1.1570, Test Loss: 1.5738\n",
      "Epoch [25/50] - Train Loss: 1.1456, Test Loss: 1.5741\n",
      "Epoch [26/50] - Train Loss: 1.1351, Test Loss: 1.5772\n",
      "Epoch [27/50] - Train Loss: 1.1265, Test Loss: 1.5830\n",
      "Epoch [28/50] - Train Loss: 1.1206, Test Loss: 1.5903\n",
      "Epoch [29/50] - Train Loss: 1.1173, Test Loss: 1.5975\n",
      "Epoch [30/50] - Train Loss: 1.1157, Test Loss: 1.6032\n",
      "Epoch [31/50] - Train Loss: 1.1150, Test Loss: 1.6070\n",
      "Epoch [32/50] - Train Loss: 1.1148, Test Loss: 1.6092\n",
      "Epoch [33/50] - Train Loss: 1.1147, Test Loss: 1.6103\n",
      "Epoch [34/50] - Train Loss: 1.1147, Test Loss: 1.6106\n",
      "Epoch [35/50] - Train Loss: 1.1146, Test Loss: 1.6106\n",
      "Epoch [36/50] - Train Loss: 1.1146, Test Loss: 1.6105\n",
      "Epoch [37/50] - Train Loss: 1.1146, Test Loss: 1.6103\n",
      "Epoch [38/50] - Train Loss: 1.1146, Test Loss: 1.6101\n",
      "Epoch [39/50] - Train Loss: 1.1146, Test Loss: 1.6100\n",
      "Epoch [40/50] - Train Loss: 1.1146, Test Loss: 1.6099\n",
      "Epoch [41/50] - Train Loss: 1.1146, Test Loss: 1.6099\n",
      "Epoch [42/50] - Train Loss: 1.1146, Test Loss: 1.6098\n",
      "Epoch [43/50] - Train Loss: 1.1146, Test Loss: 1.6098\n",
      "Epoch [44/50] - Train Loss: 1.1146, Test Loss: 1.6098\n",
      "Epoch [45/50] - Train Loss: 1.1146, Test Loss: 1.6098\n",
      "Epoch [46/50] - Train Loss: 1.1146, Test Loss: 1.6098\n",
      "Epoch [47/50] - Train Loss: 1.1146, Test Loss: 1.6098\n",
      "Epoch [48/50] - Train Loss: 1.1146, Test Loss: 1.6098\n",
      "Epoch [49/50] - Train Loss: 1.1145, Test Loss: 1.6098\n",
      "Epoch [50/50] - Train Loss: 1.1145, Test Loss: 1.6098\n",
      "Avg Test Loss: 1.6098\n",
      "Testing combination: (4, 4, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.6968, Test Loss: 3.5067\n",
      "Epoch [2/50] - Train Loss: 1.6661, Test Loss: 3.4504\n",
      "Epoch [3/50] - Train Loss: 1.6365, Test Loss: 3.3958\n",
      "Epoch [4/50] - Train Loss: 1.6081, Test Loss: 3.3428\n",
      "Epoch [5/50] - Train Loss: 1.5808, Test Loss: 3.2915\n",
      "Epoch [6/50] - Train Loss: 1.5547, Test Loss: 3.2419\n",
      "Epoch [7/50] - Train Loss: 1.5298, Test Loss: 3.1940\n",
      "Epoch [8/50] - Train Loss: 1.5060, Test Loss: 3.1477\n",
      "Epoch [9/50] - Train Loss: 1.4834, Test Loss: 3.1030\n",
      "Epoch [10/50] - Train Loss: 1.4619, Test Loss: 3.0597\n",
      "Epoch [11/50] - Train Loss: 1.4414, Test Loss: 3.0180\n",
      "Epoch [12/50] - Train Loss: 1.4221, Test Loss: 2.9778\n",
      "Epoch [13/50] - Train Loss: 1.4040, Test Loss: 2.9392\n",
      "Epoch [14/50] - Train Loss: 1.3870, Test Loss: 2.9023\n",
      "Epoch [15/50] - Train Loss: 1.3714, Test Loss: 2.8673\n",
      "Epoch [16/50] - Train Loss: 1.3572, Test Loss: 2.8345\n",
      "Epoch [17/50] - Train Loss: 1.3446, Test Loss: 2.8041\n",
      "Epoch [18/50] - Train Loss: 1.3336, Test Loss: 2.7766\n",
      "Epoch [19/50] - Train Loss: 1.3245, Test Loss: 2.7522\n",
      "Epoch [20/50] - Train Loss: 1.3171, Test Loss: 2.7312\n",
      "Epoch [21/50] - Train Loss: 1.3115, Test Loss: 2.7135\n",
      "Epoch [22/50] - Train Loss: 1.3075, Test Loss: 2.6991\n",
      "Epoch [23/50] - Train Loss: 1.3048, Test Loss: 2.6878\n",
      "Epoch [24/50] - Train Loss: 1.3032, Test Loss: 2.6790\n",
      "Epoch [25/50] - Train Loss: 1.3022, Test Loss: 2.6724\n",
      "Epoch [26/50] - Train Loss: 1.3018, Test Loss: 2.6677\n",
      "Epoch [27/50] - Train Loss: 1.3017, Test Loss: 2.6644\n",
      "Epoch [28/50] - Train Loss: 1.3016, Test Loss: 2.6622\n",
      "Epoch [29/50] - Train Loss: 1.3017, Test Loss: 2.6609\n",
      "Epoch [30/50] - Train Loss: 1.3017, Test Loss: 2.6601\n",
      "Epoch [31/50] - Train Loss: 1.3017, Test Loss: 2.6598\n",
      "Epoch [32/50] - Train Loss: 1.3018, Test Loss: 2.6599\n",
      "Epoch [33/50] - Train Loss: 1.3018, Test Loss: 2.6601\n",
      "Epoch [34/50] - Train Loss: 1.3017, Test Loss: 2.6605\n",
      "Epoch [35/50] - Train Loss: 1.3017, Test Loss: 2.6609\n",
      "Epoch [36/50] - Train Loss: 1.3017, Test Loss: 2.6613\n",
      "Epoch [37/50] - Train Loss: 1.3017, Test Loss: 2.6616\n",
      "Epoch [38/50] - Train Loss: 1.3017, Test Loss: 2.6620\n",
      "Epoch [39/50] - Train Loss: 1.3017, Test Loss: 2.6623\n",
      "Epoch [40/50] - Train Loss: 1.3017, Test Loss: 2.6625\n",
      "Epoch [41/50] - Train Loss: 1.3017, Test Loss: 2.6627\n",
      "Epoch [42/50] - Train Loss: 1.3017, Test Loss: 2.6628\n",
      "Epoch [43/50] - Train Loss: 1.3017, Test Loss: 2.6629\n",
      "Epoch [44/50] - Train Loss: 1.3017, Test Loss: 2.6630\n",
      "Epoch [45/50] - Train Loss: 1.3017, Test Loss: 2.6630\n",
      "Epoch [46/50] - Train Loss: 1.3017, Test Loss: 2.6630\n",
      "Epoch [47/50] - Train Loss: 1.3017, Test Loss: 2.6630\n",
      "Epoch [48/50] - Train Loss: 1.3017, Test Loss: 2.6630\n",
      "Epoch [49/50] - Train Loss: 1.3017, Test Loss: 2.6630\n",
      "Epoch [50/50] - Train Loss: 1.3016, Test Loss: 2.6630\n",
      "Avg Test Loss: 2.6630\n",
      "Testing combination: (4, 4, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.2736, Test Loss: 1.7866\n",
      "Epoch [2/50] - Train Loss: 1.2697, Test Loss: 1.7812\n",
      "Epoch [3/50] - Train Loss: 1.2659, Test Loss: 1.7760\n",
      "Epoch [4/50] - Train Loss: 1.2622, Test Loss: 1.7708\n",
      "Epoch [5/50] - Train Loss: 1.2586, Test Loss: 1.7657\n",
      "Epoch [6/50] - Train Loss: 1.2551, Test Loss: 1.7607\n",
      "Epoch [7/50] - Train Loss: 1.2516, Test Loss: 1.7558\n",
      "Epoch [8/50] - Train Loss: 1.2481, Test Loss: 1.7510\n",
      "Epoch [9/50] - Train Loss: 1.2448, Test Loss: 1.7462\n",
      "Epoch [10/50] - Train Loss: 1.2415, Test Loss: 1.7415\n",
      "Epoch [11/50] - Train Loss: 1.2382, Test Loss: 1.7369\n",
      "Epoch [12/50] - Train Loss: 1.2351, Test Loss: 1.7324\n",
      "Epoch [13/50] - Train Loss: 1.2319, Test Loss: 1.7279\n",
      "Epoch [14/50] - Train Loss: 1.2289, Test Loss: 1.7235\n",
      "Epoch [15/50] - Train Loss: 1.2258, Test Loss: 1.7192\n",
      "Epoch [16/50] - Train Loss: 1.2229, Test Loss: 1.7149\n",
      "Epoch [17/50] - Train Loss: 1.2199, Test Loss: 1.7107\n",
      "Epoch [18/50] - Train Loss: 1.2171, Test Loss: 1.7065\n",
      "Epoch [19/50] - Train Loss: 1.2143, Test Loss: 1.7024\n",
      "Epoch [20/50] - Train Loss: 1.2115, Test Loss: 1.6984\n",
      "Epoch [21/50] - Train Loss: 1.2088, Test Loss: 1.6944\n",
      "Epoch [22/50] - Train Loss: 1.2061, Test Loss: 1.6905\n",
      "Epoch [23/50] - Train Loss: 1.2035, Test Loss: 1.6867\n",
      "Epoch [24/50] - Train Loss: 1.2009, Test Loss: 1.6829\n",
      "Epoch [25/50] - Train Loss: 1.1984, Test Loss: 1.6791\n",
      "Epoch [26/50] - Train Loss: 1.1959, Test Loss: 1.6755\n",
      "Epoch [27/50] - Train Loss: 1.1934, Test Loss: 1.6718\n",
      "Epoch [28/50] - Train Loss: 1.1910, Test Loss: 1.6683\n",
      "Epoch [29/50] - Train Loss: 1.1887, Test Loss: 1.6647\n",
      "Epoch [30/50] - Train Loss: 1.1864, Test Loss: 1.6613\n",
      "Epoch [31/50] - Train Loss: 1.1841, Test Loss: 1.6579\n",
      "Epoch [32/50] - Train Loss: 1.1819, Test Loss: 1.6545\n",
      "Epoch [33/50] - Train Loss: 1.1797, Test Loss: 1.6512\n",
      "Epoch [34/50] - Train Loss: 1.1776, Test Loss: 1.6480\n",
      "Epoch [35/50] - Train Loss: 1.1755, Test Loss: 1.6448\n",
      "Epoch [36/50] - Train Loss: 1.1734, Test Loss: 1.6416\n",
      "Epoch [37/50] - Train Loss: 1.1714, Test Loss: 1.6385\n",
      "Epoch [38/50] - Train Loss: 1.1694, Test Loss: 1.6355\n",
      "Epoch [39/50] - Train Loss: 1.1674, Test Loss: 1.6325\n",
      "Epoch [40/50] - Train Loss: 1.1655, Test Loss: 1.6295\n",
      "Epoch [41/50] - Train Loss: 1.1637, Test Loss: 1.6266\n",
      "Epoch [42/50] - Train Loss: 1.1618, Test Loss: 1.6237\n",
      "Epoch [43/50] - Train Loss: 1.1600, Test Loss: 1.6209\n",
      "Epoch [44/50] - Train Loss: 1.1583, Test Loss: 1.6182\n",
      "Epoch [45/50] - Train Loss: 1.1566, Test Loss: 1.6155\n",
      "Epoch [46/50] - Train Loss: 1.1549, Test Loss: 1.6128\n",
      "Epoch [47/50] - Train Loss: 1.1532, Test Loss: 1.6102\n",
      "Epoch [48/50] - Train Loss: 1.1516, Test Loss: 1.6076\n",
      "Epoch [49/50] - Train Loss: 1.1500, Test Loss: 1.6051\n",
      "Epoch [50/50] - Train Loss: 1.1485, Test Loss: 1.6026\n",
      "Avg Test Loss: 1.6026\n",
      "Testing combination: (4, 4, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.2065, Test Loss: 1.8421\n",
      "Epoch [2/50] - Train Loss: 1.2054, Test Loss: 1.8402\n",
      "Epoch [3/50] - Train Loss: 1.2044, Test Loss: 1.8382\n",
      "Epoch [4/50] - Train Loss: 1.2034, Test Loss: 1.8364\n",
      "Epoch [5/50] - Train Loss: 1.2024, Test Loss: 1.8345\n",
      "Epoch [6/50] - Train Loss: 1.2014, Test Loss: 1.8326\n",
      "Epoch [7/50] - Train Loss: 1.2004, Test Loss: 1.8307\n",
      "Epoch [8/50] - Train Loss: 1.1994, Test Loss: 1.8289\n",
      "Epoch [9/50] - Train Loss: 1.1984, Test Loss: 1.8270\n",
      "Epoch [10/50] - Train Loss: 1.1974, Test Loss: 1.8252\n",
      "Epoch [11/50] - Train Loss: 1.1964, Test Loss: 1.8233\n",
      "Epoch [12/50] - Train Loss: 1.1954, Test Loss: 1.8215\n",
      "Epoch [13/50] - Train Loss: 1.1945, Test Loss: 1.8197\n",
      "Epoch [14/50] - Train Loss: 1.1935, Test Loss: 1.8179\n",
      "Epoch [15/50] - Train Loss: 1.1926, Test Loss: 1.8160\n",
      "Epoch [16/50] - Train Loss: 1.1916, Test Loss: 1.8142\n",
      "Epoch [17/50] - Train Loss: 1.1907, Test Loss: 1.8124\n",
      "Epoch [18/50] - Train Loss: 1.1897, Test Loss: 1.8106\n",
      "Epoch [19/50] - Train Loss: 1.1888, Test Loss: 1.8089\n",
      "Epoch [20/50] - Train Loss: 1.1879, Test Loss: 1.8071\n",
      "Epoch [21/50] - Train Loss: 1.1870, Test Loss: 1.8053\n",
      "Epoch [22/50] - Train Loss: 1.1860, Test Loss: 1.8035\n",
      "Epoch [23/50] - Train Loss: 1.1851, Test Loss: 1.8017\n",
      "Epoch [24/50] - Train Loss: 1.1842, Test Loss: 1.8000\n",
      "Epoch [25/50] - Train Loss: 1.1833, Test Loss: 1.7982\n",
      "Epoch [26/50] - Train Loss: 1.1824, Test Loss: 1.7964\n",
      "Epoch [27/50] - Train Loss: 1.1815, Test Loss: 1.7947\n",
      "Epoch [28/50] - Train Loss: 1.1806, Test Loss: 1.7929\n",
      "Epoch [29/50] - Train Loss: 1.1797, Test Loss: 1.7912\n",
      "Epoch [30/50] - Train Loss: 1.1788, Test Loss: 1.7894\n",
      "Epoch [31/50] - Train Loss: 1.1780, Test Loss: 1.7877\n",
      "Epoch [32/50] - Train Loss: 1.1771, Test Loss: 1.7860\n",
      "Epoch [33/50] - Train Loss: 1.1762, Test Loss: 1.7842\n",
      "Epoch [34/50] - Train Loss: 1.1754, Test Loss: 1.7825\n",
      "Epoch [35/50] - Train Loss: 1.1745, Test Loss: 1.7808\n",
      "Epoch [36/50] - Train Loss: 1.1736, Test Loss: 1.7790\n",
      "Epoch [37/50] - Train Loss: 1.1728, Test Loss: 1.7773\n",
      "Epoch [38/50] - Train Loss: 1.1719, Test Loss: 1.7756\n",
      "Epoch [39/50] - Train Loss: 1.1711, Test Loss: 1.7739\n",
      "Epoch [40/50] - Train Loss: 1.1702, Test Loss: 1.7721\n",
      "Epoch [41/50] - Train Loss: 1.1694, Test Loss: 1.7704\n",
      "Epoch [42/50] - Train Loss: 1.1685, Test Loss: 1.7687\n",
      "Epoch [43/50] - Train Loss: 1.1677, Test Loss: 1.7670\n",
      "Epoch [44/50] - Train Loss: 1.1669, Test Loss: 1.7653\n",
      "Epoch [45/50] - Train Loss: 1.1661, Test Loss: 1.7636\n",
      "Epoch [46/50] - Train Loss: 1.1652, Test Loss: 1.7619\n",
      "Epoch [47/50] - Train Loss: 1.1644, Test Loss: 1.7602\n",
      "Epoch [48/50] - Train Loss: 1.1636, Test Loss: 1.7585\n",
      "Epoch [49/50] - Train Loss: 1.1628, Test Loss: 1.7568\n",
      "Epoch [50/50] - Train Loss: 1.1620, Test Loss: 1.7551\n",
      "Avg Test Loss: 1.7551\n",
      "Testing combination: (4, 4, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3642, Test Loss: 2.6425\n",
      "Epoch [2/50] - Train Loss: 1.3638, Test Loss: 2.6422\n",
      "Epoch [3/50] - Train Loss: 1.3633, Test Loss: 2.6419\n",
      "Epoch [4/50] - Train Loss: 1.3629, Test Loss: 2.6417\n",
      "Epoch [5/50] - Train Loss: 1.3624, Test Loss: 2.6414\n",
      "Epoch [6/50] - Train Loss: 1.3620, Test Loss: 2.6412\n",
      "Epoch [7/50] - Train Loss: 1.3616, Test Loss: 2.6410\n",
      "Epoch [8/50] - Train Loss: 1.3612, Test Loss: 2.6407\n",
      "Epoch [9/50] - Train Loss: 1.3608, Test Loss: 2.6405\n",
      "Epoch [10/50] - Train Loss: 1.3604, Test Loss: 2.6403\n",
      "Epoch [11/50] - Train Loss: 1.3600, Test Loss: 2.6401\n",
      "Epoch [12/50] - Train Loss: 1.3596, Test Loss: 2.6398\n",
      "Epoch [13/50] - Train Loss: 1.3592, Test Loss: 2.6396\n",
      "Epoch [14/50] - Train Loss: 1.3588, Test Loss: 2.6394\n",
      "Epoch [15/50] - Train Loss: 1.3584, Test Loss: 2.6392\n",
      "Epoch [16/50] - Train Loss: 1.3580, Test Loss: 2.6390\n",
      "Epoch [17/50] - Train Loss: 1.3577, Test Loss: 2.6388\n",
      "Epoch [18/50] - Train Loss: 1.3573, Test Loss: 2.6386\n",
      "Epoch [19/50] - Train Loss: 1.3569, Test Loss: 2.6384\n",
      "Epoch [20/50] - Train Loss: 1.3566, Test Loss: 2.6382\n",
      "Epoch [21/50] - Train Loss: 1.3562, Test Loss: 2.6381\n",
      "Epoch [22/50] - Train Loss: 1.3559, Test Loss: 2.6379\n",
      "Epoch [23/50] - Train Loss: 1.3555, Test Loss: 2.6377\n",
      "Epoch [24/50] - Train Loss: 1.3552, Test Loss: 2.6375\n",
      "Epoch [25/50] - Train Loss: 1.3548, Test Loss: 2.6373\n",
      "Epoch [26/50] - Train Loss: 1.3545, Test Loss: 2.6372\n",
      "Epoch [27/50] - Train Loss: 1.3542, Test Loss: 2.6370\n",
      "Epoch [28/50] - Train Loss: 1.3538, Test Loss: 2.6368\n",
      "Epoch [29/50] - Train Loss: 1.3535, Test Loss: 2.6367\n",
      "Epoch [30/50] - Train Loss: 1.3532, Test Loss: 2.6365\n",
      "Epoch [31/50] - Train Loss: 1.3528, Test Loss: 2.6364\n",
      "Epoch [32/50] - Train Loss: 1.3525, Test Loss: 2.6362\n",
      "Epoch [33/50] - Train Loss: 1.3522, Test Loss: 2.6360\n",
      "Epoch [34/50] - Train Loss: 1.3519, Test Loss: 2.6359\n",
      "Epoch [35/50] - Train Loss: 1.3516, Test Loss: 2.6357\n",
      "Epoch [36/50] - Train Loss: 1.3512, Test Loss: 2.6356\n",
      "Epoch [37/50] - Train Loss: 1.3509, Test Loss: 2.6354\n",
      "Epoch [38/50] - Train Loss: 1.3506, Test Loss: 2.6353\n",
      "Epoch [39/50] - Train Loss: 1.3503, Test Loss: 2.6351\n",
      "Epoch [40/50] - Train Loss: 1.3500, Test Loss: 2.6350\n",
      "Epoch [41/50] - Train Loss: 1.3497, Test Loss: 2.6349\n",
      "Epoch [42/50] - Train Loss: 1.3494, Test Loss: 2.6347\n",
      "Epoch [43/50] - Train Loss: 1.3491, Test Loss: 2.6346\n",
      "Epoch [44/50] - Train Loss: 1.3488, Test Loss: 2.6345\n",
      "Epoch [45/50] - Train Loss: 1.3485, Test Loss: 2.6343\n",
      "Epoch [46/50] - Train Loss: 1.3482, Test Loss: 2.6342\n",
      "Epoch [47/50] - Train Loss: 1.3479, Test Loss: 2.6341\n",
      "Epoch [48/50] - Train Loss: 1.3476, Test Loss: 2.6339\n",
      "Epoch [49/50] - Train Loss: 1.3473, Test Loss: 2.6338\n",
      "Epoch [50/50] - Train Loss: 1.3470, Test Loss: 2.6337\n",
      "Avg Test Loss: 2.6337\n",
      "Testing combination: (8, 1, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1158, Test Loss: 1.4993\n",
      "Epoch [2/50] - Train Loss: 1.0915, Test Loss: 1.4807\n",
      "Epoch [3/50] - Train Loss: 1.0896, Test Loss: 1.4800\n",
      "Epoch [4/50] - Train Loss: 1.0889, Test Loss: 1.4826\n",
      "Epoch [5/50] - Train Loss: 1.0866, Test Loss: 1.4834\n",
      "Epoch [6/50] - Train Loss: 1.0852, Test Loss: 1.4828\n",
      "Epoch [7/50] - Train Loss: 1.0844, Test Loss: 1.4821\n",
      "Epoch [8/50] - Train Loss: 1.0837, Test Loss: 1.4819\n",
      "Epoch [9/50] - Train Loss: 1.0825, Test Loss: 1.4821\n",
      "Epoch [10/50] - Train Loss: 1.0803, Test Loss: 1.4830\n",
      "Epoch [11/50] - Train Loss: 1.0774, Test Loss: 1.4842\n",
      "Epoch [12/50] - Train Loss: 1.0734, Test Loss: 1.4849\n",
      "Epoch [13/50] - Train Loss: 1.0684, Test Loss: 1.4841\n",
      "Epoch [14/50] - Train Loss: 1.0653, Test Loss: 1.4917\n",
      "Epoch [15/50] - Train Loss: 1.0568, Test Loss: 1.4890\n",
      "Epoch [16/50] - Train Loss: 1.0549, Test Loss: 1.4874\n",
      "Epoch [17/50] - Train Loss: 1.0547, Test Loss: 1.4871\n",
      "Epoch [18/50] - Train Loss: 1.0550, Test Loss: 1.4875\n",
      "Epoch [19/50] - Train Loss: 1.0520, Test Loss: 1.4877\n",
      "Epoch [20/50] - Train Loss: 1.0508, Test Loss: 1.4875\n",
      "Epoch [21/50] - Train Loss: 1.0497, Test Loss: 1.4871\n",
      "Epoch [22/50] - Train Loss: 1.0489, Test Loss: 1.4868\n",
      "Epoch [23/50] - Train Loss: 1.0483, Test Loss: 1.4869\n",
      "Epoch [24/50] - Train Loss: 1.0477, Test Loss: 1.4870\n",
      "Epoch [25/50] - Train Loss: 1.0472, Test Loss: 1.4871\n",
      "Epoch [26/50] - Train Loss: 1.0468, Test Loss: 1.4872\n",
      "Epoch [27/50] - Train Loss: 1.0465, Test Loss: 1.4873\n",
      "Epoch [28/50] - Train Loss: 1.0462, Test Loss: 1.4876\n",
      "Epoch [29/50] - Train Loss: 1.0459, Test Loss: 1.4880\n",
      "Epoch [30/50] - Train Loss: 1.0456, Test Loss: 1.4888\n",
      "Epoch [31/50] - Train Loss: 1.0452, Test Loss: 1.4898\n",
      "Epoch [32/50] - Train Loss: 1.0445, Test Loss: 1.4904\n",
      "Epoch [33/50] - Train Loss: 1.0433, Test Loss: 1.4900\n",
      "Epoch [34/50] - Train Loss: 1.0401, Test Loss: 1.4850\n",
      "Epoch [35/50] - Train Loss: 1.0325, Test Loss: 1.4839\n",
      "Epoch [36/50] - Train Loss: 1.0448, Test Loss: 1.4843\n",
      "Epoch [37/50] - Train Loss: 1.0946, Test Loss: 1.4942\n",
      "Epoch [38/50] - Train Loss: 1.0908, Test Loss: 1.4856\n",
      "Epoch [39/50] - Train Loss: 1.0873, Test Loss: 1.4813\n",
      "Epoch [40/50] - Train Loss: 1.0852, Test Loss: 1.4802\n",
      "Epoch [41/50] - Train Loss: 1.0861, Test Loss: 1.4807\n",
      "Epoch [42/50] - Train Loss: 1.0860, Test Loss: 1.4811\n",
      "Epoch [43/50] - Train Loss: 1.0848, Test Loss: 1.4819\n",
      "Epoch [44/50] - Train Loss: 1.0827, Test Loss: 1.4815\n",
      "Epoch [45/50] - Train Loss: 1.0808, Test Loss: 1.4812\n",
      "Epoch [46/50] - Train Loss: 1.0712, Test Loss: 1.4816\n",
      "Epoch [47/50] - Train Loss: 1.0634, Test Loss: 1.4835\n",
      "Epoch [48/50] - Train Loss: 1.0547, Test Loss: 1.4855\n",
      "Epoch [49/50] - Train Loss: 1.0529, Test Loss: 1.4863\n",
      "Epoch [50/50] - Train Loss: 1.0493, Test Loss: 1.4848\n",
      "Avg Test Loss: 1.4848\n",
      "Testing combination: (8, 1, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1374, Test Loss: 1.6036\n",
      "Epoch [2/50] - Train Loss: 1.1121, Test Loss: 1.5933\n",
      "Epoch [3/50] - Train Loss: 1.1129, Test Loss: 1.6070\n",
      "Epoch [4/50] - Train Loss: 1.1109, Test Loss: 1.6096\n",
      "Epoch [5/50] - Train Loss: 1.1096, Test Loss: 1.6053\n",
      "Epoch [6/50] - Train Loss: 1.1091, Test Loss: 1.6029\n",
      "Epoch [7/50] - Train Loss: 1.1089, Test Loss: 1.6038\n",
      "Epoch [8/50] - Train Loss: 1.1080, Test Loss: 1.6054\n",
      "Epoch [9/50] - Train Loss: 1.1056, Test Loss: 1.6063\n",
      "Epoch [10/50] - Train Loss: 1.1046, Test Loss: 1.6079\n",
      "Epoch [11/50] - Train Loss: 1.1018, Test Loss: 1.6094\n",
      "Epoch [12/50] - Train Loss: 1.0983, Test Loss: 1.6099\n",
      "Epoch [13/50] - Train Loss: 1.0950, Test Loss: 1.6105\n",
      "Epoch [14/50] - Train Loss: 1.0914, Test Loss: 1.6107\n",
      "Epoch [15/50] - Train Loss: 1.0876, Test Loss: 1.6112\n",
      "Epoch [16/50] - Train Loss: 1.0847, Test Loss: 1.6113\n",
      "Epoch [17/50] - Train Loss: 1.0824, Test Loss: 1.6111\n",
      "Epoch [18/50] - Train Loss: 1.0810, Test Loss: 1.6114\n",
      "Epoch [19/50] - Train Loss: 1.0802, Test Loss: 1.6118\n",
      "Epoch [20/50] - Train Loss: 1.0798, Test Loss: 1.6120\n",
      "Epoch [21/50] - Train Loss: 1.0797, Test Loss: 1.6122\n",
      "Epoch [22/50] - Train Loss: 1.0796, Test Loss: 1.6124\n",
      "Epoch [23/50] - Train Loss: 1.0794, Test Loss: 1.6127\n",
      "Epoch [24/50] - Train Loss: 1.0792, Test Loss: 1.6126\n",
      "Epoch [25/50] - Train Loss: 1.0792, Test Loss: 1.6127\n",
      "Epoch [26/50] - Train Loss: 1.0791, Test Loss: 1.6129\n",
      "Epoch [27/50] - Train Loss: 1.0790, Test Loss: 1.6129\n",
      "Epoch [28/50] - Train Loss: 1.0790, Test Loss: 1.6130\n",
      "Epoch [29/50] - Train Loss: 1.0789, Test Loss: 1.6130\n",
      "Epoch [30/50] - Train Loss: 1.0789, Test Loss: 1.6131\n",
      "Epoch [31/50] - Train Loss: 1.0789, Test Loss: 1.6131\n",
      "Epoch [32/50] - Train Loss: 1.0788, Test Loss: 1.6132\n",
      "Epoch [33/50] - Train Loss: 1.0788, Test Loss: 1.6132\n",
      "Epoch [34/50] - Train Loss: 1.0788, Test Loss: 1.6132\n",
      "Epoch [35/50] - Train Loss: 1.0787, Test Loss: 1.6133\n",
      "Epoch [36/50] - Train Loss: 1.0787, Test Loss: 1.6133\n",
      "Epoch [37/50] - Train Loss: 1.0787, Test Loss: 1.6133\n",
      "Epoch [38/50] - Train Loss: 1.0787, Test Loss: 1.6133\n",
      "Epoch [39/50] - Train Loss: 1.0786, Test Loss: 1.6134\n",
      "Epoch [40/50] - Train Loss: 1.0786, Test Loss: 1.6134\n",
      "Epoch [41/50] - Train Loss: 1.0786, Test Loss: 1.6134\n",
      "Epoch [42/50] - Train Loss: 1.0786, Test Loss: 1.6134\n",
      "Epoch [43/50] - Train Loss: 1.0786, Test Loss: 1.6134\n",
      "Epoch [44/50] - Train Loss: 1.0786, Test Loss: 1.6135\n",
      "Epoch [45/50] - Train Loss: 1.0785, Test Loss: 1.6135\n",
      "Epoch [46/50] - Train Loss: 1.0785, Test Loss: 1.6135\n",
      "Epoch [47/50] - Train Loss: 1.0785, Test Loss: 1.6135\n",
      "Epoch [48/50] - Train Loss: 1.0785, Test Loss: 1.6135\n",
      "Epoch [49/50] - Train Loss: 1.0785, Test Loss: 1.6135\n",
      "Epoch [50/50] - Train Loss: 1.0785, Test Loss: 1.6136\n",
      "Avg Test Loss: 1.6136\n",
      "Testing combination: (8, 1, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3108, Test Loss: 2.6828\n",
      "Epoch [2/50] - Train Loss: 1.3016, Test Loss: 2.6775\n",
      "Epoch [3/50] - Train Loss: 1.2973, Test Loss: 2.6677\n",
      "Epoch [4/50] - Train Loss: 1.2942, Test Loss: 2.6636\n",
      "Epoch [5/50] - Train Loss: 1.2917, Test Loss: 2.6649\n",
      "Epoch [6/50] - Train Loss: 1.2904, Test Loss: 2.6693\n",
      "Epoch [7/50] - Train Loss: 1.2903, Test Loss: 2.6734\n",
      "Epoch [8/50] - Train Loss: 1.2902, Test Loss: 2.6746\n",
      "Epoch [9/50] - Train Loss: 1.2898, Test Loss: 2.6736\n",
      "Epoch [10/50] - Train Loss: 1.2895, Test Loss: 2.6720\n",
      "Epoch [11/50] - Train Loss: 1.2893, Test Loss: 2.6707\n",
      "Epoch [12/50] - Train Loss: 1.2891, Test Loss: 2.6703\n",
      "Epoch [13/50] - Train Loss: 1.2888, Test Loss: 2.6707\n",
      "Epoch [14/50] - Train Loss: 1.2884, Test Loss: 2.6715\n",
      "Epoch [15/50] - Train Loss: 1.2878, Test Loss: 2.6718\n",
      "Epoch [16/50] - Train Loss: 1.2868, Test Loss: 2.6707\n",
      "Epoch [17/50] - Train Loss: 1.2845, Test Loss: 2.6662\n",
      "Epoch [18/50] - Train Loss: 1.2799, Test Loss: 2.6579\n",
      "Epoch [19/50] - Train Loss: 1.2742, Test Loss: 2.6511\n",
      "Epoch [20/50] - Train Loss: 1.2685, Test Loss: 2.6522\n",
      "Epoch [21/50] - Train Loss: 1.2638, Test Loss: 2.6469\n",
      "Epoch [22/50] - Train Loss: 1.2590, Test Loss: 2.6432\n",
      "Epoch [23/50] - Train Loss: 1.2580, Test Loss: 2.6499\n",
      "Epoch [24/50] - Train Loss: 1.2570, Test Loss: 2.6497\n",
      "Epoch [25/50] - Train Loss: 1.2562, Test Loss: 2.6427\n",
      "Epoch [26/50] - Train Loss: 1.2557, Test Loss: 2.6425\n",
      "Epoch [27/50] - Train Loss: 1.2549, Test Loss: 2.6466\n",
      "Epoch [28/50] - Train Loss: 1.2537, Test Loss: 2.6471\n",
      "Epoch [29/50] - Train Loss: 1.2524, Test Loss: 2.6445\n",
      "Epoch [30/50] - Train Loss: 1.2506, Test Loss: 2.6427\n",
      "Epoch [31/50] - Train Loss: 1.2481, Test Loss: 2.6416\n",
      "Epoch [32/50] - Train Loss: 1.2457, Test Loss: 2.6372\n",
      "Epoch [33/50] - Train Loss: 1.2401, Test Loss: 2.6342\n",
      "Epoch [34/50] - Train Loss: 1.2617, Test Loss: 2.6254\n",
      "Epoch [35/50] - Train Loss: 1.2526, Test Loss: 2.6398\n",
      "Epoch [36/50] - Train Loss: 1.2584, Test Loss: 2.6518\n",
      "Epoch [37/50] - Train Loss: 1.2569, Test Loss: 2.6687\n",
      "Epoch [38/50] - Train Loss: 1.2571, Test Loss: 2.6765\n",
      "Epoch [39/50] - Train Loss: 1.2569, Test Loss: 2.6717\n",
      "Epoch [40/50] - Train Loss: 1.2553, Test Loss: 2.6624\n",
      "Epoch [41/50] - Train Loss: 1.2545, Test Loss: 2.6559\n",
      "Epoch [42/50] - Train Loss: 1.2545, Test Loss: 2.6543\n",
      "Epoch [43/50] - Train Loss: 1.2543, Test Loss: 2.6568\n",
      "Epoch [44/50] - Train Loss: 1.2540, Test Loss: 2.6608\n",
      "Epoch [45/50] - Train Loss: 1.2539, Test Loss: 2.6635\n",
      "Epoch [46/50] - Train Loss: 1.2538, Test Loss: 2.6636\n",
      "Epoch [47/50] - Train Loss: 1.2538, Test Loss: 2.6619\n",
      "Epoch [48/50] - Train Loss: 1.2538, Test Loss: 2.6600\n",
      "Epoch [49/50] - Train Loss: 1.2538, Test Loss: 2.6592\n",
      "Epoch [50/50] - Train Loss: 1.2538, Test Loss: 2.6594\n",
      "Avg Test Loss: 2.6594\n",
      "Testing combination: (8, 1, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1554, Test Loss: 1.4909\n",
      "Epoch [2/50] - Train Loss: 1.1396, Test Loss: 1.4842\n",
      "Epoch [3/50] - Train Loss: 1.1280, Test Loss: 1.4796\n",
      "Epoch [4/50] - Train Loss: 1.1188, Test Loss: 1.4765\n",
      "Epoch [5/50] - Train Loss: 1.1114, Test Loss: 1.4746\n",
      "Epoch [6/50] - Train Loss: 1.1055, Test Loss: 1.4736\n",
      "Epoch [7/50] - Train Loss: 1.1008, Test Loss: 1.4733\n",
      "Epoch [8/50] - Train Loss: 1.0970, Test Loss: 1.4736\n",
      "Epoch [9/50] - Train Loss: 1.0940, Test Loss: 1.4742\n",
      "Epoch [10/50] - Train Loss: 1.0916, Test Loss: 1.4750\n",
      "Epoch [11/50] - Train Loss: 1.0897, Test Loss: 1.4760\n",
      "Epoch [12/50] - Train Loss: 1.0882, Test Loss: 1.4770\n",
      "Epoch [13/50] - Train Loss: 1.0869, Test Loss: 1.4780\n",
      "Epoch [14/50] - Train Loss: 1.0860, Test Loss: 1.4790\n",
      "Epoch [15/50] - Train Loss: 1.0852, Test Loss: 1.4798\n",
      "Epoch [16/50] - Train Loss: 1.0846, Test Loss: 1.4805\n",
      "Epoch [17/50] - Train Loss: 1.0841, Test Loss: 1.4812\n",
      "Epoch [18/50] - Train Loss: 1.0838, Test Loss: 1.4816\n",
      "Epoch [19/50] - Train Loss: 1.0835, Test Loss: 1.4820\n",
      "Epoch [20/50] - Train Loss: 1.0833, Test Loss: 1.4822\n",
      "Epoch [21/50] - Train Loss: 1.0831, Test Loss: 1.4824\n",
      "Epoch [22/50] - Train Loss: 1.0830, Test Loss: 1.4825\n",
      "Epoch [23/50] - Train Loss: 1.0828, Test Loss: 1.4826\n",
      "Epoch [24/50] - Train Loss: 1.0827, Test Loss: 1.4826\n",
      "Epoch [25/50] - Train Loss: 1.0826, Test Loss: 1.4826\n",
      "Epoch [26/50] - Train Loss: 1.0825, Test Loss: 1.4826\n",
      "Epoch [27/50] - Train Loss: 1.0824, Test Loss: 1.4826\n",
      "Epoch [28/50] - Train Loss: 1.0823, Test Loss: 1.4826\n",
      "Epoch [29/50] - Train Loss: 1.0822, Test Loss: 1.4826\n",
      "Epoch [30/50] - Train Loss: 1.0822, Test Loss: 1.4826\n",
      "Epoch [31/50] - Train Loss: 1.0821, Test Loss: 1.4826\n",
      "Epoch [32/50] - Train Loss: 1.0820, Test Loss: 1.4825\n",
      "Epoch [33/50] - Train Loss: 1.0819, Test Loss: 1.4825\n",
      "Epoch [34/50] - Train Loss: 1.0819, Test Loss: 1.4825\n",
      "Epoch [35/50] - Train Loss: 1.0818, Test Loss: 1.4825\n",
      "Epoch [36/50] - Train Loss: 1.0817, Test Loss: 1.4825\n",
      "Epoch [37/50] - Train Loss: 1.0816, Test Loss: 1.4825\n",
      "Epoch [38/50] - Train Loss: 1.0816, Test Loss: 1.4825\n",
      "Epoch [39/50] - Train Loss: 1.0815, Test Loss: 1.4825\n",
      "Epoch [40/50] - Train Loss: 1.0814, Test Loss: 1.4825\n",
      "Epoch [41/50] - Train Loss: 1.0813, Test Loss: 1.4825\n",
      "Epoch [42/50] - Train Loss: 1.0813, Test Loss: 1.4825\n",
      "Epoch [43/50] - Train Loss: 1.0812, Test Loss: 1.4825\n",
      "Epoch [44/50] - Train Loss: 1.0811, Test Loss: 1.4825\n",
      "Epoch [45/50] - Train Loss: 1.0810, Test Loss: 1.4825\n",
      "Epoch [46/50] - Train Loss: 1.0810, Test Loss: 1.4825\n",
      "Epoch [47/50] - Train Loss: 1.0809, Test Loss: 1.4825\n",
      "Epoch [48/50] - Train Loss: 1.0808, Test Loss: 1.4825\n",
      "Epoch [49/50] - Train Loss: 1.0807, Test Loss: 1.4825\n",
      "Epoch [50/50] - Train Loss: 1.0807, Test Loss: 1.4826\n",
      "Avg Test Loss: 1.4826\n",
      "Testing combination: (8, 1, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.2225, Test Loss: 1.8502\n",
      "Epoch [2/50] - Train Loss: 1.2014, Test Loss: 1.8145\n",
      "Epoch [3/50] - Train Loss: 1.1831, Test Loss: 1.7815\n",
      "Epoch [4/50] - Train Loss: 1.1671, Test Loss: 1.7508\n",
      "Epoch [5/50] - Train Loss: 1.1529, Test Loss: 1.7220\n",
      "Epoch [6/50] - Train Loss: 1.1407, Test Loss: 1.6954\n",
      "Epoch [7/50] - Train Loss: 1.1305, Test Loss: 1.6714\n",
      "Epoch [8/50] - Train Loss: 1.1227, Test Loss: 1.6509\n",
      "Epoch [9/50] - Train Loss: 1.1173, Test Loss: 1.6346\n",
      "Epoch [10/50] - Train Loss: 1.1142, Test Loss: 1.6227\n",
      "Epoch [11/50] - Train Loss: 1.1126, Test Loss: 1.6150\n",
      "Epoch [12/50] - Train Loss: 1.1118, Test Loss: 1.6105\n",
      "Epoch [13/50] - Train Loss: 1.1114, Test Loss: 1.6083\n",
      "Epoch [14/50] - Train Loss: 1.1110, Test Loss: 1.6076\n",
      "Epoch [15/50] - Train Loss: 1.1105, Test Loss: 1.6075\n",
      "Epoch [16/50] - Train Loss: 1.1101, Test Loss: 1.6077\n",
      "Epoch [17/50] - Train Loss: 1.1096, Test Loss: 1.6080\n",
      "Epoch [18/50] - Train Loss: 1.1091, Test Loss: 1.6081\n",
      "Epoch [19/50] - Train Loss: 1.1086, Test Loss: 1.6082\n",
      "Epoch [20/50] - Train Loss: 1.1082, Test Loss: 1.6082\n",
      "Epoch [21/50] - Train Loss: 1.1077, Test Loss: 1.6082\n",
      "Epoch [22/50] - Train Loss: 1.1073, Test Loss: 1.6081\n",
      "Epoch [23/50] - Train Loss: 1.1069, Test Loss: 1.6081\n",
      "Epoch [24/50] - Train Loss: 1.1065, Test Loss: 1.6080\n",
      "Epoch [25/50] - Train Loss: 1.1061, Test Loss: 1.6080\n",
      "Epoch [26/50] - Train Loss: 1.1057, Test Loss: 1.6080\n",
      "Epoch [27/50] - Train Loss: 1.1053, Test Loss: 1.6080\n",
      "Epoch [28/50] - Train Loss: 1.1049, Test Loss: 1.6080\n",
      "Epoch [29/50] - Train Loss: 1.1045, Test Loss: 1.6081\n",
      "Epoch [30/50] - Train Loss: 1.1041, Test Loss: 1.6082\n",
      "Epoch [31/50] - Train Loss: 1.1037, Test Loss: 1.6083\n",
      "Epoch [32/50] - Train Loss: 1.1032, Test Loss: 1.6085\n",
      "Epoch [33/50] - Train Loss: 1.1026, Test Loss: 1.6087\n",
      "Epoch [34/50] - Train Loss: 1.1021, Test Loss: 1.6089\n",
      "Epoch [35/50] - Train Loss: 1.1015, Test Loss: 1.6091\n",
      "Epoch [36/50] - Train Loss: 1.1008, Test Loss: 1.6093\n",
      "Epoch [37/50] - Train Loss: 1.1001, Test Loss: 1.6095\n",
      "Epoch [38/50] - Train Loss: 1.0994, Test Loss: 1.6098\n",
      "Epoch [39/50] - Train Loss: 1.0987, Test Loss: 1.6100\n",
      "Epoch [40/50] - Train Loss: 1.0979, Test Loss: 1.6102\n",
      "Epoch [41/50] - Train Loss: 1.0972, Test Loss: 1.6103\n",
      "Epoch [42/50] - Train Loss: 1.0965, Test Loss: 1.6105\n",
      "Epoch [43/50] - Train Loss: 1.0957, Test Loss: 1.6107\n",
      "Epoch [44/50] - Train Loss: 1.0950, Test Loss: 1.6109\n",
      "Epoch [45/50] - Train Loss: 1.0943, Test Loss: 1.6110\n",
      "Epoch [46/50] - Train Loss: 1.0935, Test Loss: 1.6112\n",
      "Epoch [47/50] - Train Loss: 1.0928, Test Loss: 1.6114\n",
      "Epoch [48/50] - Train Loss: 1.0920, Test Loss: 1.6115\n",
      "Epoch [49/50] - Train Loss: 1.0913, Test Loss: 1.6117\n",
      "Epoch [50/50] - Train Loss: 1.0915, Test Loss: 1.6122\n",
      "Avg Test Loss: 1.6122\n",
      "Testing combination: (8, 1, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3070, Test Loss: 2.7016\n",
      "Epoch [2/50] - Train Loss: 1.3037, Test Loss: 2.6953\n",
      "Epoch [3/50] - Train Loss: 1.3012, Test Loss: 2.6899\n",
      "Epoch [4/50] - Train Loss: 1.2994, Test Loss: 2.6851\n",
      "Epoch [5/50] - Train Loss: 1.2980, Test Loss: 2.6811\n",
      "Epoch [6/50] - Train Loss: 1.2969, Test Loss: 2.6776\n",
      "Epoch [7/50] - Train Loss: 1.2959, Test Loss: 2.6748\n",
      "Epoch [8/50] - Train Loss: 1.2951, Test Loss: 2.6723\n",
      "Epoch [9/50] - Train Loss: 1.2945, Test Loss: 2.6701\n",
      "Epoch [10/50] - Train Loss: 1.2940, Test Loss: 2.6685\n",
      "Epoch [11/50] - Train Loss: 1.2936, Test Loss: 2.6674\n",
      "Epoch [12/50] - Train Loss: 1.2932, Test Loss: 2.6667\n",
      "Epoch [13/50] - Train Loss: 1.2928, Test Loss: 2.6664\n",
      "Epoch [14/50] - Train Loss: 1.2925, Test Loss: 2.6662\n",
      "Epoch [15/50] - Train Loss: 1.2923, Test Loss: 2.6663\n",
      "Epoch [16/50] - Train Loss: 1.2920, Test Loss: 2.6664\n",
      "Epoch [17/50] - Train Loss: 1.2918, Test Loss: 2.6667\n",
      "Epoch [18/50] - Train Loss: 1.2915, Test Loss: 2.6671\n",
      "Epoch [19/50] - Train Loss: 1.2913, Test Loss: 2.6674\n",
      "Epoch [20/50] - Train Loss: 1.2911, Test Loss: 2.6678\n",
      "Epoch [21/50] - Train Loss: 1.2910, Test Loss: 2.6682\n",
      "Epoch [22/50] - Train Loss: 1.2908, Test Loss: 2.6685\n",
      "Epoch [23/50] - Train Loss: 1.2906, Test Loss: 2.6688\n",
      "Epoch [24/50] - Train Loss: 1.2905, Test Loss: 2.6691\n",
      "Epoch [25/50] - Train Loss: 1.2904, Test Loss: 2.6693\n",
      "Epoch [26/50] - Train Loss: 1.2903, Test Loss: 2.6696\n",
      "Epoch [27/50] - Train Loss: 1.2901, Test Loss: 2.6698\n",
      "Epoch [28/50] - Train Loss: 1.2900, Test Loss: 2.6699\n",
      "Epoch [29/50] - Train Loss: 1.2899, Test Loss: 2.6701\n",
      "Epoch [30/50] - Train Loss: 1.2899, Test Loss: 2.6702\n",
      "Epoch [31/50] - Train Loss: 1.2898, Test Loss: 2.6703\n",
      "Epoch [32/50] - Train Loss: 1.2897, Test Loss: 2.6704\n",
      "Epoch [33/50] - Train Loss: 1.2896, Test Loss: 2.6705\n",
      "Epoch [34/50] - Train Loss: 1.2896, Test Loss: 2.6705\n",
      "Epoch [35/50] - Train Loss: 1.2895, Test Loss: 2.6706\n",
      "Epoch [36/50] - Train Loss: 1.2895, Test Loss: 2.6707\n",
      "Epoch [37/50] - Train Loss: 1.2894, Test Loss: 2.6707\n",
      "Epoch [38/50] - Train Loss: 1.2894, Test Loss: 2.6708\n",
      "Epoch [39/50] - Train Loss: 1.2893, Test Loss: 2.6708\n",
      "Epoch [40/50] - Train Loss: 1.2893, Test Loss: 2.6709\n",
      "Epoch [41/50] - Train Loss: 1.2892, Test Loss: 2.6709\n",
      "Epoch [42/50] - Train Loss: 1.2892, Test Loss: 2.6710\n",
      "Epoch [43/50] - Train Loss: 1.2892, Test Loss: 2.6710\n",
      "Epoch [44/50] - Train Loss: 1.2891, Test Loss: 2.6710\n",
      "Epoch [45/50] - Train Loss: 1.2891, Test Loss: 2.6711\n",
      "Epoch [46/50] - Train Loss: 1.2891, Test Loss: 2.6711\n",
      "Epoch [47/50] - Train Loss: 1.2890, Test Loss: 2.6711\n",
      "Epoch [48/50] - Train Loss: 1.2890, Test Loss: 2.6712\n",
      "Epoch [49/50] - Train Loss: 1.2890, Test Loss: 2.6712\n",
      "Epoch [50/50] - Train Loss: 1.2889, Test Loss: 2.6712\n",
      "Avg Test Loss: 2.6712\n",
      "Testing combination: (8, 1, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1409, Test Loss: 1.5878\n",
      "Epoch [2/50] - Train Loss: 1.1394, Test Loss: 1.5856\n",
      "Epoch [3/50] - Train Loss: 1.1381, Test Loss: 1.5834\n",
      "Epoch [4/50] - Train Loss: 1.1367, Test Loss: 1.5813\n",
      "Epoch [5/50] - Train Loss: 1.1354, Test Loss: 1.5792\n",
      "Epoch [6/50] - Train Loss: 1.1341, Test Loss: 1.5772\n",
      "Epoch [7/50] - Train Loss: 1.1329, Test Loss: 1.5752\n",
      "Epoch [8/50] - Train Loss: 1.1316, Test Loss: 1.5732\n",
      "Epoch [9/50] - Train Loss: 1.1304, Test Loss: 1.5713\n",
      "Epoch [10/50] - Train Loss: 1.1293, Test Loss: 1.5694\n",
      "Epoch [11/50] - Train Loss: 1.1281, Test Loss: 1.5675\n",
      "Epoch [12/50] - Train Loss: 1.1270, Test Loss: 1.5657\n",
      "Epoch [13/50] - Train Loss: 1.1259, Test Loss: 1.5639\n",
      "Epoch [14/50] - Train Loss: 1.1248, Test Loss: 1.5622\n",
      "Epoch [15/50] - Train Loss: 1.1238, Test Loss: 1.5605\n",
      "Epoch [16/50] - Train Loss: 1.1227, Test Loss: 1.5588\n",
      "Epoch [17/50] - Train Loss: 1.1217, Test Loss: 1.5571\n",
      "Epoch [18/50] - Train Loss: 1.1208, Test Loss: 1.5555\n",
      "Epoch [19/50] - Train Loss: 1.1198, Test Loss: 1.5539\n",
      "Epoch [20/50] - Train Loss: 1.1189, Test Loss: 1.5524\n",
      "Epoch [21/50] - Train Loss: 1.1180, Test Loss: 1.5508\n",
      "Epoch [22/50] - Train Loss: 1.1171, Test Loss: 1.5493\n",
      "Epoch [23/50] - Train Loss: 1.1162, Test Loss: 1.5478\n",
      "Epoch [24/50] - Train Loss: 1.1154, Test Loss: 1.5464\n",
      "Epoch [25/50] - Train Loss: 1.1146, Test Loss: 1.5450\n",
      "Epoch [26/50] - Train Loss: 1.1138, Test Loss: 1.5436\n",
      "Epoch [27/50] - Train Loss: 1.1131, Test Loss: 1.5422\n",
      "Epoch [28/50] - Train Loss: 1.1123, Test Loss: 1.5409\n",
      "Epoch [29/50] - Train Loss: 1.1116, Test Loss: 1.5395\n",
      "Epoch [30/50] - Train Loss: 1.1109, Test Loss: 1.5383\n",
      "Epoch [31/50] - Train Loss: 1.1102, Test Loss: 1.5370\n",
      "Epoch [32/50] - Train Loss: 1.1095, Test Loss: 1.5358\n",
      "Epoch [33/50] - Train Loss: 1.1089, Test Loss: 1.5345\n",
      "Epoch [34/50] - Train Loss: 1.1082, Test Loss: 1.5334\n",
      "Epoch [35/50] - Train Loss: 1.1076, Test Loss: 1.5322\n",
      "Epoch [36/50] - Train Loss: 1.1070, Test Loss: 1.5310\n",
      "Epoch [37/50] - Train Loss: 1.1064, Test Loss: 1.5299\n",
      "Epoch [38/50] - Train Loss: 1.1058, Test Loss: 1.5288\n",
      "Epoch [39/50] - Train Loss: 1.1053, Test Loss: 1.5278\n",
      "Epoch [40/50] - Train Loss: 1.1047, Test Loss: 1.5267\n",
      "Epoch [41/50] - Train Loss: 1.1042, Test Loss: 1.5257\n",
      "Epoch [42/50] - Train Loss: 1.1037, Test Loss: 1.5247\n",
      "Epoch [43/50] - Train Loss: 1.1032, Test Loss: 1.5237\n",
      "Epoch [44/50] - Train Loss: 1.1027, Test Loss: 1.5227\n",
      "Epoch [45/50] - Train Loss: 1.1022, Test Loss: 1.5218\n",
      "Epoch [46/50] - Train Loss: 1.1017, Test Loss: 1.5209\n",
      "Epoch [47/50] - Train Loss: 1.1013, Test Loss: 1.5200\n",
      "Epoch [48/50] - Train Loss: 1.1008, Test Loss: 1.5191\n",
      "Epoch [49/50] - Train Loss: 1.1004, Test Loss: 1.5182\n",
      "Epoch [50/50] - Train Loss: 1.1000, Test Loss: 1.5174\n",
      "Avg Test Loss: 1.5174\n",
      "Testing combination: (8, 1, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1929, Test Loss: 1.5859\n",
      "Epoch [2/50] - Train Loss: 1.1908, Test Loss: 1.5851\n",
      "Epoch [3/50] - Train Loss: 1.1887, Test Loss: 1.5843\n",
      "Epoch [4/50] - Train Loss: 1.1867, Test Loss: 1.5835\n",
      "Epoch [5/50] - Train Loss: 1.1848, Test Loss: 1.5828\n",
      "Epoch [6/50] - Train Loss: 1.1828, Test Loss: 1.5821\n",
      "Epoch [7/50] - Train Loss: 1.1810, Test Loss: 1.5814\n",
      "Epoch [8/50] - Train Loss: 1.1791, Test Loss: 1.5808\n",
      "Epoch [9/50] - Train Loss: 1.1773, Test Loss: 1.5802\n",
      "Epoch [10/50] - Train Loss: 1.1755, Test Loss: 1.5796\n",
      "Epoch [11/50] - Train Loss: 1.1738, Test Loss: 1.5791\n",
      "Epoch [12/50] - Train Loss: 1.1721, Test Loss: 1.5786\n",
      "Epoch [13/50] - Train Loss: 1.1705, Test Loss: 1.5781\n",
      "Epoch [14/50] - Train Loss: 1.1689, Test Loss: 1.5777\n",
      "Epoch [15/50] - Train Loss: 1.1673, Test Loss: 1.5773\n",
      "Epoch [16/50] - Train Loss: 1.1658, Test Loss: 1.5769\n",
      "Epoch [17/50] - Train Loss: 1.1643, Test Loss: 1.5765\n",
      "Epoch [18/50] - Train Loss: 1.1629, Test Loss: 1.5761\n",
      "Epoch [19/50] - Train Loss: 1.1614, Test Loss: 1.5758\n",
      "Epoch [20/50] - Train Loss: 1.1600, Test Loss: 1.5755\n",
      "Epoch [21/50] - Train Loss: 1.1587, Test Loss: 1.5753\n",
      "Epoch [22/50] - Train Loss: 1.1574, Test Loss: 1.5750\n",
      "Epoch [23/50] - Train Loss: 1.1561, Test Loss: 1.5748\n",
      "Epoch [24/50] - Train Loss: 1.1548, Test Loss: 1.5746\n",
      "Epoch [25/50] - Train Loss: 1.1536, Test Loss: 1.5744\n",
      "Epoch [26/50] - Train Loss: 1.1523, Test Loss: 1.5742\n",
      "Epoch [27/50] - Train Loss: 1.1512, Test Loss: 1.5741\n",
      "Epoch [28/50] - Train Loss: 1.1500, Test Loss: 1.5739\n",
      "Epoch [29/50] - Train Loss: 1.1489, Test Loss: 1.5738\n",
      "Epoch [30/50] - Train Loss: 1.1477, Test Loss: 1.5737\n",
      "Epoch [31/50] - Train Loss: 1.1466, Test Loss: 1.5737\n",
      "Epoch [32/50] - Train Loss: 1.1456, Test Loss: 1.5736\n",
      "Epoch [33/50] - Train Loss: 1.1445, Test Loss: 1.5736\n",
      "Epoch [34/50] - Train Loss: 1.1435, Test Loss: 1.5736\n",
      "Epoch [35/50] - Train Loss: 1.1425, Test Loss: 1.5736\n",
      "Epoch [36/50] - Train Loss: 1.1415, Test Loss: 1.5736\n",
      "Epoch [37/50] - Train Loss: 1.1405, Test Loss: 1.5737\n",
      "Epoch [38/50] - Train Loss: 1.1395, Test Loss: 1.5737\n",
      "Epoch [39/50] - Train Loss: 1.1386, Test Loss: 1.5738\n",
      "Epoch [40/50] - Train Loss: 1.1377, Test Loss: 1.5739\n",
      "Epoch [41/50] - Train Loss: 1.1368, Test Loss: 1.5740\n",
      "Epoch [42/50] - Train Loss: 1.1359, Test Loss: 1.5742\n",
      "Epoch [43/50] - Train Loss: 1.1350, Test Loss: 1.5743\n",
      "Epoch [44/50] - Train Loss: 1.1342, Test Loss: 1.5745\n",
      "Epoch [45/50] - Train Loss: 1.1333, Test Loss: 1.5747\n",
      "Epoch [46/50] - Train Loss: 1.1325, Test Loss: 1.5749\n",
      "Epoch [47/50] - Train Loss: 1.1317, Test Loss: 1.5751\n",
      "Epoch [48/50] - Train Loss: 1.1310, Test Loss: 1.5753\n",
      "Epoch [49/50] - Train Loss: 1.1302, Test Loss: 1.5756\n",
      "Epoch [50/50] - Train Loss: 1.1295, Test Loss: 1.5758\n",
      "Avg Test Loss: 1.5758\n",
      "Testing combination: (8, 1, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3254, Test Loss: 2.6282\n",
      "Epoch [2/50] - Train Loss: 1.3247, Test Loss: 2.6282\n",
      "Epoch [3/50] - Train Loss: 1.3241, Test Loss: 2.6282\n",
      "Epoch [4/50] - Train Loss: 1.3236, Test Loss: 2.6283\n",
      "Epoch [5/50] - Train Loss: 1.3230, Test Loss: 2.6284\n",
      "Epoch [6/50] - Train Loss: 1.3225, Test Loss: 2.6284\n",
      "Epoch [7/50] - Train Loss: 1.3220, Test Loss: 2.6285\n",
      "Epoch [8/50] - Train Loss: 1.3215, Test Loss: 2.6286\n",
      "Epoch [9/50] - Train Loss: 1.3210, Test Loss: 2.6287\n",
      "Epoch [10/50] - Train Loss: 1.3205, Test Loss: 2.6287\n",
      "Epoch [11/50] - Train Loss: 1.3200, Test Loss: 2.6288\n",
      "Epoch [12/50] - Train Loss: 1.3195, Test Loss: 2.6289\n",
      "Epoch [13/50] - Train Loss: 1.3190, Test Loss: 2.6291\n",
      "Epoch [14/50] - Train Loss: 1.3186, Test Loss: 2.6292\n",
      "Epoch [15/50] - Train Loss: 1.3181, Test Loss: 2.6293\n",
      "Epoch [16/50] - Train Loss: 1.3177, Test Loss: 2.6294\n",
      "Epoch [17/50] - Train Loss: 1.3172, Test Loss: 2.6296\n",
      "Epoch [18/50] - Train Loss: 1.3168, Test Loss: 2.6297\n",
      "Epoch [19/50] - Train Loss: 1.3163, Test Loss: 2.6298\n",
      "Epoch [20/50] - Train Loss: 1.3159, Test Loss: 2.6300\n",
      "Epoch [21/50] - Train Loss: 1.3155, Test Loss: 2.6302\n",
      "Epoch [22/50] - Train Loss: 1.3151, Test Loss: 2.6303\n",
      "Epoch [23/50] - Train Loss: 1.3147, Test Loss: 2.6305\n",
      "Epoch [24/50] - Train Loss: 1.3143, Test Loss: 2.6307\n",
      "Epoch [25/50] - Train Loss: 1.3139, Test Loss: 2.6308\n",
      "Epoch [26/50] - Train Loss: 1.3135, Test Loss: 2.6310\n",
      "Epoch [27/50] - Train Loss: 1.3131, Test Loss: 2.6312\n",
      "Epoch [28/50] - Train Loss: 1.3127, Test Loss: 2.6314\n",
      "Epoch [29/50] - Train Loss: 1.3123, Test Loss: 2.6316\n",
      "Epoch [30/50] - Train Loss: 1.3120, Test Loss: 2.6318\n",
      "Epoch [31/50] - Train Loss: 1.3116, Test Loss: 2.6320\n",
      "Epoch [32/50] - Train Loss: 1.3112, Test Loss: 2.6322\n",
      "Epoch [33/50] - Train Loss: 1.3109, Test Loss: 2.6325\n",
      "Epoch [34/50] - Train Loss: 1.3105, Test Loss: 2.6327\n",
      "Epoch [35/50] - Train Loss: 1.3101, Test Loss: 2.6329\n",
      "Epoch [36/50] - Train Loss: 1.3098, Test Loss: 2.6331\n",
      "Epoch [37/50] - Train Loss: 1.3095, Test Loss: 2.6334\n",
      "Epoch [38/50] - Train Loss: 1.3091, Test Loss: 2.6336\n",
      "Epoch [39/50] - Train Loss: 1.3088, Test Loss: 2.6339\n",
      "Epoch [40/50] - Train Loss: 1.3085, Test Loss: 2.6341\n",
      "Epoch [41/50] - Train Loss: 1.3082, Test Loss: 2.6344\n",
      "Epoch [42/50] - Train Loss: 1.3079, Test Loss: 2.6346\n",
      "Epoch [43/50] - Train Loss: 1.3076, Test Loss: 2.6349\n",
      "Epoch [44/50] - Train Loss: 1.3073, Test Loss: 2.6351\n",
      "Epoch [45/50] - Train Loss: 1.3070, Test Loss: 2.6354\n",
      "Epoch [46/50] - Train Loss: 1.3067, Test Loss: 2.6357\n",
      "Epoch [47/50] - Train Loss: 1.3065, Test Loss: 2.6359\n",
      "Epoch [48/50] - Train Loss: 1.3062, Test Loss: 2.6362\n",
      "Epoch [49/50] - Train Loss: 1.3060, Test Loss: 2.6365\n",
      "Epoch [50/50] - Train Loss: 1.3057, Test Loss: 2.6368\n",
      "Avg Test Loss: 2.6368\n",
      "Testing combination: (8, 2, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1416, Test Loss: 1.4785\n",
      "Epoch [2/50] - Train Loss: 1.1004, Test Loss: 1.4893\n",
      "Epoch [3/50] - Train Loss: 1.0962, Test Loss: 1.4886\n",
      "Epoch [4/50] - Train Loss: 1.0939, Test Loss: 1.4856\n",
      "Epoch [5/50] - Train Loss: 1.0923, Test Loss: 1.4840\n",
      "Epoch [6/50] - Train Loss: 1.0901, Test Loss: 1.4839\n",
      "Epoch [7/50] - Train Loss: 1.0871, Test Loss: 1.4841\n",
      "Epoch [8/50] - Train Loss: 1.0834, Test Loss: 1.4842\n",
      "Epoch [9/50] - Train Loss: 1.0791, Test Loss: 1.4847\n",
      "Epoch [10/50] - Train Loss: 1.0773, Test Loss: 1.4849\n",
      "Epoch [11/50] - Train Loss: 1.0806, Test Loss: 1.4854\n",
      "Epoch [12/50] - Train Loss: 1.0685, Test Loss: 1.4874\n",
      "Epoch [13/50] - Train Loss: 1.0635, Test Loss: 1.4865\n",
      "Epoch [14/50] - Train Loss: 1.0591, Test Loss: 1.4854\n",
      "Epoch [15/50] - Train Loss: 1.0567, Test Loss: 1.4854\n",
      "Epoch [16/50] - Train Loss: 1.0554, Test Loss: 1.4859\n",
      "Epoch [17/50] - Train Loss: 1.0547, Test Loss: 1.4862\n",
      "Epoch [18/50] - Train Loss: 1.0543, Test Loss: 1.4862\n",
      "Epoch [19/50] - Train Loss: 1.0541, Test Loss: 1.4862\n",
      "Epoch [20/50] - Train Loss: 1.0540, Test Loss: 1.4862\n",
      "Epoch [21/50] - Train Loss: 1.0539, Test Loss: 1.4862\n",
      "Epoch [22/50] - Train Loss: 1.0538, Test Loss: 1.4863\n",
      "Epoch [23/50] - Train Loss: 1.0537, Test Loss: 1.4863\n",
      "Epoch [24/50] - Train Loss: 1.0536, Test Loss: 1.4863\n",
      "Epoch [25/50] - Train Loss: 1.0536, Test Loss: 1.4863\n",
      "Epoch [26/50] - Train Loss: 1.0535, Test Loss: 1.4863\n",
      "Epoch [27/50] - Train Loss: 1.0534, Test Loss: 1.4863\n",
      "Epoch [28/50] - Train Loss: 1.0532, Test Loss: 1.4862\n",
      "Epoch [29/50] - Train Loss: 1.0523, Test Loss: 1.4851\n",
      "Epoch [30/50] - Train Loss: 1.0581, Test Loss: 1.4876\n",
      "Epoch [31/50] - Train Loss: 1.0535, Test Loss: 1.4866\n",
      "Epoch [32/50] - Train Loss: 1.0535, Test Loss: 1.4862\n",
      "Epoch [33/50] - Train Loss: 1.0534, Test Loss: 1.4862\n",
      "Epoch [34/50] - Train Loss: 1.0534, Test Loss: 1.4862\n",
      "Epoch [35/50] - Train Loss: 1.0534, Test Loss: 1.4862\n",
      "Epoch [36/50] - Train Loss: 1.0534, Test Loss: 1.4863\n",
      "Epoch [37/50] - Train Loss: 1.0533, Test Loss: 1.4863\n",
      "Epoch [38/50] - Train Loss: 1.0533, Test Loss: 1.4863\n",
      "Epoch [39/50] - Train Loss: 1.0533, Test Loss: 1.4863\n",
      "Epoch [40/50] - Train Loss: 1.0532, Test Loss: 1.4863\n",
      "Epoch [41/50] - Train Loss: 1.0532, Test Loss: 1.4864\n",
      "Epoch [42/50] - Train Loss: 1.0532, Test Loss: 1.4864\n",
      "Epoch [43/50] - Train Loss: 1.0532, Test Loss: 1.4864\n",
      "Epoch [44/50] - Train Loss: 1.0531, Test Loss: 1.4864\n",
      "Epoch [45/50] - Train Loss: 1.0531, Test Loss: 1.4864\n",
      "Epoch [46/50] - Train Loss: 1.0531, Test Loss: 1.4864\n",
      "Epoch [47/50] - Train Loss: 1.0530, Test Loss: 1.4865\n",
      "Epoch [48/50] - Train Loss: 1.0530, Test Loss: 1.4865\n",
      "Epoch [49/50] - Train Loss: 1.0530, Test Loss: 1.4866\n",
      "Epoch [50/50] - Train Loss: 1.0530, Test Loss: 1.4866\n",
      "Avg Test Loss: 1.4866\n",
      "Testing combination: (8, 2, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1208, Test Loss: 1.6032\n",
      "Epoch [2/50] - Train Loss: 1.1175, Test Loss: 1.6101\n",
      "Epoch [3/50] - Train Loss: 1.1164, Test Loss: 1.6103\n",
      "Epoch [4/50] - Train Loss: 1.1160, Test Loss: 1.6086\n",
      "Epoch [5/50] - Train Loss: 1.1158, Test Loss: 1.6078\n",
      "Epoch [6/50] - Train Loss: 1.1155, Test Loss: 1.6081\n",
      "Epoch [7/50] - Train Loss: 1.1148, Test Loss: 1.6084\n",
      "Epoch [8/50] - Train Loss: 1.1133, Test Loss: 1.6079\n",
      "Epoch [9/50] - Train Loss: 1.1111, Test Loss: 1.6063\n",
      "Epoch [10/50] - Train Loss: 1.1090, Test Loss: 1.6051\n",
      "Epoch [11/50] - Train Loss: 1.1074, Test Loss: 1.6049\n",
      "Epoch [12/50] - Train Loss: 1.1059, Test Loss: 1.6058\n",
      "Epoch [13/50] - Train Loss: 1.1031, Test Loss: 1.6083\n",
      "Epoch [14/50] - Train Loss: 1.0999, Test Loss: 1.6115\n",
      "Epoch [15/50] - Train Loss: 1.0970, Test Loss: 1.6116\n",
      "Epoch [16/50] - Train Loss: 1.0909, Test Loss: 1.6099\n",
      "Epoch [17/50] - Train Loss: 1.0846, Test Loss: 1.6113\n",
      "Epoch [18/50] - Train Loss: 1.0815, Test Loss: 1.6132\n",
      "Epoch [19/50] - Train Loss: 1.0798, Test Loss: 1.6117\n",
      "Epoch [20/50] - Train Loss: 1.0796, Test Loss: 1.6117\n",
      "Epoch [21/50] - Train Loss: 1.0793, Test Loss: 1.6126\n",
      "Epoch [22/50] - Train Loss: 1.0791, Test Loss: 1.6129\n",
      "Epoch [23/50] - Train Loss: 1.0789, Test Loss: 1.6128\n",
      "Epoch [24/50] - Train Loss: 1.0787, Test Loss: 1.6129\n",
      "Epoch [25/50] - Train Loss: 1.0785, Test Loss: 1.6132\n",
      "Epoch [26/50] - Train Loss: 1.0783, Test Loss: 1.6134\n",
      "Epoch [27/50] - Train Loss: 1.0780, Test Loss: 1.6135\n",
      "Epoch [28/50] - Train Loss: 1.0775, Test Loss: 1.6135\n",
      "Epoch [29/50] - Train Loss: 1.0770, Test Loss: 1.6150\n",
      "Epoch [30/50] - Train Loss: 1.0754, Test Loss: 1.6167\n",
      "Epoch [31/50] - Train Loss: 1.0747, Test Loss: 1.6202\n",
      "Epoch [32/50] - Train Loss: 1.0734, Test Loss: 1.6184\n",
      "Epoch [33/50] - Train Loss: 1.0729, Test Loss: 1.6167\n",
      "Epoch [34/50] - Train Loss: 1.0712, Test Loss: 1.6162\n",
      "Epoch [35/50] - Train Loss: 1.0712, Test Loss: 1.6160\n",
      "Epoch [36/50] - Train Loss: 1.0702, Test Loss: 1.6160\n",
      "Epoch [37/50] - Train Loss: 1.0691, Test Loss: 1.6158\n",
      "Epoch [38/50] - Train Loss: 1.0691, Test Loss: 1.6158\n",
      "Epoch [39/50] - Train Loss: 1.0678, Test Loss: 1.6165\n",
      "Epoch [40/50] - Train Loss: 1.0683, Test Loss: 1.6165\n",
      "Epoch [41/50] - Train Loss: 1.0672, Test Loss: 1.6173\n",
      "Epoch [42/50] - Train Loss: 1.0674, Test Loss: 1.6153\n",
      "Epoch [43/50] - Train Loss: 1.0682, Test Loss: 1.6155\n",
      "Epoch [44/50] - Train Loss: 1.0668, Test Loss: 1.6191\n",
      "Epoch [45/50] - Train Loss: 1.0672, Test Loss: 1.6188\n",
      "Epoch [46/50] - Train Loss: 1.0682, Test Loss: 1.6187\n",
      "Epoch [47/50] - Train Loss: 1.0665, Test Loss: 1.6199\n",
      "Epoch [48/50] - Train Loss: 1.0670, Test Loss: 1.6186\n",
      "Epoch [49/50] - Train Loss: 1.0682, Test Loss: 1.6194\n",
      "Epoch [50/50] - Train Loss: 1.0659, Test Loss: 1.6189\n",
      "Avg Test Loss: 1.6189\n",
      "Testing combination: (8, 2, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.4995, Test Loss: 2.9820\n",
      "Epoch [2/50] - Train Loss: 1.3697, Test Loss: 2.7645\n",
      "Epoch [3/50] - Train Loss: 1.3085, Test Loss: 2.6571\n",
      "Epoch [4/50] - Train Loss: 1.3050, Test Loss: 2.6357\n",
      "Epoch [5/50] - Train Loss: 1.3091, Test Loss: 2.6386\n",
      "Epoch [6/50] - Train Loss: 1.3056, Test Loss: 2.6513\n",
      "Epoch [7/50] - Train Loss: 1.3019, Test Loss: 2.6668\n",
      "Epoch [8/50] - Train Loss: 1.3009, Test Loss: 2.6766\n",
      "Epoch [9/50] - Train Loss: 1.3001, Test Loss: 2.6776\n",
      "Epoch [10/50] - Train Loss: 1.2989, Test Loss: 2.6730\n",
      "Epoch [11/50] - Train Loss: 1.2981, Test Loss: 2.6675\n",
      "Epoch [12/50] - Train Loss: 1.2983, Test Loss: 2.6633\n",
      "Epoch [13/50] - Train Loss: 1.2972, Test Loss: 2.6605\n",
      "Epoch [14/50] - Train Loss: 1.2967, Test Loss: 2.6619\n",
      "Epoch [15/50] - Train Loss: 1.2957, Test Loss: 2.6656\n",
      "Epoch [16/50] - Train Loss: 1.2941, Test Loss: 2.6691\n",
      "Epoch [17/50] - Train Loss: 1.2923, Test Loss: 2.6706\n",
      "Epoch [18/50] - Train Loss: 1.2907, Test Loss: 2.6702\n",
      "Epoch [19/50] - Train Loss: 1.2890, Test Loss: 2.6689\n",
      "Epoch [20/50] - Train Loss: 1.2871, Test Loss: 2.6670\n",
      "Epoch [21/50] - Train Loss: 1.2852, Test Loss: 2.6650\n",
      "Epoch [22/50] - Train Loss: 1.2833, Test Loss: 2.6629\n",
      "Epoch [23/50] - Train Loss: 1.2836, Test Loss: 2.6631\n",
      "Epoch [24/50] - Train Loss: 1.2950, Test Loss: 2.6638\n",
      "Epoch [25/50] - Train Loss: 1.2799, Test Loss: 2.6580\n",
      "Epoch [26/50] - Train Loss: 1.2799, Test Loss: 2.6572\n",
      "Epoch [27/50] - Train Loss: 1.2784, Test Loss: 2.6603\n",
      "Epoch [28/50] - Train Loss: 1.2760, Test Loss: 2.6607\n",
      "Epoch [29/50] - Train Loss: 1.2734, Test Loss: 2.6571\n",
      "Epoch [30/50] - Train Loss: 1.2709, Test Loss: 2.6530\n",
      "Epoch [31/50] - Train Loss: 1.2681, Test Loss: 2.6497\n",
      "Epoch [32/50] - Train Loss: 1.2649, Test Loss: 2.6456\n",
      "Epoch [33/50] - Train Loss: 1.2609, Test Loss: 2.6407\n",
      "Epoch [34/50] - Train Loss: 1.2573, Test Loss: 2.6351\n",
      "Epoch [35/50] - Train Loss: 1.2545, Test Loss: 2.6282\n",
      "Epoch [36/50] - Train Loss: 1.2523, Test Loss: 2.6146\n",
      "Epoch [37/50] - Train Loss: 1.2510, Test Loss: 2.6008\n",
      "Epoch [38/50] - Train Loss: 1.2459, Test Loss: 2.6111\n",
      "Epoch [39/50] - Train Loss: 1.2436, Test Loss: 2.6743\n",
      "Epoch [40/50] - Train Loss: 1.2674, Test Loss: 2.6690\n",
      "Epoch [41/50] - Train Loss: 1.2499, Test Loss: 2.6650\n",
      "Epoch [42/50] - Train Loss: 1.2484, Test Loss: 2.6466\n",
      "Epoch [43/50] - Train Loss: 1.2498, Test Loss: 2.6389\n",
      "Epoch [44/50] - Train Loss: 1.2503, Test Loss: 2.6440\n",
      "Epoch [45/50] - Train Loss: 1.2491, Test Loss: 2.6533\n",
      "Epoch [46/50] - Train Loss: 1.2479, Test Loss: 2.6545\n",
      "Epoch [47/50] - Train Loss: 1.2467, Test Loss: 2.6454\n",
      "Epoch [48/50] - Train Loss: 1.2457, Test Loss: 2.6349\n",
      "Epoch [49/50] - Train Loss: 1.2455, Test Loss: 2.6300\n",
      "Epoch [50/50] - Train Loss: 1.2454, Test Loss: 2.6309\n",
      "Avg Test Loss: 2.6309\n",
      "Testing combination: (8, 2, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1474, Test Loss: 1.5891\n",
      "Epoch [2/50] - Train Loss: 1.1338, Test Loss: 1.5687\n",
      "Epoch [3/50] - Train Loss: 1.1230, Test Loss: 1.5515\n",
      "Epoch [4/50] - Train Loss: 1.1144, Test Loss: 1.5371\n",
      "Epoch [5/50] - Train Loss: 1.1076, Test Loss: 1.5248\n",
      "Epoch [6/50] - Train Loss: 1.1022, Test Loss: 1.5146\n",
      "Epoch [7/50] - Train Loss: 1.0982, Test Loss: 1.5063\n",
      "Epoch [8/50] - Train Loss: 1.0954, Test Loss: 1.4999\n",
      "Epoch [9/50] - Train Loss: 1.0936, Test Loss: 1.4951\n",
      "Epoch [10/50] - Train Loss: 1.0924, Test Loss: 1.4916\n",
      "Epoch [11/50] - Train Loss: 1.0918, Test Loss: 1.4891\n",
      "Epoch [12/50] - Train Loss: 1.0913, Test Loss: 1.4874\n",
      "Epoch [13/50] - Train Loss: 1.0910, Test Loss: 1.4863\n",
      "Epoch [14/50] - Train Loss: 1.0908, Test Loss: 1.4855\n",
      "Epoch [15/50] - Train Loss: 1.0906, Test Loss: 1.4850\n",
      "Epoch [16/50] - Train Loss: 1.0904, Test Loss: 1.4846\n",
      "Epoch [17/50] - Train Loss: 1.0902, Test Loss: 1.4843\n",
      "Epoch [18/50] - Train Loss: 1.0899, Test Loss: 1.4842\n",
      "Epoch [19/50] - Train Loss: 1.0897, Test Loss: 1.4840\n",
      "Epoch [20/50] - Train Loss: 1.0895, Test Loss: 1.4839\n",
      "Epoch [21/50] - Train Loss: 1.0893, Test Loss: 1.4838\n",
      "Epoch [22/50] - Train Loss: 1.0891, Test Loss: 1.4837\n",
      "Epoch [23/50] - Train Loss: 1.0889, Test Loss: 1.4837\n",
      "Epoch [24/50] - Train Loss: 1.0887, Test Loss: 1.4836\n",
      "Epoch [25/50] - Train Loss: 1.0885, Test Loss: 1.4835\n",
      "Epoch [26/50] - Train Loss: 1.0884, Test Loss: 1.4835\n",
      "Epoch [27/50] - Train Loss: 1.0882, Test Loss: 1.4834\n",
      "Epoch [28/50] - Train Loss: 1.0880, Test Loss: 1.4834\n",
      "Epoch [29/50] - Train Loss: 1.0877, Test Loss: 1.4833\n",
      "Epoch [30/50] - Train Loss: 1.0875, Test Loss: 1.4833\n",
      "Epoch [31/50] - Train Loss: 1.0873, Test Loss: 1.4833\n",
      "Epoch [32/50] - Train Loss: 1.0870, Test Loss: 1.4832\n",
      "Epoch [33/50] - Train Loss: 1.0867, Test Loss: 1.4832\n",
      "Epoch [34/50] - Train Loss: 1.0864, Test Loss: 1.4831\n",
      "Epoch [35/50] - Train Loss: 1.0860, Test Loss: 1.4830\n",
      "Epoch [36/50] - Train Loss: 1.0857, Test Loss: 1.4830\n",
      "Epoch [37/50] - Train Loss: 1.0852, Test Loss: 1.4829\n",
      "Epoch [38/50] - Train Loss: 1.0848, Test Loss: 1.4828\n",
      "Epoch [39/50] - Train Loss: 1.0843, Test Loss: 1.4828\n",
      "Epoch [40/50] - Train Loss: 1.0838, Test Loss: 1.4827\n",
      "Epoch [41/50] - Train Loss: 1.0832, Test Loss: 1.4826\n",
      "Epoch [42/50] - Train Loss: 1.0826, Test Loss: 1.4825\n",
      "Epoch [43/50] - Train Loss: 1.0820, Test Loss: 1.4824\n",
      "Epoch [44/50] - Train Loss: 1.0813, Test Loss: 1.4823\n",
      "Epoch [45/50] - Train Loss: 1.0807, Test Loss: 1.4822\n",
      "Epoch [46/50] - Train Loss: 1.0798, Test Loss: 1.4821\n",
      "Epoch [47/50] - Train Loss: 1.0792, Test Loss: 1.4821\n",
      "Epoch [48/50] - Train Loss: 1.0790, Test Loss: 1.4821\n",
      "Epoch [49/50] - Train Loss: 1.0782, Test Loss: 1.4821\n",
      "Epoch [50/50] - Train Loss: 1.0777, Test Loss: 1.4821\n",
      "Avg Test Loss: 1.4821\n",
      "Testing combination: (8, 2, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1445, Test Loss: 1.7042\n",
      "Epoch [2/50] - Train Loss: 1.1354, Test Loss: 1.6846\n",
      "Epoch [3/50] - Train Loss: 1.1287, Test Loss: 1.6683\n",
      "Epoch [4/50] - Train Loss: 1.1238, Test Loss: 1.6548\n",
      "Epoch [5/50] - Train Loss: 1.1203, Test Loss: 1.6439\n",
      "Epoch [6/50] - Train Loss: 1.1178, Test Loss: 1.6351\n",
      "Epoch [7/50] - Train Loss: 1.1162, Test Loss: 1.6282\n",
      "Epoch [8/50] - Train Loss: 1.1152, Test Loss: 1.6229\n",
      "Epoch [9/50] - Train Loss: 1.1146, Test Loss: 1.6189\n",
      "Epoch [10/50] - Train Loss: 1.1141, Test Loss: 1.6158\n",
      "Epoch [11/50] - Train Loss: 1.1139, Test Loss: 1.6136\n",
      "Epoch [12/50] - Train Loss: 1.1136, Test Loss: 1.6120\n",
      "Epoch [13/50] - Train Loss: 1.1135, Test Loss: 1.6109\n",
      "Epoch [14/50] - Train Loss: 1.1133, Test Loss: 1.6101\n",
      "Epoch [15/50] - Train Loss: 1.1131, Test Loss: 1.6095\n",
      "Epoch [16/50] - Train Loss: 1.1129, Test Loss: 1.6091\n",
      "Epoch [17/50] - Train Loss: 1.1126, Test Loss: 1.6087\n",
      "Epoch [18/50] - Train Loss: 1.1124, Test Loss: 1.6084\n",
      "Epoch [19/50] - Train Loss: 1.1120, Test Loss: 1.6082\n",
      "Epoch [20/50] - Train Loss: 1.1117, Test Loss: 1.6079\n",
      "Epoch [21/50] - Train Loss: 1.1114, Test Loss: 1.6077\n",
      "Epoch [22/50] - Train Loss: 1.1111, Test Loss: 1.6075\n",
      "Epoch [23/50] - Train Loss: 1.1109, Test Loss: 1.6073\n",
      "Epoch [24/50] - Train Loss: 1.1107, Test Loss: 1.6072\n",
      "Epoch [25/50] - Train Loss: 1.1105, Test Loss: 1.6070\n",
      "Epoch [26/50] - Train Loss: 1.1103, Test Loss: 1.6069\n",
      "Epoch [27/50] - Train Loss: 1.1102, Test Loss: 1.6068\n",
      "Epoch [28/50] - Train Loss: 1.1100, Test Loss: 1.6067\n",
      "Epoch [29/50] - Train Loss: 1.1098, Test Loss: 1.6066\n",
      "Epoch [30/50] - Train Loss: 1.1096, Test Loss: 1.6066\n",
      "Epoch [31/50] - Train Loss: 1.1094, Test Loss: 1.6065\n",
      "Epoch [32/50] - Train Loss: 1.1092, Test Loss: 1.6064\n",
      "Epoch [33/50] - Train Loss: 1.1090, Test Loss: 1.6063\n",
      "Epoch [34/50] - Train Loss: 1.1087, Test Loss: 1.6061\n",
      "Epoch [35/50] - Train Loss: 1.1085, Test Loss: 1.6060\n",
      "Epoch [36/50] - Train Loss: 1.1083, Test Loss: 1.6059\n",
      "Epoch [37/50] - Train Loss: 1.1081, Test Loss: 1.6058\n",
      "Epoch [38/50] - Train Loss: 1.1079, Test Loss: 1.6057\n",
      "Epoch [39/50] - Train Loss: 1.1076, Test Loss: 1.6056\n",
      "Epoch [40/50] - Train Loss: 1.1074, Test Loss: 1.6055\n",
      "Epoch [41/50] - Train Loss: 1.1090, Test Loss: 1.6063\n",
      "Epoch [42/50] - Train Loss: 1.1101, Test Loss: 1.6086\n",
      "Epoch [43/50] - Train Loss: 1.1103, Test Loss: 1.6094\n",
      "Epoch [44/50] - Train Loss: 1.1101, Test Loss: 1.6094\n",
      "Epoch [45/50] - Train Loss: 1.1098, Test Loss: 1.6090\n",
      "Epoch [46/50] - Train Loss: 1.1095, Test Loss: 1.6085\n",
      "Epoch [47/50] - Train Loss: 1.1093, Test Loss: 1.6081\n",
      "Epoch [48/50] - Train Loss: 1.1091, Test Loss: 1.6077\n",
      "Epoch [49/50] - Train Loss: 1.1090, Test Loss: 1.6074\n",
      "Epoch [50/50] - Train Loss: 1.1089, Test Loss: 1.6072\n",
      "Avg Test Loss: 1.6072\n",
      "Testing combination: (8, 2, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3380, Test Loss: 2.7910\n",
      "Epoch [2/50] - Train Loss: 1.3301, Test Loss: 2.7716\n",
      "Epoch [3/50] - Train Loss: 1.3237, Test Loss: 2.7543\n",
      "Epoch [4/50] - Train Loss: 1.3183, Test Loss: 2.7389\n",
      "Epoch [5/50] - Train Loss: 1.3139, Test Loss: 2.7255\n",
      "Epoch [6/50] - Train Loss: 1.3104, Test Loss: 2.7138\n",
      "Epoch [7/50] - Train Loss: 1.3075, Test Loss: 2.7036\n",
      "Epoch [8/50] - Train Loss: 1.3054, Test Loss: 2.6949\n",
      "Epoch [9/50] - Train Loss: 1.3037, Test Loss: 2.6875\n",
      "Epoch [10/50] - Train Loss: 1.3025, Test Loss: 2.6814\n",
      "Epoch [11/50] - Train Loss: 1.3017, Test Loss: 2.6763\n",
      "Epoch [12/50] - Train Loss: 1.3011, Test Loss: 2.6722\n",
      "Epoch [13/50] - Train Loss: 1.3007, Test Loss: 2.6690\n",
      "Epoch [14/50] - Train Loss: 1.3004, Test Loss: 2.6665\n",
      "Epoch [15/50] - Train Loss: 1.3002, Test Loss: 2.6647\n",
      "Epoch [16/50] - Train Loss: 1.3000, Test Loss: 2.6633\n",
      "Epoch [17/50] - Train Loss: 1.2999, Test Loss: 2.6625\n",
      "Epoch [18/50] - Train Loss: 1.2997, Test Loss: 2.6619\n",
      "Epoch [19/50] - Train Loss: 1.2996, Test Loss: 2.6616\n",
      "Epoch [20/50] - Train Loss: 1.2994, Test Loss: 2.6615\n",
      "Epoch [21/50] - Train Loss: 1.2992, Test Loss: 2.6615\n",
      "Epoch [22/50] - Train Loss: 1.2990, Test Loss: 2.6616\n",
      "Epoch [23/50] - Train Loss: 1.2988, Test Loss: 2.6618\n",
      "Epoch [24/50] - Train Loss: 1.2986, Test Loss: 2.6620\n",
      "Epoch [25/50] - Train Loss: 1.2984, Test Loss: 2.6623\n",
      "Epoch [26/50] - Train Loss: 1.2981, Test Loss: 2.6625\n",
      "Epoch [27/50] - Train Loss: 1.2978, Test Loss: 2.6627\n",
      "Epoch [28/50] - Train Loss: 1.2976, Test Loss: 2.6629\n",
      "Epoch [29/50] - Train Loss: 1.2973, Test Loss: 2.6631\n",
      "Epoch [30/50] - Train Loss: 1.2970, Test Loss: 2.6634\n",
      "Epoch [31/50] - Train Loss: 1.2967, Test Loss: 2.6636\n",
      "Epoch [32/50] - Train Loss: 1.2964, Test Loss: 2.6638\n",
      "Epoch [33/50] - Train Loss: 1.2962, Test Loss: 2.6640\n",
      "Epoch [34/50] - Train Loss: 1.2959, Test Loss: 2.6642\n",
      "Epoch [35/50] - Train Loss: 1.2956, Test Loss: 2.6645\n",
      "Epoch [36/50] - Train Loss: 1.2954, Test Loss: 2.6647\n",
      "Epoch [37/50] - Train Loss: 1.2951, Test Loss: 2.6649\n",
      "Epoch [38/50] - Train Loss: 1.2948, Test Loss: 2.6652\n",
      "Epoch [39/50] - Train Loss: 1.2946, Test Loss: 2.6654\n",
      "Epoch [40/50] - Train Loss: 1.2943, Test Loss: 2.6656\n",
      "Epoch [41/50] - Train Loss: 1.2940, Test Loss: 2.6658\n",
      "Epoch [42/50] - Train Loss: 1.2937, Test Loss: 2.6660\n",
      "Epoch [43/50] - Train Loss: 1.2934, Test Loss: 2.6662\n",
      "Epoch [44/50] - Train Loss: 1.2932, Test Loss: 2.6664\n",
      "Epoch [45/50] - Train Loss: 1.2929, Test Loss: 2.6666\n",
      "Epoch [46/50] - Train Loss: 1.2926, Test Loss: 2.6668\n",
      "Epoch [47/50] - Train Loss: 1.2923, Test Loss: 2.6670\n",
      "Epoch [48/50] - Train Loss: 1.2921, Test Loss: 2.6672\n",
      "Epoch [49/50] - Train Loss: 1.2918, Test Loss: 2.6674\n",
      "Epoch [50/50] - Train Loss: 1.2915, Test Loss: 2.6676\n",
      "Avg Test Loss: 2.6676\n",
      "Testing combination: (8, 2, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1613, Test Loss: 1.5005\n",
      "Epoch [2/50] - Train Loss: 1.1597, Test Loss: 1.4996\n",
      "Epoch [3/50] - Train Loss: 1.1582, Test Loss: 1.4986\n",
      "Epoch [4/50] - Train Loss: 1.1567, Test Loss: 1.4977\n",
      "Epoch [5/50] - Train Loss: 1.1552, Test Loss: 1.4967\n",
      "Epoch [6/50] - Train Loss: 1.1538, Test Loss: 1.4958\n",
      "Epoch [7/50] - Train Loss: 1.1524, Test Loss: 1.4949\n",
      "Epoch [8/50] - Train Loss: 1.1509, Test Loss: 1.4940\n",
      "Epoch [9/50] - Train Loss: 1.1495, Test Loss: 1.4932\n",
      "Epoch [10/50] - Train Loss: 1.1481, Test Loss: 1.4923\n",
      "Epoch [11/50] - Train Loss: 1.1466, Test Loss: 1.4915\n",
      "Epoch [12/50] - Train Loss: 1.1452, Test Loss: 1.4906\n",
      "Epoch [13/50] - Train Loss: 1.1438, Test Loss: 1.4898\n",
      "Epoch [14/50] - Train Loss: 1.1424, Test Loss: 1.4890\n",
      "Epoch [15/50] - Train Loss: 1.1410, Test Loss: 1.4882\n",
      "Epoch [16/50] - Train Loss: 1.1396, Test Loss: 1.4874\n",
      "Epoch [17/50] - Train Loss: 1.1382, Test Loss: 1.4866\n",
      "Epoch [18/50] - Train Loss: 1.1368, Test Loss: 1.4858\n",
      "Epoch [19/50] - Train Loss: 1.1354, Test Loss: 1.4851\n",
      "Epoch [20/50] - Train Loss: 1.1340, Test Loss: 1.4843\n",
      "Epoch [21/50] - Train Loss: 1.1327, Test Loss: 1.4836\n",
      "Epoch [22/50] - Train Loss: 1.1313, Test Loss: 1.4829\n",
      "Epoch [23/50] - Train Loss: 1.1299, Test Loss: 1.4822\n",
      "Epoch [24/50] - Train Loss: 1.1286, Test Loss: 1.4816\n",
      "Epoch [25/50] - Train Loss: 1.1272, Test Loss: 1.4809\n",
      "Epoch [26/50] - Train Loss: 1.1259, Test Loss: 1.4803\n",
      "Epoch [27/50] - Train Loss: 1.1246, Test Loss: 1.4797\n",
      "Epoch [28/50] - Train Loss: 1.1233, Test Loss: 1.4791\n",
      "Epoch [29/50] - Train Loss: 1.1220, Test Loss: 1.4786\n",
      "Epoch [30/50] - Train Loss: 1.1208, Test Loss: 1.4781\n",
      "Epoch [31/50] - Train Loss: 1.1196, Test Loss: 1.4776\n",
      "Epoch [32/50] - Train Loss: 1.1183, Test Loss: 1.4771\n",
      "Epoch [33/50] - Train Loss: 1.1172, Test Loss: 1.4766\n",
      "Epoch [34/50] - Train Loss: 1.1160, Test Loss: 1.4762\n",
      "Epoch [35/50] - Train Loss: 1.1149, Test Loss: 1.4758\n",
      "Epoch [36/50] - Train Loss: 1.1137, Test Loss: 1.4755\n",
      "Epoch [37/50] - Train Loss: 1.1126, Test Loss: 1.4752\n",
      "Epoch [38/50] - Train Loss: 1.1116, Test Loss: 1.4749\n",
      "Epoch [39/50] - Train Loss: 1.1105, Test Loss: 1.4746\n",
      "Epoch [40/50] - Train Loss: 1.1095, Test Loss: 1.4743\n",
      "Epoch [41/50] - Train Loss: 1.1086, Test Loss: 1.4741\n",
      "Epoch [42/50] - Train Loss: 1.1076, Test Loss: 1.4739\n",
      "Epoch [43/50] - Train Loss: 1.1067, Test Loss: 1.4738\n",
      "Epoch [44/50] - Train Loss: 1.1058, Test Loss: 1.4736\n",
      "Epoch [45/50] - Train Loss: 1.1049, Test Loss: 1.4735\n",
      "Epoch [46/50] - Train Loss: 1.1041, Test Loss: 1.4734\n",
      "Epoch [47/50] - Train Loss: 1.1033, Test Loss: 1.4734\n",
      "Epoch [48/50] - Train Loss: 1.1025, Test Loss: 1.4734\n",
      "Epoch [49/50] - Train Loss: 1.1018, Test Loss: 1.4733\n",
      "Epoch [50/50] - Train Loss: 1.1010, Test Loss: 1.4734\n",
      "Avg Test Loss: 1.4734\n",
      "Testing combination: (8, 2, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1658, Test Loss: 1.5763\n",
      "Epoch [2/50] - Train Loss: 1.1641, Test Loss: 1.5759\n",
      "Epoch [3/50] - Train Loss: 1.1626, Test Loss: 1.5755\n",
      "Epoch [4/50] - Train Loss: 1.1610, Test Loss: 1.5752\n",
      "Epoch [5/50] - Train Loss: 1.1595, Test Loss: 1.5749\n",
      "Epoch [6/50] - Train Loss: 1.1580, Test Loss: 1.5747\n",
      "Epoch [7/50] - Train Loss: 1.1566, Test Loss: 1.5744\n",
      "Epoch [8/50] - Train Loss: 1.1552, Test Loss: 1.5742\n",
      "Epoch [9/50] - Train Loss: 1.1538, Test Loss: 1.5740\n",
      "Epoch [10/50] - Train Loss: 1.1524, Test Loss: 1.5739\n",
      "Epoch [11/50] - Train Loss: 1.1511, Test Loss: 1.5738\n",
      "Epoch [12/50] - Train Loss: 1.1498, Test Loss: 1.5737\n",
      "Epoch [13/50] - Train Loss: 1.1485, Test Loss: 1.5736\n",
      "Epoch [14/50] - Train Loss: 1.1472, Test Loss: 1.5736\n",
      "Epoch [15/50] - Train Loss: 1.1460, Test Loss: 1.5736\n",
      "Epoch [16/50] - Train Loss: 1.1448, Test Loss: 1.5736\n",
      "Epoch [17/50] - Train Loss: 1.1436, Test Loss: 1.5737\n",
      "Epoch [18/50] - Train Loss: 1.1424, Test Loss: 1.5737\n",
      "Epoch [19/50] - Train Loss: 1.1413, Test Loss: 1.5738\n",
      "Epoch [20/50] - Train Loss: 1.1402, Test Loss: 1.5740\n",
      "Epoch [21/50] - Train Loss: 1.1391, Test Loss: 1.5741\n",
      "Epoch [22/50] - Train Loss: 1.1381, Test Loss: 1.5743\n",
      "Epoch [23/50] - Train Loss: 1.1370, Test Loss: 1.5745\n",
      "Epoch [24/50] - Train Loss: 1.1360, Test Loss: 1.5747\n",
      "Epoch [25/50] - Train Loss: 1.1351, Test Loss: 1.5750\n",
      "Epoch [26/50] - Train Loss: 1.1341, Test Loss: 1.5752\n",
      "Epoch [27/50] - Train Loss: 1.1332, Test Loss: 1.5755\n",
      "Epoch [28/50] - Train Loss: 1.1323, Test Loss: 1.5758\n",
      "Epoch [29/50] - Train Loss: 1.1314, Test Loss: 1.5762\n",
      "Epoch [30/50] - Train Loss: 1.1306, Test Loss: 1.5765\n",
      "Epoch [31/50] - Train Loss: 1.1298, Test Loss: 1.5769\n",
      "Epoch [32/50] - Train Loss: 1.1290, Test Loss: 1.5773\n",
      "Epoch [33/50] - Train Loss: 1.1283, Test Loss: 1.5777\n",
      "Epoch [34/50] - Train Loss: 1.1275, Test Loss: 1.5781\n",
      "Epoch [35/50] - Train Loss: 1.1268, Test Loss: 1.5786\n",
      "Epoch [36/50] - Train Loss: 1.1261, Test Loss: 1.5790\n",
      "Epoch [37/50] - Train Loss: 1.1255, Test Loss: 1.5795\n",
      "Epoch [38/50] - Train Loss: 1.1249, Test Loss: 1.5800\n",
      "Epoch [39/50] - Train Loss: 1.1242, Test Loss: 1.5805\n",
      "Epoch [40/50] - Train Loss: 1.1237, Test Loss: 1.5810\n",
      "Epoch [41/50] - Train Loss: 1.1231, Test Loss: 1.5815\n",
      "Epoch [42/50] - Train Loss: 1.1226, Test Loss: 1.5820\n",
      "Epoch [43/50] - Train Loss: 1.1221, Test Loss: 1.5825\n",
      "Epoch [44/50] - Train Loss: 1.1216, Test Loss: 1.5831\n",
      "Epoch [45/50] - Train Loss: 1.1211, Test Loss: 1.5836\n",
      "Epoch [46/50] - Train Loss: 1.1207, Test Loss: 1.5842\n",
      "Epoch [47/50] - Train Loss: 1.1202, Test Loss: 1.5847\n",
      "Epoch [48/50] - Train Loss: 1.1198, Test Loss: 1.5853\n",
      "Epoch [49/50] - Train Loss: 1.1194, Test Loss: 1.5858\n",
      "Epoch [50/50] - Train Loss: 1.1191, Test Loss: 1.5864\n",
      "Avg Test Loss: 1.5864\n",
      "Testing combination: (8, 2, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3022, Test Loss: 2.6740\n",
      "Epoch [2/50] - Train Loss: 1.3021, Test Loss: 2.6738\n",
      "Epoch [3/50] - Train Loss: 1.3021, Test Loss: 2.6737\n",
      "Epoch [4/50] - Train Loss: 1.3020, Test Loss: 2.6735\n",
      "Epoch [5/50] - Train Loss: 1.3020, Test Loss: 2.6734\n",
      "Epoch [6/50] - Train Loss: 1.3020, Test Loss: 2.6732\n",
      "Epoch [7/50] - Train Loss: 1.3020, Test Loss: 2.6731\n",
      "Epoch [8/50] - Train Loss: 1.3019, Test Loss: 2.6729\n",
      "Epoch [9/50] - Train Loss: 1.3019, Test Loss: 2.6728\n",
      "Epoch [10/50] - Train Loss: 1.3019, Test Loss: 2.6726\n",
      "Epoch [11/50] - Train Loss: 1.3019, Test Loss: 2.6725\n",
      "Epoch [12/50] - Train Loss: 1.3018, Test Loss: 2.6723\n",
      "Epoch [13/50] - Train Loss: 1.3018, Test Loss: 2.6722\n",
      "Epoch [14/50] - Train Loss: 1.3018, Test Loss: 2.6720\n",
      "Epoch [15/50] - Train Loss: 1.3018, Test Loss: 2.6719\n",
      "Epoch [16/50] - Train Loss: 1.3018, Test Loss: 2.6718\n",
      "Epoch [17/50] - Train Loss: 1.3017, Test Loss: 2.6716\n",
      "Epoch [18/50] - Train Loss: 1.3017, Test Loss: 2.6715\n",
      "Epoch [19/50] - Train Loss: 1.3017, Test Loss: 2.6714\n",
      "Epoch [20/50] - Train Loss: 1.3017, Test Loss: 2.6713\n",
      "Epoch [21/50] - Train Loss: 1.3016, Test Loss: 2.6711\n",
      "Epoch [22/50] - Train Loss: 1.3016, Test Loss: 2.6710\n",
      "Epoch [23/50] - Train Loss: 1.3016, Test Loss: 2.6709\n",
      "Epoch [24/50] - Train Loss: 1.3016, Test Loss: 2.6708\n",
      "Epoch [25/50] - Train Loss: 1.3016, Test Loss: 2.6707\n",
      "Epoch [26/50] - Train Loss: 1.3015, Test Loss: 2.6706\n",
      "Epoch [27/50] - Train Loss: 1.3015, Test Loss: 2.6704\n",
      "Epoch [28/50] - Train Loss: 1.3015, Test Loss: 2.6703\n",
      "Epoch [29/50] - Train Loss: 1.3015, Test Loss: 2.6702\n",
      "Epoch [30/50] - Train Loss: 1.3015, Test Loss: 2.6701\n",
      "Epoch [31/50] - Train Loss: 1.3014, Test Loss: 2.6700\n",
      "Epoch [32/50] - Train Loss: 1.3014, Test Loss: 2.6699\n",
      "Epoch [33/50] - Train Loss: 1.3014, Test Loss: 2.6698\n",
      "Epoch [34/50] - Train Loss: 1.3014, Test Loss: 2.6697\n",
      "Epoch [35/50] - Train Loss: 1.3014, Test Loss: 2.6696\n",
      "Epoch [36/50] - Train Loss: 1.3013, Test Loss: 2.6695\n",
      "Epoch [37/50] - Train Loss: 1.3013, Test Loss: 2.6694\n",
      "Epoch [38/50] - Train Loss: 1.3013, Test Loss: 2.6693\n",
      "Epoch [39/50] - Train Loss: 1.3013, Test Loss: 2.6692\n",
      "Epoch [40/50] - Train Loss: 1.3013, Test Loss: 2.6691\n",
      "Epoch [41/50] - Train Loss: 1.3012, Test Loss: 2.6691\n",
      "Epoch [42/50] - Train Loss: 1.3012, Test Loss: 2.6690\n",
      "Epoch [43/50] - Train Loss: 1.3012, Test Loss: 2.6689\n",
      "Epoch [44/50] - Train Loss: 1.3012, Test Loss: 2.6688\n",
      "Epoch [45/50] - Train Loss: 1.3012, Test Loss: 2.6687\n",
      "Epoch [46/50] - Train Loss: 1.3011, Test Loss: 2.6686\n",
      "Epoch [47/50] - Train Loss: 1.3011, Test Loss: 2.6686\n",
      "Epoch [48/50] - Train Loss: 1.3011, Test Loss: 2.6685\n",
      "Epoch [49/50] - Train Loss: 1.3011, Test Loss: 2.6684\n",
      "Epoch [50/50] - Train Loss: 1.3011, Test Loss: 2.6683\n",
      "Avg Test Loss: 2.6683\n",
      "Testing combination: (8, 3, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1461, Test Loss: 1.4794\n",
      "Epoch [2/50] - Train Loss: 1.1018, Test Loss: 1.4851\n",
      "Epoch [3/50] - Train Loss: 1.0980, Test Loss: 1.4842\n",
      "Epoch [4/50] - Train Loss: 1.0970, Test Loss: 1.4828\n",
      "Epoch [5/50] - Train Loss: 1.0968, Test Loss: 1.4826\n",
      "Epoch [6/50] - Train Loss: 1.0967, Test Loss: 1.4830\n",
      "Epoch [7/50] - Train Loss: 1.0964, Test Loss: 1.4832\n",
      "Epoch [8/50] - Train Loss: 1.0959, Test Loss: 1.4833\n",
      "Epoch [9/50] - Train Loss: 1.0953, Test Loss: 1.4832\n",
      "Epoch [10/50] - Train Loss: 1.0947, Test Loss: 1.4832\n",
      "Epoch [11/50] - Train Loss: 1.0935, Test Loss: 1.4833\n",
      "Epoch [12/50] - Train Loss: 1.0923, Test Loss: 1.4835\n",
      "Epoch [13/50] - Train Loss: 1.0901, Test Loss: 1.4840\n",
      "Epoch [14/50] - Train Loss: 1.0870, Test Loss: 1.4845\n",
      "Epoch [15/50] - Train Loss: 1.0807, Test Loss: 1.4848\n",
      "Epoch [16/50] - Train Loss: 1.0782, Test Loss: 1.4882\n",
      "Epoch [17/50] - Train Loss: 1.0723, Test Loss: 1.4864\n",
      "Epoch [18/50] - Train Loss: 1.0688, Test Loss: 1.4852\n",
      "Epoch [19/50] - Train Loss: 1.0650, Test Loss: 1.4856\n",
      "Epoch [20/50] - Train Loss: 1.0593, Test Loss: 1.4857\n",
      "Epoch [21/50] - Train Loss: 1.1132, Test Loss: 1.4869\n",
      "Epoch [22/50] - Train Loss: 1.0660, Test Loss: 1.4867\n",
      "Epoch [23/50] - Train Loss: 1.0655, Test Loss: 1.4870\n",
      "Epoch [24/50] - Train Loss: 1.0607, Test Loss: 1.4878\n",
      "Epoch [25/50] - Train Loss: 1.0574, Test Loss: 1.4872\n",
      "Epoch [26/50] - Train Loss: 1.0548, Test Loss: 1.4860\n",
      "Epoch [27/50] - Train Loss: 1.0537, Test Loss: 1.4856\n",
      "Epoch [28/50] - Train Loss: 1.0531, Test Loss: 1.4858\n",
      "Epoch [29/50] - Train Loss: 1.0527, Test Loss: 1.4860\n",
      "Epoch [30/50] - Train Loss: 1.0522, Test Loss: 1.4859\n",
      "Epoch [31/50] - Train Loss: 1.0518, Test Loss: 1.4859\n",
      "Epoch [32/50] - Train Loss: 1.0513, Test Loss: 1.4859\n",
      "Epoch [33/50] - Train Loss: 1.0509, Test Loss: 1.4859\n",
      "Epoch [34/50] - Train Loss: 1.0505, Test Loss: 1.4858\n",
      "Epoch [35/50] - Train Loss: 1.0501, Test Loss: 1.4857\n",
      "Epoch [36/50] - Train Loss: 1.0497, Test Loss: 1.4856\n",
      "Epoch [37/50] - Train Loss: 1.0493, Test Loss: 1.4854\n",
      "Epoch [38/50] - Train Loss: 1.0490, Test Loss: 1.4853\n",
      "Epoch [39/50] - Train Loss: 1.0487, Test Loss: 1.4851\n",
      "Epoch [40/50] - Train Loss: 1.0483, Test Loss: 1.4850\n",
      "Epoch [41/50] - Train Loss: 1.0480, Test Loss: 1.4849\n",
      "Epoch [42/50] - Train Loss: 1.0477, Test Loss: 1.4848\n",
      "Epoch [43/50] - Train Loss: 1.0474, Test Loss: 1.4847\n",
      "Epoch [44/50] - Train Loss: 1.0471, Test Loss: 1.4847\n",
      "Epoch [45/50] - Train Loss: 1.0467, Test Loss: 1.4846\n",
      "Epoch [46/50] - Train Loss: 1.0464, Test Loss: 1.4846\n",
      "Epoch [47/50] - Train Loss: 1.0460, Test Loss: 1.4845\n",
      "Epoch [48/50] - Train Loss: 1.0457, Test Loss: 1.4845\n",
      "Epoch [49/50] - Train Loss: 1.0453, Test Loss: 1.4844\n",
      "Epoch [50/50] - Train Loss: 1.0450, Test Loss: 1.4843\n",
      "Avg Test Loss: 1.4843\n",
      "Testing combination: (8, 3, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1257, Test Loss: 1.6130\n",
      "Epoch [2/50] - Train Loss: 1.1157, Test Loss: 1.5979\n",
      "Epoch [3/50] - Train Loss: 1.1168, Test Loss: 1.6028\n",
      "Epoch [4/50] - Train Loss: 1.1163, Test Loss: 1.6095\n",
      "Epoch [5/50] - Train Loss: 1.1159, Test Loss: 1.6118\n",
      "Epoch [6/50] - Train Loss: 1.1156, Test Loss: 1.6106\n",
      "Epoch [7/50] - Train Loss: 1.1154, Test Loss: 1.6088\n",
      "Epoch [8/50] - Train Loss: 1.1152, Test Loss: 1.6080\n",
      "Epoch [9/50] - Train Loss: 1.1150, Test Loss: 1.6079\n",
      "Epoch [10/50] - Train Loss: 1.1147, Test Loss: 1.6080\n",
      "Epoch [11/50] - Train Loss: 1.1143, Test Loss: 1.6078\n",
      "Epoch [12/50] - Train Loss: 1.1135, Test Loss: 1.6073\n",
      "Epoch [13/50] - Train Loss: 1.1125, Test Loss: 1.6065\n",
      "Epoch [14/50] - Train Loss: 1.1111, Test Loss: 1.6056\n",
      "Epoch [15/50] - Train Loss: 1.1101, Test Loss: 1.6050\n",
      "Epoch [16/50] - Train Loss: 1.1091, Test Loss: 1.6048\n",
      "Epoch [17/50] - Train Loss: 1.1085, Test Loss: 1.6047\n",
      "Epoch [18/50] - Train Loss: 1.1079, Test Loss: 1.6049\n",
      "Epoch [19/50] - Train Loss: 1.1067, Test Loss: 1.6061\n",
      "Epoch [20/50] - Train Loss: 1.1046, Test Loss: 1.6096\n",
      "Epoch [21/50] - Train Loss: 1.1005, Test Loss: 1.6136\n",
      "Epoch [22/50] - Train Loss: 1.0950, Test Loss: 1.6140\n",
      "Epoch [23/50] - Train Loss: 1.0891, Test Loss: 1.6124\n",
      "Epoch [24/50] - Train Loss: 1.0821, Test Loss: 1.6129\n",
      "Epoch [25/50] - Train Loss: 1.0804, Test Loss: 1.6135\n",
      "Epoch [26/50] - Train Loss: 1.0795, Test Loss: 1.6121\n",
      "Epoch [27/50] - Train Loss: 1.0791, Test Loss: 1.6123\n",
      "Epoch [28/50] - Train Loss: 1.0790, Test Loss: 1.6133\n",
      "Epoch [29/50] - Train Loss: 1.0788, Test Loss: 1.6136\n",
      "Epoch [30/50] - Train Loss: 1.0787, Test Loss: 1.6133\n",
      "Epoch [31/50] - Train Loss: 1.0786, Test Loss: 1.6133\n",
      "Epoch [32/50] - Train Loss: 1.0786, Test Loss: 1.6135\n",
      "Epoch [33/50] - Train Loss: 1.0785, Test Loss: 1.6137\n",
      "Epoch [34/50] - Train Loss: 1.0785, Test Loss: 1.6137\n",
      "Epoch [35/50] - Train Loss: 1.0784, Test Loss: 1.6136\n",
      "Epoch [36/50] - Train Loss: 1.0784, Test Loss: 1.6136\n",
      "Epoch [37/50] - Train Loss: 1.0784, Test Loss: 1.6137\n",
      "Epoch [38/50] - Train Loss: 1.0783, Test Loss: 1.6138\n",
      "Epoch [39/50] - Train Loss: 1.0783, Test Loss: 1.6138\n",
      "Epoch [40/50] - Train Loss: 1.0783, Test Loss: 1.6138\n",
      "Epoch [41/50] - Train Loss: 1.0783, Test Loss: 1.6138\n",
      "Epoch [42/50] - Train Loss: 1.0782, Test Loss: 1.6138\n",
      "Epoch [43/50] - Train Loss: 1.0782, Test Loss: 1.6139\n",
      "Epoch [44/50] - Train Loss: 1.0782, Test Loss: 1.6139\n",
      "Epoch [45/50] - Train Loss: 1.0782, Test Loss: 1.6139\n",
      "Epoch [46/50] - Train Loss: 1.0782, Test Loss: 1.6139\n",
      "Epoch [47/50] - Train Loss: 1.0781, Test Loss: 1.6140\n",
      "Epoch [48/50] - Train Loss: 1.0781, Test Loss: 1.6140\n",
      "Epoch [49/50] - Train Loss: 1.0781, Test Loss: 1.6140\n",
      "Epoch [50/50] - Train Loss: 1.0781, Test Loss: 1.6140\n",
      "Avg Test Loss: 1.6140\n",
      "Testing combination: (8, 3, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3212, Test Loss: 2.6639\n",
      "Epoch [2/50] - Train Loss: 1.3050, Test Loss: 2.6445\n",
      "Epoch [3/50] - Train Loss: 1.3057, Test Loss: 2.6517\n",
      "Epoch [4/50] - Train Loss: 1.3037, Test Loss: 2.6644\n",
      "Epoch [5/50] - Train Loss: 1.3030, Test Loss: 2.6725\n",
      "Epoch [6/50] - Train Loss: 1.3029, Test Loss: 2.6729\n",
      "Epoch [7/50] - Train Loss: 1.3025, Test Loss: 2.6686\n",
      "Epoch [8/50] - Train Loss: 1.3022, Test Loss: 2.6637\n",
      "Epoch [9/50] - Train Loss: 1.3022, Test Loss: 2.6607\n",
      "Epoch [10/50] - Train Loss: 1.3023, Test Loss: 2.6601\n",
      "Epoch [11/50] - Train Loss: 1.3023, Test Loss: 2.6613\n",
      "Epoch [12/50] - Train Loss: 1.3021, Test Loss: 2.6632\n",
      "Epoch [13/50] - Train Loss: 1.3020, Test Loss: 2.6648\n",
      "Epoch [14/50] - Train Loss: 1.3018, Test Loss: 2.6655\n",
      "Epoch [15/50] - Train Loss: 1.3016, Test Loss: 2.6654\n",
      "Epoch [16/50] - Train Loss: 1.3014, Test Loss: 2.6649\n",
      "Epoch [17/50] - Train Loss: 1.3011, Test Loss: 2.6645\n",
      "Epoch [18/50] - Train Loss: 1.3006, Test Loss: 2.6645\n",
      "Epoch [19/50] - Train Loss: 1.2999, Test Loss: 2.6652\n",
      "Epoch [20/50] - Train Loss: 1.2988, Test Loss: 2.6664\n",
      "Epoch [21/50] - Train Loss: 1.2972, Test Loss: 2.6681\n",
      "Epoch [22/50] - Train Loss: 1.2951, Test Loss: 2.6698\n",
      "Epoch [23/50] - Train Loss: 1.2931, Test Loss: 2.6712\n",
      "Epoch [24/50] - Train Loss: 1.2912, Test Loss: 2.6716\n",
      "Epoch [25/50] - Train Loss: 1.2898, Test Loss: 2.6716\n",
      "Epoch [26/50] - Train Loss: 1.2894, Test Loss: 2.6717\n",
      "Epoch [27/50] - Train Loss: 1.2896, Test Loss: 2.6723\n",
      "Epoch [28/50] - Train Loss: 1.2895, Test Loss: 2.6759\n",
      "Epoch [29/50] - Train Loss: 1.3052, Test Loss: 2.6728\n",
      "Epoch [30/50] - Train Loss: 1.3041, Test Loss: 2.6639\n",
      "Epoch [31/50] - Train Loss: 1.3034, Test Loss: 2.6607\n",
      "Epoch [32/50] - Train Loss: 1.3025, Test Loss: 2.6630\n",
      "Epoch [33/50] - Train Loss: 1.3014, Test Loss: 2.6649\n",
      "Epoch [34/50] - Train Loss: 1.3004, Test Loss: 2.6624\n",
      "Epoch [35/50] - Train Loss: 1.2994, Test Loss: 2.6563\n",
      "Epoch [36/50] - Train Loss: 1.2977, Test Loss: 2.6488\n",
      "Epoch [37/50] - Train Loss: 1.2946, Test Loss: 2.6449\n",
      "Epoch [38/50] - Train Loss: 1.2906, Test Loss: 2.6330\n",
      "Epoch [39/50] - Train Loss: 1.2834, Test Loss: 2.6097\n",
      "Epoch [40/50] - Train Loss: 1.2722, Test Loss: 2.5687\n",
      "Epoch [41/50] - Train Loss: 1.2311, Test Loss: 2.7230\n",
      "Epoch [42/50] - Train Loss: 1.2986, Test Loss: 2.7610\n",
      "Epoch [43/50] - Train Loss: 1.4023, Test Loss: 2.6622\n",
      "Epoch [44/50] - Train Loss: 1.2978, Test Loss: 2.5871\n",
      "Epoch [45/50] - Train Loss: 1.2726, Test Loss: 2.6303\n",
      "Epoch [46/50] - Train Loss: 1.2880, Test Loss: 2.6390\n",
      "Epoch [47/50] - Train Loss: 1.2790, Test Loss: 2.6175\n",
      "Epoch [48/50] - Train Loss: 1.2643, Test Loss: 2.5995\n",
      "Epoch [49/50] - Train Loss: 1.2492, Test Loss: 2.5612\n",
      "Epoch [50/50] - Train Loss: 1.2204, Test Loss: 2.5233\n",
      "Avg Test Loss: 2.5233\n",
      "Testing combination: (8, 3, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1639, Test Loss: 1.6153\n",
      "Epoch [2/50] - Train Loss: 1.1487, Test Loss: 1.5931\n",
      "Epoch [3/50] - Train Loss: 1.1359, Test Loss: 1.5730\n",
      "Epoch [4/50] - Train Loss: 1.1249, Test Loss: 1.5548\n",
      "Epoch [5/50] - Train Loss: 1.1153, Test Loss: 1.5381\n",
      "Epoch [6/50] - Train Loss: 1.1071, Test Loss: 1.5230\n",
      "Epoch [7/50] - Train Loss: 1.1006, Test Loss: 1.5102\n",
      "Epoch [8/50] - Train Loss: 1.0961, Test Loss: 1.5004\n",
      "Epoch [9/50] - Train Loss: 1.0934, Test Loss: 1.4935\n",
      "Epoch [10/50] - Train Loss: 1.0921, Test Loss: 1.4892\n",
      "Epoch [11/50] - Train Loss: 1.0915, Test Loss: 1.4867\n",
      "Epoch [12/50] - Train Loss: 1.0912, Test Loss: 1.4853\n",
      "Epoch [13/50] - Train Loss: 1.0910, Test Loss: 1.4845\n",
      "Epoch [14/50] - Train Loss: 1.0909, Test Loss: 1.4841\n",
      "Epoch [15/50] - Train Loss: 1.0908, Test Loss: 1.4839\n",
      "Epoch [16/50] - Train Loss: 1.0907, Test Loss: 1.4838\n",
      "Epoch [17/50] - Train Loss: 1.0905, Test Loss: 1.4837\n",
      "Epoch [18/50] - Train Loss: 1.0904, Test Loss: 1.4837\n",
      "Epoch [19/50] - Train Loss: 1.0902, Test Loss: 1.4836\n",
      "Epoch [20/50] - Train Loss: 1.0900, Test Loss: 1.4836\n",
      "Epoch [21/50] - Train Loss: 1.0899, Test Loss: 1.4835\n",
      "Epoch [22/50] - Train Loss: 1.0897, Test Loss: 1.4835\n",
      "Epoch [23/50] - Train Loss: 1.0895, Test Loss: 1.4834\n",
      "Epoch [24/50] - Train Loss: 1.0893, Test Loss: 1.4834\n",
      "Epoch [25/50] - Train Loss: 1.0891, Test Loss: 1.4833\n",
      "Epoch [26/50] - Train Loss: 1.0889, Test Loss: 1.4833\n",
      "Epoch [27/50] - Train Loss: 1.0887, Test Loss: 1.4832\n",
      "Epoch [28/50] - Train Loss: 1.0885, Test Loss: 1.4832\n",
      "Epoch [29/50] - Train Loss: 1.0882, Test Loss: 1.4831\n",
      "Epoch [30/50] - Train Loss: 1.0879, Test Loss: 1.4831\n",
      "Epoch [31/50] - Train Loss: 1.0876, Test Loss: 1.4830\n",
      "Epoch [32/50] - Train Loss: 1.0874, Test Loss: 1.4830\n",
      "Epoch [33/50] - Train Loss: 1.0872, Test Loss: 1.4829\n",
      "Epoch [34/50] - Train Loss: 1.0870, Test Loss: 1.4829\n",
      "Epoch [35/50] - Train Loss: 1.0868, Test Loss: 1.4829\n",
      "Epoch [36/50] - Train Loss: 1.0866, Test Loss: 1.4829\n",
      "Epoch [37/50] - Train Loss: 1.0864, Test Loss: 1.4829\n",
      "Epoch [38/50] - Train Loss: 1.0862, Test Loss: 1.4829\n",
      "Epoch [39/50] - Train Loss: 1.0860, Test Loss: 1.4829\n",
      "Epoch [40/50] - Train Loss: 1.0858, Test Loss: 1.4829\n",
      "Epoch [41/50] - Train Loss: 1.0856, Test Loss: 1.4829\n",
      "Epoch [42/50] - Train Loss: 1.0854, Test Loss: 1.4829\n",
      "Epoch [43/50] - Train Loss: 1.0852, Test Loss: 1.4829\n",
      "Epoch [44/50] - Train Loss: 1.0850, Test Loss: 1.4829\n",
      "Epoch [45/50] - Train Loss: 1.0847, Test Loss: 1.4830\n",
      "Epoch [46/50] - Train Loss: 1.0844, Test Loss: 1.4830\n",
      "Epoch [47/50] - Train Loss: 1.0842, Test Loss: 1.4830\n",
      "Epoch [48/50] - Train Loss: 1.0838, Test Loss: 1.4831\n",
      "Epoch [49/50] - Train Loss: 1.0835, Test Loss: 1.4832\n",
      "Epoch [50/50] - Train Loss: 1.0831, Test Loss: 1.4832\n",
      "Avg Test Loss: 1.4832\n",
      "Testing combination: (8, 3, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.2259, Test Loss: 1.5967\n",
      "Epoch [2/50] - Train Loss: 1.2085, Test Loss: 1.5888\n",
      "Epoch [3/50] - Train Loss: 1.1927, Test Loss: 1.5823\n",
      "Epoch [4/50] - Train Loss: 1.1774, Test Loss: 1.5772\n",
      "Epoch [5/50] - Train Loss: 1.1625, Test Loss: 1.5742\n",
      "Epoch [6/50] - Train Loss: 1.1484, Test Loss: 1.5739\n",
      "Epoch [7/50] - Train Loss: 1.1359, Test Loss: 1.5771\n",
      "Epoch [8/50] - Train Loss: 1.1261, Test Loss: 1.5840\n",
      "Epoch [9/50] - Train Loss: 1.1197, Test Loss: 1.5932\n",
      "Epoch [10/50] - Train Loss: 1.1164, Test Loss: 1.6020\n",
      "Epoch [11/50] - Train Loss: 1.1152, Test Loss: 1.6082\n",
      "Epoch [12/50] - Train Loss: 1.1148, Test Loss: 1.6113\n",
      "Epoch [13/50] - Train Loss: 1.1147, Test Loss: 1.6121\n",
      "Epoch [14/50] - Train Loss: 1.1146, Test Loss: 1.6117\n",
      "Epoch [15/50] - Train Loss: 1.1145, Test Loss: 1.6109\n",
      "Epoch [16/50] - Train Loss: 1.1145, Test Loss: 1.6103\n",
      "Epoch [17/50] - Train Loss: 1.1145, Test Loss: 1.6098\n",
      "Epoch [18/50] - Train Loss: 1.1145, Test Loss: 1.6095\n",
      "Epoch [19/50] - Train Loss: 1.1145, Test Loss: 1.6093\n",
      "Epoch [20/50] - Train Loss: 1.1144, Test Loss: 1.6093\n",
      "Epoch [21/50] - Train Loss: 1.1144, Test Loss: 1.6093\n",
      "Epoch [22/50] - Train Loss: 1.1144, Test Loss: 1.6094\n",
      "Epoch [23/50] - Train Loss: 1.1144, Test Loss: 1.6094\n",
      "Epoch [24/50] - Train Loss: 1.1144, Test Loss: 1.6094\n",
      "Epoch [25/50] - Train Loss: 1.1143, Test Loss: 1.6094\n",
      "Epoch [26/50] - Train Loss: 1.1143, Test Loss: 1.6095\n",
      "Epoch [27/50] - Train Loss: 1.1143, Test Loss: 1.6095\n",
      "Epoch [28/50] - Train Loss: 1.1143, Test Loss: 1.6095\n",
      "Epoch [29/50] - Train Loss: 1.1142, Test Loss: 1.6095\n",
      "Epoch [30/50] - Train Loss: 1.1142, Test Loss: 1.6095\n",
      "Epoch [31/50] - Train Loss: 1.1142, Test Loss: 1.6095\n",
      "Epoch [32/50] - Train Loss: 1.1141, Test Loss: 1.6095\n",
      "Epoch [33/50] - Train Loss: 1.1141, Test Loss: 1.6095\n",
      "Epoch [34/50] - Train Loss: 1.1140, Test Loss: 1.6095\n",
      "Epoch [35/50] - Train Loss: 1.1140, Test Loss: 1.6095\n",
      "Epoch [36/50] - Train Loss: 1.1139, Test Loss: 1.6095\n",
      "Epoch [37/50] - Train Loss: 1.1138, Test Loss: 1.6095\n",
      "Epoch [38/50] - Train Loss: 1.1138, Test Loss: 1.6095\n",
      "Epoch [39/50] - Train Loss: 1.1137, Test Loss: 1.6095\n",
      "Epoch [40/50] - Train Loss: 1.1136, Test Loss: 1.6094\n",
      "Epoch [41/50] - Train Loss: 1.1135, Test Loss: 1.6094\n",
      "Epoch [42/50] - Train Loss: 1.1134, Test Loss: 1.6094\n",
      "Epoch [43/50] - Train Loss: 1.1133, Test Loss: 1.6093\n",
      "Epoch [44/50] - Train Loss: 1.1131, Test Loss: 1.6093\n",
      "Epoch [45/50] - Train Loss: 1.1130, Test Loss: 1.6092\n",
      "Epoch [46/50] - Train Loss: 1.1129, Test Loss: 1.6092\n",
      "Epoch [47/50] - Train Loss: 1.1127, Test Loss: 1.6091\n",
      "Epoch [48/50] - Train Loss: 1.1126, Test Loss: 1.6090\n",
      "Epoch [49/50] - Train Loss: 1.1124, Test Loss: 1.6089\n",
      "Epoch [50/50] - Train Loss: 1.1122, Test Loss: 1.6089\n",
      "Avg Test Loss: 1.6089\n",
      "Testing combination: (8, 3, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3255, Test Loss: 2.7535\n",
      "Epoch [2/50] - Train Loss: 1.3175, Test Loss: 2.7327\n",
      "Epoch [3/50] - Train Loss: 1.3120, Test Loss: 2.7157\n",
      "Epoch [4/50] - Train Loss: 1.3080, Test Loss: 2.7017\n",
      "Epoch [5/50] - Train Loss: 1.3052, Test Loss: 2.6905\n",
      "Epoch [6/50] - Train Loss: 1.3034, Test Loss: 2.6817\n",
      "Epoch [7/50] - Train Loss: 1.3023, Test Loss: 2.6749\n",
      "Epoch [8/50] - Train Loss: 1.3017, Test Loss: 2.6698\n",
      "Epoch [9/50] - Train Loss: 1.3014, Test Loss: 2.6661\n",
      "Epoch [10/50] - Train Loss: 1.3013, Test Loss: 2.6635\n",
      "Epoch [11/50] - Train Loss: 1.3013, Test Loss: 2.6618\n",
      "Epoch [12/50] - Train Loss: 1.3013, Test Loss: 2.6609\n",
      "Epoch [13/50] - Train Loss: 1.3013, Test Loss: 2.6604\n",
      "Epoch [14/50] - Train Loss: 1.3012, Test Loss: 2.6604\n",
      "Epoch [15/50] - Train Loss: 1.3012, Test Loss: 2.6605\n",
      "Epoch [16/50] - Train Loss: 1.3011, Test Loss: 2.6609\n",
      "Epoch [17/50] - Train Loss: 1.3011, Test Loss: 2.6613\n",
      "Epoch [18/50] - Train Loss: 1.3010, Test Loss: 2.6617\n",
      "Epoch [19/50] - Train Loss: 1.3009, Test Loss: 2.6621\n",
      "Epoch [20/50] - Train Loss: 1.3009, Test Loss: 2.6625\n",
      "Epoch [21/50] - Train Loss: 1.3008, Test Loss: 2.6628\n",
      "Epoch [22/50] - Train Loss: 1.3007, Test Loss: 2.6630\n",
      "Epoch [23/50] - Train Loss: 1.3006, Test Loss: 2.6633\n",
      "Epoch [24/50] - Train Loss: 1.3006, Test Loss: 2.6634\n",
      "Epoch [25/50] - Train Loss: 1.3005, Test Loss: 2.6635\n",
      "Epoch [26/50] - Train Loss: 1.3004, Test Loss: 2.6636\n",
      "Epoch [27/50] - Train Loss: 1.3003, Test Loss: 2.6636\n",
      "Epoch [28/50] - Train Loss: 1.3002, Test Loss: 2.6637\n",
      "Epoch [29/50] - Train Loss: 1.3001, Test Loss: 2.6637\n",
      "Epoch [30/50] - Train Loss: 1.3000, Test Loss: 2.6637\n",
      "Epoch [31/50] - Train Loss: 1.2999, Test Loss: 2.6637\n",
      "Epoch [32/50] - Train Loss: 1.2998, Test Loss: 2.6638\n",
      "Epoch [33/50] - Train Loss: 1.2997, Test Loss: 2.6638\n",
      "Epoch [34/50] - Train Loss: 1.2995, Test Loss: 2.6638\n",
      "Epoch [35/50] - Train Loss: 1.2994, Test Loss: 2.6639\n",
      "Epoch [36/50] - Train Loss: 1.2993, Test Loss: 2.6639\n",
      "Epoch [37/50] - Train Loss: 1.2991, Test Loss: 2.6639\n",
      "Epoch [38/50] - Train Loss: 1.2990, Test Loss: 2.6640\n",
      "Epoch [39/50] - Train Loss: 1.2988, Test Loss: 2.6641\n",
      "Epoch [40/50] - Train Loss: 1.2986, Test Loss: 2.6641\n",
      "Epoch [41/50] - Train Loss: 1.2984, Test Loss: 2.6642\n",
      "Epoch [42/50] - Train Loss: 1.2982, Test Loss: 2.6643\n",
      "Epoch [43/50] - Train Loss: 1.2980, Test Loss: 2.6644\n",
      "Epoch [44/50] - Train Loss: 1.2977, Test Loss: 2.6645\n",
      "Epoch [45/50] - Train Loss: 1.2975, Test Loss: 2.6646\n",
      "Epoch [46/50] - Train Loss: 1.2972, Test Loss: 2.6647\n",
      "Epoch [47/50] - Train Loss: 1.2969, Test Loss: 2.6648\n",
      "Epoch [48/50] - Train Loss: 1.2965, Test Loss: 2.6649\n",
      "Epoch [49/50] - Train Loss: 1.2961, Test Loss: 2.6650\n",
      "Epoch [50/50] - Train Loss: 1.2957, Test Loss: 2.6651\n",
      "Avg Test Loss: 2.6651\n",
      "Testing combination: (8, 3, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.0960, Test Loss: 1.4767\n",
      "Epoch [2/50] - Train Loss: 1.0957, Test Loss: 1.4768\n",
      "Epoch [3/50] - Train Loss: 1.0956, Test Loss: 1.4769\n",
      "Epoch [4/50] - Train Loss: 1.0955, Test Loss: 1.4771\n",
      "Epoch [5/50] - Train Loss: 1.0954, Test Loss: 1.4772\n",
      "Epoch [6/50] - Train Loss: 1.0953, Test Loss: 1.4773\n",
      "Epoch [7/50] - Train Loss: 1.0953, Test Loss: 1.4774\n",
      "Epoch [8/50] - Train Loss: 1.0952, Test Loss: 1.4775\n",
      "Epoch [9/50] - Train Loss: 1.0951, Test Loss: 1.4776\n",
      "Epoch [10/50] - Train Loss: 1.0950, Test Loss: 1.4777\n",
      "Epoch [11/50] - Train Loss: 1.0950, Test Loss: 1.4778\n",
      "Epoch [12/50] - Train Loss: 1.0949, Test Loss: 1.4779\n",
      "Epoch [13/50] - Train Loss: 1.0948, Test Loss: 1.4780\n",
      "Epoch [14/50] - Train Loss: 1.0948, Test Loss: 1.4782\n",
      "Epoch [15/50] - Train Loss: 1.0947, Test Loss: 1.4783\n",
      "Epoch [16/50] - Train Loss: 1.0946, Test Loss: 1.4784\n",
      "Epoch [17/50] - Train Loss: 1.0946, Test Loss: 1.4785\n",
      "Epoch [18/50] - Train Loss: 1.0945, Test Loss: 1.4786\n",
      "Epoch [19/50] - Train Loss: 1.0945, Test Loss: 1.4787\n",
      "Epoch [20/50] - Train Loss: 1.0944, Test Loss: 1.4788\n",
      "Epoch [21/50] - Train Loss: 1.0944, Test Loss: 1.4789\n",
      "Epoch [22/50] - Train Loss: 1.0943, Test Loss: 1.4790\n",
      "Epoch [23/50] - Train Loss: 1.0943, Test Loss: 1.4791\n",
      "Epoch [24/50] - Train Loss: 1.0942, Test Loss: 1.4792\n",
      "Epoch [25/50] - Train Loss: 1.0942, Test Loss: 1.4793\n",
      "Epoch [26/50] - Train Loss: 1.0941, Test Loss: 1.4793\n",
      "Epoch [27/50] - Train Loss: 1.0941, Test Loss: 1.4794\n",
      "Epoch [28/50] - Train Loss: 1.0941, Test Loss: 1.4795\n",
      "Epoch [29/50] - Train Loss: 1.0940, Test Loss: 1.4796\n",
      "Epoch [30/50] - Train Loss: 1.0940, Test Loss: 1.4797\n",
      "Epoch [31/50] - Train Loss: 1.0939, Test Loss: 1.4798\n",
      "Epoch [32/50] - Train Loss: 1.0939, Test Loss: 1.4799\n",
      "Epoch [33/50] - Train Loss: 1.0939, Test Loss: 1.4800\n",
      "Epoch [34/50] - Train Loss: 1.0938, Test Loss: 1.4801\n",
      "Epoch [35/50] - Train Loss: 1.0938, Test Loss: 1.4801\n",
      "Epoch [36/50] - Train Loss: 1.0938, Test Loss: 1.4802\n",
      "Epoch [37/50] - Train Loss: 1.0937, Test Loss: 1.4803\n",
      "Epoch [38/50] - Train Loss: 1.0937, Test Loss: 1.4804\n",
      "Epoch [39/50] - Train Loss: 1.0937, Test Loss: 1.4805\n",
      "Epoch [40/50] - Train Loss: 1.0936, Test Loss: 1.4805\n",
      "Epoch [41/50] - Train Loss: 1.0936, Test Loss: 1.4806\n",
      "Epoch [42/50] - Train Loss: 1.0936, Test Loss: 1.4807\n",
      "Epoch [43/50] - Train Loss: 1.0936, Test Loss: 1.4808\n",
      "Epoch [44/50] - Train Loss: 1.0935, Test Loss: 1.4809\n",
      "Epoch [45/50] - Train Loss: 1.0935, Test Loss: 1.4809\n",
      "Epoch [46/50] - Train Loss: 1.0935, Test Loss: 1.4810\n",
      "Epoch [47/50] - Train Loss: 1.0934, Test Loss: 1.4811\n",
      "Epoch [48/50] - Train Loss: 1.0934, Test Loss: 1.4811\n",
      "Epoch [49/50] - Train Loss: 1.0934, Test Loss: 1.4812\n",
      "Epoch [50/50] - Train Loss: 1.0933, Test Loss: 1.4813\n",
      "Avg Test Loss: 1.4813\n",
      "Testing combination: (8, 3, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1291, Test Loss: 1.6764\n",
      "Epoch [2/50] - Train Loss: 1.1284, Test Loss: 1.6746\n",
      "Epoch [3/50] - Train Loss: 1.1278, Test Loss: 1.6728\n",
      "Epoch [4/50] - Train Loss: 1.1272, Test Loss: 1.6711\n",
      "Epoch [5/50] - Train Loss: 1.1266, Test Loss: 1.6694\n",
      "Epoch [6/50] - Train Loss: 1.1261, Test Loss: 1.6678\n",
      "Epoch [7/50] - Train Loss: 1.1256, Test Loss: 1.6662\n",
      "Epoch [8/50] - Train Loss: 1.1251, Test Loss: 1.6646\n",
      "Epoch [9/50] - Train Loss: 1.1246, Test Loss: 1.6631\n",
      "Epoch [10/50] - Train Loss: 1.1241, Test Loss: 1.6616\n",
      "Epoch [11/50] - Train Loss: 1.1237, Test Loss: 1.6602\n",
      "Epoch [12/50] - Train Loss: 1.1232, Test Loss: 1.6588\n",
      "Epoch [13/50] - Train Loss: 1.1228, Test Loss: 1.6574\n",
      "Epoch [14/50] - Train Loss: 1.1224, Test Loss: 1.6561\n",
      "Epoch [15/50] - Train Loss: 1.1221, Test Loss: 1.6548\n",
      "Epoch [16/50] - Train Loss: 1.1217, Test Loss: 1.6535\n",
      "Epoch [17/50] - Train Loss: 1.1214, Test Loss: 1.6523\n",
      "Epoch [18/50] - Train Loss: 1.1210, Test Loss: 1.6511\n",
      "Epoch [19/50] - Train Loss: 1.1207, Test Loss: 1.6499\n",
      "Epoch [20/50] - Train Loss: 1.1204, Test Loss: 1.6488\n",
      "Epoch [21/50] - Train Loss: 1.1201, Test Loss: 1.6477\n",
      "Epoch [22/50] - Train Loss: 1.1198, Test Loss: 1.6466\n",
      "Epoch [23/50] - Train Loss: 1.1196, Test Loss: 1.6456\n",
      "Epoch [24/50] - Train Loss: 1.1193, Test Loss: 1.6446\n",
      "Epoch [25/50] - Train Loss: 1.1191, Test Loss: 1.6436\n",
      "Epoch [26/50] - Train Loss: 1.1188, Test Loss: 1.6426\n",
      "Epoch [27/50] - Train Loss: 1.1186, Test Loss: 1.6417\n",
      "Epoch [28/50] - Train Loss: 1.1184, Test Loss: 1.6408\n",
      "Epoch [29/50] - Train Loss: 1.1182, Test Loss: 1.6399\n",
      "Epoch [30/50] - Train Loss: 1.1180, Test Loss: 1.6390\n",
      "Epoch [31/50] - Train Loss: 1.1178, Test Loss: 1.6382\n",
      "Epoch [32/50] - Train Loss: 1.1176, Test Loss: 1.6374\n",
      "Epoch [33/50] - Train Loss: 1.1175, Test Loss: 1.6366\n",
      "Epoch [34/50] - Train Loss: 1.1173, Test Loss: 1.6358\n",
      "Epoch [35/50] - Train Loss: 1.1172, Test Loss: 1.6350\n",
      "Epoch [36/50] - Train Loss: 1.1170, Test Loss: 1.6343\n",
      "Epoch [37/50] - Train Loss: 1.1169, Test Loss: 1.6336\n",
      "Epoch [38/50] - Train Loss: 1.1167, Test Loss: 1.6329\n",
      "Epoch [39/50] - Train Loss: 1.1166, Test Loss: 1.6323\n",
      "Epoch [40/50] - Train Loss: 1.1165, Test Loss: 1.6316\n",
      "Epoch [41/50] - Train Loss: 1.1164, Test Loss: 1.6310\n",
      "Epoch [42/50] - Train Loss: 1.1163, Test Loss: 1.6304\n",
      "Epoch [43/50] - Train Loss: 1.1162, Test Loss: 1.6298\n",
      "Epoch [44/50] - Train Loss: 1.1161, Test Loss: 1.6292\n",
      "Epoch [45/50] - Train Loss: 1.1160, Test Loss: 1.6286\n",
      "Epoch [46/50] - Train Loss: 1.1159, Test Loss: 1.6281\n",
      "Epoch [47/50] - Train Loss: 1.1158, Test Loss: 1.6276\n",
      "Epoch [48/50] - Train Loss: 1.1157, Test Loss: 1.6270\n",
      "Epoch [49/50] - Train Loss: 1.1157, Test Loss: 1.6265\n",
      "Epoch [50/50] - Train Loss: 1.1156, Test Loss: 1.6261\n",
      "Avg Test Loss: 1.6261\n",
      "Testing combination: (8, 3, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3234, Test Loss: 2.7619\n",
      "Epoch [2/50] - Train Loss: 1.3229, Test Loss: 2.7603\n",
      "Epoch [3/50] - Train Loss: 1.3224, Test Loss: 2.7588\n",
      "Epoch [4/50] - Train Loss: 1.3219, Test Loss: 2.7573\n",
      "Epoch [5/50] - Train Loss: 1.3214, Test Loss: 2.7559\n",
      "Epoch [6/50] - Train Loss: 1.3210, Test Loss: 2.7545\n",
      "Epoch [7/50] - Train Loss: 1.3205, Test Loss: 2.7531\n",
      "Epoch [8/50] - Train Loss: 1.3201, Test Loss: 2.7517\n",
      "Epoch [9/50] - Train Loss: 1.3197, Test Loss: 2.7503\n",
      "Epoch [10/50] - Train Loss: 1.3192, Test Loss: 2.7489\n",
      "Epoch [11/50] - Train Loss: 1.3188, Test Loss: 2.7476\n",
      "Epoch [12/50] - Train Loss: 1.3184, Test Loss: 2.7463\n",
      "Epoch [13/50] - Train Loss: 1.3180, Test Loss: 2.7450\n",
      "Epoch [14/50] - Train Loss: 1.3176, Test Loss: 2.7437\n",
      "Epoch [15/50] - Train Loss: 1.3172, Test Loss: 2.7425\n",
      "Epoch [16/50] - Train Loss: 1.3169, Test Loss: 2.7413\n",
      "Epoch [17/50] - Train Loss: 1.3165, Test Loss: 2.7400\n",
      "Epoch [18/50] - Train Loss: 1.3161, Test Loss: 2.7388\n",
      "Epoch [19/50] - Train Loss: 1.3158, Test Loss: 2.7377\n",
      "Epoch [20/50] - Train Loss: 1.3154, Test Loss: 2.7365\n",
      "Epoch [21/50] - Train Loss: 1.3151, Test Loss: 2.7354\n",
      "Epoch [22/50] - Train Loss: 1.3148, Test Loss: 2.7342\n",
      "Epoch [23/50] - Train Loss: 1.3145, Test Loss: 2.7331\n",
      "Epoch [24/50] - Train Loss: 1.3141, Test Loss: 2.7320\n",
      "Epoch [25/50] - Train Loss: 1.3138, Test Loss: 2.7309\n",
      "Epoch [26/50] - Train Loss: 1.3135, Test Loss: 2.7299\n",
      "Epoch [27/50] - Train Loss: 1.3132, Test Loss: 2.7288\n",
      "Epoch [28/50] - Train Loss: 1.3129, Test Loss: 2.7278\n",
      "Epoch [29/50] - Train Loss: 1.3127, Test Loss: 2.7268\n",
      "Epoch [30/50] - Train Loss: 1.3124, Test Loss: 2.7258\n",
      "Epoch [31/50] - Train Loss: 1.3121, Test Loss: 2.7248\n",
      "Epoch [32/50] - Train Loss: 1.3119, Test Loss: 2.7238\n",
      "Epoch [33/50] - Train Loss: 1.3116, Test Loss: 2.7228\n",
      "Epoch [34/50] - Train Loss: 1.3113, Test Loss: 2.7219\n",
      "Epoch [35/50] - Train Loss: 1.3111, Test Loss: 2.7210\n",
      "Epoch [36/50] - Train Loss: 1.3109, Test Loss: 2.7200\n",
      "Epoch [37/50] - Train Loss: 1.3106, Test Loss: 2.7191\n",
      "Epoch [38/50] - Train Loss: 1.3104, Test Loss: 2.7182\n",
      "Epoch [39/50] - Train Loss: 1.3102, Test Loss: 2.7174\n",
      "Epoch [40/50] - Train Loss: 1.3099, Test Loss: 2.7165\n",
      "Epoch [41/50] - Train Loss: 1.3097, Test Loss: 2.7156\n",
      "Epoch [42/50] - Train Loss: 1.3095, Test Loss: 2.7148\n",
      "Epoch [43/50] - Train Loss: 1.3093, Test Loss: 2.7140\n",
      "Epoch [44/50] - Train Loss: 1.3091, Test Loss: 2.7131\n",
      "Epoch [45/50] - Train Loss: 1.3089, Test Loss: 2.7123\n",
      "Epoch [46/50] - Train Loss: 1.3087, Test Loss: 2.7115\n",
      "Epoch [47/50] - Train Loss: 1.3085, Test Loss: 2.7108\n",
      "Epoch [48/50] - Train Loss: 1.3083, Test Loss: 2.7100\n",
      "Epoch [49/50] - Train Loss: 1.3082, Test Loss: 2.7092\n",
      "Epoch [50/50] - Train Loss: 1.3080, Test Loss: 2.7085\n",
      "Avg Test Loss: 2.7085\n",
      "Testing combination: (8, 4, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1123, Test Loss: 1.4965\n",
      "Epoch [2/50] - Train Loss: 1.0954, Test Loss: 1.4829\n",
      "Epoch [3/50] - Train Loss: 1.0963, Test Loss: 1.4814\n",
      "Epoch [4/50] - Train Loss: 1.0967, Test Loss: 1.4831\n",
      "Epoch [5/50] - Train Loss: 1.0964, Test Loss: 1.4848\n",
      "Epoch [6/50] - Train Loss: 1.0960, Test Loss: 1.4854\n",
      "Epoch [7/50] - Train Loss: 1.0957, Test Loss: 1.4853\n",
      "Epoch [8/50] - Train Loss: 1.0955, Test Loss: 1.4850\n",
      "Epoch [9/50] - Train Loss: 1.0954, Test Loss: 1.4848\n",
      "Epoch [10/50] - Train Loss: 1.0951, Test Loss: 1.4847\n",
      "Epoch [11/50] - Train Loss: 1.0946, Test Loss: 1.4845\n",
      "Epoch [12/50] - Train Loss: 1.0937, Test Loss: 1.4843\n",
      "Epoch [13/50] - Train Loss: 1.0924, Test Loss: 1.4840\n",
      "Epoch [14/50] - Train Loss: 1.0940, Test Loss: 1.4838\n",
      "Epoch [15/50] - Train Loss: 1.0910, Test Loss: 1.4841\n",
      "Epoch [16/50] - Train Loss: 1.0895, Test Loss: 1.4836\n",
      "Epoch [17/50] - Train Loss: 1.0873, Test Loss: 1.4829\n",
      "Epoch [18/50] - Train Loss: 1.0868, Test Loss: 1.4825\n",
      "Epoch [19/50] - Train Loss: 1.0865, Test Loss: 1.4823\n",
      "Epoch [20/50] - Train Loss: 1.0851, Test Loss: 1.4821\n",
      "Epoch [21/50] - Train Loss: 1.0840, Test Loss: 1.4823\n",
      "Epoch [22/50] - Train Loss: 1.0819, Test Loss: 1.4829\n",
      "Epoch [23/50] - Train Loss: 1.0812, Test Loss: 1.4843\n",
      "Epoch [24/50] - Train Loss: 1.0805, Test Loss: 1.4825\n",
      "Epoch [25/50] - Train Loss: 1.0698, Test Loss: 1.4871\n",
      "Epoch [26/50] - Train Loss: 1.0732, Test Loss: 1.4869\n",
      "Epoch [27/50] - Train Loss: 1.0605, Test Loss: 1.4850\n",
      "Epoch [28/50] - Train Loss: 1.0605, Test Loss: 1.4876\n",
      "Epoch [29/50] - Train Loss: 1.0611, Test Loss: 1.4997\n",
      "Epoch [30/50] - Train Loss: 1.0590, Test Loss: 1.4944\n",
      "Epoch [31/50] - Train Loss: 1.0580, Test Loss: 1.4917\n",
      "Epoch [32/50] - Train Loss: 1.0579, Test Loss: 1.4914\n",
      "Epoch [33/50] - Train Loss: 1.0578, Test Loss: 1.4922\n",
      "Epoch [34/50] - Train Loss: 1.0576, Test Loss: 1.4932\n",
      "Epoch [35/50] - Train Loss: 1.0573, Test Loss: 1.4937\n",
      "Epoch [36/50] - Train Loss: 1.0570, Test Loss: 1.4938\n",
      "Epoch [37/50] - Train Loss: 1.0568, Test Loss: 1.4940\n",
      "Epoch [38/50] - Train Loss: 1.0566, Test Loss: 1.4940\n",
      "Epoch [39/50] - Train Loss: 1.0564, Test Loss: 1.4940\n",
      "Epoch [40/50] - Train Loss: 1.0563, Test Loss: 1.4940\n",
      "Epoch [41/50] - Train Loss: 1.0561, Test Loss: 1.4940\n",
      "Epoch [42/50] - Train Loss: 1.0559, Test Loss: 1.4940\n",
      "Epoch [43/50] - Train Loss: 1.0557, Test Loss: 1.4941\n",
      "Epoch [44/50] - Train Loss: 1.0554, Test Loss: 1.4944\n",
      "Epoch [45/50] - Train Loss: 1.0549, Test Loss: 1.4942\n",
      "Epoch [46/50] - Train Loss: 1.0543, Test Loss: 1.4933\n",
      "Epoch [47/50] - Train Loss: 1.0535, Test Loss: 1.4909\n",
      "Epoch [48/50] - Train Loss: 1.0527, Test Loss: 1.4856\n",
      "Epoch [49/50] - Train Loss: 1.0506, Test Loss: 1.4994\n",
      "Epoch [50/50] - Train Loss: 1.0556, Test Loss: 1.4661\n",
      "Avg Test Loss: 1.4661\n",
      "Testing combination: (8, 4, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1479, Test Loss: 1.6362\n",
      "Epoch [2/50] - Train Loss: 1.1165, Test Loss: 1.6052\n",
      "Epoch [3/50] - Train Loss: 1.1160, Test Loss: 1.5994\n",
      "Epoch [4/50] - Train Loss: 1.1166, Test Loss: 1.6047\n",
      "Epoch [5/50] - Train Loss: 1.1164, Test Loss: 1.6102\n",
      "Epoch [6/50] - Train Loss: 1.1161, Test Loss: 1.6110\n",
      "Epoch [7/50] - Train Loss: 1.1159, Test Loss: 1.6090\n",
      "Epoch [8/50] - Train Loss: 1.1159, Test Loss: 1.6076\n",
      "Epoch [9/50] - Train Loss: 1.1159, Test Loss: 1.6076\n",
      "Epoch [10/50] - Train Loss: 1.1160, Test Loss: 1.6082\n",
      "Epoch [11/50] - Train Loss: 1.1160, Test Loss: 1.6085\n",
      "Epoch [12/50] - Train Loss: 1.1159, Test Loss: 1.6085\n",
      "Epoch [13/50] - Train Loss: 1.1159, Test Loss: 1.6083\n",
      "Epoch [14/50] - Train Loss: 1.1159, Test Loss: 1.6083\n",
      "Epoch [15/50] - Train Loss: 1.1158, Test Loss: 1.6083\n",
      "Epoch [16/50] - Train Loss: 1.1158, Test Loss: 1.6083\n",
      "Epoch [17/50] - Train Loss: 1.1157, Test Loss: 1.6083\n",
      "Epoch [18/50] - Train Loss: 1.1156, Test Loss: 1.6083\n",
      "Epoch [19/50] - Train Loss: 1.1154, Test Loss: 1.6083\n",
      "Epoch [20/50] - Train Loss: 1.1157, Test Loss: 1.6082\n",
      "Epoch [21/50] - Train Loss: 1.1156, Test Loss: 1.6083\n",
      "Epoch [22/50] - Train Loss: 1.1148, Test Loss: 1.6084\n",
      "Epoch [23/50] - Train Loss: 1.1144, Test Loss: 1.6083\n",
      "Epoch [24/50] - Train Loss: 1.1137, Test Loss: 1.6082\n",
      "Epoch [25/50] - Train Loss: 1.1128, Test Loss: 1.6081\n",
      "Epoch [26/50] - Train Loss: 1.1117, Test Loss: 1.6079\n",
      "Epoch [27/50] - Train Loss: 1.1099, Test Loss: 1.6082\n",
      "Epoch [28/50] - Train Loss: 1.1156, Test Loss: 1.6086\n",
      "Epoch [29/50] - Train Loss: 1.1076, Test Loss: 1.6195\n",
      "Epoch [30/50] - Train Loss: 1.1343, Test Loss: 1.5959\n",
      "Epoch [31/50] - Train Loss: 1.1102, Test Loss: 1.5995\n",
      "Epoch [32/50] - Train Loss: 1.1073, Test Loss: 1.6096\n",
      "Epoch [33/50] - Train Loss: 1.1047, Test Loss: 1.6166\n",
      "Epoch [34/50] - Train Loss: 1.0915, Test Loss: 1.6213\n",
      "Epoch [35/50] - Train Loss: 1.0882, Test Loss: 1.6216\n",
      "Epoch [36/50] - Train Loss: 1.0896, Test Loss: 1.6230\n",
      "Epoch [37/50] - Train Loss: 1.0865, Test Loss: 1.6212\n",
      "Epoch [38/50] - Train Loss: 1.0844, Test Loss: 1.6165\n",
      "Epoch [39/50] - Train Loss: 1.0827, Test Loss: 1.6116\n",
      "Epoch [40/50] - Train Loss: 1.0800, Test Loss: 1.6016\n",
      "Epoch [41/50] - Train Loss: 1.0728, Test Loss: 1.6227\n",
      "Epoch [42/50] - Train Loss: 1.0554, Test Loss: 1.7293\n",
      "Epoch [43/50] - Train Loss: 1.0520, Test Loss: 1.8203\n",
      "Epoch [44/50] - Train Loss: 1.0089, Test Loss: 1.8535\n",
      "Epoch [45/50] - Train Loss: 1.0041, Test Loss: 1.9614\n",
      "Epoch [46/50] - Train Loss: 0.9794, Test Loss: 1.9216\n",
      "Epoch [47/50] - Train Loss: 0.9471, Test Loss: 2.0535\n",
      "Epoch [48/50] - Train Loss: 1.0176, Test Loss: 2.1483\n",
      "Epoch [49/50] - Train Loss: 0.9989, Test Loss: 1.5793\n",
      "Epoch [50/50] - Train Loss: 0.9599, Test Loss: 2.0004\n",
      "Avg Test Loss: 2.0004\n",
      "Testing combination: (8, 4, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3425, Test Loss: 2.6881\n",
      "Epoch [2/50] - Train Loss: 1.3095, Test Loss: 2.6359\n",
      "Epoch [3/50] - Train Loss: 1.3097, Test Loss: 2.6494\n",
      "Epoch [4/50] - Train Loss: 1.3041, Test Loss: 2.6704\n",
      "Epoch [5/50] - Train Loss: 1.3034, Test Loss: 2.6805\n",
      "Epoch [6/50] - Train Loss: 1.3034, Test Loss: 2.6778\n",
      "Epoch [7/50] - Train Loss: 1.3027, Test Loss: 2.6693\n",
      "Epoch [8/50] - Train Loss: 1.3022, Test Loss: 2.6616\n",
      "Epoch [9/50] - Train Loss: 1.3024, Test Loss: 2.6580\n",
      "Epoch [10/50] - Train Loss: 1.3026, Test Loss: 2.6585\n",
      "Epoch [11/50] - Train Loss: 1.3025, Test Loss: 2.6615\n",
      "Epoch [12/50] - Train Loss: 1.3023, Test Loss: 2.6646\n",
      "Epoch [13/50] - Train Loss: 1.3020, Test Loss: 2.6664\n",
      "Epoch [14/50] - Train Loss: 1.3018, Test Loss: 2.6664\n",
      "Epoch [15/50] - Train Loss: 1.3015, Test Loss: 2.6653\n",
      "Epoch [16/50] - Train Loss: 1.3011, Test Loss: 2.6638\n",
      "Epoch [17/50] - Train Loss: 1.3003, Test Loss: 2.6629\n",
      "Epoch [18/50] - Train Loss: 1.3026, Test Loss: 2.6626\n",
      "Epoch [19/50] - Train Loss: 1.3019, Test Loss: 2.6627\n",
      "Epoch [20/50] - Train Loss: 1.3009, Test Loss: 2.6627\n",
      "Epoch [21/50] - Train Loss: 1.2991, Test Loss: 2.6623\n",
      "Epoch [22/50] - Train Loss: 1.2977, Test Loss: 2.6612\n",
      "Epoch [23/50] - Train Loss: 1.2956, Test Loss: 2.6587\n",
      "Epoch [24/50] - Train Loss: 1.2917, Test Loss: 2.6556\n",
      "Epoch [25/50] - Train Loss: 1.2862, Test Loss: 2.6518\n",
      "Epoch [26/50] - Train Loss: 1.2769, Test Loss: 2.6403\n",
      "Epoch [27/50] - Train Loss: 1.2806, Test Loss: 2.6478\n",
      "Epoch [28/50] - Train Loss: 1.2619, Test Loss: 2.6524\n",
      "Epoch [29/50] - Train Loss: 1.3223, Test Loss: 2.6360\n",
      "Epoch [30/50] - Train Loss: 1.2677, Test Loss: 2.6828\n",
      "Epoch [31/50] - Train Loss: 1.3259, Test Loss: 2.9808\n",
      "Epoch [32/50] - Train Loss: 1.3175, Test Loss: 2.6345\n",
      "Epoch [33/50] - Train Loss: 1.2977, Test Loss: 2.6471\n",
      "Epoch [34/50] - Train Loss: 1.3025, Test Loss: 2.6527\n",
      "Epoch [35/50] - Train Loss: 1.2978, Test Loss: 2.6638\n",
      "Epoch [36/50] - Train Loss: 1.2934, Test Loss: 2.6686\n",
      "Epoch [37/50] - Train Loss: 1.2898, Test Loss: 2.6635\n",
      "Epoch [38/50] - Train Loss: 1.2867, Test Loss: 2.6558\n",
      "Epoch [39/50] - Train Loss: 1.2842, Test Loss: 2.6524\n",
      "Epoch [40/50] - Train Loss: 1.2815, Test Loss: 2.6548\n",
      "Epoch [41/50] - Train Loss: 1.2783, Test Loss: 2.6599\n",
      "Epoch [42/50] - Train Loss: 1.2752, Test Loss: 2.6625\n",
      "Epoch [43/50] - Train Loss: 1.2722, Test Loss: 2.6603\n",
      "Epoch [44/50] - Train Loss: 1.2697, Test Loss: 2.6576\n",
      "Epoch [45/50] - Train Loss: 1.2675, Test Loss: 2.6586\n",
      "Epoch [46/50] - Train Loss: 1.2650, Test Loss: 2.6612\n",
      "Epoch [47/50] - Train Loss: 1.2623, Test Loss: 2.6608\n",
      "Epoch [48/50] - Train Loss: 1.2599, Test Loss: 2.6589\n",
      "Epoch [49/50] - Train Loss: 1.2577, Test Loss: 2.6589\n",
      "Epoch [50/50] - Train Loss: 1.2561, Test Loss: 2.6602\n",
      "Avg Test Loss: 2.6602\n",
      "Testing combination: (8, 4, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1222, Test Loss: 1.4752\n",
      "Epoch [2/50] - Train Loss: 1.1127, Test Loss: 1.4737\n",
      "Epoch [3/50] - Train Loss: 1.1071, Test Loss: 1.4734\n",
      "Epoch [4/50] - Train Loss: 1.1032, Test Loss: 1.4738\n",
      "Epoch [5/50] - Train Loss: 1.1003, Test Loss: 1.4747\n",
      "Epoch [6/50] - Train Loss: 1.0983, Test Loss: 1.4758\n",
      "Epoch [7/50] - Train Loss: 1.0969, Test Loss: 1.4771\n",
      "Epoch [8/50] - Train Loss: 1.0959, Test Loss: 1.4784\n",
      "Epoch [9/50] - Train Loss: 1.0952, Test Loss: 1.4796\n",
      "Epoch [10/50] - Train Loss: 1.0947, Test Loss: 1.4806\n",
      "Epoch [11/50] - Train Loss: 1.0944, Test Loss: 1.4815\n",
      "Epoch [12/50] - Train Loss: 1.0942, Test Loss: 1.4823\n",
      "Epoch [13/50] - Train Loss: 1.0940, Test Loss: 1.4830\n",
      "Epoch [14/50] - Train Loss: 1.0939, Test Loss: 1.4835\n",
      "Epoch [15/50] - Train Loss: 1.0939, Test Loss: 1.4839\n",
      "Epoch [16/50] - Train Loss: 1.0938, Test Loss: 1.4843\n",
      "Epoch [17/50] - Train Loss: 1.0938, Test Loss: 1.4845\n",
      "Epoch [18/50] - Train Loss: 1.0938, Test Loss: 1.4848\n",
      "Epoch [19/50] - Train Loss: 1.0937, Test Loss: 1.4849\n",
      "Epoch [20/50] - Train Loss: 1.0937, Test Loss: 1.4851\n",
      "Epoch [21/50] - Train Loss: 1.0937, Test Loss: 1.4852\n",
      "Epoch [22/50] - Train Loss: 1.0937, Test Loss: 1.4853\n",
      "Epoch [23/50] - Train Loss: 1.0936, Test Loss: 1.4853\n",
      "Epoch [24/50] - Train Loss: 1.0936, Test Loss: 1.4854\n",
      "Epoch [25/50] - Train Loss: 1.0935, Test Loss: 1.4854\n",
      "Epoch [26/50] - Train Loss: 1.0935, Test Loss: 1.4855\n",
      "Epoch [27/50] - Train Loss: 1.0934, Test Loss: 1.4855\n",
      "Epoch [28/50] - Train Loss: 1.0933, Test Loss: 1.4855\n",
      "Epoch [29/50] - Train Loss: 1.0931, Test Loss: 1.4856\n",
      "Epoch [30/50] - Train Loss: 1.0929, Test Loss: 1.4856\n",
      "Epoch [31/50] - Train Loss: 1.0925, Test Loss: 1.4857\n",
      "Epoch [32/50] - Train Loss: 1.0921, Test Loss: 1.4858\n",
      "Epoch [33/50] - Train Loss: 1.0916, Test Loss: 1.4859\n",
      "Epoch [34/50] - Train Loss: 1.0910, Test Loss: 1.4860\n",
      "Epoch [35/50] - Train Loss: 1.0904, Test Loss: 1.4861\n",
      "Epoch [36/50] - Train Loss: 1.0899, Test Loss: 1.4860\n",
      "Epoch [37/50] - Train Loss: 1.0893, Test Loss: 1.4859\n",
      "Epoch [38/50] - Train Loss: 1.0887, Test Loss: 1.4858\n",
      "Epoch [39/50] - Train Loss: 1.0881, Test Loss: 1.4856\n",
      "Epoch [40/50] - Train Loss: 1.0875, Test Loss: 1.4855\n",
      "Epoch [41/50] - Train Loss: 1.0868, Test Loss: 1.4856\n",
      "Epoch [42/50] - Train Loss: 1.0861, Test Loss: 1.4858\n",
      "Epoch [43/50] - Train Loss: 1.0852, Test Loss: 1.4862\n",
      "Epoch [44/50] - Train Loss: 1.0844, Test Loss: 1.4866\n",
      "Epoch [45/50] - Train Loss: 1.0830, Test Loss: 1.4869\n",
      "Epoch [46/50] - Train Loss: 1.0818, Test Loss: 1.4880\n",
      "Epoch [47/50] - Train Loss: 1.0805, Test Loss: 1.4879\n",
      "Epoch [48/50] - Train Loss: 1.0929, Test Loss: 1.4882\n",
      "Epoch [49/50] - Train Loss: 1.0923, Test Loss: 1.4883\n",
      "Epoch [50/50] - Train Loss: 1.0917, Test Loss: 1.4884\n",
      "Avg Test Loss: 1.4884\n",
      "Testing combination: (8, 4, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.2275, Test Loss: 1.5972\n",
      "Epoch [2/50] - Train Loss: 1.2091, Test Loss: 1.5888\n",
      "Epoch [3/50] - Train Loss: 1.1925, Test Loss: 1.5821\n",
      "Epoch [4/50] - Train Loss: 1.1768, Test Loss: 1.5770\n",
      "Epoch [5/50] - Train Loss: 1.1616, Test Loss: 1.5740\n",
      "Epoch [6/50] - Train Loss: 1.1471, Test Loss: 1.5741\n",
      "Epoch [7/50] - Train Loss: 1.1339, Test Loss: 1.5788\n",
      "Epoch [8/50] - Train Loss: 1.1237, Test Loss: 1.5883\n",
      "Epoch [9/50] - Train Loss: 1.1179, Test Loss: 1.5997\n",
      "Epoch [10/50] - Train Loss: 1.1157, Test Loss: 1.6086\n",
      "Epoch [11/50] - Train Loss: 1.1152, Test Loss: 1.6129\n",
      "Epoch [12/50] - Train Loss: 1.1150, Test Loss: 1.6136\n",
      "Epoch [13/50] - Train Loss: 1.1149, Test Loss: 1.6127\n",
      "Epoch [14/50] - Train Loss: 1.1148, Test Loss: 1.6114\n",
      "Epoch [15/50] - Train Loss: 1.1147, Test Loss: 1.6104\n",
      "Epoch [16/50] - Train Loss: 1.1147, Test Loss: 1.6097\n",
      "Epoch [17/50] - Train Loss: 1.1147, Test Loss: 1.6094\n",
      "Epoch [18/50] - Train Loss: 1.1147, Test Loss: 1.6093\n",
      "Epoch [19/50] - Train Loss: 1.1147, Test Loss: 1.6093\n",
      "Epoch [20/50] - Train Loss: 1.1147, Test Loss: 1.6094\n",
      "Epoch [21/50] - Train Loss: 1.1147, Test Loss: 1.6095\n",
      "Epoch [22/50] - Train Loss: 1.1147, Test Loss: 1.6096\n",
      "Epoch [23/50] - Train Loss: 1.1147, Test Loss: 1.6096\n",
      "Epoch [24/50] - Train Loss: 1.1147, Test Loss: 1.6096\n",
      "Epoch [25/50] - Train Loss: 1.1147, Test Loss: 1.6097\n",
      "Epoch [26/50] - Train Loss: 1.1146, Test Loss: 1.6097\n",
      "Epoch [27/50] - Train Loss: 1.1146, Test Loss: 1.6097\n",
      "Epoch [28/50] - Train Loss: 1.1146, Test Loss: 1.6097\n",
      "Epoch [29/50] - Train Loss: 1.1146, Test Loss: 1.6097\n",
      "Epoch [30/50] - Train Loss: 1.1146, Test Loss: 1.6097\n",
      "Epoch [31/50] - Train Loss: 1.1145, Test Loss: 1.6097\n",
      "Epoch [32/50] - Train Loss: 1.1145, Test Loss: 1.6098\n",
      "Epoch [33/50] - Train Loss: 1.1144, Test Loss: 1.6098\n",
      "Epoch [34/50] - Train Loss: 1.1144, Test Loss: 1.6098\n",
      "Epoch [35/50] - Train Loss: 1.1143, Test Loss: 1.6099\n",
      "Epoch [36/50] - Train Loss: 1.1142, Test Loss: 1.6099\n",
      "Epoch [37/50] - Train Loss: 1.1140, Test Loss: 1.6100\n",
      "Epoch [38/50] - Train Loss: 1.1138, Test Loss: 1.6101\n",
      "Epoch [39/50] - Train Loss: 1.1135, Test Loss: 1.6102\n",
      "Epoch [40/50] - Train Loss: 1.1131, Test Loss: 1.6104\n",
      "Epoch [41/50] - Train Loss: 1.1125, Test Loss: 1.6107\n",
      "Epoch [42/50] - Train Loss: 1.1118, Test Loss: 1.6111\n",
      "Epoch [43/50] - Train Loss: 1.1111, Test Loss: 1.6115\n",
      "Epoch [44/50] - Train Loss: 1.1103, Test Loss: 1.6121\n",
      "Epoch [45/50] - Train Loss: 1.1094, Test Loss: 1.6128\n",
      "Epoch [46/50] - Train Loss: 1.1084, Test Loss: 1.6136\n",
      "Epoch [47/50] - Train Loss: 1.1073, Test Loss: 1.6145\n",
      "Epoch [48/50] - Train Loss: 1.1060, Test Loss: 1.6159\n",
      "Epoch [49/50] - Train Loss: 1.1045, Test Loss: 1.6188\n",
      "Epoch [50/50] - Train Loss: 1.1032, Test Loss: 1.6234\n",
      "Avg Test Loss: 1.6234\n",
      "Testing combination: (8, 4, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3088, Test Loss: 2.6380\n",
      "Epoch [2/50] - Train Loss: 1.3063, Test Loss: 2.6411\n",
      "Epoch [3/50] - Train Loss: 1.3049, Test Loss: 2.6442\n",
      "Epoch [4/50] - Train Loss: 1.3039, Test Loss: 2.6472\n",
      "Epoch [5/50] - Train Loss: 1.3031, Test Loss: 2.6501\n",
      "Epoch [6/50] - Train Loss: 1.3026, Test Loss: 2.6528\n",
      "Epoch [7/50] - Train Loss: 1.3022, Test Loss: 2.6552\n",
      "Epoch [8/50] - Train Loss: 1.3020, Test Loss: 2.6573\n",
      "Epoch [9/50] - Train Loss: 1.3019, Test Loss: 2.6591\n",
      "Epoch [10/50] - Train Loss: 1.3018, Test Loss: 2.6605\n",
      "Epoch [11/50] - Train Loss: 1.3017, Test Loss: 2.6616\n",
      "Epoch [12/50] - Train Loss: 1.3017, Test Loss: 2.6624\n",
      "Epoch [13/50] - Train Loss: 1.3017, Test Loss: 2.6629\n",
      "Epoch [14/50] - Train Loss: 1.3016, Test Loss: 2.6633\n",
      "Epoch [15/50] - Train Loss: 1.3016, Test Loss: 2.6635\n",
      "Epoch [16/50] - Train Loss: 1.3016, Test Loss: 2.6636\n",
      "Epoch [17/50] - Train Loss: 1.3016, Test Loss: 2.6636\n",
      "Epoch [18/50] - Train Loss: 1.3016, Test Loss: 2.6635\n",
      "Epoch [19/50] - Train Loss: 1.3016, Test Loss: 2.6635\n",
      "Epoch [20/50] - Train Loss: 1.3016, Test Loss: 2.6634\n",
      "Epoch [21/50] - Train Loss: 1.3015, Test Loss: 2.6633\n",
      "Epoch [22/50] - Train Loss: 1.3015, Test Loss: 2.6632\n",
      "Epoch [23/50] - Train Loss: 1.3015, Test Loss: 2.6632\n",
      "Epoch [24/50] - Train Loss: 1.3015, Test Loss: 2.6631\n",
      "Epoch [25/50] - Train Loss: 1.3015, Test Loss: 2.6631\n",
      "Epoch [26/50] - Train Loss: 1.3015, Test Loss: 2.6630\n",
      "Epoch [27/50] - Train Loss: 1.3014, Test Loss: 2.6630\n",
      "Epoch [28/50] - Train Loss: 1.3014, Test Loss: 2.6630\n",
      "Epoch [29/50] - Train Loss: 1.3014, Test Loss: 2.6630\n",
      "Epoch [30/50] - Train Loss: 1.3014, Test Loss: 2.6630\n",
      "Epoch [31/50] - Train Loss: 1.3013, Test Loss: 2.6631\n",
      "Epoch [32/50] - Train Loss: 1.3013, Test Loss: 2.6631\n",
      "Epoch [33/50] - Train Loss: 1.3013, Test Loss: 2.6631\n",
      "Epoch [34/50] - Train Loss: 1.3012, Test Loss: 2.6632\n",
      "Epoch [35/50] - Train Loss: 1.3012, Test Loss: 2.6632\n",
      "Epoch [36/50] - Train Loss: 1.3011, Test Loss: 2.6633\n",
      "Epoch [37/50] - Train Loss: 1.3011, Test Loss: 2.6633\n",
      "Epoch [38/50] - Train Loss: 1.3010, Test Loss: 2.6634\n",
      "Epoch [39/50] - Train Loss: 1.3009, Test Loss: 2.6635\n",
      "Epoch [40/50] - Train Loss: 1.3008, Test Loss: 2.6636\n",
      "Epoch [41/50] - Train Loss: 1.3007, Test Loss: 2.6637\n",
      "Epoch [42/50] - Train Loss: 1.3006, Test Loss: 2.6638\n",
      "Epoch [43/50] - Train Loss: 1.3004, Test Loss: 2.6640\n",
      "Epoch [44/50] - Train Loss: 1.3003, Test Loss: 2.6642\n",
      "Epoch [45/50] - Train Loss: 1.3001, Test Loss: 2.6644\n",
      "Epoch [46/50] - Train Loss: 1.2998, Test Loss: 2.6646\n",
      "Epoch [47/50] - Train Loss: 1.2995, Test Loss: 2.6649\n",
      "Epoch [48/50] - Train Loss: 1.2992, Test Loss: 2.6653\n",
      "Epoch [49/50] - Train Loss: 1.2987, Test Loss: 2.6657\n",
      "Epoch [50/50] - Train Loss: 1.2982, Test Loss: 2.6663\n",
      "Avg Test Loss: 2.6663\n",
      "Testing combination: (8, 4, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.0951, Test Loss: 1.4978\n",
      "Epoch [2/50] - Train Loss: 1.0949, Test Loss: 1.4976\n",
      "Epoch [3/50] - Train Loss: 1.0949, Test Loss: 1.4974\n",
      "Epoch [4/50] - Train Loss: 1.0948, Test Loss: 1.4971\n",
      "Epoch [5/50] - Train Loss: 1.0948, Test Loss: 1.4969\n",
      "Epoch [6/50] - Train Loss: 1.0947, Test Loss: 1.4967\n",
      "Epoch [7/50] - Train Loss: 1.0947, Test Loss: 1.4965\n",
      "Epoch [8/50] - Train Loss: 1.0946, Test Loss: 1.4963\n",
      "Epoch [9/50] - Train Loss: 1.0946, Test Loss: 1.4961\n",
      "Epoch [10/50] - Train Loss: 1.0945, Test Loss: 1.4959\n",
      "Epoch [11/50] - Train Loss: 1.0945, Test Loss: 1.4957\n",
      "Epoch [12/50] - Train Loss: 1.0944, Test Loss: 1.4955\n",
      "Epoch [13/50] - Train Loss: 1.0944, Test Loss: 1.4953\n",
      "Epoch [14/50] - Train Loss: 1.0943, Test Loss: 1.4951\n",
      "Epoch [15/50] - Train Loss: 1.0943, Test Loss: 1.4949\n",
      "Epoch [16/50] - Train Loss: 1.0943, Test Loss: 1.4948\n",
      "Epoch [17/50] - Train Loss: 1.0942, Test Loss: 1.4946\n",
      "Epoch [18/50] - Train Loss: 1.0942, Test Loss: 1.4944\n",
      "Epoch [19/50] - Train Loss: 1.0942, Test Loss: 1.4943\n",
      "Epoch [20/50] - Train Loss: 1.0941, Test Loss: 1.4941\n",
      "Epoch [21/50] - Train Loss: 1.0941, Test Loss: 1.4939\n",
      "Epoch [22/50] - Train Loss: 1.0941, Test Loss: 1.4938\n",
      "Epoch [23/50] - Train Loss: 1.0940, Test Loss: 1.4936\n",
      "Epoch [24/50] - Train Loss: 1.0940, Test Loss: 1.4935\n",
      "Epoch [25/50] - Train Loss: 1.0940, Test Loss: 1.4933\n",
      "Epoch [26/50] - Train Loss: 1.0939, Test Loss: 1.4932\n",
      "Epoch [27/50] - Train Loss: 1.0939, Test Loss: 1.4931\n",
      "Epoch [28/50] - Train Loss: 1.0939, Test Loss: 1.4929\n",
      "Epoch [29/50] - Train Loss: 1.0939, Test Loss: 1.4928\n",
      "Epoch [30/50] - Train Loss: 1.0938, Test Loss: 1.4927\n",
      "Epoch [31/50] - Train Loss: 1.0938, Test Loss: 1.4925\n",
      "Epoch [32/50] - Train Loss: 1.0938, Test Loss: 1.4924\n",
      "Epoch [33/50] - Train Loss: 1.0938, Test Loss: 1.4923\n",
      "Epoch [34/50] - Train Loss: 1.0938, Test Loss: 1.4922\n",
      "Epoch [35/50] - Train Loss: 1.0937, Test Loss: 1.4920\n",
      "Epoch [36/50] - Train Loss: 1.0937, Test Loss: 1.4919\n",
      "Epoch [37/50] - Train Loss: 1.0937, Test Loss: 1.4918\n",
      "Epoch [38/50] - Train Loss: 1.0937, Test Loss: 1.4917\n",
      "Epoch [39/50] - Train Loss: 1.0937, Test Loss: 1.4916\n",
      "Epoch [40/50] - Train Loss: 1.0936, Test Loss: 1.4915\n",
      "Epoch [41/50] - Train Loss: 1.0936, Test Loss: 1.4914\n",
      "Epoch [42/50] - Train Loss: 1.0936, Test Loss: 1.4913\n",
      "Epoch [43/50] - Train Loss: 1.0936, Test Loss: 1.4912\n",
      "Epoch [44/50] - Train Loss: 1.0936, Test Loss: 1.4911\n",
      "Epoch [45/50] - Train Loss: 1.0936, Test Loss: 1.4910\n",
      "Epoch [46/50] - Train Loss: 1.0936, Test Loss: 1.4909\n",
      "Epoch [47/50] - Train Loss: 1.0935, Test Loss: 1.4908\n",
      "Epoch [48/50] - Train Loss: 1.0935, Test Loss: 1.4907\n",
      "Epoch [49/50] - Train Loss: 1.0935, Test Loss: 1.4906\n",
      "Epoch [50/50] - Train Loss: 1.0935, Test Loss: 1.4905\n",
      "Avg Test Loss: 1.4905\n",
      "Testing combination: (8, 4, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1346, Test Loss: 1.6920\n",
      "Epoch [2/50] - Train Loss: 1.1341, Test Loss: 1.6905\n",
      "Epoch [3/50] - Train Loss: 1.1335, Test Loss: 1.6890\n",
      "Epoch [4/50] - Train Loss: 1.1330, Test Loss: 1.6876\n",
      "Epoch [5/50] - Train Loss: 1.1324, Test Loss: 1.6862\n",
      "Epoch [6/50] - Train Loss: 1.1319, Test Loss: 1.6848\n",
      "Epoch [7/50] - Train Loss: 1.1314, Test Loss: 1.6834\n",
      "Epoch [8/50] - Train Loss: 1.1309, Test Loss: 1.6820\n",
      "Epoch [9/50] - Train Loss: 1.1304, Test Loss: 1.6807\n",
      "Epoch [10/50] - Train Loss: 1.1299, Test Loss: 1.6793\n",
      "Epoch [11/50] - Train Loss: 1.1295, Test Loss: 1.6780\n",
      "Epoch [12/50] - Train Loss: 1.1290, Test Loss: 1.6767\n",
      "Epoch [13/50] - Train Loss: 1.1285, Test Loss: 1.6754\n",
      "Epoch [14/50] - Train Loss: 1.1281, Test Loss: 1.6741\n",
      "Epoch [15/50] - Train Loss: 1.1277, Test Loss: 1.6728\n",
      "Epoch [16/50] - Train Loss: 1.1272, Test Loss: 1.6716\n",
      "Epoch [17/50] - Train Loss: 1.1268, Test Loss: 1.6703\n",
      "Epoch [18/50] - Train Loss: 1.1264, Test Loss: 1.6691\n",
      "Epoch [19/50] - Train Loss: 1.1260, Test Loss: 1.6678\n",
      "Epoch [20/50] - Train Loss: 1.1256, Test Loss: 1.6666\n",
      "Epoch [21/50] - Train Loss: 1.1252, Test Loss: 1.6654\n",
      "Epoch [22/50] - Train Loss: 1.1248, Test Loss: 1.6642\n",
      "Epoch [23/50] - Train Loss: 1.1245, Test Loss: 1.6630\n",
      "Epoch [24/50] - Train Loss: 1.1241, Test Loss: 1.6618\n",
      "Epoch [25/50] - Train Loss: 1.1237, Test Loss: 1.6607\n",
      "Epoch [26/50] - Train Loss: 1.1234, Test Loss: 1.6595\n",
      "Epoch [27/50] - Train Loss: 1.1230, Test Loss: 1.6584\n",
      "Epoch [28/50] - Train Loss: 1.1227, Test Loss: 1.6572\n",
      "Epoch [29/50] - Train Loss: 1.1224, Test Loss: 1.6561\n",
      "Epoch [30/50] - Train Loss: 1.1220, Test Loss: 1.6550\n",
      "Epoch [31/50] - Train Loss: 1.1217, Test Loss: 1.6538\n",
      "Epoch [32/50] - Train Loss: 1.1214, Test Loss: 1.6527\n",
      "Epoch [33/50] - Train Loss: 1.1211, Test Loss: 1.6517\n",
      "Epoch [34/50] - Train Loss: 1.1208, Test Loss: 1.6506\n",
      "Epoch [35/50] - Train Loss: 1.1205, Test Loss: 1.6495\n",
      "Epoch [36/50] - Train Loss: 1.1203, Test Loss: 1.6485\n",
      "Epoch [37/50] - Train Loss: 1.1200, Test Loss: 1.6474\n",
      "Epoch [38/50] - Train Loss: 1.1197, Test Loss: 1.6464\n",
      "Epoch [39/50] - Train Loss: 1.1195, Test Loss: 1.6454\n",
      "Epoch [40/50] - Train Loss: 1.1192, Test Loss: 1.6444\n",
      "Epoch [41/50] - Train Loss: 1.1190, Test Loss: 1.6434\n",
      "Epoch [42/50] - Train Loss: 1.1187, Test Loss: 1.6424\n",
      "Epoch [43/50] - Train Loss: 1.1185, Test Loss: 1.6415\n",
      "Epoch [44/50] - Train Loss: 1.1183, Test Loss: 1.6406\n",
      "Epoch [45/50] - Train Loss: 1.1181, Test Loss: 1.6396\n",
      "Epoch [46/50] - Train Loss: 1.1179, Test Loss: 1.6387\n",
      "Epoch [47/50] - Train Loss: 1.1177, Test Loss: 1.6378\n",
      "Epoch [48/50] - Train Loss: 1.1175, Test Loss: 1.6370\n",
      "Epoch [49/50] - Train Loss: 1.1173, Test Loss: 1.6361\n",
      "Epoch [50/50] - Train Loss: 1.1172, Test Loss: 1.6353\n",
      "Avg Test Loss: 1.6353\n",
      "Testing combination: (8, 4, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3249, Test Loss: 2.6281\n",
      "Epoch [2/50] - Train Loss: 1.3243, Test Loss: 2.6281\n",
      "Epoch [3/50] - Train Loss: 1.3238, Test Loss: 2.6282\n",
      "Epoch [4/50] - Train Loss: 1.3232, Test Loss: 2.6282\n",
      "Epoch [5/50] - Train Loss: 1.3227, Test Loss: 2.6282\n",
      "Epoch [6/50] - Train Loss: 1.3222, Test Loss: 2.6283\n",
      "Epoch [7/50] - Train Loss: 1.3218, Test Loss: 2.6283\n",
      "Epoch [8/50] - Train Loss: 1.3213, Test Loss: 2.6284\n",
      "Epoch [9/50] - Train Loss: 1.3208, Test Loss: 2.6284\n",
      "Epoch [10/50] - Train Loss: 1.3204, Test Loss: 2.6285\n",
      "Epoch [11/50] - Train Loss: 1.3199, Test Loss: 2.6286\n",
      "Epoch [12/50] - Train Loss: 1.3195, Test Loss: 2.6287\n",
      "Epoch [13/50] - Train Loss: 1.3190, Test Loss: 2.6288\n",
      "Epoch [14/50] - Train Loss: 1.3186, Test Loss: 2.6289\n",
      "Epoch [15/50] - Train Loss: 1.3182, Test Loss: 2.6290\n",
      "Epoch [16/50] - Train Loss: 1.3178, Test Loss: 2.6291\n",
      "Epoch [17/50] - Train Loss: 1.3174, Test Loss: 2.6293\n",
      "Epoch [18/50] - Train Loss: 1.3170, Test Loss: 2.6294\n",
      "Epoch [19/50] - Train Loss: 1.3166, Test Loss: 2.6295\n",
      "Epoch [20/50] - Train Loss: 1.3162, Test Loss: 2.6297\n",
      "Epoch [21/50] - Train Loss: 1.3159, Test Loss: 2.6298\n",
      "Epoch [22/50] - Train Loss: 1.3155, Test Loss: 2.6300\n",
      "Epoch [23/50] - Train Loss: 1.3151, Test Loss: 2.6301\n",
      "Epoch [24/50] - Train Loss: 1.3148, Test Loss: 2.6303\n",
      "Epoch [25/50] - Train Loss: 1.3145, Test Loss: 2.6305\n",
      "Epoch [26/50] - Train Loss: 1.3141, Test Loss: 2.6307\n",
      "Epoch [27/50] - Train Loss: 1.3138, Test Loss: 2.6308\n",
      "Epoch [28/50] - Train Loss: 1.3135, Test Loss: 2.6310\n",
      "Epoch [29/50] - Train Loss: 1.3132, Test Loss: 2.6312\n",
      "Epoch [30/50] - Train Loss: 1.3128, Test Loss: 2.6314\n",
      "Epoch [31/50] - Train Loss: 1.3125, Test Loss: 2.6316\n",
      "Epoch [32/50] - Train Loss: 1.3122, Test Loss: 2.6318\n",
      "Epoch [33/50] - Train Loss: 1.3120, Test Loss: 2.6321\n",
      "Epoch [34/50] - Train Loss: 1.3117, Test Loss: 2.6323\n",
      "Epoch [35/50] - Train Loss: 1.3114, Test Loss: 2.6325\n",
      "Epoch [36/50] - Train Loss: 1.3111, Test Loss: 2.6327\n",
      "Epoch [37/50] - Train Loss: 1.3108, Test Loss: 2.6330\n",
      "Epoch [38/50] - Train Loss: 1.3106, Test Loss: 2.6332\n",
      "Epoch [39/50] - Train Loss: 1.3103, Test Loss: 2.6334\n",
      "Epoch [40/50] - Train Loss: 1.3101, Test Loss: 2.6337\n",
      "Epoch [41/50] - Train Loss: 1.3098, Test Loss: 2.6339\n",
      "Epoch [42/50] - Train Loss: 1.3096, Test Loss: 2.6342\n",
      "Epoch [43/50] - Train Loss: 1.3094, Test Loss: 2.6344\n",
      "Epoch [44/50] - Train Loss: 1.3091, Test Loss: 2.6347\n",
      "Epoch [45/50] - Train Loss: 1.3089, Test Loss: 2.6349\n",
      "Epoch [46/50] - Train Loss: 1.3087, Test Loss: 2.6352\n",
      "Epoch [47/50] - Train Loss: 1.3085, Test Loss: 2.6354\n",
      "Epoch [48/50] - Train Loss: 1.3083, Test Loss: 2.6357\n",
      "Epoch [49/50] - Train Loss: 1.3081, Test Loss: 2.6360\n",
      "Epoch [50/50] - Train Loss: 1.3079, Test Loss: 2.6363\n",
      "Avg Test Loss: 2.6363\n",
      "Testing combination: (16, 1, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1223, Test Loss: 1.5032\n",
      "Epoch [2/50] - Train Loss: 1.0949, Test Loss: 1.4847\n",
      "Epoch [3/50] - Train Loss: 1.0956, Test Loss: 1.4821\n",
      "Epoch [4/50] - Train Loss: 1.0961, Test Loss: 1.4833\n",
      "Epoch [5/50] - Train Loss: 1.0958, Test Loss: 1.4848\n",
      "Epoch [6/50] - Train Loss: 1.0955, Test Loss: 1.4857\n",
      "Epoch [7/50] - Train Loss: 1.0953, Test Loss: 1.4859\n",
      "Epoch [8/50] - Train Loss: 1.0952, Test Loss: 1.4859\n",
      "Epoch [9/50] - Train Loss: 1.0951, Test Loss: 1.4857\n",
      "Epoch [10/50] - Train Loss: 1.0951, Test Loss: 1.4856\n",
      "Epoch [11/50] - Train Loss: 1.0951, Test Loss: 1.4855\n",
      "Epoch [12/50] - Train Loss: 1.0950, Test Loss: 1.4855\n",
      "Epoch [13/50] - Train Loss: 1.0950, Test Loss: 1.4855\n",
      "Epoch [14/50] - Train Loss: 1.0950, Test Loss: 1.4856\n",
      "Epoch [15/50] - Train Loss: 1.0950, Test Loss: 1.4856\n",
      "Epoch [16/50] - Train Loss: 1.0949, Test Loss: 1.4856\n",
      "Epoch [17/50] - Train Loss: 1.0949, Test Loss: 1.4856\n",
      "Epoch [18/50] - Train Loss: 1.0949, Test Loss: 1.4856\n",
      "Epoch [19/50] - Train Loss: 1.0948, Test Loss: 1.4855\n",
      "Epoch [20/50] - Train Loss: 1.0948, Test Loss: 1.4855\n",
      "Epoch [21/50] - Train Loss: 1.0948, Test Loss: 1.4855\n",
      "Epoch [22/50] - Train Loss: 1.0948, Test Loss: 1.4855\n",
      "Epoch [23/50] - Train Loss: 1.0948, Test Loss: 1.4855\n",
      "Epoch [24/50] - Train Loss: 1.0947, Test Loss: 1.4855\n",
      "Epoch [25/50] - Train Loss: 1.0947, Test Loss: 1.4855\n",
      "Epoch [26/50] - Train Loss: 1.0947, Test Loss: 1.4855\n",
      "Epoch [27/50] - Train Loss: 1.0947, Test Loss: 1.4855\n",
      "Epoch [28/50] - Train Loss: 1.0947, Test Loss: 1.4855\n",
      "Epoch [29/50] - Train Loss: 1.0946, Test Loss: 1.4855\n",
      "Epoch [30/50] - Train Loss: 1.0946, Test Loss: 1.4855\n",
      "Epoch [31/50] - Train Loss: 1.0946, Test Loss: 1.4855\n",
      "Epoch [32/50] - Train Loss: 1.0946, Test Loss: 1.4855\n",
      "Epoch [33/50] - Train Loss: 1.0946, Test Loss: 1.4855\n",
      "Epoch [34/50] - Train Loss: 1.0946, Test Loss: 1.4855\n",
      "Epoch [35/50] - Train Loss: 1.0945, Test Loss: 1.4855\n",
      "Epoch [36/50] - Train Loss: 1.0945, Test Loss: 1.4855\n",
      "Epoch [37/50] - Train Loss: 1.0945, Test Loss: 1.4854\n",
      "Epoch [38/50] - Train Loss: 1.0945, Test Loss: 1.4854\n",
      "Epoch [39/50] - Train Loss: 1.0945, Test Loss: 1.4854\n",
      "Epoch [40/50] - Train Loss: 1.0945, Test Loss: 1.4854\n",
      "Epoch [41/50] - Train Loss: 1.0944, Test Loss: 1.4854\n",
      "Epoch [42/50] - Train Loss: 1.0944, Test Loss: 1.4854\n",
      "Epoch [43/50] - Train Loss: 1.0944, Test Loss: 1.4854\n",
      "Epoch [44/50] - Train Loss: 1.0944, Test Loss: 1.4853\n",
      "Epoch [45/50] - Train Loss: 1.0944, Test Loss: 1.4853\n",
      "Epoch [46/50] - Train Loss: 1.0943, Test Loss: 1.4853\n",
      "Epoch [47/50] - Train Loss: 1.0943, Test Loss: 1.4853\n",
      "Epoch [48/50] - Train Loss: 1.0943, Test Loss: 1.4853\n",
      "Epoch [49/50] - Train Loss: 1.0943, Test Loss: 1.4852\n",
      "Epoch [50/50] - Train Loss: 1.0943, Test Loss: 1.4852\n",
      "Avg Test Loss: 1.4852\n",
      "Testing combination: (16, 1, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1300, Test Loss: 1.6164\n",
      "Epoch [2/50] - Train Loss: 1.1129, Test Loss: 1.6019\n",
      "Epoch [3/50] - Train Loss: 1.1095, Test Loss: 1.6018\n",
      "Epoch [4/50] - Train Loss: 1.1085, Test Loss: 1.6040\n",
      "Epoch [5/50] - Train Loss: 1.1079, Test Loss: 1.6047\n",
      "Epoch [6/50] - Train Loss: 1.1069, Test Loss: 1.6050\n",
      "Epoch [7/50] - Train Loss: 1.1048, Test Loss: 1.6061\n",
      "Epoch [8/50] - Train Loss: 1.1012, Test Loss: 1.6090\n",
      "Epoch [9/50] - Train Loss: 1.0943, Test Loss: 1.6129\n",
      "Epoch [10/50] - Train Loss: 1.0871, Test Loss: 1.6149\n",
      "Epoch [11/50] - Train Loss: 1.0817, Test Loss: 1.6126\n",
      "Epoch [12/50] - Train Loss: 1.0820, Test Loss: 1.6111\n",
      "Epoch [13/50] - Train Loss: 1.0789, Test Loss: 1.6123\n",
      "Epoch [14/50] - Train Loss: 1.0789, Test Loss: 1.6135\n",
      "Epoch [15/50] - Train Loss: 1.0783, Test Loss: 1.6135\n",
      "Epoch [16/50] - Train Loss: 1.0765, Test Loss: 1.6133\n",
      "Epoch [17/50] - Train Loss: 1.0779, Test Loss: 1.6186\n",
      "Epoch [18/50] - Train Loss: 1.0734, Test Loss: 1.6183\n",
      "Epoch [19/50] - Train Loss: 1.0735, Test Loss: 1.6146\n",
      "Epoch [20/50] - Train Loss: 1.0726, Test Loss: 1.6145\n",
      "Epoch [21/50] - Train Loss: 1.0713, Test Loss: 1.6170\n",
      "Epoch [22/50] - Train Loss: 1.0699, Test Loss: 1.6176\n",
      "Epoch [23/50] - Train Loss: 1.0693, Test Loss: 1.6172\n",
      "Epoch [24/50] - Train Loss: 1.0677, Test Loss: 1.6184\n",
      "Epoch [25/50] - Train Loss: 1.0676, Test Loss: 1.6205\n",
      "Epoch [26/50] - Train Loss: 1.0691, Test Loss: 1.6223\n",
      "Epoch [27/50] - Train Loss: 1.0721, Test Loss: 1.6221\n",
      "Epoch [28/50] - Train Loss: 1.0667, Test Loss: 1.6175\n",
      "Epoch [29/50] - Train Loss: 1.0679, Test Loss: 1.6186\n",
      "Epoch [30/50] - Train Loss: 1.0680, Test Loss: 1.6208\n",
      "Epoch [31/50] - Train Loss: 1.0664, Test Loss: 1.6206\n",
      "Epoch [32/50] - Train Loss: 1.0669, Test Loss: 1.6205\n",
      "Epoch [33/50] - Train Loss: 1.0666, Test Loss: 1.6193\n",
      "Epoch [34/50] - Train Loss: 1.0671, Test Loss: 1.6204\n",
      "Epoch [35/50] - Train Loss: 1.0663, Test Loss: 1.6204\n",
      "Epoch [36/50] - Train Loss: 1.0669, Test Loss: 1.6209\n",
      "Epoch [37/50] - Train Loss: 1.0663, Test Loss: 1.6198\n",
      "Epoch [38/50] - Train Loss: 1.0670, Test Loss: 1.6202\n",
      "Epoch [39/50] - Train Loss: 1.0660, Test Loss: 1.6197\n",
      "Epoch [40/50] - Train Loss: 1.0671, Test Loss: 1.6204\n",
      "Epoch [41/50] - Train Loss: 1.0657, Test Loss: 1.6191\n",
      "Epoch [42/50] - Train Loss: 1.0676, Test Loss: 1.6196\n",
      "Epoch [43/50] - Train Loss: 1.0656, Test Loss: 1.6183\n",
      "Epoch [44/50] - Train Loss: 1.0662, Test Loss: 1.6218\n",
      "Epoch [45/50] - Train Loss: 1.0659, Test Loss: 1.6135\n",
      "Epoch [46/50] - Train Loss: 1.0726, Test Loss: 1.6209\n",
      "Epoch [47/50] - Train Loss: 1.0672, Test Loss: 1.6167\n",
      "Epoch [48/50] - Train Loss: 1.0674, Test Loss: 1.6154\n",
      "Epoch [49/50] - Train Loss: 1.0674, Test Loss: 1.6165\n",
      "Epoch [50/50] - Train Loss: 1.0668, Test Loss: 1.6156\n",
      "Avg Test Loss: 1.6156\n",
      "Testing combination: (16, 1, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3581, Test Loss: 2.6491\n",
      "Epoch [2/50] - Train Loss: 1.3060, Test Loss: 2.6960\n",
      "Epoch [3/50] - Train Loss: 1.3000, Test Loss: 2.6914\n",
      "Epoch [4/50] - Train Loss: 1.2945, Test Loss: 2.6726\n",
      "Epoch [5/50] - Train Loss: 1.2917, Test Loss: 2.6619\n",
      "Epoch [6/50] - Train Loss: 1.2909, Test Loss: 2.6607\n",
      "Epoch [7/50] - Train Loss: 1.2902, Test Loss: 2.6657\n",
      "Epoch [8/50] - Train Loss: 1.2894, Test Loss: 2.6726\n",
      "Epoch [9/50] - Train Loss: 1.2889, Test Loss: 2.6772\n",
      "Epoch [10/50] - Train Loss: 1.2885, Test Loss: 2.6780\n",
      "Epoch [11/50] - Train Loss: 1.2881, Test Loss: 2.6762\n",
      "Epoch [12/50] - Train Loss: 1.2877, Test Loss: 2.6737\n",
      "Epoch [13/50] - Train Loss: 1.2872, Test Loss: 2.6719\n",
      "Epoch [14/50] - Train Loss: 1.2865, Test Loss: 2.6714\n",
      "Epoch [15/50] - Train Loss: 1.2850, Test Loss: 2.6721\n",
      "Epoch [16/50] - Train Loss: 1.2822, Test Loss: 2.6729\n",
      "Epoch [17/50] - Train Loss: 1.2791, Test Loss: 2.6728\n",
      "Epoch [18/50] - Train Loss: 1.2755, Test Loss: 2.6708\n",
      "Epoch [19/50] - Train Loss: 1.2718, Test Loss: 2.6675\n",
      "Epoch [20/50] - Train Loss: 1.2671, Test Loss: 2.6640\n",
      "Epoch [21/50] - Train Loss: 1.2617, Test Loss: 2.6615\n",
      "Epoch [22/50] - Train Loss: 1.2574, Test Loss: 2.6608\n",
      "Epoch [23/50] - Train Loss: 1.2545, Test Loss: 2.6608\n",
      "Epoch [24/50] - Train Loss: 1.2542, Test Loss: 2.6605\n",
      "Epoch [25/50] - Train Loss: 1.2546, Test Loss: 2.6600\n",
      "Epoch [26/50] - Train Loss: 1.2543, Test Loss: 2.6597\n",
      "Epoch [27/50] - Train Loss: 1.2558, Test Loss: 2.6598\n",
      "Epoch [28/50] - Train Loss: 1.2539, Test Loss: 2.6605\n",
      "Epoch [29/50] - Train Loss: 1.2542, Test Loss: 2.6608\n",
      "Epoch [30/50] - Train Loss: 1.2539, Test Loss: 2.6608\n",
      "Epoch [31/50] - Train Loss: 1.2538, Test Loss: 2.6608\n",
      "Epoch [32/50] - Train Loss: 1.2537, Test Loss: 2.6604\n",
      "Epoch [33/50] - Train Loss: 1.2537, Test Loss: 2.6600\n",
      "Epoch [34/50] - Train Loss: 1.2537, Test Loss: 2.6599\n",
      "Epoch [35/50] - Train Loss: 1.2536, Test Loss: 2.6600\n",
      "Epoch [36/50] - Train Loss: 1.2535, Test Loss: 2.6600\n",
      "Epoch [37/50] - Train Loss: 1.2535, Test Loss: 2.6599\n",
      "Epoch [38/50] - Train Loss: 1.2534, Test Loss: 2.6596\n",
      "Epoch [39/50] - Train Loss: 1.2533, Test Loss: 2.6592\n",
      "Epoch [40/50] - Train Loss: 1.2530, Test Loss: 2.6585\n",
      "Epoch [41/50] - Train Loss: 1.2523, Test Loss: 2.6570\n",
      "Epoch [42/50] - Train Loss: 1.2498, Test Loss: 2.6520\n",
      "Epoch [43/50] - Train Loss: 1.2494, Test Loss: 2.6467\n",
      "Epoch [44/50] - Train Loss: 1.2472, Test Loss: 2.6412\n",
      "Epoch [45/50] - Train Loss: 1.2473, Test Loss: 2.6366\n",
      "Epoch [46/50] - Train Loss: 1.2463, Test Loss: 2.6324\n",
      "Epoch [47/50] - Train Loss: 1.2453, Test Loss: 2.6312\n",
      "Epoch [48/50] - Train Loss: 1.2443, Test Loss: 2.6315\n",
      "Epoch [49/50] - Train Loss: 1.2433, Test Loss: 2.6303\n",
      "Epoch [50/50] - Train Loss: 1.2423, Test Loss: 2.6273\n",
      "Avg Test Loss: 2.6273\n",
      "Testing combination: (16, 1, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1047, Test Loss: 1.4736\n",
      "Epoch [2/50] - Train Loss: 1.0995, Test Loss: 1.4742\n",
      "Epoch [3/50] - Train Loss: 1.0961, Test Loss: 1.4752\n",
      "Epoch [4/50] - Train Loss: 1.0932, Test Loss: 1.4764\n",
      "Epoch [5/50] - Train Loss: 1.0910, Test Loss: 1.4777\n",
      "Epoch [6/50] - Train Loss: 1.0891, Test Loss: 1.4790\n",
      "Epoch [7/50] - Train Loss: 1.0878, Test Loss: 1.4802\n",
      "Epoch [8/50] - Train Loss: 1.0868, Test Loss: 1.4811\n",
      "Epoch [9/50] - Train Loss: 1.0860, Test Loss: 1.4818\n",
      "Epoch [10/50] - Train Loss: 1.0854, Test Loss: 1.4822\n",
      "Epoch [11/50] - Train Loss: 1.0849, Test Loss: 1.4824\n",
      "Epoch [12/50] - Train Loss: 1.0844, Test Loss: 1.4826\n",
      "Epoch [13/50] - Train Loss: 1.0839, Test Loss: 1.4826\n",
      "Epoch [14/50] - Train Loss: 1.0835, Test Loss: 1.4826\n",
      "Epoch [15/50] - Train Loss: 1.0831, Test Loss: 1.4826\n",
      "Epoch [16/50] - Train Loss: 1.0826, Test Loss: 1.4826\n",
      "Epoch [17/50] - Train Loss: 1.0822, Test Loss: 1.4826\n",
      "Epoch [18/50] - Train Loss: 1.0818, Test Loss: 1.4827\n",
      "Epoch [19/50] - Train Loss: 1.0814, Test Loss: 1.4827\n",
      "Epoch [20/50] - Train Loss: 1.0808, Test Loss: 1.4828\n",
      "Epoch [21/50] - Train Loss: 1.0805, Test Loss: 1.4829\n",
      "Epoch [22/50] - Train Loss: 1.0841, Test Loss: 1.4830\n",
      "Epoch [23/50] - Train Loss: 1.0797, Test Loss: 1.4835\n",
      "Epoch [24/50] - Train Loss: 1.0797, Test Loss: 1.4839\n",
      "Epoch [25/50] - Train Loss: 1.0786, Test Loss: 1.4839\n",
      "Epoch [26/50] - Train Loss: 1.0773, Test Loss: 1.4840\n",
      "Epoch [27/50] - Train Loss: 1.0763, Test Loss: 1.4843\n",
      "Epoch [28/50] - Train Loss: 1.0751, Test Loss: 1.4849\n",
      "Epoch [29/50] - Train Loss: 1.0739, Test Loss: 1.4854\n",
      "Epoch [30/50] - Train Loss: 1.0726, Test Loss: 1.4859\n",
      "Epoch [31/50] - Train Loss: 1.0714, Test Loss: 1.4865\n",
      "Epoch [32/50] - Train Loss: 1.0705, Test Loss: 1.4870\n",
      "Epoch [33/50] - Train Loss: 1.0717, Test Loss: 1.4879\n",
      "Epoch [34/50] - Train Loss: 1.0693, Test Loss: 1.4875\n",
      "Epoch [35/50] - Train Loss: 1.0669, Test Loss: 1.4875\n",
      "Epoch [36/50] - Train Loss: 1.0654, Test Loss: 1.4877\n",
      "Epoch [37/50] - Train Loss: 1.0638, Test Loss: 1.4880\n",
      "Epoch [38/50] - Train Loss: 1.0624, Test Loss: 1.4884\n",
      "Epoch [39/50] - Train Loss: 1.0610, Test Loss: 1.4887\n",
      "Epoch [40/50] - Train Loss: 1.0597, Test Loss: 1.4890\n",
      "Epoch [41/50] - Train Loss: 1.0584, Test Loss: 1.4893\n",
      "Epoch [42/50] - Train Loss: 1.0573, Test Loss: 1.4897\n",
      "Epoch [43/50] - Train Loss: 1.0563, Test Loss: 1.4902\n",
      "Epoch [44/50] - Train Loss: 1.0553, Test Loss: 1.4905\n",
      "Epoch [45/50] - Train Loss: 1.0544, Test Loss: 1.4909\n",
      "Epoch [46/50] - Train Loss: 1.0536, Test Loss: 1.4910\n",
      "Epoch [47/50] - Train Loss: 1.0526, Test Loss: 1.4911\n",
      "Epoch [48/50] - Train Loss: 1.0515, Test Loss: 1.4911\n",
      "Epoch [49/50] - Train Loss: 1.0505, Test Loss: 1.4911\n",
      "Epoch [50/50] - Train Loss: 1.0493, Test Loss: 1.4908\n",
      "Avg Test Loss: 1.4908\n",
      "Testing combination: (16, 1, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1155, Test Loss: 1.6115\n",
      "Epoch [2/50] - Train Loss: 1.1145, Test Loss: 1.6117\n",
      "Epoch [3/50] - Train Loss: 1.1140, Test Loss: 1.6116\n",
      "Epoch [4/50] - Train Loss: 1.1135, Test Loss: 1.6112\n",
      "Epoch [5/50] - Train Loss: 1.1130, Test Loss: 1.6109\n",
      "Epoch [6/50] - Train Loss: 1.1125, Test Loss: 1.6106\n",
      "Epoch [7/50] - Train Loss: 1.1119, Test Loss: 1.6101\n",
      "Epoch [8/50] - Train Loss: 1.1113, Test Loss: 1.6097\n",
      "Epoch [9/50] - Train Loss: 1.1107, Test Loss: 1.6092\n",
      "Epoch [10/50] - Train Loss: 1.1100, Test Loss: 1.6087\n",
      "Epoch [11/50] - Train Loss: 1.1093, Test Loss: 1.6083\n",
      "Epoch [12/50] - Train Loss: 1.1086, Test Loss: 1.6079\n",
      "Epoch [13/50] - Train Loss: 1.1080, Test Loss: 1.6075\n",
      "Epoch [14/50] - Train Loss: 1.1076, Test Loss: 1.6071\n",
      "Epoch [15/50] - Train Loss: 1.1074, Test Loss: 1.6068\n",
      "Epoch [16/50] - Train Loss: 1.1072, Test Loss: 1.6065\n",
      "Epoch [17/50] - Train Loss: 1.1070, Test Loss: 1.6063\n",
      "Epoch [18/50] - Train Loss: 1.1069, Test Loss: 1.6061\n",
      "Epoch [19/50] - Train Loss: 1.1067, Test Loss: 1.6060\n",
      "Epoch [20/50] - Train Loss: 1.1065, Test Loss: 1.6060\n",
      "Epoch [21/50] - Train Loss: 1.1062, Test Loss: 1.6059\n",
      "Epoch [22/50] - Train Loss: 1.1059, Test Loss: 1.6059\n",
      "Epoch [23/50] - Train Loss: 1.1054, Test Loss: 1.6060\n",
      "Epoch [24/50] - Train Loss: 1.1048, Test Loss: 1.6061\n",
      "Epoch [25/50] - Train Loss: 1.1039, Test Loss: 1.6063\n",
      "Epoch [26/50] - Train Loss: 1.1029, Test Loss: 1.6067\n",
      "Epoch [27/50] - Train Loss: 1.1016, Test Loss: 1.6071\n",
      "Epoch [28/50] - Train Loss: 1.1001, Test Loss: 1.6079\n",
      "Epoch [29/50] - Train Loss: 1.0983, Test Loss: 1.6090\n",
      "Epoch [30/50] - Train Loss: 1.0962, Test Loss: 1.6103\n",
      "Epoch [31/50] - Train Loss: 1.0947, Test Loss: 1.6116\n",
      "Epoch [32/50] - Train Loss: 1.0924, Test Loss: 1.6129\n",
      "Epoch [33/50] - Train Loss: 1.0894, Test Loss: 1.6139\n",
      "Epoch [34/50] - Train Loss: 1.0874, Test Loss: 1.6146\n",
      "Epoch [35/50] - Train Loss: 1.0852, Test Loss: 1.6153\n",
      "Epoch [36/50] - Train Loss: 1.0831, Test Loss: 1.6158\n",
      "Epoch [37/50] - Train Loss: 1.0814, Test Loss: 1.6165\n",
      "Epoch [38/50] - Train Loss: 1.0798, Test Loss: 1.6174\n",
      "Epoch [39/50] - Train Loss: 1.0785, Test Loss: 1.6187\n",
      "Epoch [40/50] - Train Loss: 1.0776, Test Loss: 1.6200\n",
      "Epoch [41/50] - Train Loss: 1.0769, Test Loss: 1.6211\n",
      "Epoch [42/50] - Train Loss: 1.0755, Test Loss: 1.6217\n",
      "Epoch [43/50] - Train Loss: 1.0746, Test Loss: 1.6221\n",
      "Epoch [44/50] - Train Loss: 1.0738, Test Loss: 1.6220\n",
      "Epoch [45/50] - Train Loss: 1.0733, Test Loss: 1.6223\n",
      "Epoch [46/50] - Train Loss: 1.0724, Test Loss: 1.6228\n",
      "Epoch [47/50] - Train Loss: 1.0716, Test Loss: 1.6218\n",
      "Epoch [48/50] - Train Loss: 1.0710, Test Loss: 1.6209\n",
      "Epoch [49/50] - Train Loss: 1.0699, Test Loss: 1.6192\n",
      "Epoch [50/50] - Train Loss: 1.0687, Test Loss: 1.6177\n",
      "Avg Test Loss: 1.6177\n",
      "Testing combination: (16, 1, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3137, Test Loss: 2.6349\n",
      "Epoch [2/50] - Train Loss: 1.3089, Test Loss: 2.6389\n",
      "Epoch [3/50] - Train Loss: 1.3060, Test Loss: 2.6429\n",
      "Epoch [4/50] - Train Loss: 1.3041, Test Loss: 2.6468\n",
      "Epoch [5/50] - Train Loss: 1.3027, Test Loss: 2.6504\n",
      "Epoch [6/50] - Train Loss: 1.3018, Test Loss: 2.6536\n",
      "Epoch [7/50] - Train Loss: 1.3011, Test Loss: 2.6564\n",
      "Epoch [8/50] - Train Loss: 1.3005, Test Loss: 2.6588\n",
      "Epoch [9/50] - Train Loss: 1.3002, Test Loss: 2.6607\n",
      "Epoch [10/50] - Train Loss: 1.2999, Test Loss: 2.6623\n",
      "Epoch [11/50] - Train Loss: 1.2996, Test Loss: 2.6636\n",
      "Epoch [12/50] - Train Loss: 1.2993, Test Loss: 2.6645\n",
      "Epoch [13/50] - Train Loss: 1.2991, Test Loss: 2.6652\n",
      "Epoch [14/50] - Train Loss: 1.2988, Test Loss: 2.6657\n",
      "Epoch [15/50] - Train Loss: 1.2985, Test Loss: 2.6660\n",
      "Epoch [16/50] - Train Loss: 1.2981, Test Loss: 2.6662\n",
      "Epoch [17/50] - Train Loss: 1.2978, Test Loss: 2.6664\n",
      "Epoch [18/50] - Train Loss: 1.2974, Test Loss: 2.6665\n",
      "Epoch [19/50] - Train Loss: 1.2970, Test Loss: 2.6666\n",
      "Epoch [20/50] - Train Loss: 1.2965, Test Loss: 2.6667\n",
      "Epoch [21/50] - Train Loss: 1.2961, Test Loss: 2.6668\n",
      "Epoch [22/50] - Train Loss: 1.2956, Test Loss: 2.6669\n",
      "Epoch [23/50] - Train Loss: 1.2951, Test Loss: 2.6671\n",
      "Epoch [24/50] - Train Loss: 1.2946, Test Loss: 2.6672\n",
      "Epoch [25/50] - Train Loss: 1.2941, Test Loss: 2.6674\n",
      "Epoch [26/50] - Train Loss: 1.2936, Test Loss: 2.6677\n",
      "Epoch [27/50] - Train Loss: 1.2931, Test Loss: 2.6679\n",
      "Epoch [28/50] - Train Loss: 1.2926, Test Loss: 2.6682\n",
      "Epoch [29/50] - Train Loss: 1.2922, Test Loss: 2.6685\n",
      "Epoch [30/50] - Train Loss: 1.2917, Test Loss: 2.6688\n",
      "Epoch [31/50] - Train Loss: 1.2913, Test Loss: 2.6691\n",
      "Epoch [32/50] - Train Loss: 1.2909, Test Loss: 2.6694\n",
      "Epoch [33/50] - Train Loss: 1.2905, Test Loss: 2.6696\n",
      "Epoch [34/50] - Train Loss: 1.2902, Test Loss: 2.6699\n",
      "Epoch [35/50] - Train Loss: 1.2899, Test Loss: 2.6701\n",
      "Epoch [36/50] - Train Loss: 1.2896, Test Loss: 2.6704\n",
      "Epoch [37/50] - Train Loss: 1.2894, Test Loss: 2.6706\n",
      "Epoch [38/50] - Train Loss: 1.2892, Test Loss: 2.6707\n",
      "Epoch [39/50] - Train Loss: 1.2890, Test Loss: 2.6709\n",
      "Epoch [40/50] - Train Loss: 1.2889, Test Loss: 2.6710\n",
      "Epoch [41/50] - Train Loss: 1.2887, Test Loss: 2.6711\n",
      "Epoch [42/50] - Train Loss: 1.2885, Test Loss: 2.6711\n",
      "Epoch [43/50] - Train Loss: 1.2884, Test Loss: 2.6712\n",
      "Epoch [44/50] - Train Loss: 1.2882, Test Loss: 2.6712\n",
      "Epoch [45/50] - Train Loss: 1.2881, Test Loss: 2.6712\n",
      "Epoch [46/50] - Train Loss: 1.2879, Test Loss: 2.6712\n",
      "Epoch [47/50] - Train Loss: 1.2877, Test Loss: 2.6711\n",
      "Epoch [48/50] - Train Loss: 1.2875, Test Loss: 2.6710\n",
      "Epoch [49/50] - Train Loss: 1.2873, Test Loss: 2.6710\n",
      "Epoch [50/50] - Train Loss: 1.2870, Test Loss: 2.6709\n",
      "Avg Test Loss: 2.6709\n",
      "Testing combination: (16, 1, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.0999, Test Loss: 1.5129\n",
      "Epoch [2/50] - Train Loss: 1.0994, Test Loss: 1.5123\n",
      "Epoch [3/50] - Train Loss: 1.0989, Test Loss: 1.5117\n",
      "Epoch [4/50] - Train Loss: 1.0986, Test Loss: 1.5111\n",
      "Epoch [5/50] - Train Loss: 1.0982, Test Loss: 1.5105\n",
      "Epoch [6/50] - Train Loss: 1.0978, Test Loss: 1.5099\n",
      "Epoch [7/50] - Train Loss: 1.0974, Test Loss: 1.5093\n",
      "Epoch [8/50] - Train Loss: 1.0971, Test Loss: 1.5088\n",
      "Epoch [9/50] - Train Loss: 1.0967, Test Loss: 1.5083\n",
      "Epoch [10/50] - Train Loss: 1.0963, Test Loss: 1.5077\n",
      "Epoch [11/50] - Train Loss: 1.0960, Test Loss: 1.5072\n",
      "Epoch [12/50] - Train Loss: 1.0957, Test Loss: 1.5067\n",
      "Epoch [13/50] - Train Loss: 1.0953, Test Loss: 1.5062\n",
      "Epoch [14/50] - Train Loss: 1.0950, Test Loss: 1.5058\n",
      "Epoch [15/50] - Train Loss: 1.0947, Test Loss: 1.5053\n",
      "Epoch [16/50] - Train Loss: 1.0944, Test Loss: 1.5048\n",
      "Epoch [17/50] - Train Loss: 1.0941, Test Loss: 1.5044\n",
      "Epoch [18/50] - Train Loss: 1.0938, Test Loss: 1.5040\n",
      "Epoch [19/50] - Train Loss: 1.0935, Test Loss: 1.5035\n",
      "Epoch [20/50] - Train Loss: 1.0933, Test Loss: 1.5031\n",
      "Epoch [21/50] - Train Loss: 1.0930, Test Loss: 1.5027\n",
      "Epoch [22/50] - Train Loss: 1.0927, Test Loss: 1.5023\n",
      "Epoch [23/50] - Train Loss: 1.0924, Test Loss: 1.5019\n",
      "Epoch [24/50] - Train Loss: 1.0922, Test Loss: 1.5015\n",
      "Epoch [25/50] - Train Loss: 1.0920, Test Loss: 1.5012\n",
      "Epoch [26/50] - Train Loss: 1.0917, Test Loss: 1.5008\n",
      "Epoch [27/50] - Train Loss: 1.0915, Test Loss: 1.5004\n",
      "Epoch [28/50] - Train Loss: 1.0912, Test Loss: 1.5001\n",
      "Epoch [29/50] - Train Loss: 1.0910, Test Loss: 1.4997\n",
      "Epoch [30/50] - Train Loss: 1.0907, Test Loss: 1.4994\n",
      "Epoch [31/50] - Train Loss: 1.0905, Test Loss: 1.4990\n",
      "Epoch [32/50] - Train Loss: 1.0903, Test Loss: 1.4987\n",
      "Epoch [33/50] - Train Loss: 1.0900, Test Loss: 1.4984\n",
      "Epoch [34/50] - Train Loss: 1.0898, Test Loss: 1.4981\n",
      "Epoch [35/50] - Train Loss: 1.0896, Test Loss: 1.4977\n",
      "Epoch [36/50] - Train Loss: 1.0894, Test Loss: 1.4974\n",
      "Epoch [37/50] - Train Loss: 1.0892, Test Loss: 1.4971\n",
      "Epoch [38/50] - Train Loss: 1.0889, Test Loss: 1.4968\n",
      "Epoch [39/50] - Train Loss: 1.0887, Test Loss: 1.4965\n",
      "Epoch [40/50] - Train Loss: 1.0885, Test Loss: 1.4962\n",
      "Epoch [41/50] - Train Loss: 1.0883, Test Loss: 1.4960\n",
      "Epoch [42/50] - Train Loss: 1.0881, Test Loss: 1.4957\n",
      "Epoch [43/50] - Train Loss: 1.0879, Test Loss: 1.4954\n",
      "Epoch [44/50] - Train Loss: 1.0877, Test Loss: 1.4951\n",
      "Epoch [45/50] - Train Loss: 1.0875, Test Loss: 1.4949\n",
      "Epoch [46/50] - Train Loss: 1.0873, Test Loss: 1.4946\n",
      "Epoch [47/50] - Train Loss: 1.0871, Test Loss: 1.4943\n",
      "Epoch [48/50] - Train Loss: 1.0869, Test Loss: 1.4941\n",
      "Epoch [49/50] - Train Loss: 1.0868, Test Loss: 1.4938\n",
      "Epoch [50/50] - Train Loss: 1.0866, Test Loss: 1.4936\n",
      "Avg Test Loss: 1.4936\n",
      "Testing combination: (16, 1, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1284, Test Loss: 1.5781\n",
      "Epoch [2/50] - Train Loss: 1.1273, Test Loss: 1.5786\n",
      "Epoch [3/50] - Train Loss: 1.1264, Test Loss: 1.5792\n",
      "Epoch [4/50] - Train Loss: 1.1255, Test Loss: 1.5797\n",
      "Epoch [5/50] - Train Loss: 1.1247, Test Loss: 1.5803\n",
      "Epoch [6/50] - Train Loss: 1.1239, Test Loss: 1.5808\n",
      "Epoch [7/50] - Train Loss: 1.1232, Test Loss: 1.5814\n",
      "Epoch [8/50] - Train Loss: 1.1225, Test Loss: 1.5820\n",
      "Epoch [9/50] - Train Loss: 1.1219, Test Loss: 1.5826\n",
      "Epoch [10/50] - Train Loss: 1.1213, Test Loss: 1.5832\n",
      "Epoch [11/50] - Train Loss: 1.1207, Test Loss: 1.5839\n",
      "Epoch [12/50] - Train Loss: 1.1202, Test Loss: 1.5845\n",
      "Epoch [13/50] - Train Loss: 1.1197, Test Loss: 1.5851\n",
      "Epoch [14/50] - Train Loss: 1.1192, Test Loss: 1.5857\n",
      "Epoch [15/50] - Train Loss: 1.1188, Test Loss: 1.5863\n",
      "Epoch [16/50] - Train Loss: 1.1183, Test Loss: 1.5870\n",
      "Epoch [17/50] - Train Loss: 1.1179, Test Loss: 1.5876\n",
      "Epoch [18/50] - Train Loss: 1.1175, Test Loss: 1.5882\n",
      "Epoch [19/50] - Train Loss: 1.1172, Test Loss: 1.5888\n",
      "Epoch [20/50] - Train Loss: 1.1168, Test Loss: 1.5894\n",
      "Epoch [21/50] - Train Loss: 1.1165, Test Loss: 1.5900\n",
      "Epoch [22/50] - Train Loss: 1.1162, Test Loss: 1.5906\n",
      "Epoch [23/50] - Train Loss: 1.1159, Test Loss: 1.5912\n",
      "Epoch [24/50] - Train Loss: 1.1156, Test Loss: 1.5918\n",
      "Epoch [25/50] - Train Loss: 1.1153, Test Loss: 1.5924\n",
      "Epoch [26/50] - Train Loss: 1.1151, Test Loss: 1.5930\n",
      "Epoch [27/50] - Train Loss: 1.1148, Test Loss: 1.5935\n",
      "Epoch [28/50] - Train Loss: 1.1146, Test Loss: 1.5941\n",
      "Epoch [29/50] - Train Loss: 1.1144, Test Loss: 1.5946\n",
      "Epoch [30/50] - Train Loss: 1.1142, Test Loss: 1.5951\n",
      "Epoch [31/50] - Train Loss: 1.1140, Test Loss: 1.5956\n",
      "Epoch [32/50] - Train Loss: 1.1138, Test Loss: 1.5961\n",
      "Epoch [33/50] - Train Loss: 1.1136, Test Loss: 1.5966\n",
      "Epoch [34/50] - Train Loss: 1.1135, Test Loss: 1.5971\n",
      "Epoch [35/50] - Train Loss: 1.1133, Test Loss: 1.5976\n",
      "Epoch [36/50] - Train Loss: 1.1132, Test Loss: 1.5980\n",
      "Epoch [37/50] - Train Loss: 1.1130, Test Loss: 1.5985\n",
      "Epoch [38/50] - Train Loss: 1.1129, Test Loss: 1.5989\n",
      "Epoch [39/50] - Train Loss: 1.1128, Test Loss: 1.5993\n",
      "Epoch [40/50] - Train Loss: 1.1126, Test Loss: 1.5997\n",
      "Epoch [41/50] - Train Loss: 1.1125, Test Loss: 1.6001\n",
      "Epoch [42/50] - Train Loss: 1.1124, Test Loss: 1.6005\n",
      "Epoch [43/50] - Train Loss: 1.1123, Test Loss: 1.6009\n",
      "Epoch [44/50] - Train Loss: 1.1122, Test Loss: 1.6012\n",
      "Epoch [45/50] - Train Loss: 1.1121, Test Loss: 1.6015\n",
      "Epoch [46/50] - Train Loss: 1.1120, Test Loss: 1.6019\n",
      "Epoch [47/50] - Train Loss: 1.1119, Test Loss: 1.6022\n",
      "Epoch [48/50] - Train Loss: 1.1118, Test Loss: 1.6025\n",
      "Epoch [49/50] - Train Loss: 1.1117, Test Loss: 1.6028\n",
      "Epoch [50/50] - Train Loss: 1.1116, Test Loss: 1.6031\n",
      "Avg Test Loss: 1.6031\n",
      "Testing combination: (16, 1, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3255, Test Loss: 2.6281\n",
      "Epoch [2/50] - Train Loss: 1.3249, Test Loss: 2.6282\n",
      "Epoch [3/50] - Train Loss: 1.3243, Test Loss: 2.6282\n",
      "Epoch [4/50] - Train Loss: 1.3238, Test Loss: 2.6282\n",
      "Epoch [5/50] - Train Loss: 1.3233, Test Loss: 2.6283\n",
      "Epoch [6/50] - Train Loss: 1.3228, Test Loss: 2.6283\n",
      "Epoch [7/50] - Train Loss: 1.3223, Test Loss: 2.6284\n",
      "Epoch [8/50] - Train Loss: 1.3218, Test Loss: 2.6284\n",
      "Epoch [9/50] - Train Loss: 1.3213, Test Loss: 2.6285\n",
      "Epoch [10/50] - Train Loss: 1.3208, Test Loss: 2.6286\n",
      "Epoch [11/50] - Train Loss: 1.3204, Test Loss: 2.6286\n",
      "Epoch [12/50] - Train Loss: 1.3199, Test Loss: 2.6287\n",
      "Epoch [13/50] - Train Loss: 1.3194, Test Loss: 2.6288\n",
      "Epoch [14/50] - Train Loss: 1.3190, Test Loss: 2.6289\n",
      "Epoch [15/50] - Train Loss: 1.3186, Test Loss: 2.6290\n",
      "Epoch [16/50] - Train Loss: 1.3181, Test Loss: 2.6291\n",
      "Epoch [17/50] - Train Loss: 1.3177, Test Loss: 2.6292\n",
      "Epoch [18/50] - Train Loss: 1.3173, Test Loss: 2.6293\n",
      "Epoch [19/50] - Train Loss: 1.3169, Test Loss: 2.6294\n",
      "Epoch [20/50] - Train Loss: 1.3165, Test Loss: 2.6295\n",
      "Epoch [21/50] - Train Loss: 1.3161, Test Loss: 2.6296\n",
      "Epoch [22/50] - Train Loss: 1.3157, Test Loss: 2.6298\n",
      "Epoch [23/50] - Train Loss: 1.3153, Test Loss: 2.6299\n",
      "Epoch [24/50] - Train Loss: 1.3149, Test Loss: 2.6300\n",
      "Epoch [25/50] - Train Loss: 1.3145, Test Loss: 2.6302\n",
      "Epoch [26/50] - Train Loss: 1.3142, Test Loss: 2.6303\n",
      "Epoch [27/50] - Train Loss: 1.3138, Test Loss: 2.6305\n",
      "Epoch [28/50] - Train Loss: 1.3134, Test Loss: 2.6306\n",
      "Epoch [29/50] - Train Loss: 1.3131, Test Loss: 2.6308\n",
      "Epoch [30/50] - Train Loss: 1.3127, Test Loss: 2.6310\n",
      "Epoch [31/50] - Train Loss: 1.3124, Test Loss: 2.6311\n",
      "Epoch [32/50] - Train Loss: 1.3120, Test Loss: 2.6313\n",
      "Epoch [33/50] - Train Loss: 1.3117, Test Loss: 2.6315\n",
      "Epoch [34/50] - Train Loss: 1.3114, Test Loss: 2.6316\n",
      "Epoch [35/50] - Train Loss: 1.3110, Test Loss: 2.6318\n",
      "Epoch [36/50] - Train Loss: 1.3107, Test Loss: 2.6320\n",
      "Epoch [37/50] - Train Loss: 1.3104, Test Loss: 2.6322\n",
      "Epoch [38/50] - Train Loss: 1.3101, Test Loss: 2.6324\n",
      "Epoch [39/50] - Train Loss: 1.3097, Test Loss: 2.6326\n",
      "Epoch [40/50] - Train Loss: 1.3094, Test Loss: 2.6328\n",
      "Epoch [41/50] - Train Loss: 1.3091, Test Loss: 2.6330\n",
      "Epoch [42/50] - Train Loss: 1.3088, Test Loss: 2.6332\n",
      "Epoch [43/50] - Train Loss: 1.3085, Test Loss: 2.6334\n",
      "Epoch [44/50] - Train Loss: 1.3082, Test Loss: 2.6336\n",
      "Epoch [45/50] - Train Loss: 1.3079, Test Loss: 2.6338\n",
      "Epoch [46/50] - Train Loss: 1.3076, Test Loss: 2.6340\n",
      "Epoch [47/50] - Train Loss: 1.3073, Test Loss: 2.6342\n",
      "Epoch [48/50] - Train Loss: 1.3070, Test Loss: 2.6345\n",
      "Epoch [49/50] - Train Loss: 1.3067, Test Loss: 2.6347\n",
      "Epoch [50/50] - Train Loss: 1.3064, Test Loss: 2.6349\n",
      "Avg Test Loss: 2.6349\n",
      "Testing combination: (16, 2, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1196, Test Loss: 1.5036\n",
      "Epoch [2/50] - Train Loss: 1.0951, Test Loss: 1.4849\n",
      "Epoch [3/50] - Train Loss: 1.0928, Test Loss: 1.4820\n",
      "Epoch [4/50] - Train Loss: 1.0893, Test Loss: 1.4826\n",
      "Epoch [5/50] - Train Loss: 1.0866, Test Loss: 1.4828\n",
      "Epoch [6/50] - Train Loss: 1.0864, Test Loss: 1.4829\n",
      "Epoch [7/50] - Train Loss: 1.0872, Test Loss: 1.4827\n",
      "Epoch [8/50] - Train Loss: 1.0845, Test Loss: 1.4839\n",
      "Epoch [9/50] - Train Loss: 1.0817, Test Loss: 1.4833\n",
      "Epoch [10/50] - Train Loss: 1.0770, Test Loss: 1.4844\n",
      "Epoch [11/50] - Train Loss: 1.0742, Test Loss: 1.4855\n",
      "Epoch [12/50] - Train Loss: 1.0661, Test Loss: 1.4882\n",
      "Epoch [13/50] - Train Loss: 1.0578, Test Loss: 1.4888\n",
      "Epoch [14/50] - Train Loss: 1.0549, Test Loss: 1.4867\n",
      "Epoch [15/50] - Train Loss: 1.0549, Test Loss: 1.4861\n",
      "Epoch [16/50] - Train Loss: 1.0545, Test Loss: 1.4868\n",
      "Epoch [17/50] - Train Loss: 1.0541, Test Loss: 1.4871\n",
      "Epoch [18/50] - Train Loss: 1.0539, Test Loss: 1.4871\n",
      "Epoch [19/50] - Train Loss: 1.0537, Test Loss: 1.4870\n",
      "Epoch [20/50] - Train Loss: 1.0536, Test Loss: 1.4870\n",
      "Epoch [21/50] - Train Loss: 1.0535, Test Loss: 1.4870\n",
      "Epoch [22/50] - Train Loss: 1.0534, Test Loss: 1.4870\n",
      "Epoch [23/50] - Train Loss: 1.0534, Test Loss: 1.4871\n",
      "Epoch [24/50] - Train Loss: 1.0533, Test Loss: 1.4871\n",
      "Epoch [25/50] - Train Loss: 1.0532, Test Loss: 1.4871\n",
      "Epoch [26/50] - Train Loss: 1.0532, Test Loss: 1.4871\n",
      "Epoch [27/50] - Train Loss: 1.0531, Test Loss: 1.4871\n",
      "Epoch [28/50] - Train Loss: 1.0531, Test Loss: 1.4871\n",
      "Epoch [29/50] - Train Loss: 1.0531, Test Loss: 1.4871\n",
      "Epoch [30/50] - Train Loss: 1.0530, Test Loss: 1.4871\n",
      "Epoch [31/50] - Train Loss: 1.0530, Test Loss: 1.4871\n",
      "Epoch [32/50] - Train Loss: 1.0529, Test Loss: 1.4871\n",
      "Epoch [33/50] - Train Loss: 1.0529, Test Loss: 1.4871\n",
      "Epoch [34/50] - Train Loss: 1.0529, Test Loss: 1.4871\n",
      "Epoch [35/50] - Train Loss: 1.0528, Test Loss: 1.4871\n",
      "Epoch [36/50] - Train Loss: 1.0527, Test Loss: 1.4871\n",
      "Epoch [37/50] - Train Loss: 1.0526, Test Loss: 1.4869\n",
      "Epoch [38/50] - Train Loss: 1.0525, Test Loss: 1.4868\n",
      "Epoch [39/50] - Train Loss: 1.0521, Test Loss: 1.4866\n",
      "Epoch [40/50] - Train Loss: 1.0519, Test Loss: 1.4878\n",
      "Epoch [41/50] - Train Loss: 1.0542, Test Loss: 1.4892\n",
      "Epoch [42/50] - Train Loss: 1.0540, Test Loss: 1.4877\n",
      "Epoch [43/50] - Train Loss: 1.0566, Test Loss: 1.4873\n",
      "Epoch [44/50] - Train Loss: 1.0562, Test Loss: 1.4865\n",
      "Epoch [45/50] - Train Loss: 1.0533, Test Loss: 1.4871\n",
      "Epoch [46/50] - Train Loss: 1.0534, Test Loss: 1.4873\n",
      "Epoch [47/50] - Train Loss: 1.0527, Test Loss: 1.4871\n",
      "Epoch [48/50] - Train Loss: 1.0523, Test Loss: 1.4866\n",
      "Epoch [49/50] - Train Loss: 1.0520, Test Loss: 1.4865\n",
      "Epoch [50/50] - Train Loss: 1.0521, Test Loss: 1.4868\n",
      "Avg Test Loss: 1.4868\n",
      "Testing combination: (16, 2, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1539, Test Loss: 1.5934\n",
      "Epoch [2/50] - Train Loss: 1.1194, Test Loss: 1.5839\n",
      "Epoch [3/50] - Train Loss: 1.1181, Test Loss: 1.6006\n",
      "Epoch [4/50] - Train Loss: 1.1147, Test Loss: 1.6161\n",
      "Epoch [5/50] - Train Loss: 1.1117, Test Loss: 1.6102\n",
      "Epoch [6/50] - Train Loss: 1.1080, Test Loss: 1.6026\n",
      "Epoch [7/50] - Train Loss: 1.1076, Test Loss: 1.5999\n",
      "Epoch [8/50] - Train Loss: 1.1081, Test Loss: 1.6034\n",
      "Epoch [9/50] - Train Loss: 1.1040, Test Loss: 1.6093\n",
      "Epoch [10/50] - Train Loss: 1.0986, Test Loss: 1.6108\n",
      "Epoch [11/50] - Train Loss: 1.0912, Test Loss: 1.6133\n",
      "Epoch [12/50] - Train Loss: 1.0842, Test Loss: 1.6136\n",
      "Epoch [13/50] - Train Loss: 1.0805, Test Loss: 1.6113\n",
      "Epoch [14/50] - Train Loss: 1.0797, Test Loss: 1.6101\n",
      "Epoch [15/50] - Train Loss: 1.0796, Test Loss: 1.6113\n",
      "Epoch [16/50] - Train Loss: 1.0794, Test Loss: 1.6122\n",
      "Epoch [17/50] - Train Loss: 1.0791, Test Loss: 1.6120\n",
      "Epoch [18/50] - Train Loss: 1.0790, Test Loss: 1.6119\n",
      "Epoch [19/50] - Train Loss: 1.0789, Test Loss: 1.6123\n",
      "Epoch [20/50] - Train Loss: 1.0787, Test Loss: 1.6127\n",
      "Epoch [21/50] - Train Loss: 1.0785, Test Loss: 1.6129\n",
      "Epoch [22/50] - Train Loss: 1.0781, Test Loss: 1.6129\n",
      "Epoch [23/50] - Train Loss: 1.0766, Test Loss: 1.6148\n",
      "Epoch [24/50] - Train Loss: 1.0758, Test Loss: 1.6183\n",
      "Epoch [25/50] - Train Loss: 1.0736, Test Loss: 1.6167\n",
      "Epoch [26/50] - Train Loss: 1.0746, Test Loss: 1.6156\n",
      "Epoch [27/50] - Train Loss: 1.0718, Test Loss: 1.6147\n",
      "Epoch [28/50] - Train Loss: 1.0728, Test Loss: 1.6164\n",
      "Epoch [29/50] - Train Loss: 1.0719, Test Loss: 1.6162\n",
      "Epoch [30/50] - Train Loss: 1.0708, Test Loss: 1.6153\n",
      "Epoch [31/50] - Train Loss: 1.0719, Test Loss: 1.6153\n",
      "Epoch [32/50] - Train Loss: 1.0698, Test Loss: 1.6147\n",
      "Epoch [33/50] - Train Loss: 1.0715, Test Loss: 1.6147\n",
      "Epoch [34/50] - Train Loss: 1.0687, Test Loss: 1.6134\n",
      "Epoch [35/50] - Train Loss: 1.0691, Test Loss: 1.6132\n",
      "Epoch [36/50] - Train Loss: 1.1184, Test Loss: 1.6123\n",
      "Epoch [37/50] - Train Loss: 1.1152, Test Loss: 1.6028\n",
      "Epoch [38/50] - Train Loss: 1.1130, Test Loss: 1.6030\n",
      "Epoch [39/50] - Train Loss: 1.1112, Test Loss: 1.6045\n",
      "Epoch [40/50] - Train Loss: 1.1091, Test Loss: 1.6026\n",
      "Epoch [41/50] - Train Loss: 1.1072, Test Loss: 1.6021\n",
      "Epoch [42/50] - Train Loss: 1.1027, Test Loss: 1.6046\n",
      "Epoch [43/50] - Train Loss: 1.0927, Test Loss: 1.6137\n",
      "Epoch [44/50] - Train Loss: 1.1230, Test Loss: 1.6046\n",
      "Epoch [45/50] - Train Loss: 1.0928, Test Loss: 1.6056\n",
      "Epoch [46/50] - Train Loss: 1.0817, Test Loss: 1.6189\n",
      "Epoch [47/50] - Train Loss: 1.0801, Test Loss: 1.6141\n",
      "Epoch [48/50] - Train Loss: 1.0797, Test Loss: 1.6092\n",
      "Epoch [49/50] - Train Loss: 1.0808, Test Loss: 1.6114\n",
      "Epoch [50/50] - Train Loss: 1.0826, Test Loss: 1.6131\n",
      "Avg Test Loss: 1.6131\n",
      "Testing combination: (16, 2, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.4093, Test Loss: 2.7201\n",
      "Epoch [2/50] - Train Loss: 1.3068, Test Loss: 2.6352\n",
      "Epoch [3/50] - Train Loss: 1.3110, Test Loss: 2.6383\n",
      "Epoch [4/50] - Train Loss: 1.3041, Test Loss: 2.6560\n",
      "Epoch [5/50] - Train Loss: 1.2993, Test Loss: 2.6734\n",
      "Epoch [6/50] - Train Loss: 1.2976, Test Loss: 2.6812\n",
      "Epoch [7/50] - Train Loss: 1.2960, Test Loss: 2.6786\n",
      "Epoch [8/50] - Train Loss: 1.2940, Test Loss: 2.6723\n",
      "Epoch [9/50] - Train Loss: 1.2921, Test Loss: 2.6670\n",
      "Epoch [10/50] - Train Loss: 1.2902, Test Loss: 2.6654\n",
      "Epoch [11/50] - Train Loss: 1.2883, Test Loss: 2.6678\n",
      "Epoch [12/50] - Train Loss: 1.2864, Test Loss: 2.6721\n",
      "Epoch [13/50] - Train Loss: 1.2845, Test Loss: 2.6749\n",
      "Epoch [14/50] - Train Loss: 1.2815, Test Loss: 2.6731\n",
      "Epoch [15/50] - Train Loss: 1.2776, Test Loss: 2.6671\n",
      "Epoch [16/50] - Train Loss: 1.2736, Test Loss: 2.6605\n",
      "Epoch [17/50] - Train Loss: 1.2701, Test Loss: 2.6566\n",
      "Epoch [18/50] - Train Loss: 1.2650, Test Loss: 2.6578\n",
      "Epoch [19/50] - Train Loss: 1.2577, Test Loss: 2.6621\n",
      "Epoch [20/50] - Train Loss: 1.2548, Test Loss: 2.6632\n",
      "Epoch [21/50] - Train Loss: 1.2543, Test Loss: 2.6612\n",
      "Epoch [22/50] - Train Loss: 1.2545, Test Loss: 2.6601\n",
      "Epoch [23/50] - Train Loss: 1.2541, Test Loss: 2.6607\n",
      "Epoch [24/50] - Train Loss: 1.2538, Test Loss: 2.6613\n",
      "Epoch [25/50] - Train Loss: 1.2539, Test Loss: 2.6611\n",
      "Epoch [26/50] - Train Loss: 1.2538, Test Loss: 2.6605\n",
      "Epoch [27/50] - Train Loss: 1.2537, Test Loss: 2.6604\n",
      "Epoch [28/50] - Train Loss: 1.2537, Test Loss: 2.6607\n",
      "Epoch [29/50] - Train Loss: 1.2536, Test Loss: 2.6611\n",
      "Epoch [30/50] - Train Loss: 1.2535, Test Loss: 2.6610\n",
      "Epoch [31/50] - Train Loss: 1.2534, Test Loss: 2.6606\n",
      "Epoch [32/50] - Train Loss: 1.2532, Test Loss: 2.6600\n",
      "Epoch [33/50] - Train Loss: 1.2528, Test Loss: 2.6589\n",
      "Epoch [34/50] - Train Loss: 1.2520, Test Loss: 2.6568\n",
      "Epoch [35/50] - Train Loss: 1.2509, Test Loss: 2.6513\n",
      "Epoch [36/50] - Train Loss: 1.2505, Test Loss: 2.6381\n",
      "Epoch [37/50] - Train Loss: 1.2450, Test Loss: 2.6414\n",
      "Epoch [38/50] - Train Loss: 1.2463, Test Loss: 2.6503\n",
      "Epoch [39/50] - Train Loss: 1.2431, Test Loss: 2.6592\n",
      "Epoch [40/50] - Train Loss: 1.2425, Test Loss: 2.6514\n",
      "Epoch [41/50] - Train Loss: 1.2397, Test Loss: 2.6453\n",
      "Epoch [42/50] - Train Loss: 1.2410, Test Loss: 2.6486\n",
      "Epoch [43/50] - Train Loss: 1.2401, Test Loss: 2.6444\n",
      "Epoch [44/50] - Train Loss: 1.2394, Test Loss: 2.6480\n",
      "Epoch [45/50] - Train Loss: 1.2394, Test Loss: 2.6464\n",
      "Epoch [46/50] - Train Loss: 1.2398, Test Loss: 2.6425\n",
      "Epoch [47/50] - Train Loss: 1.2395, Test Loss: 2.6410\n",
      "Epoch [48/50] - Train Loss: 1.2391, Test Loss: 2.6399\n",
      "Epoch [49/50] - Train Loss: 1.2393, Test Loss: 2.6371\n",
      "Epoch [50/50] - Train Loss: 1.2396, Test Loss: 2.6343\n",
      "Avg Test Loss: 2.6343\n",
      "Testing combination: (16, 2, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1130, Test Loss: 1.4734\n",
      "Epoch [2/50] - Train Loss: 1.1039, Test Loss: 1.4738\n",
      "Epoch [3/50] - Train Loss: 1.0994, Test Loss: 1.4751\n",
      "Epoch [4/50] - Train Loss: 1.0965, Test Loss: 1.4768\n",
      "Epoch [5/50] - Train Loss: 1.0946, Test Loss: 1.4787\n",
      "Epoch [6/50] - Train Loss: 1.0934, Test Loss: 1.4804\n",
      "Epoch [7/50] - Train Loss: 1.0925, Test Loss: 1.4819\n",
      "Epoch [8/50] - Train Loss: 1.0918, Test Loss: 1.4829\n",
      "Epoch [9/50] - Train Loss: 1.0912, Test Loss: 1.4837\n",
      "Epoch [10/50] - Train Loss: 1.0907, Test Loss: 1.4842\n",
      "Epoch [11/50] - Train Loss: 1.0901, Test Loss: 1.4845\n",
      "Epoch [12/50] - Train Loss: 1.0894, Test Loss: 1.4846\n",
      "Epoch [13/50] - Train Loss: 1.0887, Test Loss: 1.4845\n",
      "Epoch [14/50] - Train Loss: 1.0880, Test Loss: 1.4845\n",
      "Epoch [15/50] - Train Loss: 1.0872, Test Loss: 1.4843\n",
      "Epoch [16/50] - Train Loss: 1.0865, Test Loss: 1.4840\n",
      "Epoch [17/50] - Train Loss: 1.0857, Test Loss: 1.4837\n",
      "Epoch [18/50] - Train Loss: 1.0850, Test Loss: 1.4834\n",
      "Epoch [19/50] - Train Loss: 1.0843, Test Loss: 1.4831\n",
      "Epoch [20/50] - Train Loss: 1.0836, Test Loss: 1.4829\n",
      "Epoch [21/50] - Train Loss: 1.0830, Test Loss: 1.4827\n",
      "Epoch [22/50] - Train Loss: 1.0824, Test Loss: 1.4826\n",
      "Epoch [23/50] - Train Loss: 1.0819, Test Loss: 1.4826\n",
      "Epoch [24/50] - Train Loss: 1.0814, Test Loss: 1.4825\n",
      "Epoch [25/50] - Train Loss: 1.0809, Test Loss: 1.4825\n",
      "Epoch [26/50] - Train Loss: 1.0804, Test Loss: 1.4826\n",
      "Epoch [27/50] - Train Loss: 1.0798, Test Loss: 1.4826\n",
      "Epoch [28/50] - Train Loss: 1.0792, Test Loss: 1.4827\n",
      "Epoch [29/50] - Train Loss: 1.0784, Test Loss: 1.4828\n",
      "Epoch [30/50] - Train Loss: 1.0775, Test Loss: 1.4830\n",
      "Epoch [31/50] - Train Loss: 1.0765, Test Loss: 1.4833\n",
      "Epoch [32/50] - Train Loss: 1.0754, Test Loss: 1.4836\n",
      "Epoch [33/50] - Train Loss: 1.0741, Test Loss: 1.4838\n",
      "Epoch [34/50] - Train Loss: 1.0728, Test Loss: 1.4841\n",
      "Epoch [35/50] - Train Loss: 1.0713, Test Loss: 1.4844\n",
      "Epoch [36/50] - Train Loss: 1.0691, Test Loss: 1.4848\n",
      "Epoch [37/50] - Train Loss: 1.0669, Test Loss: 1.4852\n",
      "Epoch [38/50] - Train Loss: 1.0644, Test Loss: 1.4857\n",
      "Epoch [39/50] - Train Loss: 1.0620, Test Loss: 1.4861\n",
      "Epoch [40/50] - Train Loss: 1.0597, Test Loss: 1.4864\n",
      "Epoch [41/50] - Train Loss: 1.0578, Test Loss: 1.4868\n",
      "Epoch [42/50] - Train Loss: 1.0561, Test Loss: 1.4870\n",
      "Epoch [43/50] - Train Loss: 1.0548, Test Loss: 1.4871\n",
      "Epoch [44/50] - Train Loss: 1.0540, Test Loss: 1.4871\n",
      "Epoch [45/50] - Train Loss: 1.0534, Test Loss: 1.4872\n",
      "Epoch [46/50] - Train Loss: 1.0530, Test Loss: 1.4872\n",
      "Epoch [47/50] - Train Loss: 1.0527, Test Loss: 1.4872\n",
      "Epoch [48/50] - Train Loss: 1.0525, Test Loss: 1.4872\n",
      "Epoch [49/50] - Train Loss: 1.0523, Test Loss: 1.4872\n",
      "Epoch [50/50] - Train Loss: 1.0522, Test Loss: 1.4872\n",
      "Avg Test Loss: 1.4872\n",
      "Testing combination: (16, 2, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1183, Test Loss: 1.6020\n",
      "Epoch [2/50] - Train Loss: 1.1154, Test Loss: 1.6069\n",
      "Epoch [3/50] - Train Loss: 1.1147, Test Loss: 1.6096\n",
      "Epoch [4/50] - Train Loss: 1.1143, Test Loss: 1.6107\n",
      "Epoch [5/50] - Train Loss: 1.1140, Test Loss: 1.6109\n",
      "Epoch [6/50] - Train Loss: 1.1137, Test Loss: 1.6107\n",
      "Epoch [7/50] - Train Loss: 1.1133, Test Loss: 1.6103\n",
      "Epoch [8/50] - Train Loss: 1.1129, Test Loss: 1.6099\n",
      "Epoch [9/50] - Train Loss: 1.1126, Test Loss: 1.6096\n",
      "Epoch [10/50] - Train Loss: 1.1122, Test Loss: 1.6093\n",
      "Epoch [11/50] - Train Loss: 1.1119, Test Loss: 1.6090\n",
      "Epoch [12/50] - Train Loss: 1.1115, Test Loss: 1.6088\n",
      "Epoch [13/50] - Train Loss: 1.1112, Test Loss: 1.6085\n",
      "Epoch [14/50] - Train Loss: 1.1108, Test Loss: 1.6083\n",
      "Epoch [15/50] - Train Loss: 1.1105, Test Loss: 1.6081\n",
      "Epoch [16/50] - Train Loss: 1.1101, Test Loss: 1.6079\n",
      "Epoch [17/50] - Train Loss: 1.1096, Test Loss: 1.6077\n",
      "Epoch [18/50] - Train Loss: 1.1091, Test Loss: 1.6075\n",
      "Epoch [19/50] - Train Loss: 1.1085, Test Loss: 1.6074\n",
      "Epoch [20/50] - Train Loss: 1.1078, Test Loss: 1.6073\n",
      "Epoch [21/50] - Train Loss: 1.1070, Test Loss: 1.6072\n",
      "Epoch [22/50] - Train Loss: 1.1059, Test Loss: 1.6073\n",
      "Epoch [23/50] - Train Loss: 1.1045, Test Loss: 1.6074\n",
      "Epoch [24/50] - Train Loss: 1.1073, Test Loss: 1.6095\n",
      "Epoch [25/50] - Train Loss: 1.1135, Test Loss: 1.6120\n",
      "Epoch [26/50] - Train Loss: 1.1114, Test Loss: 1.6082\n",
      "Epoch [27/50] - Train Loss: 1.1092, Test Loss: 1.6046\n",
      "Epoch [28/50] - Train Loss: 1.1081, Test Loss: 1.6029\n",
      "Epoch [29/50] - Train Loss: 1.1073, Test Loss: 1.6028\n",
      "Epoch [30/50] - Train Loss: 1.1064, Test Loss: 1.6036\n",
      "Epoch [31/50] - Train Loss: 1.1054, Test Loss: 1.6047\n",
      "Epoch [32/50] - Train Loss: 1.1042, Test Loss: 1.6056\n",
      "Epoch [33/50] - Train Loss: 1.1029, Test Loss: 1.6063\n",
      "Epoch [34/50] - Train Loss: 1.1013, Test Loss: 1.6069\n",
      "Epoch [35/50] - Train Loss: 1.0996, Test Loss: 1.6076\n",
      "Epoch [36/50] - Train Loss: 1.0976, Test Loss: 1.6085\n",
      "Epoch [37/50] - Train Loss: 1.0953, Test Loss: 1.6095\n",
      "Epoch [38/50] - Train Loss: 1.0928, Test Loss: 1.6104\n",
      "Epoch [39/50] - Train Loss: 1.0902, Test Loss: 1.6113\n",
      "Epoch [40/50] - Train Loss: 1.0875, Test Loss: 1.6118\n",
      "Epoch [41/50] - Train Loss: 1.0876, Test Loss: 1.6130\n",
      "Epoch [42/50] - Train Loss: 1.0853, Test Loss: 1.6139\n",
      "Epoch [43/50] - Train Loss: 1.0830, Test Loss: 1.6132\n",
      "Epoch [44/50] - Train Loss: 1.0819, Test Loss: 1.6148\n",
      "Epoch [45/50] - Train Loss: 1.0799, Test Loss: 1.6130\n",
      "Epoch [46/50] - Train Loss: 1.0785, Test Loss: 1.6123\n",
      "Epoch [47/50] - Train Loss: 1.0779, Test Loss: 1.6138\n",
      "Epoch [48/50] - Train Loss: 1.0772, Test Loss: 1.6158\n",
      "Epoch [49/50] - Train Loss: 1.0767, Test Loss: 1.6169\n",
      "Epoch [50/50] - Train Loss: 1.0763, Test Loss: 1.6170\n",
      "Avg Test Loss: 1.6170\n",
      "Testing combination: (16, 2, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3045, Test Loss: 2.6833\n",
      "Epoch [2/50] - Train Loss: 1.3025, Test Loss: 2.6780\n",
      "Epoch [3/50] - Train Loss: 1.3016, Test Loss: 2.6740\n",
      "Epoch [4/50] - Train Loss: 1.3010, Test Loss: 2.6708\n",
      "Epoch [5/50] - Train Loss: 1.3006, Test Loss: 2.6685\n",
      "Epoch [6/50] - Train Loss: 1.3002, Test Loss: 2.6667\n",
      "Epoch [7/50] - Train Loss: 1.2999, Test Loss: 2.6655\n",
      "Epoch [8/50] - Train Loss: 1.2995, Test Loss: 2.6647\n",
      "Epoch [9/50] - Train Loss: 1.2991, Test Loss: 2.6643\n",
      "Epoch [10/50] - Train Loss: 1.2986, Test Loss: 2.6642\n",
      "Epoch [11/50] - Train Loss: 1.2981, Test Loss: 2.6643\n",
      "Epoch [12/50] - Train Loss: 1.2975, Test Loss: 2.6646\n",
      "Epoch [13/50] - Train Loss: 1.2969, Test Loss: 2.6650\n",
      "Epoch [14/50] - Train Loss: 1.2962, Test Loss: 2.6655\n",
      "Epoch [15/50] - Train Loss: 1.2956, Test Loss: 2.6661\n",
      "Epoch [16/50] - Train Loss: 1.2949, Test Loss: 2.6666\n",
      "Epoch [17/50] - Train Loss: 1.2942, Test Loss: 2.6672\n",
      "Epoch [18/50] - Train Loss: 1.2935, Test Loss: 2.6678\n",
      "Epoch [19/50] - Train Loss: 1.2928, Test Loss: 2.6683\n",
      "Epoch [20/50] - Train Loss: 1.2921, Test Loss: 2.6688\n",
      "Epoch [21/50] - Train Loss: 1.2915, Test Loss: 2.6691\n",
      "Epoch [22/50] - Train Loss: 1.2909, Test Loss: 2.6695\n",
      "Epoch [23/50] - Train Loss: 1.2903, Test Loss: 2.6697\n",
      "Epoch [24/50] - Train Loss: 1.2898, Test Loss: 2.6699\n",
      "Epoch [25/50] - Train Loss: 1.2893, Test Loss: 2.6700\n",
      "Epoch [26/50] - Train Loss: 1.2887, Test Loss: 2.6700\n",
      "Epoch [27/50] - Train Loss: 1.2882, Test Loss: 2.6700\n",
      "Epoch [28/50] - Train Loss: 1.2877, Test Loss: 2.6699\n",
      "Epoch [29/50] - Train Loss: 1.2871, Test Loss: 2.6697\n",
      "Epoch [30/50] - Train Loss: 1.2865, Test Loss: 2.6694\n",
      "Epoch [31/50] - Train Loss: 1.2859, Test Loss: 2.6690\n",
      "Epoch [32/50] - Train Loss: 1.2852, Test Loss: 2.6684\n",
      "Epoch [33/50] - Train Loss: 1.2844, Test Loss: 2.6677\n",
      "Epoch [34/50] - Train Loss: 1.2835, Test Loss: 2.6668\n",
      "Epoch [35/50] - Train Loss: 1.2824, Test Loss: 2.6657\n",
      "Epoch [36/50] - Train Loss: 1.2813, Test Loss: 2.6644\n",
      "Epoch [37/50] - Train Loss: 1.2804, Test Loss: 2.6628\n",
      "Epoch [38/50] - Train Loss: 1.2790, Test Loss: 2.6613\n",
      "Epoch [39/50] - Train Loss: 1.2768, Test Loss: 2.6600\n",
      "Epoch [40/50] - Train Loss: 1.2748, Test Loss: 2.6588\n",
      "Epoch [41/50] - Train Loss: 1.2730, Test Loss: 2.6579\n",
      "Epoch [42/50] - Train Loss: 1.2705, Test Loss: 2.6571\n",
      "Epoch [43/50] - Train Loss: 1.2684, Test Loss: 2.6566\n",
      "Epoch [44/50] - Train Loss: 1.2654, Test Loss: 2.6564\n",
      "Epoch [45/50] - Train Loss: 1.2628, Test Loss: 2.6561\n",
      "Epoch [46/50] - Train Loss: 1.2602, Test Loss: 2.6556\n",
      "Epoch [47/50] - Train Loss: 1.2577, Test Loss: 2.6545\n",
      "Epoch [48/50] - Train Loss: 1.2557, Test Loss: 2.6530\n",
      "Epoch [49/50] - Train Loss: 1.2539, Test Loss: 2.6515\n",
      "Epoch [50/50] - Train Loss: 1.2523, Test Loss: 2.6506\n",
      "Avg Test Loss: 2.6506\n",
      "Testing combination: (16, 2, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1273, Test Loss: 1.4801\n",
      "Epoch [2/50] - Train Loss: 1.1258, Test Loss: 1.4795\n",
      "Epoch [3/50] - Train Loss: 1.1245, Test Loss: 1.4790\n",
      "Epoch [4/50] - Train Loss: 1.1232, Test Loss: 1.4785\n",
      "Epoch [5/50] - Train Loss: 1.1220, Test Loss: 1.4780\n",
      "Epoch [6/50] - Train Loss: 1.1208, Test Loss: 1.4775\n",
      "Epoch [7/50] - Train Loss: 1.1197, Test Loss: 1.4771\n",
      "Epoch [8/50] - Train Loss: 1.1186, Test Loss: 1.4767\n",
      "Epoch [9/50] - Train Loss: 1.1175, Test Loss: 1.4763\n",
      "Epoch [10/50] - Train Loss: 1.1164, Test Loss: 1.4759\n",
      "Epoch [11/50] - Train Loss: 1.1154, Test Loss: 1.4756\n",
      "Epoch [12/50] - Train Loss: 1.1144, Test Loss: 1.4753\n",
      "Epoch [13/50] - Train Loss: 1.1134, Test Loss: 1.4750\n",
      "Epoch [14/50] - Train Loss: 1.1124, Test Loss: 1.4747\n",
      "Epoch [15/50] - Train Loss: 1.1115, Test Loss: 1.4745\n",
      "Epoch [16/50] - Train Loss: 1.1105, Test Loss: 1.4743\n",
      "Epoch [17/50] - Train Loss: 1.1096, Test Loss: 1.4741\n",
      "Epoch [18/50] - Train Loss: 1.1088, Test Loss: 1.4739\n",
      "Epoch [19/50] - Train Loss: 1.1079, Test Loss: 1.4738\n",
      "Epoch [20/50] - Train Loss: 1.1071, Test Loss: 1.4736\n",
      "Epoch [21/50] - Train Loss: 1.1063, Test Loss: 1.4735\n",
      "Epoch [22/50] - Train Loss: 1.1055, Test Loss: 1.4735\n",
      "Epoch [23/50] - Train Loss: 1.1047, Test Loss: 1.4734\n",
      "Epoch [24/50] - Train Loss: 1.1039, Test Loss: 1.4734\n",
      "Epoch [25/50] - Train Loss: 1.1032, Test Loss: 1.4733\n",
      "Epoch [26/50] - Train Loss: 1.1025, Test Loss: 1.4734\n",
      "Epoch [27/50] - Train Loss: 1.1018, Test Loss: 1.4734\n",
      "Epoch [28/50] - Train Loss: 1.1011, Test Loss: 1.4734\n",
      "Epoch [29/50] - Train Loss: 1.1005, Test Loss: 1.4735\n",
      "Epoch [30/50] - Train Loss: 1.0999, Test Loss: 1.4736\n",
      "Epoch [31/50] - Train Loss: 1.0993, Test Loss: 1.4737\n",
      "Epoch [32/50] - Train Loss: 1.0987, Test Loss: 1.4738\n",
      "Epoch [33/50] - Train Loss: 1.0981, Test Loss: 1.4740\n",
      "Epoch [34/50] - Train Loss: 1.0976, Test Loss: 1.4741\n",
      "Epoch [35/50] - Train Loss: 1.0971, Test Loss: 1.4743\n",
      "Epoch [36/50] - Train Loss: 1.0966, Test Loss: 1.4745\n",
      "Epoch [37/50] - Train Loss: 1.0962, Test Loss: 1.4747\n",
      "Epoch [38/50] - Train Loss: 1.0957, Test Loss: 1.4749\n",
      "Epoch [39/50] - Train Loss: 1.0953, Test Loss: 1.4751\n",
      "Epoch [40/50] - Train Loss: 1.0949, Test Loss: 1.4754\n",
      "Epoch [41/50] - Train Loss: 1.0945, Test Loss: 1.4756\n",
      "Epoch [42/50] - Train Loss: 1.0942, Test Loss: 1.4758\n",
      "Epoch [43/50] - Train Loss: 1.0939, Test Loss: 1.4761\n",
      "Epoch [44/50] - Train Loss: 1.0935, Test Loss: 1.4764\n",
      "Epoch [45/50] - Train Loss: 1.0932, Test Loss: 1.4766\n",
      "Epoch [46/50] - Train Loss: 1.0930, Test Loss: 1.4769\n",
      "Epoch [47/50] - Train Loss: 1.0927, Test Loss: 1.4771\n",
      "Epoch [48/50] - Train Loss: 1.0924, Test Loss: 1.4774\n",
      "Epoch [49/50] - Train Loss: 1.0922, Test Loss: 1.4777\n",
      "Epoch [50/50] - Train Loss: 1.0920, Test Loss: 1.4779\n",
      "Avg Test Loss: 1.4779\n",
      "Testing combination: (16, 2, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1281, Test Loss: 1.5782\n",
      "Epoch [2/50] - Train Loss: 1.1269, Test Loss: 1.5789\n",
      "Epoch [3/50] - Train Loss: 1.1259, Test Loss: 1.5795\n",
      "Epoch [4/50] - Train Loss: 1.1250, Test Loss: 1.5802\n",
      "Epoch [5/50] - Train Loss: 1.1241, Test Loss: 1.5809\n",
      "Epoch [6/50] - Train Loss: 1.1233, Test Loss: 1.5816\n",
      "Epoch [7/50] - Train Loss: 1.1225, Test Loss: 1.5823\n",
      "Epoch [8/50] - Train Loss: 1.1218, Test Loss: 1.5830\n",
      "Epoch [9/50] - Train Loss: 1.1211, Test Loss: 1.5838\n",
      "Epoch [10/50] - Train Loss: 1.1205, Test Loss: 1.5845\n",
      "Epoch [11/50] - Train Loss: 1.1199, Test Loss: 1.5852\n",
      "Epoch [12/50] - Train Loss: 1.1194, Test Loss: 1.5860\n",
      "Epoch [13/50] - Train Loss: 1.1188, Test Loss: 1.5867\n",
      "Epoch [14/50] - Train Loss: 1.1183, Test Loss: 1.5875\n",
      "Epoch [15/50] - Train Loss: 1.1179, Test Loss: 1.5882\n",
      "Epoch [16/50] - Train Loss: 1.1175, Test Loss: 1.5889\n",
      "Epoch [17/50] - Train Loss: 1.1171, Test Loss: 1.5897\n",
      "Epoch [18/50] - Train Loss: 1.1167, Test Loss: 1.5904\n",
      "Epoch [19/50] - Train Loss: 1.1163, Test Loss: 1.5911\n",
      "Epoch [20/50] - Train Loss: 1.1160, Test Loss: 1.5918\n",
      "Epoch [21/50] - Train Loss: 1.1157, Test Loss: 1.5925\n",
      "Epoch [22/50] - Train Loss: 1.1154, Test Loss: 1.5932\n",
      "Epoch [23/50] - Train Loss: 1.1151, Test Loss: 1.5938\n",
      "Epoch [24/50] - Train Loss: 1.1149, Test Loss: 1.5945\n",
      "Epoch [25/50] - Train Loss: 1.1147, Test Loss: 1.5951\n",
      "Epoch [26/50] - Train Loss: 1.1144, Test Loss: 1.5958\n",
      "Epoch [27/50] - Train Loss: 1.1142, Test Loss: 1.5964\n",
      "Epoch [28/50] - Train Loss: 1.1140, Test Loss: 1.5969\n",
      "Epoch [29/50] - Train Loss: 1.1139, Test Loss: 1.5975\n",
      "Epoch [30/50] - Train Loss: 1.1137, Test Loss: 1.5981\n",
      "Epoch [31/50] - Train Loss: 1.1135, Test Loss: 1.5986\n",
      "Epoch [32/50] - Train Loss: 1.1134, Test Loss: 1.5991\n",
      "Epoch [33/50] - Train Loss: 1.1132, Test Loss: 1.5996\n",
      "Epoch [34/50] - Train Loss: 1.1131, Test Loss: 1.6001\n",
      "Epoch [35/50] - Train Loss: 1.1130, Test Loss: 1.6006\n",
      "Epoch [36/50] - Train Loss: 1.1129, Test Loss: 1.6010\n",
      "Epoch [37/50] - Train Loss: 1.1128, Test Loss: 1.6015\n",
      "Epoch [38/50] - Train Loss: 1.1126, Test Loss: 1.6019\n",
      "Epoch [39/50] - Train Loss: 1.1125, Test Loss: 1.6023\n",
      "Epoch [40/50] - Train Loss: 1.1125, Test Loss: 1.6026\n",
      "Epoch [41/50] - Train Loss: 1.1124, Test Loss: 1.6030\n",
      "Epoch [42/50] - Train Loss: 1.1123, Test Loss: 1.6034\n",
      "Epoch [43/50] - Train Loss: 1.1122, Test Loss: 1.6037\n",
      "Epoch [44/50] - Train Loss: 1.1121, Test Loss: 1.6040\n",
      "Epoch [45/50] - Train Loss: 1.1120, Test Loss: 1.6043\n",
      "Epoch [46/50] - Train Loss: 1.1119, Test Loss: 1.6046\n",
      "Epoch [47/50] - Train Loss: 1.1119, Test Loss: 1.6049\n",
      "Epoch [48/50] - Train Loss: 1.1118, Test Loss: 1.6051\n",
      "Epoch [49/50] - Train Loss: 1.1117, Test Loss: 1.6053\n",
      "Epoch [50/50] - Train Loss: 1.1117, Test Loss: 1.6056\n",
      "Avg Test Loss: 1.6056\n",
      "Testing combination: (16, 2, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3047, Test Loss: 2.6424\n",
      "Epoch [2/50] - Train Loss: 1.3045, Test Loss: 2.6427\n",
      "Epoch [3/50] - Train Loss: 1.3044, Test Loss: 2.6430\n",
      "Epoch [4/50] - Train Loss: 1.3042, Test Loss: 2.6434\n",
      "Epoch [5/50] - Train Loss: 1.3041, Test Loss: 2.6437\n",
      "Epoch [6/50] - Train Loss: 1.3039, Test Loss: 2.6440\n",
      "Epoch [7/50] - Train Loss: 1.3038, Test Loss: 2.6443\n",
      "Epoch [8/50] - Train Loss: 1.3037, Test Loss: 2.6446\n",
      "Epoch [9/50] - Train Loss: 1.3036, Test Loss: 2.6449\n",
      "Epoch [10/50] - Train Loss: 1.3035, Test Loss: 2.6452\n",
      "Epoch [11/50] - Train Loss: 1.3034, Test Loss: 2.6455\n",
      "Epoch [12/50] - Train Loss: 1.3032, Test Loss: 2.6458\n",
      "Epoch [13/50] - Train Loss: 1.3031, Test Loss: 2.6461\n",
      "Epoch [14/50] - Train Loss: 1.3030, Test Loss: 2.6464\n",
      "Epoch [15/50] - Train Loss: 1.3030, Test Loss: 2.6467\n",
      "Epoch [16/50] - Train Loss: 1.3029, Test Loss: 2.6469\n",
      "Epoch [17/50] - Train Loss: 1.3028, Test Loss: 2.6472\n",
      "Epoch [18/50] - Train Loss: 1.3027, Test Loss: 2.6475\n",
      "Epoch [19/50] - Train Loss: 1.3026, Test Loss: 2.6478\n",
      "Epoch [20/50] - Train Loss: 1.3025, Test Loss: 2.6480\n",
      "Epoch [21/50] - Train Loss: 1.3024, Test Loss: 2.6483\n",
      "Epoch [22/50] - Train Loss: 1.3024, Test Loss: 2.6485\n",
      "Epoch [23/50] - Train Loss: 1.3023, Test Loss: 2.6488\n",
      "Epoch [24/50] - Train Loss: 1.3022, Test Loss: 2.6490\n",
      "Epoch [25/50] - Train Loss: 1.3022, Test Loss: 2.6493\n",
      "Epoch [26/50] - Train Loss: 1.3021, Test Loss: 2.6495\n",
      "Epoch [27/50] - Train Loss: 1.3020, Test Loss: 2.6498\n",
      "Epoch [28/50] - Train Loss: 1.3020, Test Loss: 2.6500\n",
      "Epoch [29/50] - Train Loss: 1.3019, Test Loss: 2.6502\n",
      "Epoch [30/50] - Train Loss: 1.3018, Test Loss: 2.6505\n",
      "Epoch [31/50] - Train Loss: 1.3018, Test Loss: 2.6507\n",
      "Epoch [32/50] - Train Loss: 1.3017, Test Loss: 2.6509\n",
      "Epoch [33/50] - Train Loss: 1.3017, Test Loss: 2.6511\n",
      "Epoch [34/50] - Train Loss: 1.3016, Test Loss: 2.6514\n",
      "Epoch [35/50] - Train Loss: 1.3015, Test Loss: 2.6516\n",
      "Epoch [36/50] - Train Loss: 1.3015, Test Loss: 2.6518\n",
      "Epoch [37/50] - Train Loss: 1.3014, Test Loss: 2.6520\n",
      "Epoch [38/50] - Train Loss: 1.3014, Test Loss: 2.6522\n",
      "Epoch [39/50] - Train Loss: 1.3013, Test Loss: 2.6524\n",
      "Epoch [40/50] - Train Loss: 1.3013, Test Loss: 2.6526\n",
      "Epoch [41/50] - Train Loss: 1.3012, Test Loss: 2.6528\n",
      "Epoch [42/50] - Train Loss: 1.3012, Test Loss: 2.6530\n",
      "Epoch [43/50] - Train Loss: 1.3011, Test Loss: 2.6532\n",
      "Epoch [44/50] - Train Loss: 1.3011, Test Loss: 2.6534\n",
      "Epoch [45/50] - Train Loss: 1.3010, Test Loss: 2.6536\n",
      "Epoch [46/50] - Train Loss: 1.3010, Test Loss: 2.6538\n",
      "Epoch [47/50] - Train Loss: 1.3009, Test Loss: 2.6539\n",
      "Epoch [48/50] - Train Loss: 1.3009, Test Loss: 2.6541\n",
      "Epoch [49/50] - Train Loss: 1.3008, Test Loss: 2.6543\n",
      "Epoch [50/50] - Train Loss: 1.3008, Test Loss: 2.6545\n",
      "Avg Test Loss: 2.6545\n",
      "Testing combination: (16, 3, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1204, Test Loss: 1.4944\n",
      "Epoch [2/50] - Train Loss: 1.0955, Test Loss: 1.4846\n",
      "Epoch [3/50] - Train Loss: 1.0953, Test Loss: 1.4827\n",
      "Epoch [4/50] - Train Loss: 1.0952, Test Loss: 1.4832\n",
      "Epoch [5/50] - Train Loss: 1.0943, Test Loss: 1.4840\n",
      "Epoch [6/50] - Train Loss: 1.0922, Test Loss: 1.4842\n",
      "Epoch [7/50] - Train Loss: 1.0892, Test Loss: 1.4838\n",
      "Epoch [8/50] - Train Loss: 1.0834, Test Loss: 1.4831\n",
      "Epoch [9/50] - Train Loss: 1.0873, Test Loss: 1.4834\n",
      "Epoch [10/50] - Train Loss: 1.0874, Test Loss: 1.4835\n",
      "Epoch [11/50] - Train Loss: 1.0775, Test Loss: 1.4875\n",
      "Epoch [12/50] - Train Loss: 1.0702, Test Loss: 1.4861\n",
      "Epoch [13/50] - Train Loss: 1.0619, Test Loss: 1.4829\n",
      "Epoch [14/50] - Train Loss: 1.0601, Test Loss: 1.4867\n",
      "Epoch [15/50] - Train Loss: 1.0546, Test Loss: 1.4859\n",
      "Epoch [16/50] - Train Loss: 1.0512, Test Loss: 1.4851\n",
      "Epoch [17/50] - Train Loss: 1.0483, Test Loss: 1.4844\n",
      "Epoch [18/50] - Train Loss: 1.0488, Test Loss: 1.4841\n",
      "Epoch [19/50] - Train Loss: 1.0472, Test Loss: 1.4867\n",
      "Epoch [20/50] - Train Loss: 1.0470, Test Loss: 1.4831\n",
      "Epoch [21/50] - Train Loss: 1.0458, Test Loss: 1.4839\n",
      "Epoch [22/50] - Train Loss: 1.0438, Test Loss: 1.4864\n",
      "Epoch [23/50] - Train Loss: 1.0425, Test Loss: 1.4865\n",
      "Epoch [24/50] - Train Loss: 1.0515, Test Loss: 1.4865\n",
      "Epoch [25/50] - Train Loss: 1.0509, Test Loss: 1.4886\n",
      "Epoch [26/50] - Train Loss: 1.0485, Test Loss: 1.4868\n",
      "Epoch [27/50] - Train Loss: 1.0458, Test Loss: 1.4827\n",
      "Epoch [28/50] - Train Loss: 1.0471, Test Loss: 1.4859\n",
      "Epoch [29/50] - Train Loss: 1.0420, Test Loss: 1.4848\n",
      "Epoch [30/50] - Train Loss: 1.0430, Test Loss: 1.4900\n",
      "Epoch [31/50] - Train Loss: 1.0404, Test Loss: 1.4901\n",
      "Epoch [32/50] - Train Loss: 1.0372, Test Loss: 1.4810\n",
      "Epoch [33/50] - Train Loss: 1.0507, Test Loss: 1.4822\n",
      "Epoch [34/50] - Train Loss: 1.0484, Test Loss: 1.4874\n",
      "Epoch [35/50] - Train Loss: 1.0369, Test Loss: 1.4834\n",
      "Epoch [36/50] - Train Loss: 1.0349, Test Loss: 1.4811\n",
      "Epoch [37/50] - Train Loss: 1.0813, Test Loss: 1.4834\n",
      "Epoch [38/50] - Train Loss: 1.0518, Test Loss: 1.4880\n",
      "Epoch [39/50] - Train Loss: 1.0455, Test Loss: 1.4886\n",
      "Epoch [40/50] - Train Loss: 1.0446, Test Loss: 1.4864\n",
      "Epoch [41/50] - Train Loss: 1.0425, Test Loss: 1.4841\n",
      "Epoch [42/50] - Train Loss: 1.0408, Test Loss: 1.4864\n",
      "Epoch [43/50] - Train Loss: 1.0399, Test Loss: 1.4942\n",
      "Epoch [44/50] - Train Loss: 1.0258, Test Loss: 1.4925\n",
      "Epoch [45/50] - Train Loss: 1.0402, Test Loss: 1.4828\n",
      "Epoch [46/50] - Train Loss: 1.0463, Test Loss: 1.4847\n",
      "Epoch [47/50] - Train Loss: 1.0424, Test Loss: 1.4804\n",
      "Epoch [48/50] - Train Loss: 1.0335, Test Loss: 1.4900\n",
      "Epoch [49/50] - Train Loss: 1.0261, Test Loss: 1.4849\n",
      "Epoch [50/50] - Train Loss: 1.0202, Test Loss: 1.4823\n",
      "Avg Test Loss: 1.4823\n",
      "Testing combination: (16, 3, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1439, Test Loss: 1.6118\n",
      "Epoch [2/50] - Train Loss: 1.1153, Test Loss: 1.5966\n",
      "Epoch [3/50] - Train Loss: 1.1167, Test Loss: 1.6007\n",
      "Epoch [4/50] - Train Loss: 1.1162, Test Loss: 1.6079\n",
      "Epoch [5/50] - Train Loss: 1.1157, Test Loss: 1.6112\n",
      "Epoch [6/50] - Train Loss: 1.1151, Test Loss: 1.6101\n",
      "Epoch [7/50] - Train Loss: 1.1140, Test Loss: 1.6079\n",
      "Epoch [8/50] - Train Loss: 1.1122, Test Loss: 1.6066\n",
      "Epoch [9/50] - Train Loss: 1.1099, Test Loss: 1.6059\n",
      "Epoch [10/50] - Train Loss: 1.1084, Test Loss: 1.6055\n",
      "Epoch [11/50] - Train Loss: 1.1223, Test Loss: 1.6018\n",
      "Epoch [12/50] - Train Loss: 1.1127, Test Loss: 1.6012\n",
      "Epoch [13/50] - Train Loss: 1.1130, Test Loss: 1.6057\n",
      "Epoch [14/50] - Train Loss: 1.1109, Test Loss: 1.6099\n",
      "Epoch [15/50] - Train Loss: 1.1070, Test Loss: 1.6110\n",
      "Epoch [16/50] - Train Loss: 1.1030, Test Loss: 1.6123\n",
      "Epoch [17/50] - Train Loss: 1.0935, Test Loss: 1.6104\n",
      "Epoch [18/50] - Train Loss: 1.1124, Test Loss: 1.6779\n",
      "Epoch [19/50] - Train Loss: 1.0956, Test Loss: 1.6185\n",
      "Epoch [20/50] - Train Loss: 1.0990, Test Loss: 1.6119\n",
      "Epoch [21/50] - Train Loss: 1.0972, Test Loss: 1.6083\n",
      "Epoch [22/50] - Train Loss: 1.0927, Test Loss: 1.6109\n",
      "Epoch [23/50] - Train Loss: 1.0847, Test Loss: 1.6143\n",
      "Epoch [24/50] - Train Loss: 1.0809, Test Loss: 1.6137\n",
      "Epoch [25/50] - Train Loss: 1.0800, Test Loss: 1.6114\n",
      "Epoch [26/50] - Train Loss: 1.0793, Test Loss: 1.6112\n",
      "Epoch [27/50] - Train Loss: 1.0792, Test Loss: 1.6122\n",
      "Epoch [28/50] - Train Loss: 1.0791, Test Loss: 1.6122\n",
      "Epoch [29/50] - Train Loss: 1.0789, Test Loss: 1.6122\n",
      "Epoch [30/50] - Train Loss: 1.0789, Test Loss: 1.6124\n",
      "Epoch [31/50] - Train Loss: 1.0788, Test Loss: 1.6124\n",
      "Epoch [32/50] - Train Loss: 1.0788, Test Loss: 1.6124\n",
      "Epoch [33/50] - Train Loss: 1.0787, Test Loss: 1.6125\n",
      "Epoch [34/50] - Train Loss: 1.0787, Test Loss: 1.6126\n",
      "Epoch [35/50] - Train Loss: 1.0786, Test Loss: 1.6126\n",
      "Epoch [36/50] - Train Loss: 1.0786, Test Loss: 1.6127\n",
      "Epoch [37/50] - Train Loss: 1.0786, Test Loss: 1.6127\n",
      "Epoch [38/50] - Train Loss: 1.0786, Test Loss: 1.6128\n",
      "Epoch [39/50] - Train Loss: 1.0785, Test Loss: 1.6128\n",
      "Epoch [40/50] - Train Loss: 1.0785, Test Loss: 1.6129\n",
      "Epoch [41/50] - Train Loss: 1.0785, Test Loss: 1.6129\n",
      "Epoch [42/50] - Train Loss: 1.0784, Test Loss: 1.6130\n",
      "Epoch [43/50] - Train Loss: 1.0784, Test Loss: 1.6130\n",
      "Epoch [44/50] - Train Loss: 1.0784, Test Loss: 1.6131\n",
      "Epoch [45/50] - Train Loss: 1.0783, Test Loss: 1.6132\n",
      "Epoch [46/50] - Train Loss: 1.0783, Test Loss: 1.6133\n",
      "Epoch [47/50] - Train Loss: 1.0783, Test Loss: 1.6134\n",
      "Epoch [48/50] - Train Loss: 1.0782, Test Loss: 1.6134\n",
      "Epoch [49/50] - Train Loss: 1.0781, Test Loss: 1.6134\n",
      "Epoch [50/50] - Train Loss: 1.0780, Test Loss: 1.6135\n",
      "Avg Test Loss: 1.6135\n",
      "Testing combination: (16, 3, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3349, Test Loss: 2.6436\n",
      "Epoch [2/50] - Train Loss: 1.3055, Test Loss: 2.6823\n",
      "Epoch [3/50] - Train Loss: 1.3044, Test Loss: 2.6881\n",
      "Epoch [4/50] - Train Loss: 1.3031, Test Loss: 2.6760\n",
      "Epoch [5/50] - Train Loss: 1.3014, Test Loss: 2.6635\n",
      "Epoch [6/50] - Train Loss: 1.3009, Test Loss: 2.6571\n",
      "Epoch [7/50] - Train Loss: 1.3005, Test Loss: 2.6570\n",
      "Epoch [8/50] - Train Loss: 1.2993, Test Loss: 2.6611\n",
      "Epoch [9/50] - Train Loss: 1.2973, Test Loss: 2.6665\n",
      "Epoch [10/50] - Train Loss: 1.2949, Test Loss: 2.6708\n",
      "Epoch [11/50] - Train Loss: 1.2921, Test Loss: 2.6728\n",
      "Epoch [12/50] - Train Loss: 1.2893, Test Loss: 2.6726\n",
      "Epoch [13/50] - Train Loss: 1.2868, Test Loss: 2.6710\n",
      "Epoch [14/50] - Train Loss: 1.2825, Test Loss: 2.6675\n",
      "Epoch [15/50] - Train Loss: 1.2817, Test Loss: 2.6618\n",
      "Epoch [16/50] - Train Loss: 1.2861, Test Loss: 2.6593\n",
      "Epoch [17/50] - Train Loss: 1.2735, Test Loss: 2.6599\n",
      "Epoch [18/50] - Train Loss: 1.2679, Test Loss: 2.6585\n",
      "Epoch [19/50] - Train Loss: 1.2609, Test Loss: 2.6527\n",
      "Epoch [20/50] - Train Loss: 1.2553, Test Loss: 2.6462\n",
      "Epoch [21/50] - Train Loss: 1.2512, Test Loss: 2.6421\n",
      "Epoch [22/50] - Train Loss: 1.2474, Test Loss: 2.6410\n",
      "Epoch [23/50] - Train Loss: 1.2468, Test Loss: 2.6425\n",
      "Epoch [24/50] - Train Loss: 1.2463, Test Loss: 2.6407\n",
      "Epoch [25/50] - Train Loss: 1.2450, Test Loss: 2.6365\n",
      "Epoch [26/50] - Train Loss: 1.2431, Test Loss: 2.6352\n",
      "Epoch [27/50] - Train Loss: 1.2414, Test Loss: 2.6394\n",
      "Epoch [28/50] - Train Loss: 1.2400, Test Loss: 2.6473\n",
      "Epoch [29/50] - Train Loss: 1.2399, Test Loss: 2.6535\n",
      "Epoch [30/50] - Train Loss: 1.2398, Test Loss: 2.6526\n",
      "Epoch [31/50] - Train Loss: 1.2399, Test Loss: 2.6499\n",
      "Epoch [32/50] - Train Loss: 1.2398, Test Loss: 2.6483\n",
      "Epoch [33/50] - Train Loss: 1.2397, Test Loss: 2.6455\n",
      "Epoch [34/50] - Train Loss: 1.2397, Test Loss: 2.6428\n",
      "Epoch [35/50] - Train Loss: 1.2396, Test Loss: 2.6418\n",
      "Epoch [36/50] - Train Loss: 1.2396, Test Loss: 2.6410\n",
      "Epoch [37/50] - Train Loss: 1.2395, Test Loss: 2.6409\n",
      "Epoch [38/50] - Train Loss: 1.2395, Test Loss: 2.6410\n",
      "Epoch [39/50] - Train Loss: 1.2395, Test Loss: 2.6408\n",
      "Epoch [40/50] - Train Loss: 1.2394, Test Loss: 2.6408\n",
      "Epoch [41/50] - Train Loss: 1.2394, Test Loss: 2.6398\n",
      "Epoch [42/50] - Train Loss: 1.2394, Test Loss: 2.6388\n",
      "Epoch [43/50] - Train Loss: 1.2394, Test Loss: 2.6369\n",
      "Epoch [44/50] - Train Loss: 1.2393, Test Loss: 2.6359\n",
      "Epoch [45/50] - Train Loss: 1.2394, Test Loss: 2.6330\n",
      "Epoch [46/50] - Train Loss: 1.2392, Test Loss: 2.6334\n",
      "Epoch [47/50] - Train Loss: 1.2401, Test Loss: 2.6260\n",
      "Epoch [48/50] - Train Loss: 1.2401, Test Loss: 2.6287\n",
      "Epoch [49/50] - Train Loss: 1.2388, Test Loss: 2.6326\n",
      "Epoch [50/50] - Train Loss: 1.2410, Test Loss: 2.6176\n",
      "Avg Test Loss: 2.6176\n",
      "Testing combination: (16, 3, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1150, Test Loss: 1.4734\n",
      "Epoch [2/50] - Train Loss: 1.1040, Test Loss: 1.4740\n",
      "Epoch [3/50] - Train Loss: 1.0993, Test Loss: 1.4759\n",
      "Epoch [4/50] - Train Loss: 1.0965, Test Loss: 1.4780\n",
      "Epoch [5/50] - Train Loss: 1.0950, Test Loss: 1.4800\n",
      "Epoch [6/50] - Train Loss: 1.0940, Test Loss: 1.4817\n",
      "Epoch [7/50] - Train Loss: 1.0934, Test Loss: 1.4830\n",
      "Epoch [8/50] - Train Loss: 1.0930, Test Loss: 1.4839\n",
      "Epoch [9/50] - Train Loss: 1.0926, Test Loss: 1.4845\n",
      "Epoch [10/50] - Train Loss: 1.0923, Test Loss: 1.4849\n",
      "Epoch [11/50] - Train Loss: 1.0919, Test Loss: 1.4851\n",
      "Epoch [12/50] - Train Loss: 1.0915, Test Loss: 1.4852\n",
      "Epoch [13/50] - Train Loss: 1.0910, Test Loss: 1.4852\n",
      "Epoch [14/50] - Train Loss: 1.0906, Test Loss: 1.4851\n",
      "Epoch [15/50] - Train Loss: 1.0900, Test Loss: 1.4850\n",
      "Epoch [16/50] - Train Loss: 1.0895, Test Loss: 1.4848\n",
      "Epoch [17/50] - Train Loss: 1.0889, Test Loss: 1.4846\n",
      "Epoch [18/50] - Train Loss: 1.0882, Test Loss: 1.4845\n",
      "Epoch [19/50] - Train Loss: 1.0875, Test Loss: 1.4843\n",
      "Epoch [20/50] - Train Loss: 1.0866, Test Loss: 1.4843\n",
      "Epoch [21/50] - Train Loss: 1.0855, Test Loss: 1.4842\n",
      "Epoch [22/50] - Train Loss: 1.0841, Test Loss: 1.4843\n",
      "Epoch [23/50] - Train Loss: 1.0823, Test Loss: 1.4845\n",
      "Epoch [24/50] - Train Loss: 1.0797, Test Loss: 1.4848\n",
      "Epoch [25/50] - Train Loss: 1.0770, Test Loss: 1.4851\n",
      "Epoch [26/50] - Train Loss: 1.0739, Test Loss: 1.4857\n",
      "Epoch [27/50] - Train Loss: 1.0709, Test Loss: 1.4862\n",
      "Epoch [28/50] - Train Loss: 1.0676, Test Loss: 1.4866\n",
      "Epoch [29/50] - Train Loss: 1.0647, Test Loss: 1.4871\n",
      "Epoch [30/50] - Train Loss: 1.0617, Test Loss: 1.4871\n",
      "Epoch [31/50] - Train Loss: 1.1038, Test Loss: 1.4853\n",
      "Epoch [32/50] - Train Loss: 1.0648, Test Loss: 1.4827\n",
      "Epoch [33/50] - Train Loss: 1.0604, Test Loss: 1.4850\n",
      "Epoch [34/50] - Train Loss: 1.0544, Test Loss: 1.4886\n",
      "Epoch [35/50] - Train Loss: 1.0487, Test Loss: 1.4911\n",
      "Epoch [36/50] - Train Loss: 1.1120, Test Loss: 1.5050\n",
      "Epoch [37/50] - Train Loss: 1.0918, Test Loss: 1.4948\n",
      "Epoch [38/50] - Train Loss: 1.0592, Test Loss: 1.4939\n",
      "Epoch [39/50] - Train Loss: 1.0545, Test Loss: 1.4948\n",
      "Epoch [40/50] - Train Loss: 1.0509, Test Loss: 1.4921\n",
      "Epoch [41/50] - Train Loss: 1.0462, Test Loss: 1.4906\n",
      "Epoch [42/50] - Train Loss: 1.0759, Test Loss: 1.4959\n",
      "Epoch [43/50] - Train Loss: 1.0654, Test Loss: 1.4922\n",
      "Epoch [44/50] - Train Loss: 1.0585, Test Loss: 1.4923\n",
      "Epoch [45/50] - Train Loss: 1.0571, Test Loss: 1.4917\n",
      "Epoch [46/50] - Train Loss: 1.0573, Test Loss: 1.4917\n",
      "Epoch [47/50] - Train Loss: 1.0541, Test Loss: 1.4903\n",
      "Epoch [48/50] - Train Loss: 1.0534, Test Loss: 1.4903\n",
      "Epoch [49/50] - Train Loss: 1.0525, Test Loss: 1.4909\n",
      "Epoch [50/50] - Train Loss: 1.0517, Test Loss: 1.4911\n",
      "Avg Test Loss: 1.4911\n",
      "Testing combination: (16, 3, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1381, Test Loss: 1.6804\n",
      "Epoch [2/50] - Train Loss: 1.1254, Test Loss: 1.6513\n",
      "Epoch [3/50] - Train Loss: 1.1184, Test Loss: 1.6305\n",
      "Epoch [4/50] - Train Loss: 1.1153, Test Loss: 1.6172\n",
      "Epoch [5/50] - Train Loss: 1.1145, Test Loss: 1.6102\n",
      "Epoch [6/50] - Train Loss: 1.1146, Test Loss: 1.6074\n",
      "Epoch [7/50] - Train Loss: 1.1147, Test Loss: 1.6070\n",
      "Epoch [8/50] - Train Loss: 1.1147, Test Loss: 1.6077\n",
      "Epoch [9/50] - Train Loss: 1.1146, Test Loss: 1.6086\n",
      "Epoch [10/50] - Train Loss: 1.1145, Test Loss: 1.6093\n",
      "Epoch [11/50] - Train Loss: 1.1145, Test Loss: 1.6097\n",
      "Epoch [12/50] - Train Loss: 1.1144, Test Loss: 1.6099\n",
      "Epoch [13/50] - Train Loss: 1.1143, Test Loss: 1.6099\n",
      "Epoch [14/50] - Train Loss: 1.1142, Test Loss: 1.6098\n",
      "Epoch [15/50] - Train Loss: 1.1141, Test Loss: 1.6096\n",
      "Epoch [16/50] - Train Loss: 1.1140, Test Loss: 1.6095\n",
      "Epoch [17/50] - Train Loss: 1.1138, Test Loss: 1.6093\n",
      "Epoch [18/50] - Train Loss: 1.1137, Test Loss: 1.6092\n",
      "Epoch [19/50] - Train Loss: 1.1135, Test Loss: 1.6090\n",
      "Epoch [20/50] - Train Loss: 1.1134, Test Loss: 1.6089\n",
      "Epoch [21/50] - Train Loss: 1.1131, Test Loss: 1.6087\n",
      "Epoch [22/50] - Train Loss: 1.1129, Test Loss: 1.6086\n",
      "Epoch [23/50] - Train Loss: 1.1126, Test Loss: 1.6084\n",
      "Epoch [24/50] - Train Loss: 1.1123, Test Loss: 1.6082\n",
      "Epoch [25/50] - Train Loss: 1.1119, Test Loss: 1.6080\n",
      "Epoch [26/50] - Train Loss: 1.1113, Test Loss: 1.6078\n",
      "Epoch [27/50] - Train Loss: 1.1107, Test Loss: 1.6076\n",
      "Epoch [28/50] - Train Loss: 1.1098, Test Loss: 1.6074\n",
      "Epoch [29/50] - Train Loss: 1.1087, Test Loss: 1.6073\n",
      "Epoch [30/50] - Train Loss: 1.1074, Test Loss: 1.6072\n",
      "Epoch [31/50] - Train Loss: 1.1058, Test Loss: 1.6074\n",
      "Epoch [32/50] - Train Loss: 1.1039, Test Loss: 1.6077\n",
      "Epoch [33/50] - Train Loss: 1.1016, Test Loss: 1.6083\n",
      "Epoch [34/50] - Train Loss: 1.0988, Test Loss: 1.6091\n",
      "Epoch [35/50] - Train Loss: 1.0965, Test Loss: 1.6102\n",
      "Epoch [36/50] - Train Loss: 1.1056, Test Loss: 1.6119\n",
      "Epoch [37/50] - Train Loss: 1.0932, Test Loss: 1.6141\n",
      "Epoch [38/50] - Train Loss: 1.0906, Test Loss: 1.6137\n",
      "Epoch [39/50] - Train Loss: 1.0872, Test Loss: 1.6123\n",
      "Epoch [40/50] - Train Loss: 1.0841, Test Loss: 1.6122\n",
      "Epoch [41/50] - Train Loss: 1.0814, Test Loss: 1.6165\n",
      "Epoch [42/50] - Train Loss: 1.0807, Test Loss: 1.6232\n",
      "Epoch [43/50] - Train Loss: 1.0798, Test Loss: 1.6262\n",
      "Epoch [44/50] - Train Loss: 1.0791, Test Loss: 1.6259\n",
      "Epoch [45/50] - Train Loss: 1.0784, Test Loss: 1.6240\n",
      "Epoch [46/50] - Train Loss: 1.0775, Test Loss: 1.6227\n",
      "Epoch [47/50] - Train Loss: 1.0760, Test Loss: 1.6218\n",
      "Epoch [48/50] - Train Loss: 1.0731, Test Loss: 1.6217\n",
      "Epoch [49/50] - Train Loss: 1.0691, Test Loss: 1.6216\n",
      "Epoch [50/50] - Train Loss: 1.0651, Test Loss: 1.6184\n",
      "Avg Test Loss: 1.6184\n",
      "Testing combination: (16, 3, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3411, Test Loss: 2.7887\n",
      "Epoch [2/50] - Train Loss: 1.3272, Test Loss: 2.7559\n",
      "Epoch [3/50] - Train Loss: 1.3173, Test Loss: 2.7290\n",
      "Epoch [4/50] - Train Loss: 1.3103, Test Loss: 2.7073\n",
      "Epoch [5/50] - Train Loss: 1.3056, Test Loss: 2.6901\n",
      "Epoch [6/50] - Train Loss: 1.3029, Test Loss: 2.6772\n",
      "Epoch [7/50] - Train Loss: 1.3016, Test Loss: 2.6680\n",
      "Epoch [8/50] - Train Loss: 1.3012, Test Loss: 2.6620\n",
      "Epoch [9/50] - Train Loss: 1.3012, Test Loss: 2.6585\n",
      "Epoch [10/50] - Train Loss: 1.3013, Test Loss: 2.6569\n",
      "Epoch [11/50] - Train Loss: 1.3013, Test Loss: 2.6567\n",
      "Epoch [12/50] - Train Loss: 1.3012, Test Loss: 2.6573\n",
      "Epoch [13/50] - Train Loss: 1.3010, Test Loss: 2.6584\n",
      "Epoch [14/50] - Train Loss: 1.3008, Test Loss: 2.6597\n",
      "Epoch [15/50] - Train Loss: 1.3005, Test Loss: 2.6610\n",
      "Epoch [16/50] - Train Loss: 1.3003, Test Loss: 2.6622\n",
      "Epoch [17/50] - Train Loss: 1.3000, Test Loss: 2.6631\n",
      "Epoch [18/50] - Train Loss: 1.2997, Test Loss: 2.6638\n",
      "Epoch [19/50] - Train Loss: 1.2994, Test Loss: 2.6643\n",
      "Epoch [20/50] - Train Loss: 1.2990, Test Loss: 2.6646\n",
      "Epoch [21/50] - Train Loss: 1.2986, Test Loss: 2.6647\n",
      "Epoch [22/50] - Train Loss: 1.2982, Test Loss: 2.6648\n",
      "Epoch [23/50] - Train Loss: 1.2976, Test Loss: 2.6649\n",
      "Epoch [24/50] - Train Loss: 1.2969, Test Loss: 2.6649\n",
      "Epoch [25/50] - Train Loss: 1.2962, Test Loss: 2.6650\n",
      "Epoch [26/50] - Train Loss: 1.2954, Test Loss: 2.6652\n",
      "Epoch [27/50] - Train Loss: 1.2946, Test Loss: 2.6656\n",
      "Epoch [28/50] - Train Loss: 1.2937, Test Loss: 2.6661\n",
      "Epoch [29/50] - Train Loss: 1.2928, Test Loss: 2.6666\n",
      "Epoch [30/50] - Train Loss: 1.2918, Test Loss: 2.6672\n",
      "Epoch [31/50] - Train Loss: 1.2908, Test Loss: 2.6676\n",
      "Epoch [32/50] - Train Loss: 1.2898, Test Loss: 2.6679\n",
      "Epoch [33/50] - Train Loss: 1.2887, Test Loss: 2.6680\n",
      "Epoch [34/50] - Train Loss: 1.2877, Test Loss: 2.6679\n",
      "Epoch [35/50] - Train Loss: 1.2867, Test Loss: 2.6676\n",
      "Epoch [36/50] - Train Loss: 1.2857, Test Loss: 2.6671\n",
      "Epoch [37/50] - Train Loss: 1.2847, Test Loss: 2.6664\n",
      "Epoch [38/50] - Train Loss: 1.2837, Test Loss: 2.6655\n",
      "Epoch [39/50] - Train Loss: 1.2827, Test Loss: 2.6643\n",
      "Epoch [40/50] - Train Loss: 1.2815, Test Loss: 2.6631\n",
      "Epoch [41/50] - Train Loss: 1.2803, Test Loss: 2.6618\n",
      "Epoch [42/50] - Train Loss: 1.2791, Test Loss: 2.6605\n",
      "Epoch [43/50] - Train Loss: 1.2782, Test Loss: 2.6595\n",
      "Epoch [44/50] - Train Loss: 1.2785, Test Loss: 2.6586\n",
      "Epoch [45/50] - Train Loss: 1.2753, Test Loss: 2.6576\n",
      "Epoch [46/50] - Train Loss: 1.2761, Test Loss: 2.6574\n",
      "Epoch [47/50] - Train Loss: 1.2735, Test Loss: 2.6574\n",
      "Epoch [48/50] - Train Loss: 1.2718, Test Loss: 2.6568\n",
      "Epoch [49/50] - Train Loss: 1.2698, Test Loss: 2.6558\n",
      "Epoch [50/50] - Train Loss: 1.2686, Test Loss: 2.6550\n",
      "Avg Test Loss: 2.6550\n",
      "Testing combination: (16, 3, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1147, Test Loss: 1.5438\n",
      "Epoch [2/50] - Train Loss: 1.1137, Test Loss: 1.5421\n",
      "Epoch [3/50] - Train Loss: 1.1128, Test Loss: 1.5403\n",
      "Epoch [4/50] - Train Loss: 1.1119, Test Loss: 1.5386\n",
      "Epoch [5/50] - Train Loss: 1.1111, Test Loss: 1.5370\n",
      "Epoch [6/50] - Train Loss: 1.1103, Test Loss: 1.5354\n",
      "Epoch [7/50] - Train Loss: 1.1095, Test Loss: 1.5339\n",
      "Epoch [8/50] - Train Loss: 1.1088, Test Loss: 1.5325\n",
      "Epoch [9/50] - Train Loss: 1.1081, Test Loss: 1.5310\n",
      "Epoch [10/50] - Train Loss: 1.1074, Test Loss: 1.5296\n",
      "Epoch [11/50] - Train Loss: 1.1068, Test Loss: 1.5283\n",
      "Epoch [12/50] - Train Loss: 1.1061, Test Loss: 1.5270\n",
      "Epoch [13/50] - Train Loss: 1.1055, Test Loss: 1.5257\n",
      "Epoch [14/50] - Train Loss: 1.1050, Test Loss: 1.5245\n",
      "Epoch [15/50] - Train Loss: 1.1044, Test Loss: 1.5233\n",
      "Epoch [16/50] - Train Loss: 1.1039, Test Loss: 1.5221\n",
      "Epoch [17/50] - Train Loss: 1.1033, Test Loss: 1.5210\n",
      "Epoch [18/50] - Train Loss: 1.1028, Test Loss: 1.5199\n",
      "Epoch [19/50] - Train Loss: 1.1024, Test Loss: 1.5188\n",
      "Epoch [20/50] - Train Loss: 1.1019, Test Loss: 1.5178\n",
      "Epoch [21/50] - Train Loss: 1.1015, Test Loss: 1.5168\n",
      "Epoch [22/50] - Train Loss: 1.1010, Test Loss: 1.5158\n",
      "Epoch [23/50] - Train Loss: 1.1006, Test Loss: 1.5148\n",
      "Epoch [24/50] - Train Loss: 1.1002, Test Loss: 1.5139\n",
      "Epoch [25/50] - Train Loss: 1.0998, Test Loss: 1.5130\n",
      "Epoch [26/50] - Train Loss: 1.0995, Test Loss: 1.5121\n",
      "Epoch [27/50] - Train Loss: 1.0991, Test Loss: 1.5113\n",
      "Epoch [28/50] - Train Loss: 1.0988, Test Loss: 1.5104\n",
      "Epoch [29/50] - Train Loss: 1.0985, Test Loss: 1.5096\n",
      "Epoch [30/50] - Train Loss: 1.0982, Test Loss: 1.5088\n",
      "Epoch [31/50] - Train Loss: 1.0979, Test Loss: 1.5081\n",
      "Epoch [32/50] - Train Loss: 1.0976, Test Loss: 1.5073\n",
      "Epoch [33/50] - Train Loss: 1.0973, Test Loss: 1.5066\n",
      "Epoch [34/50] - Train Loss: 1.0970, Test Loss: 1.5059\n",
      "Epoch [35/50] - Train Loss: 1.0968, Test Loss: 1.5053\n",
      "Epoch [36/50] - Train Loss: 1.0965, Test Loss: 1.5046\n",
      "Epoch [37/50] - Train Loss: 1.0963, Test Loss: 1.5040\n",
      "Epoch [38/50] - Train Loss: 1.0961, Test Loss: 1.5033\n",
      "Epoch [39/50] - Train Loss: 1.0958, Test Loss: 1.5027\n",
      "Epoch [40/50] - Train Loss: 1.0956, Test Loss: 1.5021\n",
      "Epoch [41/50] - Train Loss: 1.0954, Test Loss: 1.5016\n",
      "Epoch [42/50] - Train Loss: 1.0952, Test Loss: 1.5010\n",
      "Epoch [43/50] - Train Loss: 1.0950, Test Loss: 1.5005\n",
      "Epoch [44/50] - Train Loss: 1.0948, Test Loss: 1.5000\n",
      "Epoch [45/50] - Train Loss: 1.0947, Test Loss: 1.4995\n",
      "Epoch [46/50] - Train Loss: 1.0945, Test Loss: 1.4990\n",
      "Epoch [47/50] - Train Loss: 1.0943, Test Loss: 1.4985\n",
      "Epoch [48/50] - Train Loss: 1.0942, Test Loss: 1.4981\n",
      "Epoch [49/50] - Train Loss: 1.0940, Test Loss: 1.4976\n",
      "Epoch [50/50] - Train Loss: 1.0938, Test Loss: 1.4972\n",
      "Avg Test Loss: 1.4972\n",
      "Testing combination: (16, 3, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.2010, Test Loss: 1.5887\n",
      "Epoch [2/50] - Train Loss: 1.1975, Test Loss: 1.5872\n",
      "Epoch [3/50] - Train Loss: 1.1942, Test Loss: 1.5858\n",
      "Epoch [4/50] - Train Loss: 1.1910, Test Loss: 1.5845\n",
      "Epoch [5/50] - Train Loss: 1.1879, Test Loss: 1.5832\n",
      "Epoch [6/50] - Train Loss: 1.1848, Test Loss: 1.5821\n",
      "Epoch [7/50] - Train Loss: 1.1819, Test Loss: 1.5810\n",
      "Epoch [8/50] - Train Loss: 1.1789, Test Loss: 1.5800\n",
      "Epoch [9/50] - Train Loss: 1.1761, Test Loss: 1.5790\n",
      "Epoch [10/50] - Train Loss: 1.1733, Test Loss: 1.5781\n",
      "Epoch [11/50] - Train Loss: 1.1705, Test Loss: 1.5773\n",
      "Epoch [12/50] - Train Loss: 1.1678, Test Loss: 1.5766\n",
      "Epoch [13/50] - Train Loss: 1.1652, Test Loss: 1.5760\n",
      "Epoch [14/50] - Train Loss: 1.1625, Test Loss: 1.5754\n",
      "Epoch [15/50] - Train Loss: 1.1599, Test Loss: 1.5749\n",
      "Epoch [16/50] - Train Loss: 1.1574, Test Loss: 1.5744\n",
      "Epoch [17/50] - Train Loss: 1.1549, Test Loss: 1.5741\n",
      "Epoch [18/50] - Train Loss: 1.1524, Test Loss: 1.5738\n",
      "Epoch [19/50] - Train Loss: 1.1499, Test Loss: 1.5737\n",
      "Epoch [20/50] - Train Loss: 1.1474, Test Loss: 1.5736\n",
      "Epoch [21/50] - Train Loss: 1.1450, Test Loss: 1.5736\n",
      "Epoch [22/50] - Train Loss: 1.1427, Test Loss: 1.5738\n",
      "Epoch [23/50] - Train Loss: 1.1403, Test Loss: 1.5741\n",
      "Epoch [24/50] - Train Loss: 1.1381, Test Loss: 1.5745\n",
      "Epoch [25/50] - Train Loss: 1.1358, Test Loss: 1.5750\n",
      "Epoch [26/50] - Train Loss: 1.1336, Test Loss: 1.5757\n",
      "Epoch [27/50] - Train Loss: 1.1315, Test Loss: 1.5765\n",
      "Epoch [28/50] - Train Loss: 1.1295, Test Loss: 1.5775\n",
      "Epoch [29/50] - Train Loss: 1.1276, Test Loss: 1.5787\n",
      "Epoch [30/50] - Train Loss: 1.1258, Test Loss: 1.5800\n",
      "Epoch [31/50] - Train Loss: 1.1242, Test Loss: 1.5815\n",
      "Epoch [32/50] - Train Loss: 1.1226, Test Loss: 1.5831\n",
      "Epoch [33/50] - Train Loss: 1.1212, Test Loss: 1.5848\n",
      "Epoch [34/50] - Train Loss: 1.1200, Test Loss: 1.5866\n",
      "Epoch [35/50] - Train Loss: 1.1190, Test Loss: 1.5884\n",
      "Epoch [36/50] - Train Loss: 1.1181, Test Loss: 1.5902\n",
      "Epoch [37/50] - Train Loss: 1.1173, Test Loss: 1.5920\n",
      "Epoch [38/50] - Train Loss: 1.1166, Test Loss: 1.5937\n",
      "Epoch [39/50] - Train Loss: 1.1161, Test Loss: 1.5954\n",
      "Epoch [40/50] - Train Loss: 1.1157, Test Loss: 1.5969\n",
      "Epoch [41/50] - Train Loss: 1.1154, Test Loss: 1.5984\n",
      "Epoch [42/50] - Train Loss: 1.1151, Test Loss: 1.5997\n",
      "Epoch [43/50] - Train Loss: 1.1149, Test Loss: 1.6009\n",
      "Epoch [44/50] - Train Loss: 1.1147, Test Loss: 1.6019\n",
      "Epoch [45/50] - Train Loss: 1.1146, Test Loss: 1.6029\n",
      "Epoch [46/50] - Train Loss: 1.1144, Test Loss: 1.6037\n",
      "Epoch [47/50] - Train Loss: 1.1144, Test Loss: 1.6045\n",
      "Epoch [48/50] - Train Loss: 1.1143, Test Loss: 1.6052\n",
      "Epoch [49/50] - Train Loss: 1.1142, Test Loss: 1.6057\n",
      "Epoch [50/50] - Train Loss: 1.1142, Test Loss: 1.6062\n",
      "Avg Test Loss: 1.6062\n",
      "Testing combination: (16, 3, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3017, Test Loss: 2.6628\n",
      "Epoch [2/50] - Train Loss: 1.3016, Test Loss: 2.6628\n",
      "Epoch [3/50] - Train Loss: 1.3016, Test Loss: 2.6629\n",
      "Epoch [4/50] - Train Loss: 1.3016, Test Loss: 2.6629\n",
      "Epoch [5/50] - Train Loss: 1.3016, Test Loss: 2.6629\n",
      "Epoch [6/50] - Train Loss: 1.3016, Test Loss: 2.6629\n",
      "Epoch [7/50] - Train Loss: 1.3016, Test Loss: 2.6629\n",
      "Epoch [8/50] - Train Loss: 1.3016, Test Loss: 2.6629\n",
      "Epoch [9/50] - Train Loss: 1.3016, Test Loss: 2.6629\n",
      "Epoch [10/50] - Train Loss: 1.3015, Test Loss: 2.6629\n",
      "Epoch [11/50] - Train Loss: 1.3015, Test Loss: 2.6629\n",
      "Epoch [12/50] - Train Loss: 1.3015, Test Loss: 2.6629\n",
      "Epoch [13/50] - Train Loss: 1.3015, Test Loss: 2.6629\n",
      "Epoch [14/50] - Train Loss: 1.3015, Test Loss: 2.6629\n",
      "Epoch [15/50] - Train Loss: 1.3015, Test Loss: 2.6629\n",
      "Epoch [16/50] - Train Loss: 1.3015, Test Loss: 2.6629\n",
      "Epoch [17/50] - Train Loss: 1.3015, Test Loss: 2.6629\n",
      "Epoch [18/50] - Train Loss: 1.3015, Test Loss: 2.6629\n",
      "Epoch [19/50] - Train Loss: 1.3015, Test Loss: 2.6629\n",
      "Epoch [20/50] - Train Loss: 1.3015, Test Loss: 2.6628\n",
      "Epoch [21/50] - Train Loss: 1.3015, Test Loss: 2.6628\n",
      "Epoch [22/50] - Train Loss: 1.3015, Test Loss: 2.6628\n",
      "Epoch [23/50] - Train Loss: 1.3015, Test Loss: 2.6628\n",
      "Epoch [24/50] - Train Loss: 1.3015, Test Loss: 2.6628\n",
      "Epoch [25/50] - Train Loss: 1.3014, Test Loss: 2.6628\n",
      "Epoch [26/50] - Train Loss: 1.3014, Test Loss: 2.6628\n",
      "Epoch [27/50] - Train Loss: 1.3014, Test Loss: 2.6628\n",
      "Epoch [28/50] - Train Loss: 1.3014, Test Loss: 2.6628\n",
      "Epoch [29/50] - Train Loss: 1.3014, Test Loss: 2.6628\n",
      "Epoch [30/50] - Train Loss: 1.3014, Test Loss: 2.6628\n",
      "Epoch [31/50] - Train Loss: 1.3014, Test Loss: 2.6628\n",
      "Epoch [32/50] - Train Loss: 1.3014, Test Loss: 2.6628\n",
      "Epoch [33/50] - Train Loss: 1.3014, Test Loss: 2.6628\n",
      "Epoch [34/50] - Train Loss: 1.3014, Test Loss: 2.6628\n",
      "Epoch [35/50] - Train Loss: 1.3014, Test Loss: 2.6628\n",
      "Epoch [36/50] - Train Loss: 1.3014, Test Loss: 2.6628\n",
      "Epoch [37/50] - Train Loss: 1.3013, Test Loss: 2.6628\n",
      "Epoch [38/50] - Train Loss: 1.3013, Test Loss: 2.6628\n",
      "Epoch [39/50] - Train Loss: 1.3013, Test Loss: 2.6628\n",
      "Epoch [40/50] - Train Loss: 1.3013, Test Loss: 2.6628\n",
      "Epoch [41/50] - Train Loss: 1.3013, Test Loss: 2.6628\n",
      "Epoch [42/50] - Train Loss: 1.3013, Test Loss: 2.6628\n",
      "Epoch [43/50] - Train Loss: 1.3013, Test Loss: 2.6628\n",
      "Epoch [44/50] - Train Loss: 1.3013, Test Loss: 2.6628\n",
      "Epoch [45/50] - Train Loss: 1.3012, Test Loss: 2.6628\n",
      "Epoch [46/50] - Train Loss: 1.3012, Test Loss: 2.6628\n",
      "Epoch [47/50] - Train Loss: 1.3012, Test Loss: 2.6628\n",
      "Epoch [48/50] - Train Loss: 1.3012, Test Loss: 2.6628\n",
      "Epoch [49/50] - Train Loss: 1.3012, Test Loss: 2.6628\n",
      "Epoch [50/50] - Train Loss: 1.3012, Test Loss: 2.6628\n",
      "Avg Test Loss: 2.6628\n",
      "Testing combination: (16, 4, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1215, Test Loss: 1.5001\n",
      "Epoch [2/50] - Train Loss: 1.0963, Test Loss: 1.4826\n",
      "Epoch [3/50] - Train Loss: 1.0975, Test Loss: 1.4827\n",
      "Epoch [4/50] - Train Loss: 1.0971, Test Loss: 1.4853\n",
      "Epoch [5/50] - Train Loss: 1.0963, Test Loss: 1.4866\n",
      "Epoch [6/50] - Train Loss: 1.0955, Test Loss: 1.4865\n",
      "Epoch [7/50] - Train Loss: 1.0941, Test Loss: 1.4857\n",
      "Epoch [8/50] - Train Loss: 1.0947, Test Loss: 1.4851\n",
      "Epoch [9/50] - Train Loss: 1.0907, Test Loss: 1.4841\n",
      "Epoch [10/50] - Train Loss: 1.0849, Test Loss: 1.4828\n",
      "Epoch [11/50] - Train Loss: 1.0853, Test Loss: 1.4827\n",
      "Epoch [12/50] - Train Loss: 1.0936, Test Loss: 1.4848\n",
      "Epoch [13/50] - Train Loss: 1.0906, Test Loss: 1.4849\n",
      "Epoch [14/50] - Train Loss: 1.0824, Test Loss: 1.4862\n",
      "Epoch [15/50] - Train Loss: 1.0702, Test Loss: 1.4852\n",
      "Epoch [16/50] - Train Loss: 1.0635, Test Loss: 1.4879\n",
      "Epoch [17/50] - Train Loss: 1.0580, Test Loss: 1.4883\n",
      "Epoch [18/50] - Train Loss: 1.0551, Test Loss: 1.4874\n",
      "Epoch [19/50] - Train Loss: 1.0545, Test Loss: 1.4861\n",
      "Epoch [20/50] - Train Loss: 1.0542, Test Loss: 1.4905\n",
      "Epoch [21/50] - Train Loss: 1.0657, Test Loss: 1.4854\n",
      "Epoch [22/50] - Train Loss: 1.0705, Test Loss: 1.4840\n",
      "Epoch [23/50] - Train Loss: 1.0656, Test Loss: 1.4848\n",
      "Epoch [24/50] - Train Loss: 1.0571, Test Loss: 1.4880\n",
      "Epoch [25/50] - Train Loss: 1.0536, Test Loss: 1.4864\n",
      "Epoch [26/50] - Train Loss: 1.0533, Test Loss: 1.4845\n",
      "Epoch [27/50] - Train Loss: 1.0535, Test Loss: 1.4857\n",
      "Epoch [28/50] - Train Loss: 1.0524, Test Loss: 1.4848\n",
      "Epoch [29/50] - Train Loss: 1.0505, Test Loss: 1.4817\n",
      "Epoch [30/50] - Train Loss: 1.0522, Test Loss: 1.4858\n",
      "Epoch [31/50] - Train Loss: 1.0510, Test Loss: 1.4843\n",
      "Epoch [32/50] - Train Loss: 1.0479, Test Loss: 1.4852\n",
      "Epoch [33/50] - Train Loss: 1.0478, Test Loss: 1.4818\n",
      "Epoch [34/50] - Train Loss: 1.0481, Test Loss: 1.4849\n",
      "Epoch [35/50] - Train Loss: 1.0470, Test Loss: 1.4842\n",
      "Epoch [36/50] - Train Loss: 1.0450, Test Loss: 1.4879\n",
      "Epoch [37/50] - Train Loss: 1.0448, Test Loss: 1.4848\n",
      "Epoch [38/50] - Train Loss: 1.0462, Test Loss: 1.4832\n",
      "Epoch [39/50] - Train Loss: 1.0434, Test Loss: 1.4835\n",
      "Epoch [40/50] - Train Loss: 1.0424, Test Loss: 1.4847\n",
      "Epoch [41/50] - Train Loss: 1.0438, Test Loss: 1.4871\n",
      "Epoch [42/50] - Train Loss: 1.0412, Test Loss: 1.4947\n",
      "Epoch [43/50] - Train Loss: 1.0410, Test Loss: 1.4918\n",
      "Epoch [44/50] - Train Loss: 1.0434, Test Loss: 1.4861\n",
      "Epoch [45/50] - Train Loss: 1.0487, Test Loss: 1.4839\n",
      "Epoch [46/50] - Train Loss: 1.0505, Test Loss: 1.4846\n",
      "Epoch [47/50] - Train Loss: 1.0469, Test Loss: 1.4910\n",
      "Epoch [48/50] - Train Loss: 1.0486, Test Loss: 1.4875\n",
      "Epoch [49/50] - Train Loss: 1.0445, Test Loss: 1.4882\n",
      "Epoch [50/50] - Train Loss: 1.0419, Test Loss: 1.4931\n",
      "Avg Test Loss: 1.4931\n",
      "Testing combination: (16, 4, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1535, Test Loss: 1.6033\n",
      "Epoch [2/50] - Train Loss: 1.1171, Test Loss: 1.5961\n",
      "Epoch [3/50] - Train Loss: 1.1177, Test Loss: 1.6055\n",
      "Epoch [4/50] - Train Loss: 1.1171, Test Loss: 1.6112\n",
      "Epoch [5/50] - Train Loss: 1.1165, Test Loss: 1.6089\n",
      "Epoch [6/50] - Train Loss: 1.1161, Test Loss: 1.6060\n",
      "Epoch [7/50] - Train Loss: 1.1162, Test Loss: 1.6059\n",
      "Epoch [8/50] - Train Loss: 1.1161, Test Loss: 1.6070\n",
      "Epoch [9/50] - Train Loss: 1.1157, Test Loss: 1.6075\n",
      "Epoch [10/50] - Train Loss: 1.1148, Test Loss: 1.6071\n",
      "Epoch [11/50] - Train Loss: 1.1208, Test Loss: 1.6051\n",
      "Epoch [12/50] - Train Loss: 1.1143, Test Loss: 1.6046\n",
      "Epoch [13/50] - Train Loss: 1.1140, Test Loss: 1.6072\n",
      "Epoch [14/50] - Train Loss: 1.1126, Test Loss: 1.6093\n",
      "Epoch [15/50] - Train Loss: 1.1108, Test Loss: 1.6097\n",
      "Epoch [16/50] - Train Loss: 1.1072, Test Loss: 1.6083\n",
      "Epoch [17/50] - Train Loss: 1.1066, Test Loss: 1.6560\n",
      "Epoch [18/50] - Train Loss: 1.0950, Test Loss: 1.6215\n",
      "Epoch [19/50] - Train Loss: 1.0960, Test Loss: 1.6081\n",
      "Epoch [20/50] - Train Loss: 1.0908, Test Loss: 1.6092\n",
      "Epoch [21/50] - Train Loss: 1.0841, Test Loss: 1.6139\n",
      "Epoch [22/50] - Train Loss: 1.0804, Test Loss: 1.6120\n",
      "Epoch [23/50] - Train Loss: 1.0797, Test Loss: 1.6108\n",
      "Epoch [24/50] - Train Loss: 1.0813, Test Loss: 1.6109\n",
      "Epoch [25/50] - Train Loss: 1.0793, Test Loss: 1.6108\n",
      "Epoch [26/50] - Train Loss: 1.0794, Test Loss: 1.6121\n",
      "Epoch [27/50] - Train Loss: 1.0792, Test Loss: 1.6128\n",
      "Epoch [28/50] - Train Loss: 1.0790, Test Loss: 1.6122\n",
      "Epoch [29/50] - Train Loss: 1.0790, Test Loss: 1.6117\n",
      "Epoch [30/50] - Train Loss: 1.0790, Test Loss: 1.6118\n",
      "Epoch [31/50] - Train Loss: 1.0789, Test Loss: 1.6122\n",
      "Epoch [32/50] - Train Loss: 1.0789, Test Loss: 1.6124\n",
      "Epoch [33/50] - Train Loss: 1.0789, Test Loss: 1.6123\n",
      "Epoch [34/50] - Train Loss: 1.0788, Test Loss: 1.6123\n",
      "Epoch [35/50] - Train Loss: 1.0788, Test Loss: 1.6123\n",
      "Epoch [36/50] - Train Loss: 1.0788, Test Loss: 1.6124\n",
      "Epoch [37/50] - Train Loss: 1.0788, Test Loss: 1.6125\n",
      "Epoch [38/50] - Train Loss: 1.0787, Test Loss: 1.6125\n",
      "Epoch [39/50] - Train Loss: 1.0787, Test Loss: 1.6125\n",
      "Epoch [40/50] - Train Loss: 1.0786, Test Loss: 1.6126\n",
      "Epoch [41/50] - Train Loss: 1.0786, Test Loss: 1.6126\n",
      "Epoch [42/50] - Train Loss: 1.0784, Test Loss: 1.6127\n",
      "Epoch [43/50] - Train Loss: 1.0783, Test Loss: 1.6129\n",
      "Epoch [44/50] - Train Loss: 1.0776, Test Loss: 1.6121\n",
      "Epoch [45/50] - Train Loss: 1.0774, Test Loss: 1.6122\n",
      "Epoch [46/50] - Train Loss: 1.1061, Test Loss: 1.6154\n",
      "Epoch [47/50] - Train Loss: 1.0837, Test Loss: 1.6122\n",
      "Epoch [48/50] - Train Loss: 1.0806, Test Loss: 1.6113\n",
      "Epoch [49/50] - Train Loss: 1.0796, Test Loss: 1.6129\n",
      "Epoch [50/50] - Train Loss: 1.0792, Test Loss: 1.6139\n",
      "Avg Test Loss: 1.6139\n",
      "Testing combination: (16, 4, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3462, Test Loss: 2.6781\n",
      "Epoch [2/50] - Train Loss: 1.3066, Test Loss: 2.6412\n",
      "Epoch [3/50] - Train Loss: 1.3068, Test Loss: 2.6488\n",
      "Epoch [4/50] - Train Loss: 1.3037, Test Loss: 2.6616\n",
      "Epoch [5/50] - Train Loss: 1.3027, Test Loss: 2.6705\n",
      "Epoch [6/50] - Train Loss: 1.3026, Test Loss: 2.6731\n",
      "Epoch [7/50] - Train Loss: 1.3024, Test Loss: 2.6711\n",
      "Epoch [8/50] - Train Loss: 1.3021, Test Loss: 2.6672\n",
      "Epoch [9/50] - Train Loss: 1.3018, Test Loss: 2.6637\n",
      "Epoch [10/50] - Train Loss: 1.3017, Test Loss: 2.6615\n",
      "Epoch [11/50] - Train Loss: 1.3016, Test Loss: 2.6610\n",
      "Epoch [12/50] - Train Loss: 1.3014, Test Loss: 2.6619\n",
      "Epoch [13/50] - Train Loss: 1.3009, Test Loss: 2.6636\n",
      "Epoch [14/50] - Train Loss: 1.2998, Test Loss: 2.6656\n",
      "Epoch [15/50] - Train Loss: 1.2977, Test Loss: 2.6677\n",
      "Epoch [16/50] - Train Loss: 1.2950, Test Loss: 2.6698\n",
      "Epoch [17/50] - Train Loss: 1.2917, Test Loss: 2.6714\n",
      "Epoch [18/50] - Train Loss: 1.2932, Test Loss: 2.6719\n",
      "Epoch [19/50] - Train Loss: 1.3039, Test Loss: 2.6700\n",
      "Epoch [20/50] - Train Loss: 1.3028, Test Loss: 2.6644\n",
      "Epoch [21/50] - Train Loss: 1.3017, Test Loss: 2.6592\n",
      "Epoch [22/50] - Train Loss: 1.3034, Test Loss: 2.6572\n",
      "Epoch [23/50] - Train Loss: 1.2996, Test Loss: 2.6594\n",
      "Epoch [24/50] - Train Loss: 1.2991, Test Loss: 2.6626\n",
      "Epoch [25/50] - Train Loss: 1.2957, Test Loss: 2.6649\n",
      "Epoch [26/50] - Train Loss: 1.2886, Test Loss: 2.6633\n",
      "Epoch [27/50] - Train Loss: 1.2811, Test Loss: 2.6505\n",
      "Epoch [28/50] - Train Loss: 1.2733, Test Loss: 2.6354\n",
      "Epoch [29/50] - Train Loss: 1.3073, Test Loss: 2.6423\n",
      "Epoch [30/50] - Train Loss: 1.2869, Test Loss: 2.6394\n",
      "Epoch [31/50] - Train Loss: 1.2652, Test Loss: 2.6342\n",
      "Epoch [32/50] - Train Loss: 1.2668, Test Loss: 2.6296\n",
      "Epoch [33/50] - Train Loss: 1.2614, Test Loss: 2.6372\n",
      "Epoch [34/50] - Train Loss: 1.2585, Test Loss: 2.6203\n",
      "Epoch [35/50] - Train Loss: 1.2624, Test Loss: 2.6372\n",
      "Epoch [36/50] - Train Loss: 1.2603, Test Loss: 2.6545\n",
      "Epoch [37/50] - Train Loss: 1.2611, Test Loss: 2.6606\n",
      "Epoch [38/50] - Train Loss: 1.2554, Test Loss: 2.6650\n",
      "Epoch [39/50] - Train Loss: 1.2553, Test Loss: 2.6635\n",
      "Epoch [40/50] - Train Loss: 1.2548, Test Loss: 2.6604\n",
      "Epoch [41/50] - Train Loss: 1.2539, Test Loss: 2.6590\n",
      "Epoch [42/50] - Train Loss: 1.2536, Test Loss: 2.6592\n",
      "Epoch [43/50] - Train Loss: 1.2532, Test Loss: 2.6588\n",
      "Epoch [44/50] - Train Loss: 1.2521, Test Loss: 2.6554\n",
      "Epoch [45/50] - Train Loss: 1.2539, Test Loss: 2.6485\n",
      "Epoch [46/50] - Train Loss: 1.2481, Test Loss: 2.6461\n",
      "Epoch [47/50] - Train Loss: 1.2493, Test Loss: 2.6464\n",
      "Epoch [48/50] - Train Loss: 1.2468, Test Loss: 2.6439\n",
      "Epoch [49/50] - Train Loss: 1.2444, Test Loss: 2.6414\n",
      "Epoch [50/50] - Train Loss: 1.2401, Test Loss: 2.6437\n",
      "Avg Test Loss: 2.6437\n",
      "Testing combination: (16, 4, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.0955, Test Loss: 1.4892\n",
      "Epoch [2/50] - Train Loss: 1.0940, Test Loss: 1.4889\n",
      "Epoch [3/50] - Train Loss: 1.0938, Test Loss: 1.4884\n",
      "Epoch [4/50] - Train Loss: 1.0937, Test Loss: 1.4879\n",
      "Epoch [5/50] - Train Loss: 1.0937, Test Loss: 1.4875\n",
      "Epoch [6/50] - Train Loss: 1.0937, Test Loss: 1.4871\n",
      "Epoch [7/50] - Train Loss: 1.0936, Test Loss: 1.4869\n",
      "Epoch [8/50] - Train Loss: 1.0936, Test Loss: 1.4866\n",
      "Epoch [9/50] - Train Loss: 1.0935, Test Loss: 1.4864\n",
      "Epoch [10/50] - Train Loss: 1.0935, Test Loss: 1.4863\n",
      "Epoch [11/50] - Train Loss: 1.0934, Test Loss: 1.4862\n",
      "Epoch [12/50] - Train Loss: 1.0933, Test Loss: 1.4860\n",
      "Epoch [13/50] - Train Loss: 1.0932, Test Loss: 1.4859\n",
      "Epoch [14/50] - Train Loss: 1.0931, Test Loss: 1.4858\n",
      "Epoch [15/50] - Train Loss: 1.0929, Test Loss: 1.4857\n",
      "Epoch [16/50] - Train Loss: 1.0927, Test Loss: 1.4856\n",
      "Epoch [17/50] - Train Loss: 1.0925, Test Loss: 1.4855\n",
      "Epoch [18/50] - Train Loss: 1.0922, Test Loss: 1.4854\n",
      "Epoch [19/50] - Train Loss: 1.0919, Test Loss: 1.4853\n",
      "Epoch [20/50] - Train Loss: 1.0914, Test Loss: 1.4851\n",
      "Epoch [21/50] - Train Loss: 1.0908, Test Loss: 1.4850\n",
      "Epoch [22/50] - Train Loss: 1.0900, Test Loss: 1.4848\n",
      "Epoch [23/50] - Train Loss: 1.0889, Test Loss: 1.4846\n",
      "Epoch [24/50] - Train Loss: 1.0877, Test Loss: 1.4845\n",
      "Epoch [25/50] - Train Loss: 1.0857, Test Loss: 1.4843\n",
      "Epoch [26/50] - Train Loss: 1.0870, Test Loss: 1.4841\n",
      "Epoch [27/50] - Train Loss: 1.0911, Test Loss: 1.4840\n",
      "Epoch [28/50] - Train Loss: 1.0844, Test Loss: 1.4842\n",
      "Epoch [29/50] - Train Loss: 1.0830, Test Loss: 1.4842\n",
      "Epoch [30/50] - Train Loss: 1.0800, Test Loss: 1.4843\n",
      "Epoch [31/50] - Train Loss: 1.0780, Test Loss: 1.4843\n",
      "Epoch [32/50] - Train Loss: 1.0757, Test Loss: 1.4843\n",
      "Epoch [33/50] - Train Loss: 1.0730, Test Loss: 1.4843\n",
      "Epoch [34/50] - Train Loss: 1.0697, Test Loss: 1.4842\n",
      "Epoch [35/50] - Train Loss: 1.0649, Test Loss: 1.4840\n",
      "Epoch [36/50] - Train Loss: 1.0612, Test Loss: 1.4873\n",
      "Epoch [37/50] - Train Loss: 1.0564, Test Loss: 1.4881\n",
      "Epoch [38/50] - Train Loss: 1.0550, Test Loss: 1.4897\n",
      "Epoch [39/50] - Train Loss: 1.0542, Test Loss: 1.4906\n",
      "Epoch [40/50] - Train Loss: 1.0532, Test Loss: 1.4907\n",
      "Epoch [41/50] - Train Loss: 1.0524, Test Loss: 1.4906\n",
      "Epoch [42/50] - Train Loss: 1.0511, Test Loss: 1.4908\n",
      "Epoch [43/50] - Train Loss: 1.0489, Test Loss: 1.4914\n",
      "Epoch [44/50] - Train Loss: 1.0518, Test Loss: 1.4889\n",
      "Epoch [45/50] - Train Loss: 1.0454, Test Loss: 1.4883\n",
      "Epoch [46/50] - Train Loss: 1.1110, Test Loss: 1.4892\n",
      "Epoch [47/50] - Train Loss: 1.0915, Test Loss: 1.4928\n",
      "Epoch [48/50] - Train Loss: 1.1125, Test Loss: 1.4887\n",
      "Epoch [49/50] - Train Loss: 1.0868, Test Loss: 1.4875\n",
      "Epoch [50/50] - Train Loss: 1.0784, Test Loss: 1.4864\n",
      "Avg Test Loss: 1.4864\n",
      "Testing combination: (16, 4, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1344, Test Loss: 1.6739\n",
      "Epoch [2/50] - Train Loss: 1.1240, Test Loss: 1.6500\n",
      "Epoch [3/50] - Train Loss: 1.1185, Test Loss: 1.6331\n",
      "Epoch [4/50] - Train Loss: 1.1158, Test Loss: 1.6218\n",
      "Epoch [5/50] - Train Loss: 1.1148, Test Loss: 1.6148\n",
      "Epoch [6/50] - Train Loss: 1.1145, Test Loss: 1.6109\n",
      "Epoch [7/50] - Train Loss: 1.1146, Test Loss: 1.6091\n",
      "Epoch [8/50] - Train Loss: 1.1146, Test Loss: 1.6086\n",
      "Epoch [9/50] - Train Loss: 1.1146, Test Loss: 1.6086\n",
      "Epoch [10/50] - Train Loss: 1.1146, Test Loss: 1.6089\n",
      "Epoch [11/50] - Train Loss: 1.1146, Test Loss: 1.6093\n",
      "Epoch [12/50] - Train Loss: 1.1145, Test Loss: 1.6095\n",
      "Epoch [13/50] - Train Loss: 1.1145, Test Loss: 1.6097\n",
      "Epoch [14/50] - Train Loss: 1.1144, Test Loss: 1.6098\n",
      "Epoch [15/50] - Train Loss: 1.1144, Test Loss: 1.6098\n",
      "Epoch [16/50] - Train Loss: 1.1143, Test Loss: 1.6097\n",
      "Epoch [17/50] - Train Loss: 1.1142, Test Loss: 1.6096\n",
      "Epoch [18/50] - Train Loss: 1.1141, Test Loss: 1.6096\n",
      "Epoch [19/50] - Train Loss: 1.1139, Test Loss: 1.6094\n",
      "Epoch [20/50] - Train Loss: 1.1137, Test Loss: 1.6093\n",
      "Epoch [21/50] - Train Loss: 1.1134, Test Loss: 1.6092\n",
      "Epoch [22/50] - Train Loss: 1.1130, Test Loss: 1.6091\n",
      "Epoch [23/50] - Train Loss: 1.1125, Test Loss: 1.6089\n",
      "Epoch [24/50] - Train Loss: 1.1118, Test Loss: 1.6087\n",
      "Epoch [25/50] - Train Loss: 1.1109, Test Loss: 1.6084\n",
      "Epoch [26/50] - Train Loss: 1.1096, Test Loss: 1.6080\n",
      "Epoch [27/50] - Train Loss: 1.1082, Test Loss: 1.6078\n",
      "Epoch [28/50] - Train Loss: 1.1115, Test Loss: 1.6074\n",
      "Epoch [29/50] - Train Loss: 1.1059, Test Loss: 1.6073\n",
      "Epoch [30/50] - Train Loss: 1.1051, Test Loss: 1.6077\n",
      "Epoch [31/50] - Train Loss: 1.1045, Test Loss: 1.6081\n",
      "Epoch [32/50] - Train Loss: 1.1020, Test Loss: 1.6085\n",
      "Epoch [33/50] - Train Loss: 1.0996, Test Loss: 1.6094\n",
      "Epoch [34/50] - Train Loss: 1.0968, Test Loss: 1.6102\n",
      "Epoch [35/50] - Train Loss: 1.0943, Test Loss: 1.6114\n",
      "Epoch [36/50] - Train Loss: 1.0921, Test Loss: 1.6123\n",
      "Epoch [37/50] - Train Loss: 1.0903, Test Loss: 1.6132\n",
      "Epoch [38/50] - Train Loss: 1.0900, Test Loss: 1.6136\n",
      "Epoch [39/50] - Train Loss: 1.0857, Test Loss: 1.6129\n",
      "Epoch [40/50] - Train Loss: 1.0853, Test Loss: 1.6135\n",
      "Epoch [41/50] - Train Loss: 1.0836, Test Loss: 1.6145\n",
      "Epoch [42/50] - Train Loss: 1.0823, Test Loss: 1.6146\n",
      "Epoch [43/50] - Train Loss: 1.0810, Test Loss: 1.6139\n",
      "Epoch [44/50] - Train Loss: 1.0797, Test Loss: 1.6129\n",
      "Epoch [45/50] - Train Loss: 1.0784, Test Loss: 1.6126\n",
      "Epoch [46/50] - Train Loss: 1.0766, Test Loss: 1.6160\n",
      "Epoch [47/50] - Train Loss: 1.0750, Test Loss: 1.6204\n",
      "Epoch [48/50] - Train Loss: 1.0736, Test Loss: 1.6230\n",
      "Epoch [49/50] - Train Loss: 1.0725, Test Loss: 1.6237\n",
      "Epoch [50/50] - Train Loss: 1.0711, Test Loss: 1.6236\n",
      "Avg Test Loss: 1.6236\n",
      "Testing combination: (16, 4, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3030, Test Loss: 2.6589\n",
      "Epoch [2/50] - Train Loss: 1.3021, Test Loss: 2.6609\n",
      "Epoch [3/50] - Train Loss: 1.3019, Test Loss: 2.6622\n",
      "Epoch [4/50] - Train Loss: 1.3019, Test Loss: 2.6630\n",
      "Epoch [5/50] - Train Loss: 1.3018, Test Loss: 2.6635\n",
      "Epoch [6/50] - Train Loss: 1.3018, Test Loss: 2.6637\n",
      "Epoch [7/50] - Train Loss: 1.3018, Test Loss: 2.6637\n",
      "Epoch [8/50] - Train Loss: 1.3017, Test Loss: 2.6636\n",
      "Epoch [9/50] - Train Loss: 1.3017, Test Loss: 2.6635\n",
      "Epoch [10/50] - Train Loss: 1.3017, Test Loss: 2.6633\n",
      "Epoch [11/50] - Train Loss: 1.3016, Test Loss: 2.6632\n",
      "Epoch [12/50] - Train Loss: 1.3016, Test Loss: 2.6631\n",
      "Epoch [13/50] - Train Loss: 1.3016, Test Loss: 2.6630\n",
      "Epoch [14/50] - Train Loss: 1.3015, Test Loss: 2.6630\n",
      "Epoch [15/50] - Train Loss: 1.3015, Test Loss: 2.6629\n",
      "Epoch [16/50] - Train Loss: 1.3014, Test Loss: 2.6630\n",
      "Epoch [17/50] - Train Loss: 1.3014, Test Loss: 2.6630\n",
      "Epoch [18/50] - Train Loss: 1.3013, Test Loss: 2.6631\n",
      "Epoch [19/50] - Train Loss: 1.3012, Test Loss: 2.6632\n",
      "Epoch [20/50] - Train Loss: 1.3012, Test Loss: 2.6633\n",
      "Epoch [21/50] - Train Loss: 1.3011, Test Loss: 2.6634\n",
      "Epoch [22/50] - Train Loss: 1.3010, Test Loss: 2.6635\n",
      "Epoch [23/50] - Train Loss: 1.3008, Test Loss: 2.6637\n",
      "Epoch [24/50] - Train Loss: 1.3007, Test Loss: 2.6638\n",
      "Epoch [25/50] - Train Loss: 1.3005, Test Loss: 2.6640\n",
      "Epoch [26/50] - Train Loss: 1.3004, Test Loss: 2.6642\n",
      "Epoch [27/50] - Train Loss: 1.3001, Test Loss: 2.6644\n",
      "Epoch [28/50] - Train Loss: 1.2999, Test Loss: 2.6647\n",
      "Epoch [29/50] - Train Loss: 1.2995, Test Loss: 2.6650\n",
      "Epoch [30/50] - Train Loss: 1.2989, Test Loss: 2.6654\n",
      "Epoch [31/50] - Train Loss: 1.2982, Test Loss: 2.6659\n",
      "Epoch [32/50] - Train Loss: 1.2975, Test Loss: 2.6665\n",
      "Epoch [33/50] - Train Loss: 1.2966, Test Loss: 2.6673\n",
      "Epoch [34/50] - Train Loss: 1.2956, Test Loss: 2.6681\n",
      "Epoch [35/50] - Train Loss: 1.2945, Test Loss: 2.6690\n",
      "Epoch [36/50] - Train Loss: 1.2933, Test Loss: 2.6699\n",
      "Epoch [37/50] - Train Loss: 1.2921, Test Loss: 2.6707\n",
      "Epoch [38/50] - Train Loss: 1.2908, Test Loss: 2.6713\n",
      "Epoch [39/50] - Train Loss: 1.2895, Test Loss: 2.6716\n",
      "Epoch [40/50] - Train Loss: 1.2883, Test Loss: 2.6716\n",
      "Epoch [41/50] - Train Loss: 1.2871, Test Loss: 2.6713\n",
      "Epoch [42/50] - Train Loss: 1.2860, Test Loss: 2.6707\n",
      "Epoch [43/50] - Train Loss: 1.2850, Test Loss: 2.6697\n",
      "Epoch [44/50] - Train Loss: 1.2838, Test Loss: 2.6684\n",
      "Epoch [45/50] - Train Loss: 1.2928, Test Loss: 2.6658\n",
      "Epoch [46/50] - Train Loss: 1.3251, Test Loss: 2.6620\n",
      "Epoch [47/50] - Train Loss: 1.3178, Test Loss: 2.6599\n",
      "Epoch [48/50] - Train Loss: 1.3062, Test Loss: 2.6597\n",
      "Epoch [49/50] - Train Loss: 1.2963, Test Loss: 2.6606\n",
      "Epoch [50/50] - Train Loss: 1.2930, Test Loss: 2.6614\n",
      "Avg Test Loss: 2.6614\n",
      "Testing combination: (16, 4, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1027, Test Loss: 1.4735\n",
      "Epoch [2/50] - Train Loss: 1.1021, Test Loss: 1.4735\n",
      "Epoch [3/50] - Train Loss: 1.1017, Test Loss: 1.4736\n",
      "Epoch [4/50] - Train Loss: 1.1013, Test Loss: 1.4736\n",
      "Epoch [5/50] - Train Loss: 1.1010, Test Loss: 1.4737\n",
      "Epoch [6/50] - Train Loss: 1.1007, Test Loss: 1.4738\n",
      "Epoch [7/50] - Train Loss: 1.1004, Test Loss: 1.4739\n",
      "Epoch [8/50] - Train Loss: 1.1000, Test Loss: 1.4740\n",
      "Epoch [9/50] - Train Loss: 1.0998, Test Loss: 1.4741\n",
      "Epoch [10/50] - Train Loss: 1.0995, Test Loss: 1.4742\n",
      "Epoch [11/50] - Train Loss: 1.0992, Test Loss: 1.4743\n",
      "Epoch [12/50] - Train Loss: 1.0989, Test Loss: 1.4744\n",
      "Epoch [13/50] - Train Loss: 1.0987, Test Loss: 1.4745\n",
      "Epoch [14/50] - Train Loss: 1.0985, Test Loss: 1.4746\n",
      "Epoch [15/50] - Train Loss: 1.0982, Test Loss: 1.4748\n",
      "Epoch [16/50] - Train Loss: 1.0980, Test Loss: 1.4749\n",
      "Epoch [17/50] - Train Loss: 1.0978, Test Loss: 1.4750\n",
      "Epoch [18/50] - Train Loss: 1.0976, Test Loss: 1.4751\n",
      "Epoch [19/50] - Train Loss: 1.0974, Test Loss: 1.4753\n",
      "Epoch [20/50] - Train Loss: 1.0972, Test Loss: 1.4754\n",
      "Epoch [21/50] - Train Loss: 1.0970, Test Loss: 1.4756\n",
      "Epoch [22/50] - Train Loss: 1.0968, Test Loss: 1.4757\n",
      "Epoch [23/50] - Train Loss: 1.0966, Test Loss: 1.4758\n",
      "Epoch [24/50] - Train Loss: 1.0965, Test Loss: 1.4760\n",
      "Epoch [25/50] - Train Loss: 1.0963, Test Loss: 1.4761\n",
      "Epoch [26/50] - Train Loss: 1.0962, Test Loss: 1.4763\n",
      "Epoch [27/50] - Train Loss: 1.0960, Test Loss: 1.4764\n",
      "Epoch [28/50] - Train Loss: 1.0959, Test Loss: 1.4766\n",
      "Epoch [29/50] - Train Loss: 1.0958, Test Loss: 1.4767\n",
      "Epoch [30/50] - Train Loss: 1.0956, Test Loss: 1.4769\n",
      "Epoch [31/50] - Train Loss: 1.0955, Test Loss: 1.4771\n",
      "Epoch [32/50] - Train Loss: 1.0954, Test Loss: 1.4772\n",
      "Epoch [33/50] - Train Loss: 1.0953, Test Loss: 1.4774\n",
      "Epoch [34/50] - Train Loss: 1.0952, Test Loss: 1.4775\n",
      "Epoch [35/50] - Train Loss: 1.0951, Test Loss: 1.4777\n",
      "Epoch [36/50] - Train Loss: 1.0950, Test Loss: 1.4778\n",
      "Epoch [37/50] - Train Loss: 1.0949, Test Loss: 1.4780\n",
      "Epoch [38/50] - Train Loss: 1.0948, Test Loss: 1.4781\n",
      "Epoch [39/50] - Train Loss: 1.0947, Test Loss: 1.4783\n",
      "Epoch [40/50] - Train Loss: 1.0946, Test Loss: 1.4784\n",
      "Epoch [41/50] - Train Loss: 1.0945, Test Loss: 1.4786\n",
      "Epoch [42/50] - Train Loss: 1.0944, Test Loss: 1.4787\n",
      "Epoch [43/50] - Train Loss: 1.0944, Test Loss: 1.4789\n",
      "Epoch [44/50] - Train Loss: 1.0943, Test Loss: 1.4790\n",
      "Epoch [45/50] - Train Loss: 1.0942, Test Loss: 1.4792\n",
      "Epoch [46/50] - Train Loss: 1.0942, Test Loss: 1.4793\n",
      "Epoch [47/50] - Train Loss: 1.0941, Test Loss: 1.4794\n",
      "Epoch [48/50] - Train Loss: 1.0941, Test Loss: 1.4796\n",
      "Epoch [49/50] - Train Loss: 1.0940, Test Loss: 1.4797\n",
      "Epoch [50/50] - Train Loss: 1.0939, Test Loss: 1.4799\n",
      "Avg Test Loss: 1.4799\n",
      "Testing combination: (16, 4, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1606, Test Loss: 1.5750\n",
      "Epoch [2/50] - Train Loss: 1.1585, Test Loss: 1.5747\n",
      "Epoch [3/50] - Train Loss: 1.1565, Test Loss: 1.5744\n",
      "Epoch [4/50] - Train Loss: 1.1546, Test Loss: 1.5741\n",
      "Epoch [5/50] - Train Loss: 1.1528, Test Loss: 1.5739\n",
      "Epoch [6/50] - Train Loss: 1.1511, Test Loss: 1.5738\n",
      "Epoch [7/50] - Train Loss: 1.1494, Test Loss: 1.5737\n",
      "Epoch [8/50] - Train Loss: 1.1478, Test Loss: 1.5736\n",
      "Epoch [9/50] - Train Loss: 1.1463, Test Loss: 1.5736\n",
      "Epoch [10/50] - Train Loss: 1.1448, Test Loss: 1.5736\n",
      "Epoch [11/50] - Train Loss: 1.1434, Test Loss: 1.5737\n",
      "Epoch [12/50] - Train Loss: 1.1420, Test Loss: 1.5738\n",
      "Epoch [13/50] - Train Loss: 1.1406, Test Loss: 1.5739\n",
      "Epoch [14/50] - Train Loss: 1.1393, Test Loss: 1.5741\n",
      "Epoch [15/50] - Train Loss: 1.1381, Test Loss: 1.5743\n",
      "Epoch [16/50] - Train Loss: 1.1369, Test Loss: 1.5746\n",
      "Epoch [17/50] - Train Loss: 1.1357, Test Loss: 1.5749\n",
      "Epoch [18/50] - Train Loss: 1.1345, Test Loss: 1.5752\n",
      "Epoch [19/50] - Train Loss: 1.1334, Test Loss: 1.5756\n",
      "Epoch [20/50] - Train Loss: 1.1323, Test Loss: 1.5760\n",
      "Epoch [21/50] - Train Loss: 1.1313, Test Loss: 1.5764\n",
      "Epoch [22/50] - Train Loss: 1.1303, Test Loss: 1.5769\n",
      "Epoch [23/50] - Train Loss: 1.1293, Test Loss: 1.5774\n",
      "Epoch [24/50] - Train Loss: 1.1284, Test Loss: 1.5779\n",
      "Epoch [25/50] - Train Loss: 1.1274, Test Loss: 1.5785\n",
      "Epoch [26/50] - Train Loss: 1.1266, Test Loss: 1.5791\n",
      "Epoch [27/50] - Train Loss: 1.1257, Test Loss: 1.5797\n",
      "Epoch [28/50] - Train Loss: 1.1249, Test Loss: 1.5804\n",
      "Epoch [29/50] - Train Loss: 1.1242, Test Loss: 1.5811\n",
      "Epoch [30/50] - Train Loss: 1.1234, Test Loss: 1.5818\n",
      "Epoch [31/50] - Train Loss: 1.1227, Test Loss: 1.5826\n",
      "Epoch [32/50] - Train Loss: 1.1221, Test Loss: 1.5833\n",
      "Epoch [33/50] - Train Loss: 1.1214, Test Loss: 1.5841\n",
      "Epoch [34/50] - Train Loss: 1.1208, Test Loss: 1.5849\n",
      "Epoch [35/50] - Train Loss: 1.1203, Test Loss: 1.5858\n",
      "Epoch [36/50] - Train Loss: 1.1197, Test Loss: 1.5866\n",
      "Epoch [37/50] - Train Loss: 1.1192, Test Loss: 1.5875\n",
      "Epoch [38/50] - Train Loss: 1.1188, Test Loss: 1.5883\n",
      "Epoch [39/50] - Train Loss: 1.1183, Test Loss: 1.5892\n",
      "Epoch [40/50] - Train Loss: 1.1179, Test Loss: 1.5901\n",
      "Epoch [41/50] - Train Loss: 1.1175, Test Loss: 1.5909\n",
      "Epoch [42/50] - Train Loss: 1.1172, Test Loss: 1.5918\n",
      "Epoch [43/50] - Train Loss: 1.1169, Test Loss: 1.5927\n",
      "Epoch [44/50] - Train Loss: 1.1166, Test Loss: 1.5935\n",
      "Epoch [45/50] - Train Loss: 1.1163, Test Loss: 1.5943\n",
      "Epoch [46/50] - Train Loss: 1.1161, Test Loss: 1.5951\n",
      "Epoch [47/50] - Train Loss: 1.1159, Test Loss: 1.5959\n",
      "Epoch [48/50] - Train Loss: 1.1157, Test Loss: 1.5967\n",
      "Epoch [49/50] - Train Loss: 1.1155, Test Loss: 1.5975\n",
      "Epoch [50/50] - Train Loss: 1.1153, Test Loss: 1.5982\n",
      "Avg Test Loss: 1.5982\n",
      "Testing combination: (16, 4, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3029, Test Loss: 2.6800\n",
      "Epoch [2/50] - Train Loss: 1.3028, Test Loss: 2.6796\n",
      "Epoch [3/50] - Train Loss: 1.3027, Test Loss: 2.6792\n",
      "Epoch [4/50] - Train Loss: 1.3027, Test Loss: 2.6787\n",
      "Epoch [5/50] - Train Loss: 1.3026, Test Loss: 2.6783\n",
      "Epoch [6/50] - Train Loss: 1.3026, Test Loss: 2.6779\n",
      "Epoch [7/50] - Train Loss: 1.3025, Test Loss: 2.6775\n",
      "Epoch [8/50] - Train Loss: 1.3025, Test Loss: 2.6772\n",
      "Epoch [9/50] - Train Loss: 1.3024, Test Loss: 2.6768\n",
      "Epoch [10/50] - Train Loss: 1.3024, Test Loss: 2.6764\n",
      "Epoch [11/50] - Train Loss: 1.3024, Test Loss: 2.6761\n",
      "Epoch [12/50] - Train Loss: 1.3023, Test Loss: 2.6757\n",
      "Epoch [13/50] - Train Loss: 1.3023, Test Loss: 2.6754\n",
      "Epoch [14/50] - Train Loss: 1.3023, Test Loss: 2.6750\n",
      "Epoch [15/50] - Train Loss: 1.3022, Test Loss: 2.6747\n",
      "Epoch [16/50] - Train Loss: 1.3022, Test Loss: 2.6744\n",
      "Epoch [17/50] - Train Loss: 1.3022, Test Loss: 2.6741\n",
      "Epoch [18/50] - Train Loss: 1.3021, Test Loss: 2.6738\n",
      "Epoch [19/50] - Train Loss: 1.3021, Test Loss: 2.6735\n",
      "Epoch [20/50] - Train Loss: 1.3021, Test Loss: 2.6733\n",
      "Epoch [21/50] - Train Loss: 1.3021, Test Loss: 2.6730\n",
      "Epoch [22/50] - Train Loss: 1.3020, Test Loss: 2.6727\n",
      "Epoch [23/50] - Train Loss: 1.3020, Test Loss: 2.6725\n",
      "Epoch [24/50] - Train Loss: 1.3020, Test Loss: 2.6722\n",
      "Epoch [25/50] - Train Loss: 1.3020, Test Loss: 2.6720\n",
      "Epoch [26/50] - Train Loss: 1.3020, Test Loss: 2.6717\n",
      "Epoch [27/50] - Train Loss: 1.3019, Test Loss: 2.6715\n",
      "Epoch [28/50] - Train Loss: 1.3019, Test Loss: 2.6713\n",
      "Epoch [29/50] - Train Loss: 1.3019, Test Loss: 2.6711\n",
      "Epoch [30/50] - Train Loss: 1.3019, Test Loss: 2.6708\n",
      "Epoch [31/50] - Train Loss: 1.3019, Test Loss: 2.6706\n",
      "Epoch [32/50] - Train Loss: 1.3019, Test Loss: 2.6704\n",
      "Epoch [33/50] - Train Loss: 1.3018, Test Loss: 2.6702\n",
      "Epoch [34/50] - Train Loss: 1.3018, Test Loss: 2.6700\n",
      "Epoch [35/50] - Train Loss: 1.3018, Test Loss: 2.6699\n",
      "Epoch [36/50] - Train Loss: 1.3018, Test Loss: 2.6697\n",
      "Epoch [37/50] - Train Loss: 1.3018, Test Loss: 2.6695\n",
      "Epoch [38/50] - Train Loss: 1.3018, Test Loss: 2.6693\n",
      "Epoch [39/50] - Train Loss: 1.3018, Test Loss: 2.6692\n",
      "Epoch [40/50] - Train Loss: 1.3018, Test Loss: 2.6690\n",
      "Epoch [41/50] - Train Loss: 1.3017, Test Loss: 2.6688\n",
      "Epoch [42/50] - Train Loss: 1.3017, Test Loss: 2.6687\n",
      "Epoch [43/50] - Train Loss: 1.3017, Test Loss: 2.6685\n",
      "Epoch [44/50] - Train Loss: 1.3017, Test Loss: 2.6684\n",
      "Epoch [45/50] - Train Loss: 1.3017, Test Loss: 2.6682\n",
      "Epoch [46/50] - Train Loss: 1.3017, Test Loss: 2.6681\n",
      "Epoch [47/50] - Train Loss: 1.3017, Test Loss: 2.6680\n",
      "Epoch [48/50] - Train Loss: 1.3017, Test Loss: 2.6678\n",
      "Epoch [49/50] - Train Loss: 1.3017, Test Loss: 2.6677\n",
      "Epoch [50/50] - Train Loss: 1.3017, Test Loss: 2.6676\n",
      "Avg Test Loss: 2.6676\n",
      "Testing combination: (32, 1, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1263, Test Loss: 1.4878\n",
      "Epoch [2/50] - Train Loss: 1.0860, Test Loss: 1.4801\n",
      "Epoch [3/50] - Train Loss: 1.0880, Test Loss: 1.4801\n",
      "Epoch [4/50] - Train Loss: 1.0843, Test Loss: 1.4814\n",
      "Epoch [5/50] - Train Loss: 1.0828, Test Loss: 1.4822\n",
      "Epoch [6/50] - Train Loss: 1.0798, Test Loss: 1.4832\n",
      "Epoch [7/50] - Train Loss: 1.0742, Test Loss: 1.4853\n",
      "Epoch [8/50] - Train Loss: 1.0621, Test Loss: 1.4879\n",
      "Epoch [9/50] - Train Loss: 1.0593, Test Loss: 1.4879\n",
      "Epoch [10/50] - Train Loss: 1.0833, Test Loss: 1.4840\n",
      "Epoch [11/50] - Train Loss: 1.0596, Test Loss: 1.4837\n",
      "Epoch [12/50] - Train Loss: 1.0556, Test Loss: 1.4863\n",
      "Epoch [13/50] - Train Loss: 1.0549, Test Loss: 1.4871\n",
      "Epoch [14/50] - Train Loss: 1.0538, Test Loss: 1.4863\n",
      "Epoch [15/50] - Train Loss: 1.0534, Test Loss: 1.4859\n",
      "Epoch [16/50] - Train Loss: 1.0533, Test Loss: 1.4861\n",
      "Epoch [17/50] - Train Loss: 1.0532, Test Loss: 1.4863\n",
      "Epoch [18/50] - Train Loss: 1.0531, Test Loss: 1.4863\n",
      "Epoch [19/50] - Train Loss: 1.0529, Test Loss: 1.4863\n",
      "Epoch [20/50] - Train Loss: 1.0528, Test Loss: 1.4863\n",
      "Epoch [21/50] - Train Loss: 1.0527, Test Loss: 1.4863\n",
      "Epoch [22/50] - Train Loss: 1.0526, Test Loss: 1.4863\n",
      "Epoch [23/50] - Train Loss: 1.0525, Test Loss: 1.4862\n",
      "Epoch [24/50] - Train Loss: 1.0523, Test Loss: 1.4861\n",
      "Epoch [25/50] - Train Loss: 1.0520, Test Loss: 1.4859\n",
      "Epoch [26/50] - Train Loss: 1.0515, Test Loss: 1.4855\n",
      "Epoch [27/50] - Train Loss: 1.0501, Test Loss: 1.4832\n",
      "Epoch [28/50] - Train Loss: 1.0511, Test Loss: 1.4882\n",
      "Epoch [29/50] - Train Loss: 1.0481, Test Loss: 1.4919\n",
      "Epoch [30/50] - Train Loss: 1.0742, Test Loss: 1.4888\n",
      "Epoch [31/50] - Train Loss: 1.0552, Test Loss: 1.4865\n",
      "Epoch [32/50] - Train Loss: 1.0533, Test Loss: 1.4859\n",
      "Epoch [33/50] - Train Loss: 1.0531, Test Loss: 1.4860\n",
      "Epoch [34/50] - Train Loss: 1.0530, Test Loss: 1.4862\n",
      "Epoch [35/50] - Train Loss: 1.0528, Test Loss: 1.4864\n",
      "Epoch [36/50] - Train Loss: 1.0527, Test Loss: 1.4866\n",
      "Epoch [37/50] - Train Loss: 1.0525, Test Loss: 1.4866\n",
      "Epoch [38/50] - Train Loss: 1.0524, Test Loss: 1.4866\n",
      "Epoch [39/50] - Train Loss: 1.0523, Test Loss: 1.4865\n",
      "Epoch [40/50] - Train Loss: 1.0522, Test Loss: 1.4865\n",
      "Epoch [41/50] - Train Loss: 1.0521, Test Loss: 1.4864\n",
      "Epoch [42/50] - Train Loss: 1.0520, Test Loss: 1.4863\n",
      "Epoch [43/50] - Train Loss: 1.0519, Test Loss: 1.4861\n",
      "Epoch [44/50] - Train Loss: 1.0517, Test Loss: 1.4858\n",
      "Epoch [45/50] - Train Loss: 1.0516, Test Loss: 1.4855\n",
      "Epoch [46/50] - Train Loss: 1.0512, Test Loss: 1.4855\n",
      "Epoch [47/50] - Train Loss: 1.0486, Test Loss: 1.4980\n",
      "Epoch [48/50] - Train Loss: 1.0568, Test Loss: 1.4866\n",
      "Epoch [49/50] - Train Loss: 1.0511, Test Loss: 1.4869\n",
      "Epoch [50/50] - Train Loss: 1.0506, Test Loss: 1.4714\n",
      "Avg Test Loss: 1.4714\n",
      "Testing combination: (32, 1, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1365, Test Loss: 1.6065\n",
      "Epoch [2/50] - Train Loss: 1.1112, Test Loss: 1.5970\n",
      "Epoch [3/50] - Train Loss: 1.1098, Test Loss: 1.6017\n",
      "Epoch [4/50] - Train Loss: 1.1087, Test Loss: 1.6043\n",
      "Epoch [5/50] - Train Loss: 1.1066, Test Loss: 1.6039\n",
      "Epoch [6/50] - Train Loss: 1.1027, Test Loss: 1.6066\n",
      "Epoch [7/50] - Train Loss: 1.0932, Test Loss: 1.6133\n",
      "Epoch [8/50] - Train Loss: 1.0820, Test Loss: 1.6141\n",
      "Epoch [9/50] - Train Loss: 1.0815, Test Loss: 1.6098\n",
      "Epoch [10/50] - Train Loss: 1.0940, Test Loss: 1.6120\n",
      "Epoch [11/50] - Train Loss: 1.0805, Test Loss: 1.6150\n",
      "Epoch [12/50] - Train Loss: 1.0892, Test Loss: 1.6097\n",
      "Epoch [13/50] - Train Loss: 1.0803, Test Loss: 1.6119\n",
      "Epoch [14/50] - Train Loss: 1.0788, Test Loss: 1.6160\n",
      "Epoch [15/50] - Train Loss: 1.0784, Test Loss: 1.6138\n",
      "Epoch [16/50] - Train Loss: 1.0775, Test Loss: 1.6114\n",
      "Epoch [17/50] - Train Loss: 1.0774, Test Loss: 1.6164\n",
      "Epoch [18/50] - Train Loss: 1.0758, Test Loss: 1.6180\n",
      "Epoch [19/50] - Train Loss: 1.0778, Test Loss: 1.6161\n",
      "Epoch [20/50] - Train Loss: 1.0778, Test Loss: 1.6110\n",
      "Epoch [21/50] - Train Loss: 1.0783, Test Loss: 1.6113\n",
      "Epoch [22/50] - Train Loss: 1.0785, Test Loss: 1.6130\n",
      "Epoch [23/50] - Train Loss: 1.0784, Test Loss: 1.6137\n",
      "Epoch [24/50] - Train Loss: 1.0783, Test Loss: 1.6137\n",
      "Epoch [25/50] - Train Loss: 1.0782, Test Loss: 1.6134\n",
      "Epoch [26/50] - Train Loss: 1.0782, Test Loss: 1.6132\n",
      "Epoch [27/50] - Train Loss: 1.0781, Test Loss: 1.6132\n",
      "Epoch [28/50] - Train Loss: 1.0780, Test Loss: 1.6133\n",
      "Epoch [29/50] - Train Loss: 1.0778, Test Loss: 1.6135\n",
      "Epoch [30/50] - Train Loss: 1.0776, Test Loss: 1.6135\n",
      "Epoch [31/50] - Train Loss: 1.0771, Test Loss: 1.6136\n",
      "Epoch [32/50] - Train Loss: 1.0762, Test Loss: 1.6139\n",
      "Epoch [33/50] - Train Loss: 1.0744, Test Loss: 1.6159\n",
      "Epoch [34/50] - Train Loss: 1.0877, Test Loss: 1.6196\n",
      "Epoch [35/50] - Train Loss: 1.0791, Test Loss: 1.6145\n",
      "Epoch [36/50] - Train Loss: 1.0800, Test Loss: 1.6123\n",
      "Epoch [37/50] - Train Loss: 1.0785, Test Loss: 1.6131\n",
      "Epoch [38/50] - Train Loss: 1.0785, Test Loss: 1.6131\n",
      "Epoch [39/50] - Train Loss: 1.0784, Test Loss: 1.6136\n",
      "Epoch [40/50] - Train Loss: 1.0783, Test Loss: 1.6141\n",
      "Epoch [41/50] - Train Loss: 1.0783, Test Loss: 1.6138\n",
      "Epoch [42/50] - Train Loss: 1.0782, Test Loss: 1.6133\n",
      "Epoch [43/50] - Train Loss: 1.0782, Test Loss: 1.6133\n",
      "Epoch [44/50] - Train Loss: 1.0782, Test Loss: 1.6136\n",
      "Epoch [45/50] - Train Loss: 1.0782, Test Loss: 1.6137\n",
      "Epoch [46/50] - Train Loss: 1.0782, Test Loss: 1.6137\n",
      "Epoch [47/50] - Train Loss: 1.0782, Test Loss: 1.6137\n",
      "Epoch [48/50] - Train Loss: 1.0781, Test Loss: 1.6137\n",
      "Epoch [49/50] - Train Loss: 1.0781, Test Loss: 1.6137\n",
      "Epoch [50/50] - Train Loss: 1.0781, Test Loss: 1.6138\n",
      "Avg Test Loss: 1.6138\n",
      "Testing combination: (32, 1, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3163, Test Loss: 2.6477\n",
      "Epoch [2/50] - Train Loss: 1.2935, Test Loss: 2.6716\n",
      "Epoch [3/50] - Train Loss: 1.2907, Test Loss: 2.6835\n",
      "Epoch [4/50] - Train Loss: 1.2898, Test Loss: 2.6846\n",
      "Epoch [5/50] - Train Loss: 1.2884, Test Loss: 2.6790\n",
      "Epoch [6/50] - Train Loss: 1.2861, Test Loss: 2.6702\n",
      "Epoch [7/50] - Train Loss: 1.2819, Test Loss: 2.6605\n",
      "Epoch [8/50] - Train Loss: 1.2745, Test Loss: 2.6520\n",
      "Epoch [9/50] - Train Loss: 1.2637, Test Loss: 2.6472\n",
      "Epoch [10/50] - Train Loss: 1.2605, Test Loss: 2.6575\n",
      "Epoch [11/50] - Train Loss: 1.2537, Test Loss: 2.6593\n",
      "Epoch [12/50] - Train Loss: 1.2531, Test Loss: 2.6535\n",
      "Epoch [13/50] - Train Loss: 1.2531, Test Loss: 2.6532\n",
      "Epoch [14/50] - Train Loss: 1.2524, Test Loss: 2.6544\n",
      "Epoch [15/50] - Train Loss: 1.2521, Test Loss: 2.6542\n",
      "Epoch [16/50] - Train Loss: 1.2515, Test Loss: 2.6522\n",
      "Epoch [17/50] - Train Loss: 1.2511, Test Loss: 2.6491\n",
      "Epoch [18/50] - Train Loss: 1.2497, Test Loss: 2.6470\n",
      "Epoch [19/50] - Train Loss: 1.2486, Test Loss: 2.6462\n",
      "Epoch [20/50] - Train Loss: 1.2479, Test Loss: 2.6432\n",
      "Epoch [21/50] - Train Loss: 1.2460, Test Loss: 2.6392\n",
      "Epoch [22/50] - Train Loss: 1.2494, Test Loss: 2.6394\n",
      "Epoch [23/50] - Train Loss: 1.2955, Test Loss: 2.6548\n",
      "Epoch [24/50] - Train Loss: 1.2537, Test Loss: 2.6653\n",
      "Epoch [25/50] - Train Loss: 1.2631, Test Loss: 2.6639\n",
      "Epoch [26/50] - Train Loss: 1.2535, Test Loss: 2.6551\n",
      "Epoch [27/50] - Train Loss: 1.2509, Test Loss: 2.6446\n",
      "Epoch [28/50] - Train Loss: 1.2488, Test Loss: 2.6375\n",
      "Epoch [29/50] - Train Loss: 1.2498, Test Loss: 2.6405\n",
      "Epoch [30/50] - Train Loss: 1.2464, Test Loss: 2.6407\n",
      "Epoch [31/50] - Train Loss: 1.2454, Test Loss: 2.6398\n",
      "Epoch [32/50] - Train Loss: 1.2447, Test Loss: 2.6314\n",
      "Epoch [33/50] - Train Loss: 1.2465, Test Loss: 2.6371\n",
      "Epoch [34/50] - Train Loss: 1.2363, Test Loss: 2.6465\n",
      "Epoch [35/50] - Train Loss: 1.2650, Test Loss: 2.6557\n",
      "Epoch [36/50] - Train Loss: 1.2593, Test Loss: 2.6718\n",
      "Epoch [37/50] - Train Loss: 1.2386, Test Loss: 2.6404\n",
      "Epoch [38/50] - Train Loss: 1.3054, Test Loss: 2.6398\n",
      "Epoch [39/50] - Train Loss: 1.2966, Test Loss: 2.6638\n",
      "Epoch [40/50] - Train Loss: 1.2885, Test Loss: 2.6988\n",
      "Epoch [41/50] - Train Loss: 1.2880, Test Loss: 2.7084\n",
      "Epoch [42/50] - Train Loss: 1.2854, Test Loss: 2.6883\n",
      "Epoch [43/50] - Train Loss: 1.2815, Test Loss: 2.6666\n",
      "Epoch [44/50] - Train Loss: 1.2790, Test Loss: 2.6590\n",
      "Epoch [45/50] - Train Loss: 1.2754, Test Loss: 2.6642\n",
      "Epoch [46/50] - Train Loss: 1.2702, Test Loss: 2.6734\n",
      "Epoch [47/50] - Train Loss: 1.2653, Test Loss: 2.6728\n",
      "Epoch [48/50] - Train Loss: 1.2607, Test Loss: 2.6619\n",
      "Epoch [49/50] - Train Loss: 1.2575, Test Loss: 2.6554\n",
      "Epoch [50/50] - Train Loss: 1.2560, Test Loss: 2.6580\n",
      "Avg Test Loss: 2.6580\n",
      "Testing combination: (32, 1, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1057, Test Loss: 1.5123\n",
      "Epoch [2/50] - Train Loss: 1.0981, Test Loss: 1.5035\n",
      "Epoch [3/50] - Train Loss: 1.0937, Test Loss: 1.4970\n",
      "Epoch [4/50] - Train Loss: 1.0905, Test Loss: 1.4924\n",
      "Epoch [5/50] - Train Loss: 1.0881, Test Loss: 1.4892\n",
      "Epoch [6/50] - Train Loss: 1.0859, Test Loss: 1.4870\n",
      "Epoch [7/50] - Train Loss: 1.0843, Test Loss: 1.4855\n",
      "Epoch [8/50] - Train Loss: 1.0835, Test Loss: 1.4843\n",
      "Epoch [9/50] - Train Loss: 1.0832, Test Loss: 1.4835\n",
      "Epoch [10/50] - Train Loss: 1.0832, Test Loss: 1.4829\n",
      "Epoch [11/50] - Train Loss: 1.0830, Test Loss: 1.4825\n",
      "Epoch [12/50] - Train Loss: 1.0829, Test Loss: 1.4823\n",
      "Epoch [13/50] - Train Loss: 1.0828, Test Loss: 1.4822\n",
      "Epoch [14/50] - Train Loss: 1.0827, Test Loss: 1.4822\n",
      "Epoch [15/50] - Train Loss: 1.0825, Test Loss: 1.4821\n",
      "Epoch [16/50] - Train Loss: 1.0824, Test Loss: 1.4821\n",
      "Epoch [17/50] - Train Loss: 1.0821, Test Loss: 1.4821\n",
      "Epoch [18/50] - Train Loss: 1.0818, Test Loss: 1.4820\n",
      "Epoch [19/50] - Train Loss: 1.0814, Test Loss: 1.4821\n",
      "Epoch [20/50] - Train Loss: 1.0806, Test Loss: 1.4820\n",
      "Epoch [21/50] - Train Loss: 1.0792, Test Loss: 1.4819\n",
      "Epoch [22/50] - Train Loss: 1.0766, Test Loss: 1.4817\n",
      "Epoch [23/50] - Train Loss: 1.0725, Test Loss: 1.4817\n",
      "Epoch [24/50] - Train Loss: 1.0679, Test Loss: 1.4819\n",
      "Epoch [25/50] - Train Loss: 1.0640, Test Loss: 1.4826\n",
      "Epoch [26/50] - Train Loss: 1.0610, Test Loss: 1.4835\n",
      "Epoch [27/50] - Train Loss: 1.0585, Test Loss: 1.4846\n",
      "Epoch [28/50] - Train Loss: 1.0565, Test Loss: 1.4855\n",
      "Epoch [29/50] - Train Loss: 1.0550, Test Loss: 1.4862\n",
      "Epoch [30/50] - Train Loss: 1.0540, Test Loss: 1.4867\n",
      "Epoch [31/50] - Train Loss: 1.0549, Test Loss: 1.4871\n",
      "Epoch [32/50] - Train Loss: 1.0558, Test Loss: 1.4876\n",
      "Epoch [33/50] - Train Loss: 1.0528, Test Loss: 1.4875\n",
      "Epoch [34/50] - Train Loss: 1.0528, Test Loss: 1.4874\n",
      "Epoch [35/50] - Train Loss: 1.0524, Test Loss: 1.4874\n",
      "Epoch [36/50] - Train Loss: 1.0523, Test Loss: 1.4874\n",
      "Epoch [37/50] - Train Loss: 1.0523, Test Loss: 1.4874\n",
      "Epoch [38/50] - Train Loss: 1.0522, Test Loss: 1.4874\n",
      "Epoch [39/50] - Train Loss: 1.0521, Test Loss: 1.4874\n",
      "Epoch [40/50] - Train Loss: 1.0521, Test Loss: 1.4873\n",
      "Epoch [41/50] - Train Loss: 1.0521, Test Loss: 1.4873\n",
      "Epoch [42/50] - Train Loss: 1.0520, Test Loss: 1.4873\n",
      "Epoch [43/50] - Train Loss: 1.0520, Test Loss: 1.4872\n",
      "Epoch [44/50] - Train Loss: 1.0520, Test Loss: 1.4872\n",
      "Epoch [45/50] - Train Loss: 1.0520, Test Loss: 1.4873\n",
      "Epoch [46/50] - Train Loss: 1.0519, Test Loss: 1.4873\n",
      "Epoch [47/50] - Train Loss: 1.0519, Test Loss: 1.4873\n",
      "Epoch [48/50] - Train Loss: 1.0518, Test Loss: 1.4873\n",
      "Epoch [49/50] - Train Loss: 1.0518, Test Loss: 1.4873\n",
      "Epoch [50/50] - Train Loss: 1.0517, Test Loss: 1.4872\n",
      "Avg Test Loss: 1.4872\n",
      "Testing combination: (32, 1, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1245, Test Loss: 1.5849\n",
      "Epoch [2/50] - Train Loss: 1.1172, Test Loss: 1.5915\n",
      "Epoch [3/50] - Train Loss: 1.1132, Test Loss: 1.5978\n",
      "Epoch [4/50] - Train Loss: 1.1108, Test Loss: 1.6031\n",
      "Epoch [5/50] - Train Loss: 1.1094, Test Loss: 1.6068\n",
      "Epoch [6/50] - Train Loss: 1.1085, Test Loss: 1.6085\n",
      "Epoch [7/50] - Train Loss: 1.1080, Test Loss: 1.6086\n",
      "Epoch [8/50] - Train Loss: 1.1077, Test Loss: 1.6078\n",
      "Epoch [9/50] - Train Loss: 1.1073, Test Loss: 1.6067\n",
      "Epoch [10/50] - Train Loss: 1.1070, Test Loss: 1.6059\n",
      "Epoch [11/50] - Train Loss: 1.1067, Test Loss: 1.6054\n",
      "Epoch [12/50] - Train Loss: 1.1062, Test Loss: 1.6054\n",
      "Epoch [13/50] - Train Loss: 1.1055, Test Loss: 1.6057\n",
      "Epoch [14/50] - Train Loss: 1.1044, Test Loss: 1.6063\n",
      "Epoch [15/50] - Train Loss: 1.1026, Test Loss: 1.6073\n",
      "Epoch [16/50] - Train Loss: 1.1000, Test Loss: 1.6088\n",
      "Epoch [17/50] - Train Loss: 1.0966, Test Loss: 1.6109\n",
      "Epoch [18/50] - Train Loss: 1.0929, Test Loss: 1.6135\n",
      "Epoch [19/50] - Train Loss: 1.0892, Test Loss: 1.6160\n",
      "Epoch [20/50] - Train Loss: 1.0855, Test Loss: 1.6177\n",
      "Epoch [21/50] - Train Loss: 1.0826, Test Loss: 1.6184\n",
      "Epoch [22/50] - Train Loss: 1.0826, Test Loss: 1.6183\n",
      "Epoch [23/50] - Train Loss: 1.0788, Test Loss: 1.6189\n",
      "Epoch [24/50] - Train Loss: 1.0777, Test Loss: 1.6210\n",
      "Epoch [25/50] - Train Loss: 1.0766, Test Loss: 1.6220\n",
      "Epoch [26/50] - Train Loss: 1.0757, Test Loss: 1.6212\n",
      "Epoch [27/50] - Train Loss: 1.0750, Test Loss: 1.6203\n",
      "Epoch [28/50] - Train Loss: 1.0744, Test Loss: 1.6199\n",
      "Epoch [29/50] - Train Loss: 1.0739, Test Loss: 1.6201\n",
      "Epoch [30/50] - Train Loss: 1.0734, Test Loss: 1.6204\n",
      "Epoch [31/50] - Train Loss: 1.0727, Test Loss: 1.6204\n",
      "Epoch [32/50] - Train Loss: 1.0718, Test Loss: 1.6202\n",
      "Epoch [33/50] - Train Loss: 1.0708, Test Loss: 1.6200\n",
      "Epoch [34/50] - Train Loss: 1.0696, Test Loss: 1.6182\n",
      "Epoch [35/50] - Train Loss: 1.0678, Test Loss: 1.6162\n",
      "Epoch [36/50] - Train Loss: 1.0654, Test Loss: 1.6145\n",
      "Epoch [37/50] - Train Loss: 1.0626, Test Loss: 1.6130\n",
      "Epoch [38/50] - Train Loss: 1.0593, Test Loss: 1.6167\n",
      "Epoch [39/50] - Train Loss: 1.0758, Test Loss: 1.6378\n",
      "Epoch [40/50] - Train Loss: 1.0923, Test Loss: 1.6343\n",
      "Epoch [41/50] - Train Loss: 1.0767, Test Loss: 1.6270\n",
      "Epoch [42/50] - Train Loss: 1.0775, Test Loss: 1.6213\n",
      "Epoch [43/50] - Train Loss: 1.0748, Test Loss: 1.6178\n",
      "Epoch [44/50] - Train Loss: 1.0733, Test Loss: 1.6160\n",
      "Epoch [45/50] - Train Loss: 1.0719, Test Loss: 1.6156\n",
      "Epoch [46/50] - Train Loss: 1.0700, Test Loss: 1.6158\n",
      "Epoch [47/50] - Train Loss: 1.0680, Test Loss: 1.6161\n",
      "Epoch [48/50] - Train Loss: 1.0659, Test Loss: 1.6159\n",
      "Epoch [49/50] - Train Loss: 1.0636, Test Loss: 1.6145\n",
      "Epoch [50/50] - Train Loss: 1.0613, Test Loss: 1.6128\n",
      "Avg Test Loss: 1.6128\n",
      "Testing combination: (32, 1, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3153, Test Loss: 2.7196\n",
      "Epoch [2/50] - Train Loss: 1.3061, Test Loss: 2.6984\n",
      "Epoch [3/50] - Train Loss: 1.3004, Test Loss: 2.6827\n",
      "Epoch [4/50] - Train Loss: 1.2968, Test Loss: 2.6716\n",
      "Epoch [5/50] - Train Loss: 1.2946, Test Loss: 2.6644\n",
      "Epoch [6/50] - Train Loss: 1.2930, Test Loss: 2.6602\n",
      "Epoch [7/50] - Train Loss: 1.2917, Test Loss: 2.6585\n",
      "Epoch [8/50] - Train Loss: 1.2907, Test Loss: 2.6586\n",
      "Epoch [9/50] - Train Loss: 1.2900, Test Loss: 2.6602\n",
      "Epoch [10/50] - Train Loss: 1.2896, Test Loss: 2.6628\n",
      "Epoch [11/50] - Train Loss: 1.2894, Test Loss: 2.6659\n",
      "Epoch [12/50] - Train Loss: 1.2891, Test Loss: 2.6690\n",
      "Epoch [13/50] - Train Loss: 1.2888, Test Loss: 2.6715\n",
      "Epoch [14/50] - Train Loss: 1.2886, Test Loss: 2.6732\n",
      "Epoch [15/50] - Train Loss: 1.2885, Test Loss: 2.6740\n",
      "Epoch [16/50] - Train Loss: 1.2883, Test Loss: 2.6741\n",
      "Epoch [17/50] - Train Loss: 1.2881, Test Loss: 2.6737\n",
      "Epoch [18/50] - Train Loss: 1.2879, Test Loss: 2.6730\n",
      "Epoch [19/50] - Train Loss: 1.2877, Test Loss: 2.6722\n",
      "Epoch [20/50] - Train Loss: 1.2874, Test Loss: 2.6715\n",
      "Epoch [21/50] - Train Loss: 1.2871, Test Loss: 2.6708\n",
      "Epoch [22/50] - Train Loss: 1.2867, Test Loss: 2.6702\n",
      "Epoch [23/50] - Train Loss: 1.2863, Test Loss: 2.6695\n",
      "Epoch [24/50] - Train Loss: 1.2857, Test Loss: 2.6689\n",
      "Epoch [25/50] - Train Loss: 1.2851, Test Loss: 2.6682\n",
      "Epoch [26/50] - Train Loss: 1.2843, Test Loss: 2.6675\n",
      "Epoch [27/50] - Train Loss: 1.2834, Test Loss: 2.6667\n",
      "Epoch [28/50] - Train Loss: 1.2824, Test Loss: 2.6658\n",
      "Epoch [29/50] - Train Loss: 1.2812, Test Loss: 2.6648\n",
      "Epoch [30/50] - Train Loss: 1.2798, Test Loss: 2.6636\n",
      "Epoch [31/50] - Train Loss: 1.2782, Test Loss: 2.6624\n",
      "Epoch [32/50] - Train Loss: 1.2763, Test Loss: 2.6611\n",
      "Epoch [33/50] - Train Loss: 1.2742, Test Loss: 2.6600\n",
      "Epoch [34/50] - Train Loss: 1.2717, Test Loss: 2.6590\n",
      "Epoch [35/50] - Train Loss: 1.2691, Test Loss: 2.6583\n",
      "Epoch [36/50] - Train Loss: 1.2662, Test Loss: 2.6579\n",
      "Epoch [37/50] - Train Loss: 1.2632, Test Loss: 2.6576\n",
      "Epoch [38/50] - Train Loss: 1.2604, Test Loss: 2.6576\n",
      "Epoch [39/50] - Train Loss: 1.2579, Test Loss: 2.6578\n",
      "Epoch [40/50] - Train Loss: 1.2561, Test Loss: 2.6581\n",
      "Epoch [41/50] - Train Loss: 1.2548, Test Loss: 2.6584\n",
      "Epoch [42/50] - Train Loss: 1.2541, Test Loss: 2.6586\n",
      "Epoch [43/50] - Train Loss: 1.2537, Test Loss: 2.6586\n",
      "Epoch [44/50] - Train Loss: 1.2535, Test Loss: 2.6584\n",
      "Epoch [45/50] - Train Loss: 1.2533, Test Loss: 2.6582\n",
      "Epoch [46/50] - Train Loss: 1.2532, Test Loss: 2.6578\n",
      "Epoch [47/50] - Train Loss: 1.2531, Test Loss: 2.6575\n",
      "Epoch [48/50] - Train Loss: 1.2532, Test Loss: 2.6570\n",
      "Epoch [49/50] - Train Loss: 1.2537, Test Loss: 2.6560\n",
      "Epoch [50/50] - Train Loss: 1.2535, Test Loss: 2.6554\n",
      "Avg Test Loss: 2.6554\n",
      "Testing combination: (32, 1, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1041, Test Loss: 1.4734\n",
      "Epoch [2/50] - Train Loss: 1.1025, Test Loss: 1.4734\n",
      "Epoch [3/50] - Train Loss: 1.1013, Test Loss: 1.4733\n",
      "Epoch [4/50] - Train Loss: 1.1002, Test Loss: 1.4734\n",
      "Epoch [5/50] - Train Loss: 1.0992, Test Loss: 1.4734\n",
      "Epoch [6/50] - Train Loss: 1.0982, Test Loss: 1.4735\n",
      "Epoch [7/50] - Train Loss: 1.0973, Test Loss: 1.4736\n",
      "Epoch [8/50] - Train Loss: 1.0964, Test Loss: 1.4737\n",
      "Epoch [9/50] - Train Loss: 1.0956, Test Loss: 1.4739\n",
      "Epoch [10/50] - Train Loss: 1.0947, Test Loss: 1.4740\n",
      "Epoch [11/50] - Train Loss: 1.0939, Test Loss: 1.4742\n",
      "Epoch [12/50] - Train Loss: 1.0932, Test Loss: 1.4744\n",
      "Epoch [13/50] - Train Loss: 1.0925, Test Loss: 1.4746\n",
      "Epoch [14/50] - Train Loss: 1.0918, Test Loss: 1.4748\n",
      "Epoch [15/50] - Train Loss: 1.0911, Test Loss: 1.4750\n",
      "Epoch [16/50] - Train Loss: 1.0905, Test Loss: 1.4753\n",
      "Epoch [17/50] - Train Loss: 1.0899, Test Loss: 1.4755\n",
      "Epoch [18/50] - Train Loss: 1.0893, Test Loss: 1.4758\n",
      "Epoch [19/50] - Train Loss: 1.0887, Test Loss: 1.4760\n",
      "Epoch [20/50] - Train Loss: 1.0882, Test Loss: 1.4763\n",
      "Epoch [21/50] - Train Loss: 1.0877, Test Loss: 1.4765\n",
      "Epoch [22/50] - Train Loss: 1.0873, Test Loss: 1.4768\n",
      "Epoch [23/50] - Train Loss: 1.0868, Test Loss: 1.4771\n",
      "Epoch [24/50] - Train Loss: 1.0864, Test Loss: 1.4773\n",
      "Epoch [25/50] - Train Loss: 1.0861, Test Loss: 1.4776\n",
      "Epoch [26/50] - Train Loss: 1.0857, Test Loss: 1.4778\n",
      "Epoch [27/50] - Train Loss: 1.0854, Test Loss: 1.4780\n",
      "Epoch [28/50] - Train Loss: 1.0851, Test Loss: 1.4783\n",
      "Epoch [29/50] - Train Loss: 1.0848, Test Loss: 1.4785\n",
      "Epoch [30/50] - Train Loss: 1.0846, Test Loss: 1.4787\n",
      "Epoch [31/50] - Train Loss: 1.0843, Test Loss: 1.4789\n",
      "Epoch [32/50] - Train Loss: 1.0841, Test Loss: 1.4791\n",
      "Epoch [33/50] - Train Loss: 1.0839, Test Loss: 1.4793\n",
      "Epoch [34/50] - Train Loss: 1.0838, Test Loss: 1.4795\n",
      "Epoch [35/50] - Train Loss: 1.0836, Test Loss: 1.4797\n",
      "Epoch [36/50] - Train Loss: 1.0835, Test Loss: 1.4798\n",
      "Epoch [37/50] - Train Loss: 1.0833, Test Loss: 1.4800\n",
      "Epoch [38/50] - Train Loss: 1.0832, Test Loss: 1.4801\n",
      "Epoch [39/50] - Train Loss: 1.0831, Test Loss: 1.4803\n",
      "Epoch [40/50] - Train Loss: 1.0830, Test Loss: 1.4804\n",
      "Epoch [41/50] - Train Loss: 1.0829, Test Loss: 1.4805\n",
      "Epoch [42/50] - Train Loss: 1.0829, Test Loss: 1.4806\n",
      "Epoch [43/50] - Train Loss: 1.0828, Test Loss: 1.4807\n",
      "Epoch [44/50] - Train Loss: 1.0828, Test Loss: 1.4808\n",
      "Epoch [45/50] - Train Loss: 1.0827, Test Loss: 1.4809\n",
      "Epoch [46/50] - Train Loss: 1.0827, Test Loss: 1.4810\n",
      "Epoch [47/50] - Train Loss: 1.0826, Test Loss: 1.4811\n",
      "Epoch [48/50] - Train Loss: 1.0826, Test Loss: 1.4811\n",
      "Epoch [49/50] - Train Loss: 1.0825, Test Loss: 1.4812\n",
      "Epoch [50/50] - Train Loss: 1.0825, Test Loss: 1.4812\n",
      "Avg Test Loss: 1.4812\n",
      "Testing combination: (32, 1, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1238, Test Loss: 1.5818\n",
      "Epoch [2/50] - Train Loss: 1.1228, Test Loss: 1.5826\n",
      "Epoch [3/50] - Train Loss: 1.1219, Test Loss: 1.5833\n",
      "Epoch [4/50] - Train Loss: 1.1211, Test Loss: 1.5840\n",
      "Epoch [5/50] - Train Loss: 1.1203, Test Loss: 1.5848\n",
      "Epoch [6/50] - Train Loss: 1.1196, Test Loss: 1.5855\n",
      "Epoch [7/50] - Train Loss: 1.1189, Test Loss: 1.5863\n",
      "Epoch [8/50] - Train Loss: 1.1183, Test Loss: 1.5870\n",
      "Epoch [9/50] - Train Loss: 1.1177, Test Loss: 1.5878\n",
      "Epoch [10/50] - Train Loss: 1.1171, Test Loss: 1.5885\n",
      "Epoch [11/50] - Train Loss: 1.1166, Test Loss: 1.5893\n",
      "Epoch [12/50] - Train Loss: 1.1161, Test Loss: 1.5900\n",
      "Epoch [13/50] - Train Loss: 1.1156, Test Loss: 1.5907\n",
      "Epoch [14/50] - Train Loss: 1.1151, Test Loss: 1.5914\n",
      "Epoch [15/50] - Train Loss: 1.1147, Test Loss: 1.5922\n",
      "Epoch [16/50] - Train Loss: 1.1143, Test Loss: 1.5929\n",
      "Epoch [17/50] - Train Loss: 1.1139, Test Loss: 1.5935\n",
      "Epoch [18/50] - Train Loss: 1.1135, Test Loss: 1.5942\n",
      "Epoch [19/50] - Train Loss: 1.1132, Test Loss: 1.5949\n",
      "Epoch [20/50] - Train Loss: 1.1128, Test Loss: 1.5955\n",
      "Epoch [21/50] - Train Loss: 1.1125, Test Loss: 1.5961\n",
      "Epoch [22/50] - Train Loss: 1.1122, Test Loss: 1.5967\n",
      "Epoch [23/50] - Train Loss: 1.1119, Test Loss: 1.5973\n",
      "Epoch [24/50] - Train Loss: 1.1116, Test Loss: 1.5979\n",
      "Epoch [25/50] - Train Loss: 1.1114, Test Loss: 1.5984\n",
      "Epoch [26/50] - Train Loss: 1.1111, Test Loss: 1.5990\n",
      "Epoch [27/50] - Train Loss: 1.1109, Test Loss: 1.5995\n",
      "Epoch [28/50] - Train Loss: 1.1107, Test Loss: 1.6000\n",
      "Epoch [29/50] - Train Loss: 1.1104, Test Loss: 1.6004\n",
      "Epoch [30/50] - Train Loss: 1.1102, Test Loss: 1.6009\n",
      "Epoch [31/50] - Train Loss: 1.1100, Test Loss: 1.6013\n",
      "Epoch [32/50] - Train Loss: 1.1099, Test Loss: 1.6017\n",
      "Epoch [33/50] - Train Loss: 1.1097, Test Loss: 1.6021\n",
      "Epoch [34/50] - Train Loss: 1.1095, Test Loss: 1.6025\n",
      "Epoch [35/50] - Train Loss: 1.1094, Test Loss: 1.6028\n",
      "Epoch [36/50] - Train Loss: 1.1092, Test Loss: 1.6032\n",
      "Epoch [37/50] - Train Loss: 1.1091, Test Loss: 1.6035\n",
      "Epoch [38/50] - Train Loss: 1.1090, Test Loss: 1.6038\n",
      "Epoch [39/50] - Train Loss: 1.1088, Test Loss: 1.6040\n",
      "Epoch [40/50] - Train Loss: 1.1087, Test Loss: 1.6043\n",
      "Epoch [41/50] - Train Loss: 1.1086, Test Loss: 1.6045\n",
      "Epoch [42/50] - Train Loss: 1.1085, Test Loss: 1.6047\n",
      "Epoch [43/50] - Train Loss: 1.1084, Test Loss: 1.6049\n",
      "Epoch [44/50] - Train Loss: 1.1083, Test Loss: 1.6051\n",
      "Epoch [45/50] - Train Loss: 1.1082, Test Loss: 1.6053\n",
      "Epoch [46/50] - Train Loss: 1.1081, Test Loss: 1.6054\n",
      "Epoch [47/50] - Train Loss: 1.1081, Test Loss: 1.6055\n",
      "Epoch [48/50] - Train Loss: 1.1080, Test Loss: 1.6056\n",
      "Epoch [49/50] - Train Loss: 1.1080, Test Loss: 1.6057\n",
      "Epoch [50/50] - Train Loss: 1.1079, Test Loss: 1.6058\n",
      "Avg Test Loss: 1.6058\n",
      "Testing combination: (32, 1, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3083, Test Loss: 2.6383\n",
      "Epoch [2/50] - Train Loss: 1.3077, Test Loss: 2.6388\n",
      "Epoch [3/50] - Train Loss: 1.3072, Test Loss: 2.6394\n",
      "Epoch [4/50] - Train Loss: 1.3068, Test Loss: 2.6399\n",
      "Epoch [5/50] - Train Loss: 1.3064, Test Loss: 2.6404\n",
      "Epoch [6/50] - Train Loss: 1.3060, Test Loss: 2.6409\n",
      "Epoch [7/50] - Train Loss: 1.3056, Test Loss: 2.6414\n",
      "Epoch [8/50] - Train Loss: 1.3052, Test Loss: 2.6419\n",
      "Epoch [9/50] - Train Loss: 1.3049, Test Loss: 2.6423\n",
      "Epoch [10/50] - Train Loss: 1.3045, Test Loss: 2.6428\n",
      "Epoch [11/50] - Train Loss: 1.3041, Test Loss: 2.6433\n",
      "Epoch [12/50] - Train Loss: 1.3038, Test Loss: 2.6438\n",
      "Epoch [13/50] - Train Loss: 1.3034, Test Loss: 2.6443\n",
      "Epoch [14/50] - Train Loss: 1.3031, Test Loss: 2.6447\n",
      "Epoch [15/50] - Train Loss: 1.3027, Test Loss: 2.6452\n",
      "Epoch [16/50] - Train Loss: 1.3024, Test Loss: 2.6456\n",
      "Epoch [17/50] - Train Loss: 1.3021, Test Loss: 2.6461\n",
      "Epoch [18/50] - Train Loss: 1.3017, Test Loss: 2.6465\n",
      "Epoch [19/50] - Train Loss: 1.3014, Test Loss: 2.6470\n",
      "Epoch [20/50] - Train Loss: 1.3011, Test Loss: 2.6474\n",
      "Epoch [21/50] - Train Loss: 1.3008, Test Loss: 2.6478\n",
      "Epoch [22/50] - Train Loss: 1.3005, Test Loss: 2.6483\n",
      "Epoch [23/50] - Train Loss: 1.3002, Test Loss: 2.6487\n",
      "Epoch [24/50] - Train Loss: 1.2999, Test Loss: 2.6491\n",
      "Epoch [25/50] - Train Loss: 1.2996, Test Loss: 2.6495\n",
      "Epoch [26/50] - Train Loss: 1.2993, Test Loss: 2.6499\n",
      "Epoch [27/50] - Train Loss: 1.2991, Test Loss: 2.6503\n",
      "Epoch [28/50] - Train Loss: 1.2988, Test Loss: 2.6507\n",
      "Epoch [29/50] - Train Loss: 1.2985, Test Loss: 2.6511\n",
      "Epoch [30/50] - Train Loss: 1.2982, Test Loss: 2.6515\n",
      "Epoch [31/50] - Train Loss: 1.2980, Test Loss: 2.6519\n",
      "Epoch [32/50] - Train Loss: 1.2977, Test Loss: 2.6522\n",
      "Epoch [33/50] - Train Loss: 1.2974, Test Loss: 2.6526\n",
      "Epoch [34/50] - Train Loss: 1.2972, Test Loss: 2.6530\n",
      "Epoch [35/50] - Train Loss: 1.2969, Test Loss: 2.6533\n",
      "Epoch [36/50] - Train Loss: 1.2966, Test Loss: 2.6537\n",
      "Epoch [37/50] - Train Loss: 1.2964, Test Loss: 2.6541\n",
      "Epoch [38/50] - Train Loss: 1.2961, Test Loss: 2.6544\n",
      "Epoch [39/50] - Train Loss: 1.2958, Test Loss: 2.6547\n",
      "Epoch [40/50] - Train Loss: 1.2956, Test Loss: 2.6551\n",
      "Epoch [41/50] - Train Loss: 1.2953, Test Loss: 2.6554\n",
      "Epoch [42/50] - Train Loss: 1.2951, Test Loss: 2.6558\n",
      "Epoch [43/50] - Train Loss: 1.2948, Test Loss: 2.6561\n",
      "Epoch [44/50] - Train Loss: 1.2946, Test Loss: 2.6564\n",
      "Epoch [45/50] - Train Loss: 1.2943, Test Loss: 2.6567\n",
      "Epoch [46/50] - Train Loss: 1.2941, Test Loss: 2.6571\n",
      "Epoch [47/50] - Train Loss: 1.2938, Test Loss: 2.6574\n",
      "Epoch [48/50] - Train Loss: 1.2936, Test Loss: 2.6577\n",
      "Epoch [49/50] - Train Loss: 1.2933, Test Loss: 2.6580\n",
      "Epoch [50/50] - Train Loss: 1.2931, Test Loss: 2.6583\n",
      "Avg Test Loss: 2.6583\n",
      "Testing combination: (32, 2, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1328, Test Loss: 1.4919\n",
      "Epoch [2/50] - Train Loss: 1.0950, Test Loss: 1.4816\n",
      "Epoch [3/50] - Train Loss: 1.0908, Test Loss: 1.4828\n",
      "Epoch [4/50] - Train Loss: 1.0908, Test Loss: 1.4835\n",
      "Epoch [5/50] - Train Loss: 1.0889, Test Loss: 1.4834\n",
      "Epoch [6/50] - Train Loss: 1.0846, Test Loss: 1.4824\n",
      "Epoch [7/50] - Train Loss: 1.0847, Test Loss: 1.4822\n",
      "Epoch [8/50] - Train Loss: 1.0846, Test Loss: 1.4825\n",
      "Epoch [9/50] - Train Loss: 1.0820, Test Loss: 1.4822\n",
      "Epoch [10/50] - Train Loss: 1.0771, Test Loss: 1.4834\n",
      "Epoch [11/50] - Train Loss: 1.0716, Test Loss: 1.4883\n",
      "Epoch [12/50] - Train Loss: 1.0641, Test Loss: 1.4869\n",
      "Epoch [13/50] - Train Loss: 1.0971, Test Loss: 1.4878\n",
      "Epoch [14/50] - Train Loss: 1.0633, Test Loss: 1.5188\n",
      "Epoch [15/50] - Train Loss: 1.0543, Test Loss: 1.4942\n",
      "Epoch [16/50] - Train Loss: 1.0514, Test Loss: 1.4893\n",
      "Epoch [17/50] - Train Loss: 1.0479, Test Loss: 1.4784\n",
      "Epoch [18/50] - Train Loss: 1.0630, Test Loss: 1.5313\n",
      "Epoch [19/50] - Train Loss: 1.1496, Test Loss: 1.5321\n",
      "Epoch [20/50] - Train Loss: 1.0646, Test Loss: 1.4840\n",
      "Epoch [21/50] - Train Loss: 1.0539, Test Loss: 1.4793\n",
      "Epoch [22/50] - Train Loss: 1.0524, Test Loss: 1.4858\n",
      "Epoch [23/50] - Train Loss: 1.0482, Test Loss: 1.4828\n",
      "Epoch [24/50] - Train Loss: 1.0543, Test Loss: 1.4942\n",
      "Epoch [25/50] - Train Loss: 1.0437, Test Loss: 1.5409\n",
      "Epoch [26/50] - Train Loss: 1.0360, Test Loss: 1.5185\n",
      "Epoch [27/50] - Train Loss: 1.0305, Test Loss: 1.5818\n",
      "Epoch [28/50] - Train Loss: 1.0439, Test Loss: 1.4984\n",
      "Epoch [29/50] - Train Loss: 1.0038, Test Loss: 1.5293\n",
      "Epoch [30/50] - Train Loss: 0.9854, Test Loss: 1.6702\n",
      "Epoch [31/50] - Train Loss: 1.0583, Test Loss: 1.7833\n",
      "Epoch [32/50] - Train Loss: 1.0002, Test Loss: 1.4603\n",
      "Epoch [33/50] - Train Loss: 0.9820, Test Loss: 1.6626\n",
      "Epoch [34/50] - Train Loss: 0.9806, Test Loss: 1.7079\n",
      "Epoch [35/50] - Train Loss: 0.9597, Test Loss: 1.5672\n",
      "Epoch [36/50] - Train Loss: 0.9805, Test Loss: 1.5439\n",
      "Epoch [37/50] - Train Loss: 0.9837, Test Loss: 1.7461\n",
      "Epoch [38/50] - Train Loss: 0.9636, Test Loss: 1.6726\n",
      "Epoch [39/50] - Train Loss: 0.9589, Test Loss: 1.6601\n",
      "Epoch [40/50] - Train Loss: 0.9488, Test Loss: 1.7875\n",
      "Epoch [41/50] - Train Loss: 0.9655, Test Loss: 1.7855\n",
      "Epoch [42/50] - Train Loss: 0.9416, Test Loss: 1.7321\n",
      "Epoch [43/50] - Train Loss: 0.9108, Test Loss: 1.7324\n",
      "Epoch [44/50] - Train Loss: 0.9577, Test Loss: 1.3249\n",
      "Epoch [45/50] - Train Loss: 1.0566, Test Loss: 1.7435\n",
      "Epoch [46/50] - Train Loss: 0.9482, Test Loss: 1.5887\n",
      "Epoch [47/50] - Train Loss: 0.9267, Test Loss: 1.7540\n",
      "Epoch [48/50] - Train Loss: 0.9019, Test Loss: 1.8189\n",
      "Epoch [49/50] - Train Loss: 0.8669, Test Loss: 1.7520\n",
      "Epoch [50/50] - Train Loss: 0.8749, Test Loss: 1.8462\n",
      "Avg Test Loss: 1.8462\n",
      "Testing combination: (32, 2, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1486, Test Loss: 1.5976\n",
      "Epoch [2/50] - Train Loss: 1.1165, Test Loss: 1.5921\n",
      "Epoch [3/50] - Train Loss: 1.1149, Test Loss: 1.6013\n",
      "Epoch [4/50] - Train Loss: 1.1111, Test Loss: 1.6083\n",
      "Epoch [5/50] - Train Loss: 1.1074, Test Loss: 1.6081\n",
      "Epoch [6/50] - Train Loss: 1.1017, Test Loss: 1.6078\n",
      "Epoch [7/50] - Train Loss: 1.0936, Test Loss: 1.6144\n",
      "Epoch [8/50] - Train Loss: 1.0870, Test Loss: 1.6127\n",
      "Epoch [9/50] - Train Loss: 1.1096, Test Loss: 1.6108\n",
      "Epoch [10/50] - Train Loss: 1.0817, Test Loss: 1.6144\n",
      "Epoch [11/50] - Train Loss: 1.0953, Test Loss: 1.6097\n",
      "Epoch [12/50] - Train Loss: 1.0929, Test Loss: 1.6088\n",
      "Epoch [13/50] - Train Loss: 1.0835, Test Loss: 1.6140\n",
      "Epoch [14/50] - Train Loss: 1.0794, Test Loss: 1.6148\n",
      "Epoch [15/50] - Train Loss: 1.0792, Test Loss: 1.6114\n",
      "Epoch [16/50] - Train Loss: 1.0792, Test Loss: 1.6117\n",
      "Epoch [17/50] - Train Loss: 1.0791, Test Loss: 1.6134\n",
      "Epoch [18/50] - Train Loss: 1.0789, Test Loss: 1.6132\n",
      "Epoch [19/50] - Train Loss: 1.0787, Test Loss: 1.6125\n",
      "Epoch [20/50] - Train Loss: 1.0787, Test Loss: 1.6126\n",
      "Epoch [21/50] - Train Loss: 1.0787, Test Loss: 1.6129\n",
      "Epoch [22/50] - Train Loss: 1.0786, Test Loss: 1.6130\n",
      "Epoch [23/50] - Train Loss: 1.0785, Test Loss: 1.6130\n",
      "Epoch [24/50] - Train Loss: 1.0785, Test Loss: 1.6131\n",
      "Epoch [25/50] - Train Loss: 1.0784, Test Loss: 1.6132\n",
      "Epoch [26/50] - Train Loss: 1.0783, Test Loss: 1.6132\n",
      "Epoch [27/50] - Train Loss: 1.0780, Test Loss: 1.6129\n",
      "Epoch [28/50] - Train Loss: 1.0770, Test Loss: 1.6126\n",
      "Epoch [29/50] - Train Loss: 1.0760, Test Loss: 1.6162\n",
      "Epoch [30/50] - Train Loss: 1.0767, Test Loss: 1.6178\n",
      "Epoch [31/50] - Train Loss: 1.0773, Test Loss: 1.6150\n",
      "Epoch [32/50] - Train Loss: 1.0776, Test Loss: 1.6119\n",
      "Epoch [33/50] - Train Loss: 1.0763, Test Loss: 1.6120\n",
      "Epoch [34/50] - Train Loss: 1.0748, Test Loss: 1.6123\n",
      "Epoch [35/50] - Train Loss: 1.0739, Test Loss: 1.6148\n",
      "Epoch [36/50] - Train Loss: 1.0727, Test Loss: 1.6149\n",
      "Epoch [37/50] - Train Loss: 1.0718, Test Loss: 1.6131\n",
      "Epoch [38/50] - Train Loss: 1.0712, Test Loss: 1.6117\n",
      "Epoch [39/50] - Train Loss: 1.0703, Test Loss: 1.6105\n",
      "Epoch [40/50] - Train Loss: 1.0690, Test Loss: 1.6102\n",
      "Epoch [41/50] - Train Loss: 1.0687, Test Loss: 1.6099\n",
      "Epoch [42/50] - Train Loss: 1.0683, Test Loss: 1.6121\n",
      "Epoch [43/50] - Train Loss: 1.0690, Test Loss: 1.6117\n",
      "Epoch [44/50] - Train Loss: 1.0671, Test Loss: 1.6107\n",
      "Epoch [45/50] - Train Loss: 1.0690, Test Loss: 1.6141\n",
      "Epoch [46/50] - Train Loss: 1.0675, Test Loss: 1.6206\n",
      "Epoch [47/50] - Train Loss: 1.0679, Test Loss: 1.6200\n",
      "Epoch [48/50] - Train Loss: 1.0647, Test Loss: 1.6477\n",
      "Epoch [49/50] - Train Loss: 1.0996, Test Loss: 1.6216\n",
      "Epoch [50/50] - Train Loss: 1.0746, Test Loss: 1.6268\n",
      "Avg Test Loss: 1.6268\n",
      "Testing combination: (32, 2, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3367, Test Loss: 2.6534\n",
      "Epoch [2/50] - Train Loss: 1.3029, Test Loss: 2.6809\n",
      "Epoch [3/50] - Train Loss: 1.2993, Test Loss: 2.6797\n",
      "Epoch [4/50] - Train Loss: 1.2942, Test Loss: 2.6686\n",
      "Epoch [5/50] - Train Loss: 1.2922, Test Loss: 2.6659\n",
      "Epoch [6/50] - Train Loss: 1.2890, Test Loss: 2.6731\n",
      "Epoch [7/50] - Train Loss: 1.2866, Test Loss: 2.6767\n",
      "Epoch [8/50] - Train Loss: 1.2818, Test Loss: 2.6719\n",
      "Epoch [9/50] - Train Loss: 1.2749, Test Loss: 2.6614\n",
      "Epoch [10/50] - Train Loss: 1.2631, Test Loss: 2.6522\n",
      "Epoch [11/50] - Train Loss: 1.2655, Test Loss: 2.6605\n",
      "Epoch [12/50] - Train Loss: 1.2630, Test Loss: 2.6711\n",
      "Epoch [13/50] - Train Loss: 1.2596, Test Loss: 2.6684\n",
      "Epoch [14/50] - Train Loss: 1.2581, Test Loss: 2.6584\n",
      "Epoch [15/50] - Train Loss: 1.2543, Test Loss: 2.6529\n",
      "Epoch [16/50] - Train Loss: 1.2545, Test Loss: 2.6562\n",
      "Epoch [17/50] - Train Loss: 1.2556, Test Loss: 2.6630\n",
      "Epoch [18/50] - Train Loss: 1.2591, Test Loss: 2.6671\n",
      "Epoch [19/50] - Train Loss: 1.2543, Test Loss: 2.6653\n",
      "Epoch [20/50] - Train Loss: 1.2554, Test Loss: 2.6593\n",
      "Epoch [21/50] - Train Loss: 1.2539, Test Loss: 2.6554\n",
      "Epoch [22/50] - Train Loss: 1.2541, Test Loss: 2.6570\n",
      "Epoch [23/50] - Train Loss: 1.2539, Test Loss: 2.6612\n",
      "Epoch [24/50] - Train Loss: 1.2534, Test Loss: 2.6627\n",
      "Epoch [25/50] - Train Loss: 1.2530, Test Loss: 2.6595\n",
      "Epoch [26/50] - Train Loss: 1.2524, Test Loss: 2.6537\n",
      "Epoch [27/50] - Train Loss: 1.2523, Test Loss: 2.6506\n",
      "Epoch [28/50] - Train Loss: 1.2514, Test Loss: 2.6496\n",
      "Epoch [29/50] - Train Loss: 1.2496, Test Loss: 2.6489\n",
      "Epoch [30/50] - Train Loss: 1.2483, Test Loss: 2.6485\n",
      "Epoch [31/50] - Train Loss: 1.2468, Test Loss: 2.6458\n",
      "Epoch [32/50] - Train Loss: 1.2443, Test Loss: 2.6431\n",
      "Epoch [33/50] - Train Loss: 1.2429, Test Loss: 2.6413\n",
      "Epoch [34/50] - Train Loss: 1.2412, Test Loss: 2.6436\n",
      "Epoch [35/50] - Train Loss: 1.2399, Test Loss: 2.6507\n",
      "Epoch [36/50] - Train Loss: 1.2399, Test Loss: 2.6531\n",
      "Epoch [37/50] - Train Loss: 1.2398, Test Loss: 2.6553\n",
      "Epoch [38/50] - Train Loss: 1.2400, Test Loss: 2.6491\n",
      "Epoch [39/50] - Train Loss: 1.2397, Test Loss: 2.6446\n",
      "Epoch [40/50] - Train Loss: 1.2396, Test Loss: 2.6377\n",
      "Epoch [41/50] - Train Loss: 1.2400, Test Loss: 2.6339\n",
      "Epoch [42/50] - Train Loss: 1.2392, Test Loss: 2.6408\n",
      "Epoch [43/50] - Train Loss: 1.2395, Test Loss: 2.6339\n",
      "Epoch [44/50] - Train Loss: 1.2408, Test Loss: 2.6300\n",
      "Epoch [45/50] - Train Loss: 1.2393, Test Loss: 2.6495\n",
      "Epoch [46/50] - Train Loss: 1.2406, Test Loss: 2.6462\n",
      "Epoch [47/50] - Train Loss: 1.2396, Test Loss: 2.6305\n",
      "Epoch [48/50] - Train Loss: 1.2408, Test Loss: 2.6233\n",
      "Epoch [49/50] - Train Loss: 1.2390, Test Loss: 2.6401\n",
      "Epoch [50/50] - Train Loss: 1.2397, Test Loss: 2.6384\n",
      "Avg Test Loss: 2.6384\n",
      "Testing combination: (32, 2, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.0975, Test Loss: 1.4878\n",
      "Epoch [2/50] - Train Loss: 1.0939, Test Loss: 1.4878\n",
      "Epoch [3/50] - Train Loss: 1.0930, Test Loss: 1.4873\n",
      "Epoch [4/50] - Train Loss: 1.0921, Test Loss: 1.4867\n",
      "Epoch [5/50] - Train Loss: 1.0910, Test Loss: 1.4863\n",
      "Epoch [6/50] - Train Loss: 1.0894, Test Loss: 1.4859\n",
      "Epoch [7/50] - Train Loss: 1.0872, Test Loss: 1.4855\n",
      "Epoch [8/50] - Train Loss: 1.0850, Test Loss: 1.4851\n",
      "Epoch [9/50] - Train Loss: 1.0836, Test Loss: 1.4844\n",
      "Epoch [10/50] - Train Loss: 1.0827, Test Loss: 1.4836\n",
      "Epoch [11/50] - Train Loss: 1.0817, Test Loss: 1.4829\n",
      "Epoch [12/50] - Train Loss: 1.0806, Test Loss: 1.4826\n",
      "Epoch [13/50] - Train Loss: 1.0790, Test Loss: 1.4826\n",
      "Epoch [14/50] - Train Loss: 1.0764, Test Loss: 1.4829\n",
      "Epoch [15/50] - Train Loss: 1.0731, Test Loss: 1.4836\n",
      "Epoch [16/50] - Train Loss: 1.0708, Test Loss: 1.4844\n",
      "Epoch [17/50] - Train Loss: 1.0647, Test Loss: 1.4854\n",
      "Epoch [18/50] - Train Loss: 1.0590, Test Loss: 1.4863\n",
      "Epoch [19/50] - Train Loss: 1.0552, Test Loss: 1.4870\n",
      "Epoch [20/50] - Train Loss: 1.0531, Test Loss: 1.4873\n",
      "Epoch [21/50] - Train Loss: 1.0523, Test Loss: 1.4874\n",
      "Epoch [22/50] - Train Loss: 1.0521, Test Loss: 1.4874\n",
      "Epoch [23/50] - Train Loss: 1.0519, Test Loss: 1.4873\n",
      "Epoch [24/50] - Train Loss: 1.0516, Test Loss: 1.4873\n",
      "Epoch [25/50] - Train Loss: 1.0514, Test Loss: 1.4872\n",
      "Epoch [26/50] - Train Loss: 1.0511, Test Loss: 1.4872\n",
      "Epoch [27/50] - Train Loss: 1.0508, Test Loss: 1.4872\n",
      "Epoch [28/50] - Train Loss: 1.0504, Test Loss: 1.4873\n",
      "Epoch [29/50] - Train Loss: 1.0500, Test Loss: 1.4876\n",
      "Epoch [30/50] - Train Loss: 1.0495, Test Loss: 1.4882\n",
      "Epoch [31/50] - Train Loss: 1.0489, Test Loss: 1.4889\n",
      "Epoch [32/50] - Train Loss: 1.0482, Test Loss: 1.4892\n",
      "Epoch [33/50] - Train Loss: 1.0469, Test Loss: 1.4891\n",
      "Epoch [34/50] - Train Loss: 1.0452, Test Loss: 1.4873\n",
      "Epoch [35/50] - Train Loss: 1.0420, Test Loss: 1.4747\n",
      "Epoch [36/50] - Train Loss: 1.0618, Test Loss: 1.4968\n",
      "Epoch [37/50] - Train Loss: 1.0788, Test Loss: 1.4952\n",
      "Epoch [38/50] - Train Loss: 1.0512, Test Loss: 1.4892\n",
      "Epoch [39/50] - Train Loss: 1.0464, Test Loss: 1.4876\n",
      "Epoch [40/50] - Train Loss: 1.0465, Test Loss: 1.4882\n",
      "Epoch [41/50] - Train Loss: 1.0454, Test Loss: 1.4880\n",
      "Epoch [42/50] - Train Loss: 1.0436, Test Loss: 1.4877\n",
      "Epoch [43/50] - Train Loss: 1.0414, Test Loss: 1.4863\n",
      "Epoch [44/50] - Train Loss: 1.0384, Test Loss: 1.4827\n",
      "Epoch [45/50] - Train Loss: 1.0348, Test Loss: 1.4735\n",
      "Epoch [46/50] - Train Loss: 1.0344, Test Loss: 1.4753\n",
      "Epoch [47/50] - Train Loss: 1.0314, Test Loss: 1.4600\n",
      "Epoch [48/50] - Train Loss: 1.0485, Test Loss: 1.5022\n",
      "Epoch [49/50] - Train Loss: 1.0921, Test Loss: 1.4991\n",
      "Epoch [50/50] - Train Loss: 1.0879, Test Loss: 1.4930\n",
      "Avg Test Loss: 1.4930\n",
      "Testing combination: (32, 2, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1178, Test Loss: 1.6240\n",
      "Epoch [2/50] - Train Loss: 1.1148, Test Loss: 1.6161\n",
      "Epoch [3/50] - Train Loss: 1.1136, Test Loss: 1.6109\n",
      "Epoch [4/50] - Train Loss: 1.1129, Test Loss: 1.6083\n",
      "Epoch [5/50] - Train Loss: 1.1122, Test Loss: 1.6072\n",
      "Epoch [6/50] - Train Loss: 1.1112, Test Loss: 1.6071\n",
      "Epoch [7/50] - Train Loss: 1.1101, Test Loss: 1.6072\n",
      "Epoch [8/50] - Train Loss: 1.1092, Test Loss: 1.6071\n",
      "Epoch [9/50] - Train Loss: 1.1084, Test Loss: 1.6068\n",
      "Epoch [10/50] - Train Loss: 1.1075, Test Loss: 1.6063\n",
      "Epoch [11/50] - Train Loss: 1.1065, Test Loss: 1.6059\n",
      "Epoch [12/50] - Train Loss: 1.1052, Test Loss: 1.6058\n",
      "Epoch [13/50] - Train Loss: 1.1034, Test Loss: 1.6059\n",
      "Epoch [14/50] - Train Loss: 1.1002, Test Loss: 1.6065\n",
      "Epoch [15/50] - Train Loss: 1.0954, Test Loss: 1.6078\n",
      "Epoch [16/50] - Train Loss: 1.0895, Test Loss: 1.6100\n",
      "Epoch [17/50] - Train Loss: 1.0835, Test Loss: 1.6128\n",
      "Epoch [18/50] - Train Loss: 1.0826, Test Loss: 1.6156\n",
      "Epoch [19/50] - Train Loss: 1.0851, Test Loss: 1.6176\n",
      "Epoch [20/50] - Train Loss: 1.0784, Test Loss: 1.6160\n",
      "Epoch [21/50] - Train Loss: 1.0775, Test Loss: 1.6145\n",
      "Epoch [22/50] - Train Loss: 1.0773, Test Loss: 1.6141\n",
      "Epoch [23/50] - Train Loss: 1.0767, Test Loss: 1.6146\n",
      "Epoch [24/50] - Train Loss: 1.0762, Test Loss: 1.6156\n",
      "Epoch [25/50] - Train Loss: 1.0758, Test Loss: 1.6175\n",
      "Epoch [26/50] - Train Loss: 1.0754, Test Loss: 1.6196\n",
      "Epoch [27/50] - Train Loss: 1.0749, Test Loss: 1.6208\n",
      "Epoch [28/50] - Train Loss: 1.0743, Test Loss: 1.6208\n",
      "Epoch [29/50] - Train Loss: 1.0738, Test Loss: 1.6202\n",
      "Epoch [30/50] - Train Loss: 1.0731, Test Loss: 1.6193\n",
      "Epoch [31/50] - Train Loss: 1.0722, Test Loss: 1.6180\n",
      "Epoch [32/50] - Train Loss: 1.0707, Test Loss: 1.6153\n",
      "Epoch [33/50] - Train Loss: 1.0675, Test Loss: 1.6152\n",
      "Epoch [34/50] - Train Loss: 1.0623, Test Loss: 1.6021\n",
      "Epoch [35/50] - Train Loss: 1.0916, Test Loss: 1.6278\n",
      "Epoch [36/50] - Train Loss: 1.0708, Test Loss: 1.6332\n",
      "Epoch [37/50] - Train Loss: 1.0706, Test Loss: 1.6265\n",
      "Epoch [38/50] - Train Loss: 1.0689, Test Loss: 1.6191\n",
      "Epoch [39/50] - Train Loss: 1.0671, Test Loss: 1.6134\n",
      "Epoch [40/50] - Train Loss: 1.0641, Test Loss: 1.6086\n",
      "Epoch [41/50] - Train Loss: 1.0586, Test Loss: 1.6017\n",
      "Epoch [42/50] - Train Loss: 1.0448, Test Loss: 1.5945\n",
      "Epoch [43/50] - Train Loss: 1.0617, Test Loss: 1.6345\n",
      "Epoch [44/50] - Train Loss: 1.0822, Test Loss: 1.6200\n",
      "Epoch [45/50] - Train Loss: 1.0724, Test Loss: 1.6075\n",
      "Epoch [46/50] - Train Loss: 1.0951, Test Loss: 1.6563\n",
      "Epoch [47/50] - Train Loss: 1.1016, Test Loss: 1.6458\n",
      "Epoch [48/50] - Train Loss: 1.0939, Test Loss: 1.6297\n",
      "Epoch [49/50] - Train Loss: 1.0863, Test Loss: 1.6180\n",
      "Epoch [50/50] - Train Loss: 1.0814, Test Loss: 1.6117\n",
      "Avg Test Loss: 1.6117\n",
      "Testing combination: (32, 2, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3205, Test Loss: 2.7307\n",
      "Epoch [2/50] - Train Loss: 1.3096, Test Loss: 2.7033\n",
      "Epoch [3/50] - Train Loss: 1.3036, Test Loss: 2.6834\n",
      "Epoch [4/50] - Train Loss: 1.3003, Test Loss: 2.6698\n",
      "Epoch [5/50] - Train Loss: 1.2988, Test Loss: 2.6613\n",
      "Epoch [6/50] - Train Loss: 1.2981, Test Loss: 2.6568\n",
      "Epoch [7/50] - Train Loss: 1.2974, Test Loss: 2.6553\n",
      "Epoch [8/50] - Train Loss: 1.2965, Test Loss: 2.6557\n",
      "Epoch [9/50] - Train Loss: 1.2954, Test Loss: 2.6574\n",
      "Epoch [10/50] - Train Loss: 1.2941, Test Loss: 2.6598\n",
      "Epoch [11/50] - Train Loss: 1.2928, Test Loss: 2.6625\n",
      "Epoch [12/50] - Train Loss: 1.2917, Test Loss: 2.6651\n",
      "Epoch [13/50] - Train Loss: 1.2910, Test Loss: 2.6676\n",
      "Epoch [14/50] - Train Loss: 1.2904, Test Loss: 2.6697\n",
      "Epoch [15/50] - Train Loss: 1.2898, Test Loss: 2.6713\n",
      "Epoch [16/50] - Train Loss: 1.2893, Test Loss: 2.6723\n",
      "Epoch [17/50] - Train Loss: 1.2887, Test Loss: 2.6726\n",
      "Epoch [18/50] - Train Loss: 1.2881, Test Loss: 2.6722\n",
      "Epoch [19/50] - Train Loss: 1.2874, Test Loss: 2.6715\n",
      "Epoch [20/50] - Train Loss: 1.2866, Test Loss: 2.6705\n",
      "Epoch [21/50] - Train Loss: 1.2855, Test Loss: 2.6693\n",
      "Epoch [22/50] - Train Loss: 1.2841, Test Loss: 2.6678\n",
      "Epoch [23/50] - Train Loss: 1.2823, Test Loss: 2.6660\n",
      "Epoch [24/50] - Train Loss: 1.2799, Test Loss: 2.6640\n",
      "Epoch [25/50] - Train Loss: 1.2770, Test Loss: 2.6615\n",
      "Epoch [26/50] - Train Loss: 1.2736, Test Loss: 2.6588\n",
      "Epoch [27/50] - Train Loss: 1.2704, Test Loss: 2.6562\n",
      "Epoch [28/50] - Train Loss: 1.2737, Test Loss: 2.6542\n",
      "Epoch [29/50] - Train Loss: 1.2659, Test Loss: 2.6525\n",
      "Epoch [30/50] - Train Loss: 1.2636, Test Loss: 2.6526\n",
      "Epoch [31/50] - Train Loss: 1.2612, Test Loss: 2.6530\n",
      "Epoch [32/50] - Train Loss: 1.2577, Test Loss: 2.6524\n",
      "Epoch [33/50] - Train Loss: 1.2555, Test Loss: 2.6516\n",
      "Epoch [34/50] - Train Loss: 1.2540, Test Loss: 2.6508\n",
      "Epoch [35/50] - Train Loss: 1.2529, Test Loss: 2.6500\n",
      "Epoch [36/50] - Train Loss: 1.2524, Test Loss: 2.6494\n",
      "Epoch [37/50] - Train Loss: 1.2518, Test Loss: 2.6490\n",
      "Epoch [38/50] - Train Loss: 1.2513, Test Loss: 2.6490\n",
      "Epoch [39/50] - Train Loss: 1.2507, Test Loss: 2.6493\n",
      "Epoch [40/50] - Train Loss: 1.2503, Test Loss: 2.6493\n",
      "Epoch [41/50] - Train Loss: 1.2498, Test Loss: 2.6492\n",
      "Epoch [42/50] - Train Loss: 1.2493, Test Loss: 2.6487\n",
      "Epoch [43/50] - Train Loss: 1.2487, Test Loss: 2.6477\n",
      "Epoch [44/50] - Train Loss: 1.2478, Test Loss: 2.6463\n",
      "Epoch [45/50] - Train Loss: 1.2467, Test Loss: 2.6443\n",
      "Epoch [46/50] - Train Loss: 1.2452, Test Loss: 2.6409\n",
      "Epoch [47/50] - Train Loss: 1.2431, Test Loss: 2.6353\n",
      "Epoch [48/50] - Train Loss: 1.2430, Test Loss: 2.6269\n",
      "Epoch [49/50] - Train Loss: 1.2466, Test Loss: 2.6260\n",
      "Epoch [50/50] - Train Loss: 1.2488, Test Loss: 2.6515\n",
      "Avg Test Loss: 2.6515\n",
      "Testing combination: (32, 2, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.0953, Test Loss: 1.4960\n",
      "Epoch [2/50] - Train Loss: 1.0949, Test Loss: 1.4957\n",
      "Epoch [3/50] - Train Loss: 1.0947, Test Loss: 1.4953\n",
      "Epoch [4/50] - Train Loss: 1.0945, Test Loss: 1.4949\n",
      "Epoch [5/50] - Train Loss: 1.0943, Test Loss: 1.4945\n",
      "Epoch [6/50] - Train Loss: 1.0941, Test Loss: 1.4942\n",
      "Epoch [7/50] - Train Loss: 1.0940, Test Loss: 1.4938\n",
      "Epoch [8/50] - Train Loss: 1.0938, Test Loss: 1.4935\n",
      "Epoch [9/50] - Train Loss: 1.0936, Test Loss: 1.4931\n",
      "Epoch [10/50] - Train Loss: 1.0935, Test Loss: 1.4928\n",
      "Epoch [11/50] - Train Loss: 1.0933, Test Loss: 1.4925\n",
      "Epoch [12/50] - Train Loss: 1.0932, Test Loss: 1.4922\n",
      "Epoch [13/50] - Train Loss: 1.0930, Test Loss: 1.4919\n",
      "Epoch [14/50] - Train Loss: 1.0928, Test Loss: 1.4916\n",
      "Epoch [15/50] - Train Loss: 1.0927, Test Loss: 1.4914\n",
      "Epoch [16/50] - Train Loss: 1.0925, Test Loss: 1.4911\n",
      "Epoch [17/50] - Train Loss: 1.0924, Test Loss: 1.4909\n",
      "Epoch [18/50] - Train Loss: 1.0922, Test Loss: 1.4906\n",
      "Epoch [19/50] - Train Loss: 1.0921, Test Loss: 1.4904\n",
      "Epoch [20/50] - Train Loss: 1.0919, Test Loss: 1.4901\n",
      "Epoch [21/50] - Train Loss: 1.0918, Test Loss: 1.4899\n",
      "Epoch [22/50] - Train Loss: 1.0916, Test Loss: 1.4897\n",
      "Epoch [23/50] - Train Loss: 1.0915, Test Loss: 1.4895\n",
      "Epoch [24/50] - Train Loss: 1.0913, Test Loss: 1.4893\n",
      "Epoch [25/50] - Train Loss: 1.0911, Test Loss: 1.4891\n",
      "Epoch [26/50] - Train Loss: 1.0910, Test Loss: 1.4889\n",
      "Epoch [27/50] - Train Loss: 1.0908, Test Loss: 1.4887\n",
      "Epoch [28/50] - Train Loss: 1.0906, Test Loss: 1.4886\n",
      "Epoch [29/50] - Train Loss: 1.0904, Test Loss: 1.4884\n",
      "Epoch [30/50] - Train Loss: 1.0902, Test Loss: 1.4882\n",
      "Epoch [31/50] - Train Loss: 1.0900, Test Loss: 1.4881\n",
      "Epoch [32/50] - Train Loss: 1.0898, Test Loss: 1.4879\n",
      "Epoch [33/50] - Train Loss: 1.0896, Test Loss: 1.4878\n",
      "Epoch [34/50] - Train Loss: 1.0894, Test Loss: 1.4876\n",
      "Epoch [35/50] - Train Loss: 1.0892, Test Loss: 1.4875\n",
      "Epoch [36/50] - Train Loss: 1.0889, Test Loss: 1.4873\n",
      "Epoch [37/50] - Train Loss: 1.0887, Test Loss: 1.4872\n",
      "Epoch [38/50] - Train Loss: 1.0885, Test Loss: 1.4870\n",
      "Epoch [39/50] - Train Loss: 1.0882, Test Loss: 1.4869\n",
      "Epoch [40/50] - Train Loss: 1.0880, Test Loss: 1.4868\n",
      "Epoch [41/50] - Train Loss: 1.0877, Test Loss: 1.4867\n",
      "Epoch [42/50] - Train Loss: 1.0874, Test Loss: 1.4865\n",
      "Epoch [43/50] - Train Loss: 1.0872, Test Loss: 1.4864\n",
      "Epoch [44/50] - Train Loss: 1.0869, Test Loss: 1.4863\n",
      "Epoch [45/50] - Train Loss: 1.0867, Test Loss: 1.4862\n",
      "Epoch [46/50] - Train Loss: 1.0865, Test Loss: 1.4860\n",
      "Epoch [47/50] - Train Loss: 1.0862, Test Loss: 1.4859\n",
      "Epoch [48/50] - Train Loss: 1.0860, Test Loss: 1.4858\n",
      "Epoch [49/50] - Train Loss: 1.0857, Test Loss: 1.4857\n",
      "Epoch [50/50] - Train Loss: 1.0855, Test Loss: 1.4856\n",
      "Avg Test Loss: 1.4856\n",
      "Testing combination: (32, 2, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1179, Test Loss: 1.6370\n",
      "Epoch [2/50] - Train Loss: 1.1175, Test Loss: 1.6355\n",
      "Epoch [3/50] - Train Loss: 1.1171, Test Loss: 1.6339\n",
      "Epoch [4/50] - Train Loss: 1.1168, Test Loss: 1.6325\n",
      "Epoch [5/50] - Train Loss: 1.1166, Test Loss: 1.6311\n",
      "Epoch [6/50] - Train Loss: 1.1163, Test Loss: 1.6298\n",
      "Epoch [7/50] - Train Loss: 1.1161, Test Loss: 1.6285\n",
      "Epoch [8/50] - Train Loss: 1.1159, Test Loss: 1.6274\n",
      "Epoch [9/50] - Train Loss: 1.1157, Test Loss: 1.6263\n",
      "Epoch [10/50] - Train Loss: 1.1155, Test Loss: 1.6253\n",
      "Epoch [11/50] - Train Loss: 1.1153, Test Loss: 1.6243\n",
      "Epoch [12/50] - Train Loss: 1.1152, Test Loss: 1.6234\n",
      "Epoch [13/50] - Train Loss: 1.1150, Test Loss: 1.6225\n",
      "Epoch [14/50] - Train Loss: 1.1149, Test Loss: 1.6217\n",
      "Epoch [15/50] - Train Loss: 1.1148, Test Loss: 1.6210\n",
      "Epoch [16/50] - Train Loss: 1.1147, Test Loss: 1.6202\n",
      "Epoch [17/50] - Train Loss: 1.1146, Test Loss: 1.6196\n",
      "Epoch [18/50] - Train Loss: 1.1145, Test Loss: 1.6189\n",
      "Epoch [19/50] - Train Loss: 1.1144, Test Loss: 1.6183\n",
      "Epoch [20/50] - Train Loss: 1.1143, Test Loss: 1.6178\n",
      "Epoch [21/50] - Train Loss: 1.1142, Test Loss: 1.6172\n",
      "Epoch [22/50] - Train Loss: 1.1142, Test Loss: 1.6167\n",
      "Epoch [23/50] - Train Loss: 1.1141, Test Loss: 1.6163\n",
      "Epoch [24/50] - Train Loss: 1.1140, Test Loss: 1.6158\n",
      "Epoch [25/50] - Train Loss: 1.1140, Test Loss: 1.6154\n",
      "Epoch [26/50] - Train Loss: 1.1139, Test Loss: 1.6150\n",
      "Epoch [27/50] - Train Loss: 1.1138, Test Loss: 1.6146\n",
      "Epoch [28/50] - Train Loss: 1.1138, Test Loss: 1.6143\n",
      "Epoch [29/50] - Train Loss: 1.1137, Test Loss: 1.6140\n",
      "Epoch [30/50] - Train Loss: 1.1136, Test Loss: 1.6136\n",
      "Epoch [31/50] - Train Loss: 1.1136, Test Loss: 1.6133\n",
      "Epoch [32/50] - Train Loss: 1.1135, Test Loss: 1.6131\n",
      "Epoch [33/50] - Train Loss: 1.1135, Test Loss: 1.6128\n",
      "Epoch [34/50] - Train Loss: 1.1134, Test Loss: 1.6125\n",
      "Epoch [35/50] - Train Loss: 1.1133, Test Loss: 1.6123\n",
      "Epoch [36/50] - Train Loss: 1.1133, Test Loss: 1.6121\n",
      "Epoch [37/50] - Train Loss: 1.1132, Test Loss: 1.6119\n",
      "Epoch [38/50] - Train Loss: 1.1131, Test Loss: 1.6117\n",
      "Epoch [39/50] - Train Loss: 1.1131, Test Loss: 1.6115\n",
      "Epoch [40/50] - Train Loss: 1.1130, Test Loss: 1.6113\n",
      "Epoch [41/50] - Train Loss: 1.1129, Test Loss: 1.6111\n",
      "Epoch [42/50] - Train Loss: 1.1129, Test Loss: 1.6109\n",
      "Epoch [43/50] - Train Loss: 1.1128, Test Loss: 1.6108\n",
      "Epoch [44/50] - Train Loss: 1.1127, Test Loss: 1.6106\n",
      "Epoch [45/50] - Train Loss: 1.1126, Test Loss: 1.6105\n",
      "Epoch [46/50] - Train Loss: 1.1126, Test Loss: 1.6103\n",
      "Epoch [47/50] - Train Loss: 1.1125, Test Loss: 1.6102\n",
      "Epoch [48/50] - Train Loss: 1.1124, Test Loss: 1.6101\n",
      "Epoch [49/50] - Train Loss: 1.1123, Test Loss: 1.6099\n",
      "Epoch [50/50] - Train Loss: 1.1122, Test Loss: 1.6098\n",
      "Avg Test Loss: 1.6098\n",
      "Testing combination: (32, 2, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3115, Test Loss: 2.7201\n",
      "Epoch [2/50] - Train Loss: 1.3108, Test Loss: 2.7179\n",
      "Epoch [3/50] - Train Loss: 1.3102, Test Loss: 2.7158\n",
      "Epoch [4/50] - Train Loss: 1.3096, Test Loss: 2.7138\n",
      "Epoch [5/50] - Train Loss: 1.3091, Test Loss: 2.7118\n",
      "Epoch [6/50] - Train Loss: 1.3086, Test Loss: 2.7099\n",
      "Epoch [7/50] - Train Loss: 1.3081, Test Loss: 2.7081\n",
      "Epoch [8/50] - Train Loss: 1.3076, Test Loss: 2.7063\n",
      "Epoch [9/50] - Train Loss: 1.3072, Test Loss: 2.7046\n",
      "Epoch [10/50] - Train Loss: 1.3068, Test Loss: 2.7030\n",
      "Epoch [11/50] - Train Loss: 1.3063, Test Loss: 2.7014\n",
      "Epoch [12/50] - Train Loss: 1.3060, Test Loss: 2.6998\n",
      "Epoch [13/50] - Train Loss: 1.3056, Test Loss: 2.6983\n",
      "Epoch [14/50] - Train Loss: 1.3052, Test Loss: 2.6969\n",
      "Epoch [15/50] - Train Loss: 1.3049, Test Loss: 2.6955\n",
      "Epoch [16/50] - Train Loss: 1.3046, Test Loss: 2.6942\n",
      "Epoch [17/50] - Train Loss: 1.3043, Test Loss: 2.6929\n",
      "Epoch [18/50] - Train Loss: 1.3040, Test Loss: 2.6916\n",
      "Epoch [19/50] - Train Loss: 1.3037, Test Loss: 2.6904\n",
      "Epoch [20/50] - Train Loss: 1.3034, Test Loss: 2.6893\n",
      "Epoch [21/50] - Train Loss: 1.3032, Test Loss: 2.6881\n",
      "Epoch [22/50] - Train Loss: 1.3029, Test Loss: 2.6871\n",
      "Epoch [23/50] - Train Loss: 1.3027, Test Loss: 2.6860\n",
      "Epoch [24/50] - Train Loss: 1.3024, Test Loss: 2.6850\n",
      "Epoch [25/50] - Train Loss: 1.3022, Test Loss: 2.6841\n",
      "Epoch [26/50] - Train Loss: 1.3020, Test Loss: 2.6831\n",
      "Epoch [27/50] - Train Loss: 1.3018, Test Loss: 2.6823\n",
      "Epoch [28/50] - Train Loss: 1.3016, Test Loss: 2.6814\n",
      "Epoch [29/50] - Train Loss: 1.3014, Test Loss: 2.6806\n",
      "Epoch [30/50] - Train Loss: 1.3012, Test Loss: 2.6798\n",
      "Epoch [31/50] - Train Loss: 1.3011, Test Loss: 2.6790\n",
      "Epoch [32/50] - Train Loss: 1.3009, Test Loss: 2.6783\n",
      "Epoch [33/50] - Train Loss: 1.3007, Test Loss: 2.6776\n",
      "Epoch [34/50] - Train Loss: 1.3005, Test Loss: 2.6769\n",
      "Epoch [35/50] - Train Loss: 1.3004, Test Loss: 2.6763\n",
      "Epoch [36/50] - Train Loss: 1.3002, Test Loss: 2.6757\n",
      "Epoch [37/50] - Train Loss: 1.3001, Test Loss: 2.6751\n",
      "Epoch [38/50] - Train Loss: 1.2999, Test Loss: 2.6745\n",
      "Epoch [39/50] - Train Loss: 1.2998, Test Loss: 2.6740\n",
      "Epoch [40/50] - Train Loss: 1.2996, Test Loss: 2.6734\n",
      "Epoch [41/50] - Train Loss: 1.2995, Test Loss: 2.6729\n",
      "Epoch [42/50] - Train Loss: 1.2993, Test Loss: 2.6725\n",
      "Epoch [43/50] - Train Loss: 1.2992, Test Loss: 2.6720\n",
      "Epoch [44/50] - Train Loss: 1.2990, Test Loss: 2.6716\n",
      "Epoch [45/50] - Train Loss: 1.2989, Test Loss: 2.6712\n",
      "Epoch [46/50] - Train Loss: 1.2987, Test Loss: 2.6708\n",
      "Epoch [47/50] - Train Loss: 1.2986, Test Loss: 2.6704\n",
      "Epoch [48/50] - Train Loss: 1.2984, Test Loss: 2.6701\n",
      "Epoch [49/50] - Train Loss: 1.2983, Test Loss: 2.6698\n",
      "Epoch [50/50] - Train Loss: 1.2982, Test Loss: 2.6694\n",
      "Avg Test Loss: 2.6694\n",
      "Testing combination: (32, 3, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1237, Test Loss: 1.4883\n",
      "Epoch [2/50] - Train Loss: 1.0958, Test Loss: 1.4821\n",
      "Epoch [3/50] - Train Loss: 1.0940, Test Loss: 1.4825\n",
      "Epoch [4/50] - Train Loss: 1.0928, Test Loss: 1.4836\n",
      "Epoch [5/50] - Train Loss: 1.0853, Test Loss: 1.4832\n",
      "Epoch [6/50] - Train Loss: 1.1205, Test Loss: 1.4834\n",
      "Epoch [7/50] - Train Loss: 1.0955, Test Loss: 1.4844\n",
      "Epoch [8/50] - Train Loss: 1.0859, Test Loss: 1.4834\n",
      "Epoch [9/50] - Train Loss: 1.0823, Test Loss: 1.4827\n",
      "Epoch [10/50] - Train Loss: 1.0821, Test Loss: 1.4850\n",
      "Epoch [11/50] - Train Loss: 1.0723, Test Loss: 1.4865\n",
      "Epoch [12/50] - Train Loss: 1.0560, Test Loss: 1.4871\n",
      "Epoch [13/50] - Train Loss: 1.0722, Test Loss: 1.4879\n",
      "Epoch [14/50] - Train Loss: 1.0798, Test Loss: 1.4868\n",
      "Epoch [15/50] - Train Loss: 1.0675, Test Loss: 1.4856\n",
      "Epoch [16/50] - Train Loss: 1.0566, Test Loss: 1.4864\n",
      "Epoch [17/50] - Train Loss: 1.0566, Test Loss: 1.4874\n",
      "Epoch [18/50] - Train Loss: 1.0523, Test Loss: 1.4874\n",
      "Epoch [19/50] - Train Loss: 1.0509, Test Loss: 1.4864\n",
      "Epoch [20/50] - Train Loss: 1.0504, Test Loss: 1.4854\n",
      "Epoch [21/50] - Train Loss: 1.0485, Test Loss: 1.4859\n",
      "Epoch [22/50] - Train Loss: 1.0519, Test Loss: 1.4851\n",
      "Epoch [23/50] - Train Loss: 1.0473, Test Loss: 1.4872\n",
      "Epoch [24/50] - Train Loss: 1.0476, Test Loss: 1.4852\n",
      "Epoch [25/50] - Train Loss: 1.0475, Test Loss: 1.4863\n",
      "Epoch [26/50] - Train Loss: 1.0449, Test Loss: 1.4863\n",
      "Epoch [27/50] - Train Loss: 1.0469, Test Loss: 1.4783\n",
      "Epoch [28/50] - Train Loss: 1.0518, Test Loss: 1.4976\n",
      "Epoch [29/50] - Train Loss: 1.0516, Test Loss: 1.4378\n",
      "Epoch [30/50] - Train Loss: 1.0600, Test Loss: 1.4759\n",
      "Epoch [31/50] - Train Loss: 1.0392, Test Loss: 1.5138\n",
      "Epoch [32/50] - Train Loss: 1.0700, Test Loss: 1.4848\n",
      "Epoch [33/50] - Train Loss: 1.0458, Test Loss: 1.4880\n",
      "Epoch [34/50] - Train Loss: 1.0447, Test Loss: 1.4851\n",
      "Epoch [35/50] - Train Loss: 1.0421, Test Loss: 1.4871\n",
      "Epoch [36/50] - Train Loss: 1.0409, Test Loss: 1.4913\n",
      "Epoch [37/50] - Train Loss: 1.0364, Test Loss: 1.5032\n",
      "Epoch [38/50] - Train Loss: 1.0366, Test Loss: 1.4808\n",
      "Epoch [39/50] - Train Loss: 1.0456, Test Loss: 1.5376\n",
      "Epoch [40/50] - Train Loss: 1.0329, Test Loss: 1.5292\n",
      "Epoch [41/50] - Train Loss: 1.0351, Test Loss: 1.4455\n",
      "Epoch [42/50] - Train Loss: 1.0664, Test Loss: 1.5057\n",
      "Epoch [43/50] - Train Loss: 1.0472, Test Loss: 1.4988\n",
      "Epoch [44/50] - Train Loss: 1.0403, Test Loss: 1.4967\n",
      "Epoch [45/50] - Train Loss: 1.0311, Test Loss: 1.5128\n",
      "Epoch [46/50] - Train Loss: 1.0222, Test Loss: 1.5355\n",
      "Epoch [47/50] - Train Loss: 1.0202, Test Loss: 1.5432\n",
      "Epoch [48/50] - Train Loss: 1.0266, Test Loss: 1.5343\n",
      "Epoch [49/50] - Train Loss: 1.0201, Test Loss: 1.4280\n",
      "Epoch [50/50] - Train Loss: 1.1069, Test Loss: 1.5295\n",
      "Avg Test Loss: 1.5295\n",
      "Testing combination: (32, 3, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1280, Test Loss: 1.6144\n",
      "Epoch [2/50] - Train Loss: 1.1169, Test Loss: 1.6107\n",
      "Epoch [3/50] - Train Loss: 1.1159, Test Loss: 1.6081\n",
      "Epoch [4/50] - Train Loss: 1.1150, Test Loss: 1.6077\n",
      "Epoch [5/50] - Train Loss: 1.1122, Test Loss: 1.6070\n",
      "Epoch [6/50] - Train Loss: 1.1093, Test Loss: 1.6041\n",
      "Epoch [7/50] - Train Loss: 1.1584, Test Loss: 1.6076\n",
      "Epoch [8/50] - Train Loss: 1.1166, Test Loss: 1.6126\n",
      "Epoch [9/50] - Train Loss: 1.1153, Test Loss: 1.6079\n",
      "Epoch [10/50] - Train Loss: 1.1141, Test Loss: 1.6046\n",
      "Epoch [11/50] - Train Loss: 1.1127, Test Loss: 1.6049\n",
      "Epoch [12/50] - Train Loss: 1.1100, Test Loss: 1.6053\n",
      "Epoch [13/50] - Train Loss: 1.1065, Test Loss: 1.6063\n",
      "Epoch [14/50] - Train Loss: 1.0986, Test Loss: 1.6104\n",
      "Epoch [15/50] - Train Loss: 1.0924, Test Loss: 1.6196\n",
      "Epoch [16/50] - Train Loss: 1.0860, Test Loss: 1.6113\n",
      "Epoch [17/50] - Train Loss: 1.0803, Test Loss: 1.6097\n",
      "Epoch [18/50] - Train Loss: 1.0820, Test Loss: 1.6169\n",
      "Epoch [19/50] - Train Loss: 1.1047, Test Loss: 1.6140\n",
      "Epoch [20/50] - Train Loss: 1.0804, Test Loss: 1.6096\n",
      "Epoch [21/50] - Train Loss: 1.0795, Test Loss: 1.6120\n",
      "Epoch [22/50] - Train Loss: 1.0795, Test Loss: 1.6136\n",
      "Epoch [23/50] - Train Loss: 1.0790, Test Loss: 1.6132\n",
      "Epoch [24/50] - Train Loss: 1.0788, Test Loss: 1.6127\n",
      "Epoch [25/50] - Train Loss: 1.0786, Test Loss: 1.6129\n",
      "Epoch [26/50] - Train Loss: 1.0785, Test Loss: 1.6132\n",
      "Epoch [27/50] - Train Loss: 1.0784, Test Loss: 1.6134\n",
      "Epoch [28/50] - Train Loss: 1.0783, Test Loss: 1.6134\n",
      "Epoch [29/50] - Train Loss: 1.0782, Test Loss: 1.6135\n",
      "Epoch [30/50] - Train Loss: 1.0781, Test Loss: 1.6134\n",
      "Epoch [31/50] - Train Loss: 1.0780, Test Loss: 1.6133\n",
      "Epoch [32/50] - Train Loss: 1.0778, Test Loss: 1.6129\n",
      "Epoch [33/50] - Train Loss: 1.0770, Test Loss: 1.6126\n",
      "Epoch [34/50] - Train Loss: 1.0778, Test Loss: 1.6154\n",
      "Epoch [35/50] - Train Loss: 1.0816, Test Loss: 1.6163\n",
      "Epoch [36/50] - Train Loss: 1.0789, Test Loss: 1.6104\n",
      "Epoch [37/50] - Train Loss: 1.0792, Test Loss: 1.6120\n",
      "Epoch [38/50] - Train Loss: 1.0790, Test Loss: 1.6140\n",
      "Epoch [39/50] - Train Loss: 1.0786, Test Loss: 1.6137\n",
      "Epoch [40/50] - Train Loss: 1.0785, Test Loss: 1.6133\n",
      "Epoch [41/50] - Train Loss: 1.0784, Test Loss: 1.6136\n",
      "Epoch [42/50] - Train Loss: 1.0783, Test Loss: 1.6138\n",
      "Epoch [43/50] - Train Loss: 1.0783, Test Loss: 1.6138\n",
      "Epoch [44/50] - Train Loss: 1.0782, Test Loss: 1.6138\n",
      "Epoch [45/50] - Train Loss: 1.0782, Test Loss: 1.6139\n",
      "Epoch [46/50] - Train Loss: 1.0782, Test Loss: 1.6139\n",
      "Epoch [47/50] - Train Loss: 1.0781, Test Loss: 1.6139\n",
      "Epoch [48/50] - Train Loss: 1.0781, Test Loss: 1.6139\n",
      "Epoch [49/50] - Train Loss: 1.0781, Test Loss: 1.6140\n",
      "Epoch [50/50] - Train Loss: 1.0781, Test Loss: 1.6140\n",
      "Avg Test Loss: 1.6140\n",
      "Testing combination: (32, 3, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3198, Test Loss: 2.6989\n",
      "Epoch [2/50] - Train Loss: 1.3059, Test Loss: 2.6843\n",
      "Epoch [3/50] - Train Loss: 1.3024, Test Loss: 2.6667\n",
      "Epoch [4/50] - Train Loss: 1.3000, Test Loss: 2.6586\n",
      "Epoch [5/50] - Train Loss: 1.2954, Test Loss: 2.6596\n",
      "Epoch [6/50] - Train Loss: 1.2886, Test Loss: 2.6654\n",
      "Epoch [7/50] - Train Loss: 1.2851, Test Loss: 2.6713\n",
      "Epoch [8/50] - Train Loss: 1.2772, Test Loss: 2.6701\n",
      "Epoch [9/50] - Train Loss: 1.2619, Test Loss: 2.6557\n",
      "Epoch [10/50] - Train Loss: 1.2538, Test Loss: 2.6454\n",
      "Epoch [11/50] - Train Loss: 1.2548, Test Loss: 2.6497\n",
      "Epoch [12/50] - Train Loss: 1.2524, Test Loss: 2.6529\n",
      "Epoch [13/50] - Train Loss: 1.2501, Test Loss: 2.6431\n",
      "Epoch [14/50] - Train Loss: 1.2534, Test Loss: 2.6473\n",
      "Epoch [15/50] - Train Loss: 1.2505, Test Loss: 2.6432\n",
      "Epoch [16/50] - Train Loss: 1.2513, Test Loss: 2.6360\n",
      "Epoch [17/50] - Train Loss: 1.2460, Test Loss: 2.6276\n",
      "Epoch [18/50] - Train Loss: 1.2429, Test Loss: 2.5851\n",
      "Epoch [19/50] - Train Loss: 1.2416, Test Loss: 2.8180\n",
      "Epoch [20/50] - Train Loss: 1.2921, Test Loss: 2.6490\n",
      "Epoch [21/50] - Train Loss: 1.2536, Test Loss: 2.6500\n",
      "Epoch [22/50] - Train Loss: 1.2702, Test Loss: 2.6525\n",
      "Epoch [23/50] - Train Loss: 1.2516, Test Loss: 2.6558\n",
      "Epoch [24/50] - Train Loss: 1.2492, Test Loss: 2.6557\n",
      "Epoch [25/50] - Train Loss: 1.2596, Test Loss: 2.6536\n",
      "Epoch [26/50] - Train Loss: 1.2469, Test Loss: 2.6442\n",
      "Epoch [27/50] - Train Loss: 1.2475, Test Loss: 2.6344\n",
      "Epoch [28/50] - Train Loss: 1.2463, Test Loss: 2.6351\n",
      "Epoch [29/50] - Train Loss: 1.2429, Test Loss: 2.6418\n",
      "Epoch [30/50] - Train Loss: 1.2419, Test Loss: 2.6449\n",
      "Epoch [31/50] - Train Loss: 1.2415, Test Loss: 2.6425\n",
      "Epoch [32/50] - Train Loss: 1.2408, Test Loss: 2.6409\n",
      "Epoch [33/50] - Train Loss: 1.2402, Test Loss: 2.6437\n",
      "Epoch [34/50] - Train Loss: 1.2399, Test Loss: 2.6475\n",
      "Epoch [35/50] - Train Loss: 1.2399, Test Loss: 2.6496\n",
      "Epoch [36/50] - Train Loss: 1.2398, Test Loss: 2.6493\n",
      "Epoch [37/50] - Train Loss: 1.2397, Test Loss: 2.6481\n",
      "Epoch [38/50] - Train Loss: 1.2397, Test Loss: 2.6475\n",
      "Epoch [39/50] - Train Loss: 1.2396, Test Loss: 2.6478\n",
      "Epoch [40/50] - Train Loss: 1.2396, Test Loss: 2.6482\n",
      "Epoch [41/50] - Train Loss: 1.2396, Test Loss: 2.6482\n",
      "Epoch [42/50] - Train Loss: 1.2396, Test Loss: 2.6478\n",
      "Epoch [43/50] - Train Loss: 1.2395, Test Loss: 2.6474\n",
      "Epoch [44/50] - Train Loss: 1.2395, Test Loss: 2.6471\n",
      "Epoch [45/50] - Train Loss: 1.2395, Test Loss: 2.6469\n",
      "Epoch [46/50] - Train Loss: 1.2395, Test Loss: 2.6467\n",
      "Epoch [47/50] - Train Loss: 1.2395, Test Loss: 2.6465\n",
      "Epoch [48/50] - Train Loss: 1.2395, Test Loss: 2.6463\n",
      "Epoch [49/50] - Train Loss: 1.2395, Test Loss: 2.6461\n",
      "Epoch [50/50] - Train Loss: 1.2394, Test Loss: 2.6459\n",
      "Avg Test Loss: 2.6459\n",
      "Testing combination: (32, 3, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1061, Test Loss: 1.5138\n",
      "Epoch [2/50] - Train Loss: 1.0984, Test Loss: 1.5017\n",
      "Epoch [3/50] - Train Loss: 1.0951, Test Loss: 1.4936\n",
      "Epoch [4/50] - Train Loss: 1.0937, Test Loss: 1.4889\n",
      "Epoch [5/50] - Train Loss: 1.0930, Test Loss: 1.4864\n",
      "Epoch [6/50] - Train Loss: 1.0924, Test Loss: 1.4853\n",
      "Epoch [7/50] - Train Loss: 1.0914, Test Loss: 1.4848\n",
      "Epoch [8/50] - Train Loss: 1.0903, Test Loss: 1.4845\n",
      "Epoch [9/50] - Train Loss: 1.0889, Test Loss: 1.4842\n",
      "Epoch [10/50] - Train Loss: 1.0871, Test Loss: 1.4839\n",
      "Epoch [11/50] - Train Loss: 1.0848, Test Loss: 1.4835\n",
      "Epoch [12/50] - Train Loss: 1.0821, Test Loss: 1.4831\n",
      "Epoch [13/50] - Train Loss: 1.0792, Test Loss: 1.4829\n",
      "Epoch [14/50] - Train Loss: 1.0758, Test Loss: 1.4828\n",
      "Epoch [15/50] - Train Loss: 1.0728, Test Loss: 1.4831\n",
      "Epoch [16/50] - Train Loss: 1.0681, Test Loss: 1.4834\n",
      "Epoch [17/50] - Train Loss: 1.0691, Test Loss: 1.4841\n",
      "Epoch [18/50] - Train Loss: 1.0633, Test Loss: 1.4849\n",
      "Epoch [19/50] - Train Loss: 1.0567, Test Loss: 1.4855\n",
      "Epoch [20/50] - Train Loss: 1.0549, Test Loss: 1.4863\n",
      "Epoch [21/50] - Train Loss: 1.0537, Test Loss: 1.4873\n",
      "Epoch [22/50] - Train Loss: 1.0532, Test Loss: 1.4879\n",
      "Epoch [23/50] - Train Loss: 1.0527, Test Loss: 1.4880\n",
      "Epoch [24/50] - Train Loss: 1.0525, Test Loss: 1.4880\n",
      "Epoch [25/50] - Train Loss: 1.0524, Test Loss: 1.4878\n",
      "Epoch [26/50] - Train Loss: 1.0522, Test Loss: 1.4876\n",
      "Epoch [27/50] - Train Loss: 1.0521, Test Loss: 1.4875\n",
      "Epoch [28/50] - Train Loss: 1.0520, Test Loss: 1.4874\n",
      "Epoch [29/50] - Train Loss: 1.0519, Test Loss: 1.4874\n",
      "Epoch [30/50] - Train Loss: 1.0517, Test Loss: 1.4873\n",
      "Epoch [31/50] - Train Loss: 1.0514, Test Loss: 1.4873\n",
      "Epoch [32/50] - Train Loss: 1.0511, Test Loss: 1.4872\n",
      "Epoch [33/50] - Train Loss: 1.0506, Test Loss: 1.4873\n",
      "Epoch [34/50] - Train Loss: 1.0499, Test Loss: 1.4877\n",
      "Epoch [35/50] - Train Loss: 1.0490, Test Loss: 1.4887\n",
      "Epoch [36/50] - Train Loss: 1.0474, Test Loss: 1.4895\n",
      "Epoch [37/50] - Train Loss: 1.0461, Test Loss: 1.4899\n",
      "Epoch [38/50] - Train Loss: 1.0407, Test Loss: 1.4824\n",
      "Epoch [39/50] - Train Loss: 1.0365, Test Loss: 1.4897\n",
      "Epoch [40/50] - Train Loss: 1.0725, Test Loss: 1.5227\n",
      "Epoch [41/50] - Train Loss: 1.0330, Test Loss: 1.4904\n",
      "Epoch [42/50] - Train Loss: 1.0425, Test Loss: 1.4922\n",
      "Epoch [43/50] - Train Loss: 1.0422, Test Loss: 1.4913\n",
      "Epoch [44/50] - Train Loss: 1.0348, Test Loss: 1.4771\n",
      "Epoch [45/50] - Train Loss: 1.0270, Test Loss: 1.4699\n",
      "Epoch [46/50] - Train Loss: 1.0285, Test Loss: 1.4912\n",
      "Epoch [47/50] - Train Loss: 1.0442, Test Loss: 1.4944\n",
      "Epoch [48/50] - Train Loss: 1.0383, Test Loss: 1.4831\n",
      "Epoch [49/50] - Train Loss: 1.0322, Test Loss: 1.4751\n",
      "Epoch [50/50] - Train Loss: 1.0553, Test Loss: 1.5703\n",
      "Avg Test Loss: 1.5703\n",
      "Testing combination: (32, 3, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1219, Test Loss: 1.6385\n",
      "Epoch [2/50] - Train Loss: 1.1165, Test Loss: 1.6229\n",
      "Epoch [3/50] - Train Loss: 1.1148, Test Loss: 1.6136\n",
      "Epoch [4/50] - Train Loss: 1.1145, Test Loss: 1.6089\n",
      "Epoch [5/50] - Train Loss: 1.1145, Test Loss: 1.6074\n",
      "Epoch [6/50] - Train Loss: 1.1145, Test Loss: 1.6074\n",
      "Epoch [7/50] - Train Loss: 1.1143, Test Loss: 1.6081\n",
      "Epoch [8/50] - Train Loss: 1.1141, Test Loss: 1.6086\n",
      "Epoch [9/50] - Train Loss: 1.1138, Test Loss: 1.6089\n",
      "Epoch [10/50] - Train Loss: 1.1135, Test Loss: 1.6089\n",
      "Epoch [11/50] - Train Loss: 1.1130, Test Loss: 1.6086\n",
      "Epoch [12/50] - Train Loss: 1.1123, Test Loss: 1.6081\n",
      "Epoch [13/50] - Train Loss: 1.1114, Test Loss: 1.6076\n",
      "Epoch [14/50] - Train Loss: 1.1101, Test Loss: 1.6070\n",
      "Epoch [15/50] - Train Loss: 1.1082, Test Loss: 1.6064\n",
      "Epoch [16/50] - Train Loss: 1.1060, Test Loss: 1.6060\n",
      "Epoch [17/50] - Train Loss: 1.1042, Test Loss: 1.6059\n",
      "Epoch [18/50] - Train Loss: 1.1010, Test Loss: 1.6066\n",
      "Epoch [19/50] - Train Loss: 1.0982, Test Loss: 1.6084\n",
      "Epoch [20/50] - Train Loss: 1.0909, Test Loss: 1.6103\n",
      "Epoch [21/50] - Train Loss: 1.0873, Test Loss: 1.6128\n",
      "Epoch [22/50] - Train Loss: 1.1167, Test Loss: 1.6134\n",
      "Epoch [23/50] - Train Loss: 1.0904, Test Loss: 1.6121\n",
      "Epoch [24/50] - Train Loss: 1.0827, Test Loss: 1.6126\n",
      "Epoch [25/50] - Train Loss: 1.0810, Test Loss: 1.6145\n",
      "Epoch [26/50] - Train Loss: 1.0791, Test Loss: 1.6158\n",
      "Epoch [27/50] - Train Loss: 1.0785, Test Loss: 1.6161\n",
      "Epoch [28/50] - Train Loss: 1.0781, Test Loss: 1.6157\n",
      "Epoch [29/50] - Train Loss: 1.0779, Test Loss: 1.6153\n",
      "Epoch [30/50] - Train Loss: 1.0778, Test Loss: 1.6152\n",
      "Epoch [31/50] - Train Loss: 1.0777, Test Loss: 1.6152\n",
      "Epoch [32/50] - Train Loss: 1.0775, Test Loss: 1.6152\n",
      "Epoch [33/50] - Train Loss: 1.0773, Test Loss: 1.6151\n",
      "Epoch [34/50] - Train Loss: 1.0770, Test Loss: 1.6149\n",
      "Epoch [35/50] - Train Loss: 1.0767, Test Loss: 1.6149\n",
      "Epoch [36/50] - Train Loss: 1.0763, Test Loss: 1.6152\n",
      "Epoch [37/50] - Train Loss: 1.0758, Test Loss: 1.6166\n",
      "Epoch [38/50] - Train Loss: 1.0754, Test Loss: 1.6189\n",
      "Epoch [39/50] - Train Loss: 1.0746, Test Loss: 1.6205\n",
      "Epoch [40/50] - Train Loss: 1.0739, Test Loss: 1.6209\n",
      "Epoch [41/50] - Train Loss: 1.0732, Test Loss: 1.6211\n",
      "Epoch [42/50] - Train Loss: 1.0725, Test Loss: 1.6210\n",
      "Epoch [43/50] - Train Loss: 1.0719, Test Loss: 1.6208\n",
      "Epoch [44/50] - Train Loss: 1.0712, Test Loss: 1.6204\n",
      "Epoch [45/50] - Train Loss: 1.0710, Test Loss: 1.6214\n",
      "Epoch [46/50] - Train Loss: 1.0705, Test Loss: 1.6212\n",
      "Epoch [47/50] - Train Loss: 1.0680, Test Loss: 1.6167\n",
      "Epoch [48/50] - Train Loss: 1.0626, Test Loss: 1.6075\n",
      "Epoch [49/50] - Train Loss: 1.0602, Test Loss: 1.6165\n",
      "Epoch [50/50] - Train Loss: 1.0622, Test Loss: 1.6173\n",
      "Avg Test Loss: 1.6173\n",
      "Testing combination: (32, 3, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3098, Test Loss: 2.6984\n",
      "Epoch [2/50] - Train Loss: 1.3045, Test Loss: 2.6829\n",
      "Epoch [3/50] - Train Loss: 1.3025, Test Loss: 2.6722\n",
      "Epoch [4/50] - Train Loss: 1.3016, Test Loss: 2.6652\n",
      "Epoch [5/50] - Train Loss: 1.3014, Test Loss: 2.6609\n",
      "Epoch [6/50] - Train Loss: 1.3013, Test Loss: 2.6587\n",
      "Epoch [7/50] - Train Loss: 1.3012, Test Loss: 2.6579\n",
      "Epoch [8/50] - Train Loss: 1.3010, Test Loss: 2.6582\n",
      "Epoch [9/50] - Train Loss: 1.3008, Test Loss: 2.6589\n",
      "Epoch [10/50] - Train Loss: 1.3004, Test Loss: 2.6599\n",
      "Epoch [11/50] - Train Loss: 1.2999, Test Loss: 2.6609\n",
      "Epoch [12/50] - Train Loss: 1.2994, Test Loss: 2.6618\n",
      "Epoch [13/50] - Train Loss: 1.2988, Test Loss: 2.6625\n",
      "Epoch [14/50] - Train Loss: 1.2980, Test Loss: 2.6631\n",
      "Epoch [15/50] - Train Loss: 1.2970, Test Loss: 2.6635\n",
      "Epoch [16/50] - Train Loss: 1.2959, Test Loss: 2.6639\n",
      "Epoch [17/50] - Train Loss: 1.2946, Test Loss: 2.6645\n",
      "Epoch [18/50] - Train Loss: 1.2931, Test Loss: 2.6654\n",
      "Epoch [19/50] - Train Loss: 1.2916, Test Loss: 2.6666\n",
      "Epoch [20/50] - Train Loss: 1.2900, Test Loss: 2.6679\n",
      "Epoch [21/50] - Train Loss: 1.2882, Test Loss: 2.6690\n",
      "Epoch [22/50] - Train Loss: 1.2863, Test Loss: 2.6695\n",
      "Epoch [23/50] - Train Loss: 1.2842, Test Loss: 2.6695\n",
      "Epoch [24/50] - Train Loss: 1.2815, Test Loss: 2.6689\n",
      "Epoch [25/50] - Train Loss: 1.2782, Test Loss: 2.6679\n",
      "Epoch [26/50] - Train Loss: 1.2773, Test Loss: 2.6662\n",
      "Epoch [27/50] - Train Loss: 1.2772, Test Loss: 2.6642\n",
      "Epoch [28/50] - Train Loss: 1.2715, Test Loss: 2.6629\n",
      "Epoch [29/50] - Train Loss: 1.2648, Test Loss: 2.6595\n",
      "Epoch [30/50] - Train Loss: 1.2631, Test Loss: 2.6575\n",
      "Epoch [31/50] - Train Loss: 1.2592, Test Loss: 2.6579\n",
      "Epoch [32/50] - Train Loss: 1.2574, Test Loss: 2.6584\n",
      "Epoch [33/50] - Train Loss: 1.2549, Test Loss: 2.6578\n",
      "Epoch [34/50] - Train Loss: 1.2542, Test Loss: 2.6574\n",
      "Epoch [35/50] - Train Loss: 1.2537, Test Loss: 2.6573\n",
      "Epoch [36/50] - Train Loss: 1.2536, Test Loss: 2.6570\n",
      "Epoch [37/50] - Train Loss: 1.2533, Test Loss: 2.6565\n",
      "Epoch [38/50] - Train Loss: 1.2531, Test Loss: 2.6565\n",
      "Epoch [39/50] - Train Loss: 1.2529, Test Loss: 2.6567\n",
      "Epoch [40/50] - Train Loss: 1.2527, Test Loss: 2.6567\n",
      "Epoch [41/50] - Train Loss: 1.2525, Test Loss: 2.6566\n",
      "Epoch [42/50] - Train Loss: 1.2524, Test Loss: 2.6563\n",
      "Epoch [43/50] - Train Loss: 1.2522, Test Loss: 2.6558\n",
      "Epoch [44/50] - Train Loss: 1.2520, Test Loss: 2.6552\n",
      "Epoch [45/50] - Train Loss: 1.2518, Test Loss: 2.6545\n",
      "Epoch [46/50] - Train Loss: 1.2516, Test Loss: 2.6539\n",
      "Epoch [47/50] - Train Loss: 1.2513, Test Loss: 2.6533\n",
      "Epoch [48/50] - Train Loss: 1.2511, Test Loss: 2.6528\n",
      "Epoch [49/50] - Train Loss: 1.2510, Test Loss: 2.6524\n",
      "Epoch [50/50] - Train Loss: 1.2509, Test Loss: 2.6519\n",
      "Avg Test Loss: 2.6519\n",
      "Testing combination: (32, 3, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.0992, Test Loss: 1.5095\n",
      "Epoch [2/50] - Train Loss: 1.0985, Test Loss: 1.5083\n",
      "Epoch [3/50] - Train Loss: 1.0981, Test Loss: 1.5072\n",
      "Epoch [4/50] - Train Loss: 1.0976, Test Loss: 1.5061\n",
      "Epoch [5/50] - Train Loss: 1.0973, Test Loss: 1.5050\n",
      "Epoch [6/50] - Train Loss: 1.0969, Test Loss: 1.5040\n",
      "Epoch [7/50] - Train Loss: 1.0966, Test Loss: 1.5031\n",
      "Epoch [8/50] - Train Loss: 1.0963, Test Loss: 1.5022\n",
      "Epoch [9/50] - Train Loss: 1.0960, Test Loss: 1.5014\n",
      "Epoch [10/50] - Train Loss: 1.0958, Test Loss: 1.5006\n",
      "Epoch [11/50] - Train Loss: 1.0955, Test Loss: 1.4999\n",
      "Epoch [12/50] - Train Loss: 1.0953, Test Loss: 1.4992\n",
      "Epoch [13/50] - Train Loss: 1.0951, Test Loss: 1.4985\n",
      "Epoch [14/50] - Train Loss: 1.0949, Test Loss: 1.4979\n",
      "Epoch [15/50] - Train Loss: 1.0947, Test Loss: 1.4973\n",
      "Epoch [16/50] - Train Loss: 1.0946, Test Loss: 1.4967\n",
      "Epoch [17/50] - Train Loss: 1.0944, Test Loss: 1.4962\n",
      "Epoch [18/50] - Train Loss: 1.0943, Test Loss: 1.4957\n",
      "Epoch [19/50] - Train Loss: 1.0941, Test Loss: 1.4952\n",
      "Epoch [20/50] - Train Loss: 1.0940, Test Loss: 1.4947\n",
      "Epoch [21/50] - Train Loss: 1.0939, Test Loss: 1.4943\n",
      "Epoch [22/50] - Train Loss: 1.0938, Test Loss: 1.4939\n",
      "Epoch [23/50] - Train Loss: 1.0937, Test Loss: 1.4935\n",
      "Epoch [24/50] - Train Loss: 1.0936, Test Loss: 1.4931\n",
      "Epoch [25/50] - Train Loss: 1.0935, Test Loss: 1.4927\n",
      "Epoch [26/50] - Train Loss: 1.0934, Test Loss: 1.4924\n",
      "Epoch [27/50] - Train Loss: 1.0933, Test Loss: 1.4921\n",
      "Epoch [28/50] - Train Loss: 1.0932, Test Loss: 1.4918\n",
      "Epoch [29/50] - Train Loss: 1.0931, Test Loss: 1.4915\n",
      "Epoch [30/50] - Train Loss: 1.0930, Test Loss: 1.4912\n",
      "Epoch [31/50] - Train Loss: 1.0929, Test Loss: 1.4909\n",
      "Epoch [32/50] - Train Loss: 1.0928, Test Loss: 1.4906\n",
      "Epoch [33/50] - Train Loss: 1.0927, Test Loss: 1.4904\n",
      "Epoch [34/50] - Train Loss: 1.0926, Test Loss: 1.4902\n",
      "Epoch [35/50] - Train Loss: 1.0925, Test Loss: 1.4899\n",
      "Epoch [36/50] - Train Loss: 1.0924, Test Loss: 1.4897\n",
      "Epoch [37/50] - Train Loss: 1.0923, Test Loss: 1.4895\n",
      "Epoch [38/50] - Train Loss: 1.0921, Test Loss: 1.4893\n",
      "Epoch [39/50] - Train Loss: 1.0920, Test Loss: 1.4891\n",
      "Epoch [40/50] - Train Loss: 1.0919, Test Loss: 1.4889\n",
      "Epoch [41/50] - Train Loss: 1.0918, Test Loss: 1.4887\n",
      "Epoch [42/50] - Train Loss: 1.0917, Test Loss: 1.4885\n",
      "Epoch [43/50] - Train Loss: 1.0916, Test Loss: 1.4884\n",
      "Epoch [44/50] - Train Loss: 1.0914, Test Loss: 1.4882\n",
      "Epoch [45/50] - Train Loss: 1.0913, Test Loss: 1.4880\n",
      "Epoch [46/50] - Train Loss: 1.0912, Test Loss: 1.4879\n",
      "Epoch [47/50] - Train Loss: 1.0911, Test Loss: 1.4877\n",
      "Epoch [48/50] - Train Loss: 1.0909, Test Loss: 1.4876\n",
      "Epoch [49/50] - Train Loss: 1.0908, Test Loss: 1.4874\n",
      "Epoch [50/50] - Train Loss: 1.0906, Test Loss: 1.4873\n",
      "Avg Test Loss: 1.4873\n",
      "Testing combination: (32, 3, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1221, Test Loss: 1.5839\n",
      "Epoch [2/50] - Train Loss: 1.1211, Test Loss: 1.5850\n",
      "Epoch [3/50] - Train Loss: 1.1203, Test Loss: 1.5860\n",
      "Epoch [4/50] - Train Loss: 1.1197, Test Loss: 1.5870\n",
      "Epoch [5/50] - Train Loss: 1.1191, Test Loss: 1.5880\n",
      "Epoch [6/50] - Train Loss: 1.1186, Test Loss: 1.5889\n",
      "Epoch [7/50] - Train Loss: 1.1181, Test Loss: 1.5899\n",
      "Epoch [8/50] - Train Loss: 1.1177, Test Loss: 1.5908\n",
      "Epoch [9/50] - Train Loss: 1.1173, Test Loss: 1.5917\n",
      "Epoch [10/50] - Train Loss: 1.1170, Test Loss: 1.5926\n",
      "Epoch [11/50] - Train Loss: 1.1167, Test Loss: 1.5934\n",
      "Epoch [12/50] - Train Loss: 1.1164, Test Loss: 1.5942\n",
      "Epoch [13/50] - Train Loss: 1.1162, Test Loss: 1.5950\n",
      "Epoch [14/50] - Train Loss: 1.1160, Test Loss: 1.5958\n",
      "Epoch [15/50] - Train Loss: 1.1158, Test Loss: 1.5965\n",
      "Epoch [16/50] - Train Loss: 1.1156, Test Loss: 1.5973\n",
      "Epoch [17/50] - Train Loss: 1.1155, Test Loss: 1.5980\n",
      "Epoch [18/50] - Train Loss: 1.1153, Test Loss: 1.5986\n",
      "Epoch [19/50] - Train Loss: 1.1152, Test Loss: 1.5993\n",
      "Epoch [20/50] - Train Loss: 1.1151, Test Loss: 1.5999\n",
      "Epoch [21/50] - Train Loss: 1.1150, Test Loss: 1.6004\n",
      "Epoch [22/50] - Train Loss: 1.1149, Test Loss: 1.6010\n",
      "Epoch [23/50] - Train Loss: 1.1148, Test Loss: 1.6015\n",
      "Epoch [24/50] - Train Loss: 1.1147, Test Loss: 1.6020\n",
      "Epoch [25/50] - Train Loss: 1.1147, Test Loss: 1.6025\n",
      "Epoch [26/50] - Train Loss: 1.1146, Test Loss: 1.6030\n",
      "Epoch [27/50] - Train Loss: 1.1146, Test Loss: 1.6034\n",
      "Epoch [28/50] - Train Loss: 1.1145, Test Loss: 1.6038\n",
      "Epoch [29/50] - Train Loss: 1.1145, Test Loss: 1.6042\n",
      "Epoch [30/50] - Train Loss: 1.1144, Test Loss: 1.6045\n",
      "Epoch [31/50] - Train Loss: 1.1144, Test Loss: 1.6049\n",
      "Epoch [32/50] - Train Loss: 1.1143, Test Loss: 1.6052\n",
      "Epoch [33/50] - Train Loss: 1.1143, Test Loss: 1.6055\n",
      "Epoch [34/50] - Train Loss: 1.1143, Test Loss: 1.6058\n",
      "Epoch [35/50] - Train Loss: 1.1142, Test Loss: 1.6061\n",
      "Epoch [36/50] - Train Loss: 1.1142, Test Loss: 1.6063\n",
      "Epoch [37/50] - Train Loss: 1.1142, Test Loss: 1.6065\n",
      "Epoch [38/50] - Train Loss: 1.1142, Test Loss: 1.6068\n",
      "Epoch [39/50] - Train Loss: 1.1141, Test Loss: 1.6070\n",
      "Epoch [40/50] - Train Loss: 1.1141, Test Loss: 1.6072\n",
      "Epoch [41/50] - Train Loss: 1.1141, Test Loss: 1.6074\n",
      "Epoch [42/50] - Train Loss: 1.1141, Test Loss: 1.6075\n",
      "Epoch [43/50] - Train Loss: 1.1140, Test Loss: 1.6077\n",
      "Epoch [44/50] - Train Loss: 1.1140, Test Loss: 1.6078\n",
      "Epoch [45/50] - Train Loss: 1.1140, Test Loss: 1.6080\n",
      "Epoch [46/50] - Train Loss: 1.1140, Test Loss: 1.6081\n",
      "Epoch [47/50] - Train Loss: 1.1139, Test Loss: 1.6082\n",
      "Epoch [48/50] - Train Loss: 1.1139, Test Loss: 1.6084\n",
      "Epoch [49/50] - Train Loss: 1.1139, Test Loss: 1.6085\n",
      "Epoch [50/50] - Train Loss: 1.1138, Test Loss: 1.6086\n",
      "Avg Test Loss: 1.6086\n",
      "Testing combination: (32, 3, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3298, Test Loss: 2.6283\n",
      "Epoch [2/50] - Train Loss: 1.3273, Test Loss: 2.6282\n",
      "Epoch [3/50] - Train Loss: 1.3252, Test Loss: 2.6281\n",
      "Epoch [4/50] - Train Loss: 1.3233, Test Loss: 2.6283\n",
      "Epoch [5/50] - Train Loss: 1.3215, Test Loss: 2.6285\n",
      "Epoch [6/50] - Train Loss: 1.3198, Test Loss: 2.6288\n",
      "Epoch [7/50] - Train Loss: 1.3182, Test Loss: 2.6292\n",
      "Epoch [8/50] - Train Loss: 1.3168, Test Loss: 2.6297\n",
      "Epoch [9/50] - Train Loss: 1.3154, Test Loss: 2.6303\n",
      "Epoch [10/50] - Train Loss: 1.3142, Test Loss: 2.6309\n",
      "Epoch [11/50] - Train Loss: 1.3131, Test Loss: 2.6316\n",
      "Epoch [12/50] - Train Loss: 1.3120, Test Loss: 2.6324\n",
      "Epoch [13/50] - Train Loss: 1.3110, Test Loss: 2.6332\n",
      "Epoch [14/50] - Train Loss: 1.3101, Test Loss: 2.6340\n",
      "Epoch [15/50] - Train Loss: 1.3093, Test Loss: 2.6349\n",
      "Epoch [16/50] - Train Loss: 1.3085, Test Loss: 2.6358\n",
      "Epoch [17/50] - Train Loss: 1.3078, Test Loss: 2.6367\n",
      "Epoch [18/50] - Train Loss: 1.3072, Test Loss: 2.6376\n",
      "Epoch [19/50] - Train Loss: 1.3066, Test Loss: 2.6386\n",
      "Epoch [20/50] - Train Loss: 1.3061, Test Loss: 2.6395\n",
      "Epoch [21/50] - Train Loss: 1.3056, Test Loss: 2.6405\n",
      "Epoch [22/50] - Train Loss: 1.3051, Test Loss: 2.6414\n",
      "Epoch [23/50] - Train Loss: 1.3047, Test Loss: 2.6424\n",
      "Epoch [24/50] - Train Loss: 1.3043, Test Loss: 2.6433\n",
      "Epoch [25/50] - Train Loss: 1.3040, Test Loss: 2.6443\n",
      "Epoch [26/50] - Train Loss: 1.3036, Test Loss: 2.6452\n",
      "Epoch [27/50] - Train Loss: 1.3034, Test Loss: 2.6461\n",
      "Epoch [28/50] - Train Loss: 1.3031, Test Loss: 2.6470\n",
      "Epoch [29/50] - Train Loss: 1.3029, Test Loss: 2.6478\n",
      "Epoch [30/50] - Train Loss: 1.3026, Test Loss: 2.6487\n",
      "Epoch [31/50] - Train Loss: 1.3024, Test Loss: 2.6495\n",
      "Epoch [32/50] - Train Loss: 1.3023, Test Loss: 2.6503\n",
      "Epoch [33/50] - Train Loss: 1.3021, Test Loss: 2.6511\n",
      "Epoch [34/50] - Train Loss: 1.3020, Test Loss: 2.6518\n",
      "Epoch [35/50] - Train Loss: 1.3018, Test Loss: 2.6525\n",
      "Epoch [36/50] - Train Loss: 1.3017, Test Loss: 2.6532\n",
      "Epoch [37/50] - Train Loss: 1.3016, Test Loss: 2.6538\n",
      "Epoch [38/50] - Train Loss: 1.3015, Test Loss: 2.6545\n",
      "Epoch [39/50] - Train Loss: 1.3014, Test Loss: 2.6551\n",
      "Epoch [40/50] - Train Loss: 1.3013, Test Loss: 2.6556\n",
      "Epoch [41/50] - Train Loss: 1.3012, Test Loss: 2.6562\n",
      "Epoch [42/50] - Train Loss: 1.3011, Test Loss: 2.6567\n",
      "Epoch [43/50] - Train Loss: 1.3010, Test Loss: 2.6571\n",
      "Epoch [44/50] - Train Loss: 1.3010, Test Loss: 2.6576\n",
      "Epoch [45/50] - Train Loss: 1.3009, Test Loss: 2.6580\n",
      "Epoch [46/50] - Train Loss: 1.3008, Test Loss: 2.6584\n",
      "Epoch [47/50] - Train Loss: 1.3008, Test Loss: 2.6588\n",
      "Epoch [48/50] - Train Loss: 1.3007, Test Loss: 2.6592\n",
      "Epoch [49/50] - Train Loss: 1.3006, Test Loss: 2.6596\n",
      "Epoch [50/50] - Train Loss: 1.3006, Test Loss: 2.6599\n",
      "Avg Test Loss: 2.6599\n",
      "Testing combination: (32, 4, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1493, Test Loss: 1.4828\n",
      "Epoch [2/50] - Train Loss: 1.0963, Test Loss: 1.4772\n",
      "Epoch [3/50] - Train Loss: 1.0980, Test Loss: 1.4793\n",
      "Epoch [4/50] - Train Loss: 1.0972, Test Loss: 1.4823\n",
      "Epoch [5/50] - Train Loss: 1.0964, Test Loss: 1.4842\n",
      "Epoch [6/50] - Train Loss: 1.0956, Test Loss: 1.4843\n",
      "Epoch [7/50] - Train Loss: 1.0935, Test Loss: 1.4837\n",
      "Epoch [8/50] - Train Loss: 1.0935, Test Loss: 1.4831\n",
      "Epoch [9/50] - Train Loss: 1.0849, Test Loss: 1.4832\n",
      "Epoch [10/50] - Train Loss: 1.0792, Test Loss: 1.4845\n",
      "Epoch [11/50] - Train Loss: 1.1063, Test Loss: 1.4829\n",
      "Epoch [12/50] - Train Loss: 1.0788, Test Loss: 1.4815\n",
      "Epoch [13/50] - Train Loss: 1.0905, Test Loss: 1.4846\n",
      "Epoch [14/50] - Train Loss: 1.0681, Test Loss: 1.4874\n",
      "Epoch [15/50] - Train Loss: 1.0672, Test Loss: 1.4886\n",
      "Epoch [16/50] - Train Loss: 1.0553, Test Loss: 1.4873\n",
      "Epoch [17/50] - Train Loss: 1.0552, Test Loss: 1.4845\n",
      "Epoch [18/50] - Train Loss: 1.0527, Test Loss: 1.4820\n",
      "Epoch [19/50] - Train Loss: 1.0513, Test Loss: 1.4848\n",
      "Epoch [20/50] - Train Loss: 1.0502, Test Loss: 1.4836\n",
      "Epoch [21/50] - Train Loss: 1.0501, Test Loss: 1.4868\n",
      "Epoch [22/50] - Train Loss: 1.0536, Test Loss: 1.4877\n",
      "Epoch [23/50] - Train Loss: 1.0533, Test Loss: 1.4863\n",
      "Epoch [24/50] - Train Loss: 1.0504, Test Loss: 1.4848\n",
      "Epoch [25/50] - Train Loss: 1.0493, Test Loss: 1.4853\n",
      "Epoch [26/50] - Train Loss: 1.0500, Test Loss: 1.4861\n",
      "Epoch [27/50] - Train Loss: 1.0506, Test Loss: 1.4819\n",
      "Epoch [28/50] - Train Loss: 1.0432, Test Loss: 1.4870\n",
      "Epoch [29/50] - Train Loss: 1.0439, Test Loss: 1.4857\n",
      "Epoch [30/50] - Train Loss: 1.0428, Test Loss: 1.4898\n",
      "Epoch [31/50] - Train Loss: 1.0448, Test Loss: 1.4844\n",
      "Epoch [32/50] - Train Loss: 1.0420, Test Loss: 1.4874\n",
      "Epoch [33/50] - Train Loss: 1.0419, Test Loss: 1.4877\n",
      "Epoch [34/50] - Train Loss: 1.0417, Test Loss: 1.4885\n",
      "Epoch [35/50] - Train Loss: 1.0415, Test Loss: 1.4891\n",
      "Epoch [36/50] - Train Loss: 1.0416, Test Loss: 1.4900\n",
      "Epoch [37/50] - Train Loss: 1.0412, Test Loss: 1.4897\n",
      "Epoch [38/50] - Train Loss: 1.0416, Test Loss: 1.4907\n",
      "Epoch [39/50] - Train Loss: 1.0410, Test Loss: 1.4896\n",
      "Epoch [40/50] - Train Loss: 1.0417, Test Loss: 1.4909\n",
      "Epoch [41/50] - Train Loss: 1.0408, Test Loss: 1.4894\n",
      "Epoch [42/50] - Train Loss: 1.0415, Test Loss: 1.4908\n",
      "Epoch [43/50] - Train Loss: 1.0408, Test Loss: 1.4897\n",
      "Epoch [44/50] - Train Loss: 1.0412, Test Loss: 1.4906\n",
      "Epoch [45/50] - Train Loss: 1.0409, Test Loss: 1.4901\n",
      "Epoch [46/50] - Train Loss: 1.0410, Test Loss: 1.4905\n",
      "Epoch [47/50] - Train Loss: 1.0409, Test Loss: 1.4902\n",
      "Epoch [48/50] - Train Loss: 1.0409, Test Loss: 1.4903\n",
      "Epoch [49/50] - Train Loss: 1.0408, Test Loss: 1.4901\n",
      "Epoch [50/50] - Train Loss: 1.0408, Test Loss: 1.4900\n",
      "Avg Test Loss: 1.4900\n",
      "Testing combination: (32, 4, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1310, Test Loss: 1.6261\n",
      "Epoch [2/50] - Train Loss: 1.1166, Test Loss: 1.6085\n",
      "Epoch [3/50] - Train Loss: 1.1159, Test Loss: 1.6058\n",
      "Epoch [4/50] - Train Loss: 1.1157, Test Loss: 1.6082\n",
      "Epoch [5/50] - Train Loss: 1.1155, Test Loss: 1.6102\n",
      "Epoch [6/50] - Train Loss: 1.1156, Test Loss: 1.6106\n",
      "Epoch [7/50] - Train Loss: 1.1155, Test Loss: 1.6097\n",
      "Epoch [8/50] - Train Loss: 1.1151, Test Loss: 1.6091\n",
      "Epoch [9/50] - Train Loss: 1.1129, Test Loss: 1.6078\n",
      "Epoch [10/50] - Train Loss: 1.1351, Test Loss: 1.6094\n",
      "Epoch [11/50] - Train Loss: 1.1146, Test Loss: 1.6118\n",
      "Epoch [12/50] - Train Loss: 1.1107, Test Loss: 1.6105\n",
      "Epoch [13/50] - Train Loss: 1.1018, Test Loss: 1.6136\n",
      "Epoch [14/50] - Train Loss: 1.0928, Test Loss: 1.6126\n",
      "Epoch [15/50] - Train Loss: 1.0817, Test Loss: 1.6137\n",
      "Epoch [16/50] - Train Loss: 1.0934, Test Loss: 1.6000\n",
      "Epoch [17/50] - Train Loss: 1.0873, Test Loss: 1.6189\n",
      "Epoch [18/50] - Train Loss: 1.0977, Test Loss: 1.6164\n",
      "Epoch [19/50] - Train Loss: 1.0874, Test Loss: 1.6146\n",
      "Epoch [20/50] - Train Loss: 1.0765, Test Loss: 1.6067\n",
      "Epoch [21/50] - Train Loss: 1.0816, Test Loss: 1.6204\n",
      "Epoch [22/50] - Train Loss: 1.0752, Test Loss: 1.6222\n",
      "Epoch [23/50] - Train Loss: 1.0731, Test Loss: 1.6217\n",
      "Epoch [24/50] - Train Loss: 1.0722, Test Loss: 1.6226\n",
      "Epoch [25/50] - Train Loss: 1.0713, Test Loss: 1.6230\n",
      "Epoch [26/50] - Train Loss: 1.0676, Test Loss: 1.6181\n",
      "Epoch [27/50] - Train Loss: 1.0758, Test Loss: 1.6213\n",
      "Epoch [28/50] - Train Loss: 1.0797, Test Loss: 1.6230\n",
      "Epoch [29/50] - Train Loss: 1.0720, Test Loss: 1.6109\n",
      "Epoch [30/50] - Train Loss: 1.0759, Test Loss: 1.6100\n",
      "Epoch [31/50] - Train Loss: 1.0723, Test Loss: 1.6114\n",
      "Epoch [32/50] - Train Loss: 1.0739, Test Loss: 1.6135\n",
      "Epoch [33/50] - Train Loss: 1.0690, Test Loss: 1.5783\n",
      "Epoch [34/50] - Train Loss: 1.0737, Test Loss: 1.7153\n",
      "Epoch [35/50] - Train Loss: 1.0722, Test Loss: 1.5833\n",
      "Epoch [36/50] - Train Loss: 1.0715, Test Loss: 1.6123\n",
      "Epoch [37/50] - Train Loss: 1.0437, Test Loss: 1.5657\n",
      "Epoch [38/50] - Train Loss: 1.0547, Test Loss: 1.5693\n",
      "Epoch [39/50] - Train Loss: 1.0497, Test Loss: 1.5084\n",
      "Epoch [40/50] - Train Loss: 1.0789, Test Loss: 1.5743\n",
      "Epoch [41/50] - Train Loss: 1.0601, Test Loss: 1.5728\n",
      "Epoch [42/50] - Train Loss: 1.0397, Test Loss: 1.6267\n",
      "Epoch [43/50] - Train Loss: 1.0163, Test Loss: 1.6895\n",
      "Epoch [44/50] - Train Loss: 1.0341, Test Loss: 1.7432\n",
      "Epoch [45/50] - Train Loss: 0.9943, Test Loss: 1.7023\n",
      "Epoch [46/50] - Train Loss: 0.9409, Test Loss: 1.6199\n",
      "Epoch [47/50] - Train Loss: 0.9959, Test Loss: 1.4576\n",
      "Epoch [48/50] - Train Loss: 1.0777, Test Loss: 1.6167\n",
      "Epoch [49/50] - Train Loss: 1.0173, Test Loss: 2.0773\n",
      "Epoch [50/50] - Train Loss: 1.0489, Test Loss: 1.5966\n",
      "Avg Test Loss: 1.5966\n",
      "Testing combination: (32, 4, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3183, Test Loss: 2.6897\n",
      "Epoch [2/50] - Train Loss: 1.3039, Test Loss: 2.6614\n",
      "Epoch [3/50] - Train Loss: 1.3028, Test Loss: 2.6545\n",
      "Epoch [4/50] - Train Loss: 1.3029, Test Loss: 2.6557\n",
      "Epoch [5/50] - Train Loss: 1.3024, Test Loss: 2.6601\n",
      "Epoch [6/50] - Train Loss: 1.3012, Test Loss: 2.6652\n",
      "Epoch [7/50] - Train Loss: 1.2983, Test Loss: 2.6699\n",
      "Epoch [8/50] - Train Loss: 1.2921, Test Loss: 2.6737\n",
      "Epoch [9/50] - Train Loss: 1.2877, Test Loss: 2.6739\n",
      "Epoch [10/50] - Train Loss: 1.2800, Test Loss: 2.6657\n",
      "Epoch [11/50] - Train Loss: 1.2738, Test Loss: 2.6609\n",
      "Epoch [12/50] - Train Loss: 1.2656, Test Loss: 2.6556\n",
      "Epoch [13/50] - Train Loss: 1.2645, Test Loss: 2.6526\n",
      "Epoch [14/50] - Train Loss: 1.2614, Test Loss: 2.6645\n",
      "Epoch [15/50] - Train Loss: 1.2554, Test Loss: 2.6704\n",
      "Epoch [16/50] - Train Loss: 1.2554, Test Loss: 2.6606\n",
      "Epoch [17/50] - Train Loss: 1.2549, Test Loss: 2.6554\n",
      "Epoch [18/50] - Train Loss: 1.2544, Test Loss: 2.6586\n",
      "Epoch [19/50] - Train Loss: 1.2541, Test Loss: 2.6627\n",
      "Epoch [20/50] - Train Loss: 1.2538, Test Loss: 2.6615\n",
      "Epoch [21/50] - Train Loss: 1.2530, Test Loss: 2.6553\n",
      "Epoch [22/50] - Train Loss: 1.2528, Test Loss: 2.6480\n",
      "Epoch [23/50] - Train Loss: 1.2509, Test Loss: 2.6458\n",
      "Epoch [24/50] - Train Loss: 1.2506, Test Loss: 2.6478\n",
      "Epoch [25/50] - Train Loss: 1.2497, Test Loss: 2.6460\n",
      "Epoch [26/50] - Train Loss: 1.2474, Test Loss: 2.6434\n",
      "Epoch [27/50] - Train Loss: 1.2483, Test Loss: 2.6382\n",
      "Epoch [28/50] - Train Loss: 1.2453, Test Loss: 2.6402\n",
      "Epoch [29/50] - Train Loss: 1.2466, Test Loss: 2.6372\n",
      "Epoch [30/50] - Train Loss: 1.2436, Test Loss: 2.6470\n",
      "Epoch [31/50] - Train Loss: 1.2448, Test Loss: 2.6472\n",
      "Epoch [32/50] - Train Loss: 1.2408, Test Loss: 2.6565\n",
      "Epoch [33/50] - Train Loss: 1.2401, Test Loss: 2.6572\n",
      "Epoch [34/50] - Train Loss: 1.2397, Test Loss: 2.6526\n",
      "Epoch [35/50] - Train Loss: 1.2401, Test Loss: 2.6499\n",
      "Epoch [36/50] - Train Loss: 1.2404, Test Loss: 2.6464\n",
      "Epoch [37/50] - Train Loss: 1.2398, Test Loss: 2.6530\n",
      "Epoch [38/50] - Train Loss: 1.2391, Test Loss: 2.6568\n",
      "Epoch [39/50] - Train Loss: 1.2433, Test Loss: 2.6538\n",
      "Epoch [40/50] - Train Loss: 1.2391, Test Loss: 2.6371\n",
      "Epoch [41/50] - Train Loss: 1.2439, Test Loss: 2.6437\n",
      "Epoch [42/50] - Train Loss: 1.2423, Test Loss: 2.6728\n",
      "Epoch [43/50] - Train Loss: 1.2351, Test Loss: 2.7138\n",
      "Epoch [44/50] - Train Loss: 1.2816, Test Loss: 2.6524\n",
      "Epoch [45/50] - Train Loss: 1.2625, Test Loss: 2.6209\n",
      "Epoch [46/50] - Train Loss: 1.2669, Test Loss: 2.6412\n",
      "Epoch [47/50] - Train Loss: 1.2489, Test Loss: 2.6458\n",
      "Epoch [48/50] - Train Loss: 1.2477, Test Loss: 2.6286\n",
      "Epoch [49/50] - Train Loss: 1.2522, Test Loss: 2.6317\n",
      "Epoch [50/50] - Train Loss: 1.2487, Test Loss: 2.6496\n",
      "Avg Test Loss: 2.6496\n",
      "Testing combination: (32, 4, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1189, Test Loss: 1.5332\n",
      "Epoch [2/50] - Train Loss: 1.1038, Test Loss: 1.5113\n",
      "Epoch [3/50] - Train Loss: 1.0971, Test Loss: 1.4979\n",
      "Epoch [4/50] - Train Loss: 1.0946, Test Loss: 1.4904\n",
      "Epoch [5/50] - Train Loss: 1.0942, Test Loss: 1.4868\n",
      "Epoch [6/50] - Train Loss: 1.0943, Test Loss: 1.4855\n",
      "Epoch [7/50] - Train Loss: 1.0942, Test Loss: 1.4853\n",
      "Epoch [8/50] - Train Loss: 1.0941, Test Loss: 1.4854\n",
      "Epoch [9/50] - Train Loss: 1.0938, Test Loss: 1.4855\n",
      "Epoch [10/50] - Train Loss: 1.0934, Test Loss: 1.4854\n",
      "Epoch [11/50] - Train Loss: 1.0929, Test Loss: 1.4853\n",
      "Epoch [12/50] - Train Loss: 1.0922, Test Loss: 1.4851\n",
      "Epoch [13/50] - Train Loss: 1.0911, Test Loss: 1.4848\n",
      "Epoch [14/50] - Train Loss: 1.0895, Test Loss: 1.4844\n",
      "Epoch [15/50] - Train Loss: 1.0875, Test Loss: 1.4840\n",
      "Epoch [16/50] - Train Loss: 1.0856, Test Loss: 1.4836\n",
      "Epoch [17/50] - Train Loss: 1.0831, Test Loss: 1.4831\n",
      "Epoch [18/50] - Train Loss: 1.0817, Test Loss: 1.4828\n",
      "Epoch [19/50] - Train Loss: 1.0852, Test Loss: 1.4826\n",
      "Epoch [20/50] - Train Loss: 1.0939, Test Loss: 1.4831\n",
      "Epoch [21/50] - Train Loss: 1.0818, Test Loss: 1.4836\n",
      "Epoch [22/50] - Train Loss: 1.0801, Test Loss: 1.4834\n",
      "Epoch [23/50] - Train Loss: 1.0772, Test Loss: 1.4830\n",
      "Epoch [24/50] - Train Loss: 1.0747, Test Loss: 1.4829\n",
      "Epoch [25/50] - Train Loss: 1.0712, Test Loss: 1.4834\n",
      "Epoch [26/50] - Train Loss: 1.0663, Test Loss: 1.4843\n",
      "Epoch [27/50] - Train Loss: 1.0613, Test Loss: 1.4855\n",
      "Epoch [28/50] - Train Loss: 1.0588, Test Loss: 1.4871\n",
      "Epoch [29/50] - Train Loss: 1.0567, Test Loss: 1.4885\n",
      "Epoch [30/50] - Train Loss: 1.0543, Test Loss: 1.4887\n",
      "Epoch [31/50] - Train Loss: 1.0531, Test Loss: 1.4882\n",
      "Epoch [32/50] - Train Loss: 1.0524, Test Loss: 1.4877\n",
      "Epoch [33/50] - Train Loss: 1.0519, Test Loss: 1.4873\n",
      "Epoch [34/50] - Train Loss: 1.0513, Test Loss: 1.4870\n",
      "Epoch [35/50] - Train Loss: 1.0507, Test Loss: 1.4869\n",
      "Epoch [36/50] - Train Loss: 1.0510, Test Loss: 1.4875\n",
      "Epoch [37/50] - Train Loss: 1.0496, Test Loss: 1.4890\n",
      "Epoch [38/50] - Train Loss: 1.0489, Test Loss: 1.4900\n",
      "Epoch [39/50] - Train Loss: 1.0490, Test Loss: 1.4905\n",
      "Epoch [40/50] - Train Loss: 1.0472, Test Loss: 1.4904\n",
      "Epoch [41/50] - Train Loss: 1.0460, Test Loss: 1.4897\n",
      "Epoch [42/50] - Train Loss: 1.0450, Test Loss: 1.4885\n",
      "Epoch [43/50] - Train Loss: 1.0428, Test Loss: 1.4854\n",
      "Epoch [44/50] - Train Loss: 1.0435, Test Loss: 1.4781\n",
      "Epoch [45/50] - Train Loss: 1.0354, Test Loss: 1.4756\n",
      "Epoch [46/50] - Train Loss: 1.0335, Test Loss: 1.4785\n",
      "Epoch [47/50] - Train Loss: 1.0811, Test Loss: 1.4640\n",
      "Epoch [48/50] - Train Loss: 1.0534, Test Loss: 1.4869\n",
      "Epoch [49/50] - Train Loss: 1.0436, Test Loss: 1.4938\n",
      "Epoch [50/50] - Train Loss: 1.0409, Test Loss: 1.4864\n",
      "Avg Test Loss: 1.4864\n",
      "Testing combination: (32, 4, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1361, Test Loss: 1.5838\n",
      "Epoch [2/50] - Train Loss: 1.1196, Test Loss: 1.6018\n",
      "Epoch [3/50] - Train Loss: 1.1162, Test Loss: 1.6140\n",
      "Epoch [4/50] - Train Loss: 1.1156, Test Loss: 1.6163\n",
      "Epoch [5/50] - Train Loss: 1.1152, Test Loss: 1.6135\n",
      "Epoch [6/50] - Train Loss: 1.1148, Test Loss: 1.6104\n",
      "Epoch [7/50] - Train Loss: 1.1148, Test Loss: 1.6085\n",
      "Epoch [8/50] - Train Loss: 1.1148, Test Loss: 1.6080\n",
      "Epoch [9/50] - Train Loss: 1.1148, Test Loss: 1.6081\n",
      "Epoch [10/50] - Train Loss: 1.1148, Test Loss: 1.6086\n",
      "Epoch [11/50] - Train Loss: 1.1147, Test Loss: 1.6090\n",
      "Epoch [12/50] - Train Loss: 1.1146, Test Loss: 1.6092\n",
      "Epoch [13/50] - Train Loss: 1.1144, Test Loss: 1.6093\n",
      "Epoch [14/50] - Train Loss: 1.1141, Test Loss: 1.6092\n",
      "Epoch [15/50] - Train Loss: 1.1138, Test Loss: 1.6092\n",
      "Epoch [16/50] - Train Loss: 1.1132, Test Loss: 1.6093\n",
      "Epoch [17/50] - Train Loss: 1.1121, Test Loss: 1.6095\n",
      "Epoch [18/50] - Train Loss: 1.1097, Test Loss: 1.6101\n",
      "Epoch [19/50] - Train Loss: 1.1058, Test Loss: 1.6115\n",
      "Epoch [20/50] - Train Loss: 1.1011, Test Loss: 1.6137\n",
      "Epoch [21/50] - Train Loss: 1.0951, Test Loss: 1.6153\n",
      "Epoch [22/50] - Train Loss: 1.0890, Test Loss: 1.6187\n",
      "Epoch [23/50] - Train Loss: 1.0849, Test Loss: 1.6221\n",
      "Epoch [24/50] - Train Loss: 1.1135, Test Loss: 1.6195\n",
      "Epoch [25/50] - Train Loss: 1.1085, Test Loss: 1.6176\n",
      "Epoch [26/50] - Train Loss: 1.1006, Test Loss: 1.6189\n",
      "Epoch [27/50] - Train Loss: 1.1021, Test Loss: 1.6173\n",
      "Epoch [28/50] - Train Loss: 1.1052, Test Loss: 1.6161\n",
      "Epoch [29/50] - Train Loss: 1.1053, Test Loss: 1.6190\n",
      "Epoch [30/50] - Train Loss: 1.1040, Test Loss: 1.6207\n",
      "Epoch [31/50] - Train Loss: 1.1028, Test Loss: 1.6211\n",
      "Epoch [32/50] - Train Loss: 1.1018, Test Loss: 1.6215\n",
      "Epoch [33/50] - Train Loss: 1.1003, Test Loss: 1.6214\n",
      "Epoch [34/50] - Train Loss: 1.0950, Test Loss: 1.6205\n",
      "Epoch [35/50] - Train Loss: 1.0841, Test Loss: 1.6214\n",
      "Epoch [36/50] - Train Loss: 1.0779, Test Loss: 1.6196\n",
      "Epoch [37/50] - Train Loss: 1.0734, Test Loss: 1.6135\n",
      "Epoch [38/50] - Train Loss: 1.0785, Test Loss: 1.6102\n",
      "Epoch [39/50] - Train Loss: 1.1052, Test Loss: 1.6351\n",
      "Epoch [40/50] - Train Loss: 1.0859, Test Loss: 1.6290\n",
      "Epoch [41/50] - Train Loss: 1.0730, Test Loss: 1.6144\n",
      "Epoch [42/50] - Train Loss: 1.0706, Test Loss: 1.6172\n",
      "Epoch [43/50] - Train Loss: 1.0934, Test Loss: 1.6446\n",
      "Epoch [44/50] - Train Loss: 1.0633, Test Loss: 1.6243\n",
      "Epoch [45/50] - Train Loss: 1.0904, Test Loss: 1.6216\n",
      "Epoch [46/50] - Train Loss: 1.0694, Test Loss: 1.5983\n",
      "Epoch [47/50] - Train Loss: 1.0845, Test Loss: 1.6100\n",
      "Epoch [48/50] - Train Loss: 1.0782, Test Loss: 1.6279\n",
      "Epoch [49/50] - Train Loss: 1.0756, Test Loss: 1.6171\n",
      "Epoch [50/50] - Train Loss: 1.0836, Test Loss: 1.6301\n",
      "Avg Test Loss: 1.6301\n",
      "Testing combination: (32, 4, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3041, Test Loss: 2.6529\n",
      "Epoch [2/50] - Train Loss: 1.3027, Test Loss: 2.6574\n",
      "Epoch [3/50] - Train Loss: 1.3021, Test Loss: 2.6609\n",
      "Epoch [4/50] - Train Loss: 1.3019, Test Loss: 2.6634\n",
      "Epoch [5/50] - Train Loss: 1.3017, Test Loss: 2.6648\n",
      "Epoch [6/50] - Train Loss: 1.3016, Test Loss: 2.6655\n",
      "Epoch [7/50] - Train Loss: 1.3015, Test Loss: 2.6655\n",
      "Epoch [8/50] - Train Loss: 1.3013, Test Loss: 2.6653\n",
      "Epoch [9/50] - Train Loss: 1.3011, Test Loss: 2.6649\n",
      "Epoch [10/50] - Train Loss: 1.3008, Test Loss: 2.6645\n",
      "Epoch [11/50] - Train Loss: 1.3004, Test Loss: 2.6642\n",
      "Epoch [12/50] - Train Loss: 1.3000, Test Loss: 2.6641\n",
      "Epoch [13/50] - Train Loss: 1.2993, Test Loss: 2.6642\n",
      "Epoch [14/50] - Train Loss: 1.2985, Test Loss: 2.6646\n",
      "Epoch [15/50] - Train Loss: 1.2975, Test Loss: 2.6652\n",
      "Epoch [16/50] - Train Loss: 1.2960, Test Loss: 2.6660\n",
      "Epoch [17/50] - Train Loss: 1.2942, Test Loss: 2.6669\n",
      "Epoch [18/50] - Train Loss: 1.2920, Test Loss: 2.6680\n",
      "Epoch [19/50] - Train Loss: 1.2898, Test Loss: 2.6689\n",
      "Epoch [20/50] - Train Loss: 1.2883, Test Loss: 2.6697\n",
      "Epoch [21/50] - Train Loss: 1.2876, Test Loss: 2.6700\n",
      "Epoch [22/50] - Train Loss: 1.2874, Test Loss: 2.6701\n",
      "Epoch [23/50] - Train Loss: 1.2887, Test Loss: 2.6695\n",
      "Epoch [24/50] - Train Loss: 1.2868, Test Loss: 2.6684\n",
      "Epoch [25/50] - Train Loss: 1.2832, Test Loss: 2.6674\n",
      "Epoch [26/50] - Train Loss: 1.2836, Test Loss: 2.6656\n",
      "Epoch [27/50] - Train Loss: 1.2795, Test Loss: 2.6633\n",
      "Epoch [28/50] - Train Loss: 1.2758, Test Loss: 2.6611\n",
      "Epoch [29/50] - Train Loss: 1.2701, Test Loss: 2.6586\n",
      "Epoch [30/50] - Train Loss: 1.2648, Test Loss: 2.6556\n",
      "Epoch [31/50] - Train Loss: 1.2599, Test Loss: 2.6533\n",
      "Epoch [32/50] - Train Loss: 1.2566, Test Loss: 2.6525\n",
      "Epoch [33/50] - Train Loss: 1.2569, Test Loss: 2.6530\n",
      "Epoch [34/50] - Train Loss: 1.2549, Test Loss: 2.6539\n",
      "Epoch [35/50] - Train Loss: 1.2945, Test Loss: 2.6550\n",
      "Epoch [36/50] - Train Loss: 1.2581, Test Loss: 2.6544\n",
      "Epoch [37/50] - Train Loss: 1.2996, Test Loss: 2.6541\n",
      "Epoch [38/50] - Train Loss: 1.2819, Test Loss: 2.6545\n",
      "Epoch [39/50] - Train Loss: 1.2691, Test Loss: 2.6548\n",
      "Epoch [40/50] - Train Loss: 1.2690, Test Loss: 2.6552\n",
      "Epoch [41/50] - Train Loss: 1.2682, Test Loss: 2.6558\n",
      "Epoch [42/50] - Train Loss: 1.2641, Test Loss: 2.6564\n",
      "Epoch [43/50] - Train Loss: 1.2591, Test Loss: 2.6563\n",
      "Epoch [44/50] - Train Loss: 1.2558, Test Loss: 2.6552\n",
      "Epoch [45/50] - Train Loss: 1.2542, Test Loss: 2.6534\n",
      "Epoch [46/50] - Train Loss: 1.2535, Test Loss: 2.6515\n",
      "Epoch [47/50] - Train Loss: 1.2530, Test Loss: 2.6500\n",
      "Epoch [48/50] - Train Loss: 1.2526, Test Loss: 2.6496\n",
      "Epoch [49/50] - Train Loss: 1.2523, Test Loss: 2.6501\n",
      "Epoch [50/50] - Train Loss: 1.2520, Test Loss: 2.6510\n",
      "Avg Test Loss: 2.6510\n",
      "Testing combination: (32, 4, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1343, Test Loss: 1.4829\n",
      "Epoch [2/50] - Train Loss: 1.1312, Test Loss: 1.4815\n",
      "Epoch [3/50] - Train Loss: 1.1287, Test Loss: 1.4803\n",
      "Epoch [4/50] - Train Loss: 1.1263, Test Loss: 1.4792\n",
      "Epoch [5/50] - Train Loss: 1.1240, Test Loss: 1.4782\n",
      "Epoch [6/50] - Train Loss: 1.1218, Test Loss: 1.4774\n",
      "Epoch [7/50] - Train Loss: 1.1197, Test Loss: 1.4766\n",
      "Epoch [8/50] - Train Loss: 1.1178, Test Loss: 1.4759\n",
      "Epoch [9/50] - Train Loss: 1.1159, Test Loss: 1.4752\n",
      "Epoch [10/50] - Train Loss: 1.1140, Test Loss: 1.4747\n",
      "Epoch [11/50] - Train Loss: 1.1123, Test Loss: 1.4743\n",
      "Epoch [12/50] - Train Loss: 1.1106, Test Loss: 1.4739\n",
      "Epoch [13/50] - Train Loss: 1.1090, Test Loss: 1.4736\n",
      "Epoch [14/50] - Train Loss: 1.1075, Test Loss: 1.4735\n",
      "Epoch [15/50] - Train Loss: 1.1061, Test Loss: 1.4734\n",
      "Epoch [16/50] - Train Loss: 1.1048, Test Loss: 1.4734\n",
      "Epoch [17/50] - Train Loss: 1.1035, Test Loss: 1.4734\n",
      "Epoch [18/50] - Train Loss: 1.1024, Test Loss: 1.4736\n",
      "Epoch [19/50] - Train Loss: 1.1013, Test Loss: 1.4738\n",
      "Epoch [20/50] - Train Loss: 1.1003, Test Loss: 1.4741\n",
      "Epoch [21/50] - Train Loss: 1.0994, Test Loss: 1.4744\n",
      "Epoch [22/50] - Train Loss: 1.0985, Test Loss: 1.4748\n",
      "Epoch [23/50] - Train Loss: 1.0978, Test Loss: 1.4752\n",
      "Epoch [24/50] - Train Loss: 1.0971, Test Loss: 1.4757\n",
      "Epoch [25/50] - Train Loss: 1.0965, Test Loss: 1.4762\n",
      "Epoch [26/50] - Train Loss: 1.0960, Test Loss: 1.4768\n",
      "Epoch [27/50] - Train Loss: 1.0955, Test Loss: 1.4773\n",
      "Epoch [28/50] - Train Loss: 1.0951, Test Loss: 1.4778\n",
      "Epoch [29/50] - Train Loss: 1.0948, Test Loss: 1.4784\n",
      "Epoch [30/50] - Train Loss: 1.0944, Test Loss: 1.4789\n",
      "Epoch [31/50] - Train Loss: 1.0942, Test Loss: 1.4794\n",
      "Epoch [32/50] - Train Loss: 1.0940, Test Loss: 1.4799\n",
      "Epoch [33/50] - Train Loss: 1.0938, Test Loss: 1.4804\n",
      "Epoch [34/50] - Train Loss: 1.0936, Test Loss: 1.4808\n",
      "Epoch [35/50] - Train Loss: 1.0934, Test Loss: 1.4813\n",
      "Epoch [36/50] - Train Loss: 1.0933, Test Loss: 1.4816\n",
      "Epoch [37/50] - Train Loss: 1.0932, Test Loss: 1.4820\n",
      "Epoch [38/50] - Train Loss: 1.0931, Test Loss: 1.4823\n",
      "Epoch [39/50] - Train Loss: 1.0930, Test Loss: 1.4827\n",
      "Epoch [40/50] - Train Loss: 1.0929, Test Loss: 1.4829\n",
      "Epoch [41/50] - Train Loss: 1.0929, Test Loss: 1.4832\n",
      "Epoch [42/50] - Train Loss: 1.0928, Test Loss: 1.4834\n",
      "Epoch [43/50] - Train Loss: 1.0927, Test Loss: 1.4836\n",
      "Epoch [44/50] - Train Loss: 1.0927, Test Loss: 1.4838\n",
      "Epoch [45/50] - Train Loss: 1.0926, Test Loss: 1.4840\n",
      "Epoch [46/50] - Train Loss: 1.0926, Test Loss: 1.4842\n",
      "Epoch [47/50] - Train Loss: 1.0925, Test Loss: 1.4843\n",
      "Epoch [48/50] - Train Loss: 1.0925, Test Loss: 1.4844\n",
      "Epoch [49/50] - Train Loss: 1.0924, Test Loss: 1.4846\n",
      "Epoch [50/50] - Train Loss: 1.0924, Test Loss: 1.4847\n",
      "Avg Test Loss: 1.4847\n",
      "Testing combination: (32, 4, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1194, Test Loss: 1.5879\n",
      "Epoch [2/50] - Train Loss: 1.1186, Test Loss: 1.5891\n",
      "Epoch [3/50] - Train Loss: 1.1180, Test Loss: 1.5902\n",
      "Epoch [4/50] - Train Loss: 1.1176, Test Loss: 1.5913\n",
      "Epoch [5/50] - Train Loss: 1.1172, Test Loss: 1.5923\n",
      "Epoch [6/50] - Train Loss: 1.1168, Test Loss: 1.5933\n",
      "Epoch [7/50] - Train Loss: 1.1165, Test Loss: 1.5943\n",
      "Epoch [8/50] - Train Loss: 1.1162, Test Loss: 1.5952\n",
      "Epoch [9/50] - Train Loss: 1.1160, Test Loss: 1.5961\n",
      "Epoch [10/50] - Train Loss: 1.1158, Test Loss: 1.5969\n",
      "Epoch [11/50] - Train Loss: 1.1156, Test Loss: 1.5977\n",
      "Epoch [12/50] - Train Loss: 1.1154, Test Loss: 1.5985\n",
      "Epoch [13/50] - Train Loss: 1.1153, Test Loss: 1.5992\n",
      "Epoch [14/50] - Train Loss: 1.1152, Test Loss: 1.5999\n",
      "Epoch [15/50] - Train Loss: 1.1150, Test Loss: 1.6006\n",
      "Epoch [16/50] - Train Loss: 1.1149, Test Loss: 1.6012\n",
      "Epoch [17/50] - Train Loss: 1.1149, Test Loss: 1.6018\n",
      "Epoch [18/50] - Train Loss: 1.1148, Test Loss: 1.6024\n",
      "Epoch [19/50] - Train Loss: 1.1147, Test Loss: 1.6029\n",
      "Epoch [20/50] - Train Loss: 1.1147, Test Loss: 1.6034\n",
      "Epoch [21/50] - Train Loss: 1.1146, Test Loss: 1.6038\n",
      "Epoch [22/50] - Train Loss: 1.1146, Test Loss: 1.6043\n",
      "Epoch [23/50] - Train Loss: 1.1145, Test Loss: 1.6047\n",
      "Epoch [24/50] - Train Loss: 1.1145, Test Loss: 1.6051\n",
      "Epoch [25/50] - Train Loss: 1.1145, Test Loss: 1.6054\n",
      "Epoch [26/50] - Train Loss: 1.1145, Test Loss: 1.6057\n",
      "Epoch [27/50] - Train Loss: 1.1144, Test Loss: 1.6061\n",
      "Epoch [28/50] - Train Loss: 1.1144, Test Loss: 1.6063\n",
      "Epoch [29/50] - Train Loss: 1.1144, Test Loss: 1.6066\n",
      "Epoch [30/50] - Train Loss: 1.1144, Test Loss: 1.6069\n",
      "Epoch [31/50] - Train Loss: 1.1144, Test Loss: 1.6071\n",
      "Epoch [32/50] - Train Loss: 1.1143, Test Loss: 1.6073\n",
      "Epoch [33/50] - Train Loss: 1.1143, Test Loss: 1.6075\n",
      "Epoch [34/50] - Train Loss: 1.1143, Test Loss: 1.6077\n",
      "Epoch [35/50] - Train Loss: 1.1143, Test Loss: 1.6079\n",
      "Epoch [36/50] - Train Loss: 1.1143, Test Loss: 1.6081\n",
      "Epoch [37/50] - Train Loss: 1.1143, Test Loss: 1.6082\n",
      "Epoch [38/50] - Train Loss: 1.1143, Test Loss: 1.6084\n",
      "Epoch [39/50] - Train Loss: 1.1143, Test Loss: 1.6085\n",
      "Epoch [40/50] - Train Loss: 1.1143, Test Loss: 1.6086\n",
      "Epoch [41/50] - Train Loss: 1.1142, Test Loss: 1.6087\n",
      "Epoch [42/50] - Train Loss: 1.1142, Test Loss: 1.6089\n",
      "Epoch [43/50] - Train Loss: 1.1142, Test Loss: 1.6090\n",
      "Epoch [44/50] - Train Loss: 1.1142, Test Loss: 1.6090\n",
      "Epoch [45/50] - Train Loss: 1.1142, Test Loss: 1.6091\n",
      "Epoch [46/50] - Train Loss: 1.1142, Test Loss: 1.6092\n",
      "Epoch [47/50] - Train Loss: 1.1142, Test Loss: 1.6093\n",
      "Epoch [48/50] - Train Loss: 1.1141, Test Loss: 1.6094\n",
      "Epoch [49/50] - Train Loss: 1.1141, Test Loss: 1.6094\n",
      "Epoch [50/50] - Train Loss: 1.1141, Test Loss: 1.6095\n",
      "Avg Test Loss: 1.6095\n",
      "Testing combination: (32, 4, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3124, Test Loss: 2.7242\n",
      "Epoch [2/50] - Train Loss: 1.3116, Test Loss: 2.7215\n",
      "Epoch [3/50] - Train Loss: 1.3108, Test Loss: 2.7189\n",
      "Epoch [4/50] - Train Loss: 1.3102, Test Loss: 2.7164\n",
      "Epoch [5/50] - Train Loss: 1.3096, Test Loss: 2.7140\n",
      "Epoch [6/50] - Train Loss: 1.3090, Test Loss: 2.7116\n",
      "Epoch [7/50] - Train Loss: 1.3084, Test Loss: 2.7094\n",
      "Epoch [8/50] - Train Loss: 1.3079, Test Loss: 2.7072\n",
      "Epoch [9/50] - Train Loss: 1.3074, Test Loss: 2.7052\n",
      "Epoch [10/50] - Train Loss: 1.3070, Test Loss: 2.7032\n",
      "Epoch [11/50] - Train Loss: 1.3066, Test Loss: 2.7012\n",
      "Epoch [12/50] - Train Loss: 1.3062, Test Loss: 2.6994\n",
      "Epoch [13/50] - Train Loss: 1.3058, Test Loss: 2.6976\n",
      "Epoch [14/50] - Train Loss: 1.3054, Test Loss: 2.6959\n",
      "Epoch [15/50] - Train Loss: 1.3051, Test Loss: 2.6943\n",
      "Epoch [16/50] - Train Loss: 1.3048, Test Loss: 2.6927\n",
      "Epoch [17/50] - Train Loss: 1.3045, Test Loss: 2.6911\n",
      "Epoch [18/50] - Train Loss: 1.3043, Test Loss: 2.6897\n",
      "Epoch [19/50] - Train Loss: 1.3040, Test Loss: 2.6883\n",
      "Epoch [20/50] - Train Loss: 1.3038, Test Loss: 2.6869\n",
      "Epoch [21/50] - Train Loss: 1.3036, Test Loss: 2.6857\n",
      "Epoch [22/50] - Train Loss: 1.3034, Test Loss: 2.6844\n",
      "Epoch [23/50] - Train Loss: 1.3032, Test Loss: 2.6833\n",
      "Epoch [24/50] - Train Loss: 1.3031, Test Loss: 2.6821\n",
      "Epoch [25/50] - Train Loss: 1.3029, Test Loss: 2.6811\n",
      "Epoch [26/50] - Train Loss: 1.3028, Test Loss: 2.6800\n",
      "Epoch [27/50] - Train Loss: 1.3026, Test Loss: 2.6790\n",
      "Epoch [28/50] - Train Loss: 1.3025, Test Loss: 2.6781\n",
      "Epoch [29/50] - Train Loss: 1.3024, Test Loss: 2.6772\n",
      "Epoch [30/50] - Train Loss: 1.3023, Test Loss: 2.6764\n",
      "Epoch [31/50] - Train Loss: 1.3022, Test Loss: 2.6756\n",
      "Epoch [32/50] - Train Loss: 1.3022, Test Loss: 2.6748\n",
      "Epoch [33/50] - Train Loss: 1.3021, Test Loss: 2.6741\n",
      "Epoch [34/50] - Train Loss: 1.3020, Test Loss: 2.6734\n",
      "Epoch [35/50] - Train Loss: 1.3020, Test Loss: 2.6728\n",
      "Epoch [36/50] - Train Loss: 1.3019, Test Loss: 2.6722\n",
      "Epoch [37/50] - Train Loss: 1.3019, Test Loss: 2.6716\n",
      "Epoch [38/50] - Train Loss: 1.3018, Test Loss: 2.6710\n",
      "Epoch [39/50] - Train Loss: 1.3018, Test Loss: 2.6705\n",
      "Epoch [40/50] - Train Loss: 1.3017, Test Loss: 2.6700\n",
      "Epoch [41/50] - Train Loss: 1.3017, Test Loss: 2.6696\n",
      "Epoch [42/50] - Train Loss: 1.3017, Test Loss: 2.6691\n",
      "Epoch [43/50] - Train Loss: 1.3016, Test Loss: 2.6687\n",
      "Epoch [44/50] - Train Loss: 1.3016, Test Loss: 2.6683\n",
      "Epoch [45/50] - Train Loss: 1.3016, Test Loss: 2.6680\n",
      "Epoch [46/50] - Train Loss: 1.3016, Test Loss: 2.6676\n",
      "Epoch [47/50] - Train Loss: 1.3015, Test Loss: 2.6673\n",
      "Epoch [48/50] - Train Loss: 1.3015, Test Loss: 2.6670\n",
      "Epoch [49/50] - Train Loss: 1.3015, Test Loss: 2.6667\n",
      "Epoch [50/50] - Train Loss: 1.3015, Test Loss: 2.6665\n",
      "Avg Test Loss: 2.6665\n",
      "Testing combination: (64, 1, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1216, Test Loss: 1.4883\n",
      "Epoch [2/50] - Train Loss: 1.0901, Test Loss: 1.4831\n",
      "Epoch [3/50] - Train Loss: 1.0857, Test Loss: 1.4819\n",
      "Epoch [4/50] - Train Loss: 1.0849, Test Loss: 1.4815\n",
      "Epoch [5/50] - Train Loss: 1.0833, Test Loss: 1.4816\n",
      "Epoch [6/50] - Train Loss: 1.0822, Test Loss: 1.4821\n",
      "Epoch [7/50] - Train Loss: 1.0759, Test Loss: 1.4833\n",
      "Epoch [8/50] - Train Loss: 1.0964, Test Loss: 1.4853\n",
      "Epoch [9/50] - Train Loss: 1.0731, Test Loss: 1.4873\n",
      "Epoch [10/50] - Train Loss: 1.0600, Test Loss: 1.4875\n",
      "Epoch [11/50] - Train Loss: 1.0618, Test Loss: 1.4843\n",
      "Epoch [12/50] - Train Loss: 1.0605, Test Loss: 1.4840\n",
      "Epoch [13/50] - Train Loss: 1.0589, Test Loss: 1.4892\n",
      "Epoch [14/50] - Train Loss: 1.0537, Test Loss: 1.4863\n",
      "Epoch [15/50] - Train Loss: 1.0543, Test Loss: 1.4854\n",
      "Epoch [16/50] - Train Loss: 1.0537, Test Loss: 1.4856\n",
      "Epoch [17/50] - Train Loss: 1.0535, Test Loss: 1.4863\n",
      "Epoch [18/50] - Train Loss: 1.0530, Test Loss: 1.4861\n",
      "Epoch [19/50] - Train Loss: 1.0523, Test Loss: 1.4867\n",
      "Epoch [20/50] - Train Loss: 1.0431, Test Loss: 1.4173\n",
      "Epoch [21/50] - Train Loss: 1.1553, Test Loss: 1.4013\n",
      "Epoch [22/50] - Train Loss: 1.0722, Test Loss: 1.5224\n",
      "Epoch [23/50] - Train Loss: 1.1623, Test Loss: 1.4892\n",
      "Epoch [24/50] - Train Loss: 1.1452, Test Loss: 1.4953\n",
      "Epoch [25/50] - Train Loss: 1.0929, Test Loss: 1.4759\n",
      "Epoch [26/50] - Train Loss: 1.0938, Test Loss: 1.4784\n",
      "Epoch [27/50] - Train Loss: 1.0900, Test Loss: 1.4830\n",
      "Epoch [28/50] - Train Loss: 1.0802, Test Loss: 1.4799\n",
      "Epoch [29/50] - Train Loss: 1.0748, Test Loss: 1.4813\n",
      "Epoch [30/50] - Train Loss: 1.0677, Test Loss: 1.4883\n",
      "Epoch [31/50] - Train Loss: 1.0646, Test Loss: 1.4889\n",
      "Epoch [32/50] - Train Loss: 1.0646, Test Loss: 1.4881\n",
      "Epoch [33/50] - Train Loss: 1.0809, Test Loss: 1.4971\n",
      "Epoch [34/50] - Train Loss: 1.0623, Test Loss: 1.4813\n",
      "Epoch [35/50] - Train Loss: 1.0577, Test Loss: 1.4853\n",
      "Epoch [36/50] - Train Loss: 1.0665, Test Loss: 1.4870\n",
      "Epoch [37/50] - Train Loss: 1.0636, Test Loss: 1.4758\n",
      "Epoch [38/50] - Train Loss: 1.0661, Test Loss: 1.6070\n",
      "Epoch [39/50] - Train Loss: 1.0924, Test Loss: 1.4879\n",
      "Epoch [40/50] - Train Loss: 1.0791, Test Loss: 1.4794\n",
      "Epoch [41/50] - Train Loss: 1.0747, Test Loss: 1.4837\n",
      "Epoch [42/50] - Train Loss: 1.0625, Test Loss: 1.4863\n",
      "Epoch [43/50] - Train Loss: 1.0589, Test Loss: 1.4852\n",
      "Epoch [44/50] - Train Loss: 1.0580, Test Loss: 1.4850\n",
      "Epoch [45/50] - Train Loss: 1.0579, Test Loss: 1.4857\n",
      "Epoch [46/50] - Train Loss: 1.0575, Test Loss: 1.4858\n",
      "Epoch [47/50] - Train Loss: 1.0572, Test Loss: 1.4857\n",
      "Epoch [48/50] - Train Loss: 1.0571, Test Loss: 1.4857\n",
      "Epoch [49/50] - Train Loss: 1.0570, Test Loss: 1.4857\n",
      "Epoch [50/50] - Train Loss: 1.0568, Test Loss: 1.4858\n",
      "Avg Test Loss: 1.4858\n",
      "Testing combination: (64, 1, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1288, Test Loss: 1.6038\n",
      "Epoch [2/50] - Train Loss: 1.1106, Test Loss: 1.6007\n",
      "Epoch [3/50] - Train Loss: 1.1099, Test Loss: 1.6024\n",
      "Epoch [4/50] - Train Loss: 1.1089, Test Loss: 1.6057\n",
      "Epoch [5/50] - Train Loss: 1.1044, Test Loss: 1.6092\n",
      "Epoch [6/50] - Train Loss: 1.0961, Test Loss: 1.6168\n",
      "Epoch [7/50] - Train Loss: 1.0851, Test Loss: 1.6167\n",
      "Epoch [8/50] - Train Loss: 1.0881, Test Loss: 1.6153\n",
      "Epoch [9/50] - Train Loss: 1.1110, Test Loss: 1.6084\n",
      "Epoch [10/50] - Train Loss: 1.0909, Test Loss: 1.6058\n",
      "Epoch [11/50] - Train Loss: 1.0866, Test Loss: 1.6116\n",
      "Epoch [12/50] - Train Loss: 1.0813, Test Loss: 1.6146\n",
      "Epoch [13/50] - Train Loss: 1.0797, Test Loss: 1.6112\n",
      "Epoch [14/50] - Train Loss: 1.0796, Test Loss: 1.6109\n",
      "Epoch [15/50] - Train Loss: 1.0790, Test Loss: 1.6129\n",
      "Epoch [16/50] - Train Loss: 1.0786, Test Loss: 1.6136\n",
      "Epoch [17/50] - Train Loss: 1.0783, Test Loss: 1.6130\n",
      "Epoch [18/50] - Train Loss: 1.0781, Test Loss: 1.6123\n",
      "Epoch [19/50] - Train Loss: 1.0778, Test Loss: 1.6116\n",
      "Epoch [20/50] - Train Loss: 1.0777, Test Loss: 1.6111\n",
      "Epoch [21/50] - Train Loss: 1.0774, Test Loss: 1.6125\n",
      "Epoch [22/50] - Train Loss: 1.0708, Test Loss: 1.5758\n",
      "Epoch [23/50] - Train Loss: 1.1371, Test Loss: 1.6202\n",
      "Epoch [24/50] - Train Loss: 1.0907, Test Loss: 1.6196\n",
      "Epoch [25/50] - Train Loss: 1.0819, Test Loss: 1.6133\n",
      "Epoch [26/50] - Train Loss: 1.0797, Test Loss: 1.6108\n",
      "Epoch [27/50] - Train Loss: 1.0793, Test Loss: 1.6117\n",
      "Epoch [28/50] - Train Loss: 1.0792, Test Loss: 1.6127\n",
      "Epoch [29/50] - Train Loss: 1.0789, Test Loss: 1.6129\n",
      "Epoch [30/50] - Train Loss: 1.0788, Test Loss: 1.6130\n",
      "Epoch [31/50] - Train Loss: 1.0787, Test Loss: 1.6131\n",
      "Epoch [32/50] - Train Loss: 1.0787, Test Loss: 1.6131\n",
      "Epoch [33/50] - Train Loss: 1.0786, Test Loss: 1.6130\n",
      "Epoch [34/50] - Train Loss: 1.0786, Test Loss: 1.6130\n",
      "Epoch [35/50] - Train Loss: 1.0786, Test Loss: 1.6131\n",
      "Epoch [36/50] - Train Loss: 1.0785, Test Loss: 1.6132\n",
      "Epoch [37/50] - Train Loss: 1.0785, Test Loss: 1.6132\n",
      "Epoch [38/50] - Train Loss: 1.0785, Test Loss: 1.6132\n",
      "Epoch [39/50] - Train Loss: 1.0785, Test Loss: 1.6133\n",
      "Epoch [40/50] - Train Loss: 1.0784, Test Loss: 1.6133\n",
      "Epoch [41/50] - Train Loss: 1.0784, Test Loss: 1.6133\n",
      "Epoch [42/50] - Train Loss: 1.0784, Test Loss: 1.6134\n",
      "Epoch [43/50] - Train Loss: 1.0784, Test Loss: 1.6134\n",
      "Epoch [44/50] - Train Loss: 1.0784, Test Loss: 1.6134\n",
      "Epoch [45/50] - Train Loss: 1.0784, Test Loss: 1.6134\n",
      "Epoch [46/50] - Train Loss: 1.0783, Test Loss: 1.6134\n",
      "Epoch [47/50] - Train Loss: 1.0783, Test Loss: 1.6135\n",
      "Epoch [48/50] - Train Loss: 1.0783, Test Loss: 1.6135\n",
      "Epoch [49/50] - Train Loss: 1.0783, Test Loss: 1.6135\n",
      "Epoch [50/50] - Train Loss: 1.0783, Test Loss: 1.6135\n",
      "Avg Test Loss: 1.6135\n",
      "Testing combination: (64, 1, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3237, Test Loss: 2.7055\n",
      "Epoch [2/50] - Train Loss: 1.2965, Test Loss: 2.6886\n",
      "Epoch [3/50] - Train Loss: 1.2952, Test Loss: 2.6704\n",
      "Epoch [4/50] - Train Loss: 1.2901, Test Loss: 2.6678\n",
      "Epoch [5/50] - Train Loss: 1.2905, Test Loss: 2.6684\n",
      "Epoch [6/50] - Train Loss: 1.2890, Test Loss: 2.6695\n",
      "Epoch [7/50] - Train Loss: 1.2870, Test Loss: 2.6703\n",
      "Epoch [8/50] - Train Loss: 1.2846, Test Loss: 2.6700\n",
      "Epoch [9/50] - Train Loss: 1.2729, Test Loss: 2.6652\n",
      "Epoch [10/50] - Train Loss: 1.2562, Test Loss: 2.6612\n",
      "Epoch [11/50] - Train Loss: 1.2617, Test Loss: 2.6585\n",
      "Epoch [12/50] - Train Loss: 1.2566, Test Loss: 2.6617\n",
      "Epoch [13/50] - Train Loss: 1.2612, Test Loss: 2.6732\n",
      "Epoch [14/50] - Train Loss: 1.2574, Test Loss: 2.6649\n",
      "Epoch [15/50] - Train Loss: 1.2544, Test Loss: 2.6679\n",
      "Epoch [16/50] - Train Loss: 1.2533, Test Loss: 2.6591\n",
      "Epoch [17/50] - Train Loss: 1.2488, Test Loss: 2.6458\n",
      "Epoch [18/50] - Train Loss: 1.2499, Test Loss: 2.6532\n",
      "Epoch [19/50] - Train Loss: 1.2440, Test Loss: 2.6612\n",
      "Epoch [20/50] - Train Loss: 1.2484, Test Loss: 2.6523\n",
      "Epoch [21/50] - Train Loss: 1.2488, Test Loss: 2.6527\n",
      "Epoch [22/50] - Train Loss: 1.2538, Test Loss: 2.6536\n",
      "Epoch [23/50] - Train Loss: 1.2517, Test Loss: 2.6555\n",
      "Epoch [24/50] - Train Loss: 1.2511, Test Loss: 2.6563\n",
      "Epoch [25/50] - Train Loss: 1.2490, Test Loss: 2.6529\n",
      "Epoch [26/50] - Train Loss: 1.2459, Test Loss: 2.6443\n",
      "Epoch [27/50] - Train Loss: 1.2437, Test Loss: 2.6454\n",
      "Epoch [28/50] - Train Loss: 1.2433, Test Loss: 2.6437\n",
      "Epoch [29/50] - Train Loss: 1.2416, Test Loss: 2.6288\n",
      "Epoch [30/50] - Train Loss: 1.2515, Test Loss: 2.6162\n",
      "Epoch [31/50] - Train Loss: 1.2435, Test Loss: 2.6447\n",
      "Epoch [32/50] - Train Loss: 1.2504, Test Loss: 2.6263\n",
      "Epoch [33/50] - Train Loss: 1.2399, Test Loss: 2.6015\n",
      "Epoch [34/50] - Train Loss: 1.2354, Test Loss: 3.1352\n",
      "Epoch [35/50] - Train Loss: 1.3692, Test Loss: 2.5776\n",
      "Epoch [36/50] - Train Loss: 1.2843, Test Loss: 2.8280\n",
      "Epoch [37/50] - Train Loss: 1.2737, Test Loss: 2.6248\n",
      "Epoch [38/50] - Train Loss: 1.2801, Test Loss: 2.6544\n",
      "Epoch [39/50] - Train Loss: 1.2612, Test Loss: 2.7174\n",
      "Epoch [40/50] - Train Loss: 1.2517, Test Loss: 2.6320\n",
      "Epoch [41/50] - Train Loss: 1.2508, Test Loss: 2.6239\n",
      "Epoch [42/50] - Train Loss: 1.2454, Test Loss: 2.6574\n",
      "Epoch [43/50] - Train Loss: 1.2431, Test Loss: 2.6537\n",
      "Epoch [44/50] - Train Loss: 1.2417, Test Loss: 2.6376\n",
      "Epoch [45/50] - Train Loss: 1.2422, Test Loss: 2.6467\n",
      "Epoch [46/50] - Train Loss: 1.2417, Test Loss: 2.6569\n",
      "Epoch [47/50] - Train Loss: 1.2406, Test Loss: 2.6461\n",
      "Epoch [48/50] - Train Loss: 1.2408, Test Loss: 2.6406\n",
      "Epoch [49/50] - Train Loss: 1.2409, Test Loss: 2.6447\n",
      "Epoch [50/50] - Train Loss: 1.2404, Test Loss: 2.6446\n",
      "Avg Test Loss: 2.6446\n",
      "Testing combination: (64, 1, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1034, Test Loss: 1.4805\n",
      "Epoch [2/50] - Train Loss: 1.0909, Test Loss: 1.4844\n",
      "Epoch [3/50] - Train Loss: 1.0868, Test Loss: 1.4858\n",
      "Epoch [4/50] - Train Loss: 1.0846, Test Loss: 1.4854\n",
      "Epoch [5/50] - Train Loss: 1.0839, Test Loss: 1.4838\n",
      "Epoch [6/50] - Train Loss: 1.0832, Test Loss: 1.4822\n",
      "Epoch [7/50] - Train Loss: 1.0831, Test Loss: 1.4815\n",
      "Epoch [8/50] - Train Loss: 1.0830, Test Loss: 1.4814\n",
      "Epoch [9/50] - Train Loss: 1.0827, Test Loss: 1.4814\n",
      "Epoch [10/50] - Train Loss: 1.0821, Test Loss: 1.4815\n",
      "Epoch [11/50] - Train Loss: 1.0813, Test Loss: 1.4817\n",
      "Epoch [12/50] - Train Loss: 1.0797, Test Loss: 1.4821\n",
      "Epoch [13/50] - Train Loss: 1.0765, Test Loss: 1.4827\n",
      "Epoch [14/50] - Train Loss: 1.0725, Test Loss: 1.4838\n",
      "Epoch [15/50] - Train Loss: 1.0666, Test Loss: 1.4857\n",
      "Epoch [16/50] - Train Loss: 1.0607, Test Loss: 1.4870\n",
      "Epoch [17/50] - Train Loss: 1.0553, Test Loss: 1.4876\n",
      "Epoch [18/50] - Train Loss: 1.0539, Test Loss: 1.4877\n",
      "Epoch [19/50] - Train Loss: 1.0531, Test Loss: 1.4874\n",
      "Epoch [20/50] - Train Loss: 1.0526, Test Loss: 1.4869\n",
      "Epoch [21/50] - Train Loss: 1.0523, Test Loss: 1.4866\n",
      "Epoch [22/50] - Train Loss: 1.0521, Test Loss: 1.4865\n",
      "Epoch [23/50] - Train Loss: 1.0519, Test Loss: 1.4866\n",
      "Epoch [24/50] - Train Loss: 1.0516, Test Loss: 1.4866\n",
      "Epoch [25/50] - Train Loss: 1.0513, Test Loss: 1.4868\n",
      "Epoch [26/50] - Train Loss: 1.0509, Test Loss: 1.4872\n",
      "Epoch [27/50] - Train Loss: 1.0504, Test Loss: 1.4879\n",
      "Epoch [28/50] - Train Loss: 1.0500, Test Loss: 1.4885\n",
      "Epoch [29/50] - Train Loss: 1.0492, Test Loss: 1.4890\n",
      "Epoch [30/50] - Train Loss: 1.0485, Test Loss: 1.4892\n",
      "Epoch [31/50] - Train Loss: 1.0478, Test Loss: 1.4889\n",
      "Epoch [32/50] - Train Loss: 1.0467, Test Loss: 1.4890\n",
      "Epoch [33/50] - Train Loss: 1.0452, Test Loss: 1.4855\n",
      "Epoch [34/50] - Train Loss: 1.0422, Test Loss: 1.4913\n",
      "Epoch [35/50] - Train Loss: 1.0687, Test Loss: 1.4905\n",
      "Epoch [36/50] - Train Loss: 1.0527, Test Loss: 1.4872\n",
      "Epoch [37/50] - Train Loss: 1.0480, Test Loss: 1.4880\n",
      "Epoch [38/50] - Train Loss: 1.0459, Test Loss: 1.4874\n",
      "Epoch [39/50] - Train Loss: 1.0432, Test Loss: 1.4850\n",
      "Epoch [40/50] - Train Loss: 1.0590, Test Loss: 1.4920\n",
      "Epoch [41/50] - Train Loss: 1.0815, Test Loss: 1.4892\n",
      "Epoch [42/50] - Train Loss: 1.0692, Test Loss: 1.4868\n",
      "Epoch [43/50] - Train Loss: 1.0570, Test Loss: 1.4859\n",
      "Epoch [44/50] - Train Loss: 1.0523, Test Loss: 1.4859\n",
      "Epoch [45/50] - Train Loss: 1.0514, Test Loss: 1.4863\n",
      "Epoch [46/50] - Train Loss: 1.0510, Test Loss: 1.4865\n",
      "Epoch [47/50] - Train Loss: 1.0506, Test Loss: 1.4867\n",
      "Epoch [48/50] - Train Loss: 1.0501, Test Loss: 1.4866\n",
      "Epoch [49/50] - Train Loss: 1.0495, Test Loss: 1.4865\n",
      "Epoch [50/50] - Train Loss: 1.0487, Test Loss: 1.4864\n",
      "Avg Test Loss: 1.4864\n",
      "Testing combination: (64, 1, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1201, Test Loss: 1.6260\n",
      "Epoch [2/50] - Train Loss: 1.1137, Test Loss: 1.6130\n",
      "Epoch [3/50] - Train Loss: 1.1113, Test Loss: 1.6066\n",
      "Epoch [4/50] - Train Loss: 1.1098, Test Loss: 1.6047\n",
      "Epoch [5/50] - Train Loss: 1.1086, Test Loss: 1.6049\n",
      "Epoch [6/50] - Train Loss: 1.1079, Test Loss: 1.6056\n",
      "Epoch [7/50] - Train Loss: 1.1074, Test Loss: 1.6060\n",
      "Epoch [8/50] - Train Loss: 1.1064, Test Loss: 1.6058\n",
      "Epoch [9/50] - Train Loss: 1.1051, Test Loss: 1.6056\n",
      "Epoch [10/50] - Train Loss: 1.1021, Test Loss: 1.6053\n",
      "Epoch [11/50] - Train Loss: 1.0964, Test Loss: 1.6053\n",
      "Epoch [12/50] - Train Loss: 1.0878, Test Loss: 1.6065\n",
      "Epoch [13/50] - Train Loss: 1.0809, Test Loss: 1.6102\n",
      "Epoch [14/50] - Train Loss: 1.0804, Test Loss: 1.6157\n",
      "Epoch [15/50] - Train Loss: 1.0809, Test Loss: 1.6182\n",
      "Epoch [16/50] - Train Loss: 1.0779, Test Loss: 1.6166\n",
      "Epoch [17/50] - Train Loss: 1.0778, Test Loss: 1.6146\n",
      "Epoch [18/50] - Train Loss: 1.0773, Test Loss: 1.6139\n",
      "Epoch [19/50] - Train Loss: 1.0771, Test Loss: 1.6144\n",
      "Epoch [20/50] - Train Loss: 1.0767, Test Loss: 1.6154\n",
      "Epoch [21/50] - Train Loss: 1.0764, Test Loss: 1.6166\n",
      "Epoch [22/50] - Train Loss: 1.0759, Test Loss: 1.6180\n",
      "Epoch [23/50] - Train Loss: 1.0754, Test Loss: 1.6193\n",
      "Epoch [24/50] - Train Loss: 1.0749, Test Loss: 1.6202\n",
      "Epoch [25/50] - Train Loss: 1.0743, Test Loss: 1.6206\n",
      "Epoch [26/50] - Train Loss: 1.0737, Test Loss: 1.6205\n",
      "Epoch [27/50] - Train Loss: 1.0731, Test Loss: 1.6203\n",
      "Epoch [28/50] - Train Loss: 1.0722, Test Loss: 1.6199\n",
      "Epoch [29/50] - Train Loss: 1.0708, Test Loss: 1.6178\n",
      "Epoch [30/50] - Train Loss: 1.0709, Test Loss: 1.6222\n",
      "Epoch [31/50] - Train Loss: 1.0890, Test Loss: 1.6222\n",
      "Epoch [32/50] - Train Loss: 1.0750, Test Loss: 1.6135\n",
      "Epoch [33/50] - Train Loss: 1.0719, Test Loss: 1.6111\n",
      "Epoch [34/50] - Train Loss: 1.0719, Test Loss: 1.6159\n",
      "Epoch [35/50] - Train Loss: 1.0696, Test Loss: 1.6197\n",
      "Epoch [36/50] - Train Loss: 1.0665, Test Loss: 1.6181\n",
      "Epoch [37/50] - Train Loss: 1.0651, Test Loss: 1.6261\n",
      "Epoch [38/50] - Train Loss: 1.0738, Test Loss: 1.6321\n",
      "Epoch [39/50] - Train Loss: 1.0745, Test Loss: 1.6182\n",
      "Epoch [40/50] - Train Loss: 1.0682, Test Loss: 1.6102\n",
      "Epoch [41/50] - Train Loss: 1.0620, Test Loss: 1.5830\n",
      "Epoch [42/50] - Train Loss: 1.1177, Test Loss: 1.6455\n",
      "Epoch [43/50] - Train Loss: 1.1039, Test Loss: 1.6444\n",
      "Epoch [44/50] - Train Loss: 1.0993, Test Loss: 1.6313\n",
      "Epoch [45/50] - Train Loss: 1.0902, Test Loss: 1.6192\n",
      "Epoch [46/50] - Train Loss: 1.0846, Test Loss: 1.6117\n",
      "Epoch [47/50] - Train Loss: 1.0810, Test Loss: 1.6085\n",
      "Epoch [48/50] - Train Loss: 1.0795, Test Loss: 1.6084\n",
      "Epoch [49/50] - Train Loss: 1.0789, Test Loss: 1.6100\n",
      "Epoch [50/50] - Train Loss: 1.0786, Test Loss: 1.6119\n",
      "Avg Test Loss: 1.6119\n",
      "Testing combination: (64, 1, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3089, Test Loss: 2.6496\n",
      "Epoch [2/50] - Train Loss: 1.3012, Test Loss: 2.6597\n",
      "Epoch [3/50] - Train Loss: 1.2978, Test Loss: 2.6665\n",
      "Epoch [4/50] - Train Loss: 1.2955, Test Loss: 2.6704\n",
      "Epoch [5/50] - Train Loss: 1.2934, Test Loss: 2.6722\n",
      "Epoch [6/50] - Train Loss: 1.2915, Test Loss: 2.6725\n",
      "Epoch [7/50] - Train Loss: 1.2900, Test Loss: 2.6719\n",
      "Epoch [8/50] - Train Loss: 1.2895, Test Loss: 2.6712\n",
      "Epoch [9/50] - Train Loss: 1.2898, Test Loss: 2.6707\n",
      "Epoch [10/50] - Train Loss: 1.2894, Test Loss: 2.6705\n",
      "Epoch [11/50] - Train Loss: 1.2889, Test Loss: 2.6706\n",
      "Epoch [12/50] - Train Loss: 1.2887, Test Loss: 2.6709\n",
      "Epoch [13/50] - Train Loss: 1.2885, Test Loss: 2.6711\n",
      "Epoch [14/50] - Train Loss: 1.2882, Test Loss: 2.6712\n",
      "Epoch [15/50] - Train Loss: 1.2877, Test Loss: 2.6712\n",
      "Epoch [16/50] - Train Loss: 1.2871, Test Loss: 2.6713\n",
      "Epoch [17/50] - Train Loss: 1.2861, Test Loss: 2.6714\n",
      "Epoch [18/50] - Train Loss: 1.2845, Test Loss: 2.6716\n",
      "Epoch [19/50] - Train Loss: 1.2818, Test Loss: 2.6715\n",
      "Epoch [20/50] - Train Loss: 1.2772, Test Loss: 2.6709\n",
      "Epoch [21/50] - Train Loss: 1.2706, Test Loss: 2.6698\n",
      "Epoch [22/50] - Train Loss: 1.2628, Test Loss: 2.6676\n",
      "Epoch [23/50] - Train Loss: 1.2566, Test Loss: 2.6636\n",
      "Epoch [24/50] - Train Loss: 1.2593, Test Loss: 2.6582\n",
      "Epoch [25/50] - Train Loss: 1.2596, Test Loss: 2.6530\n",
      "Epoch [26/50] - Train Loss: 1.2553, Test Loss: 2.6524\n",
      "Epoch [27/50] - Train Loss: 1.2532, Test Loss: 2.6539\n",
      "Epoch [28/50] - Train Loss: 1.2530, Test Loss: 2.6554\n",
      "Epoch [29/50] - Train Loss: 1.2519, Test Loss: 2.6558\n",
      "Epoch [30/50] - Train Loss: 1.2508, Test Loss: 2.6550\n",
      "Epoch [31/50] - Train Loss: 1.2502, Test Loss: 2.6529\n",
      "Epoch [32/50] - Train Loss: 1.2496, Test Loss: 2.6497\n",
      "Epoch [33/50] - Train Loss: 1.2489, Test Loss: 2.6468\n",
      "Epoch [34/50] - Train Loss: 1.2484, Test Loss: 2.6453\n",
      "Epoch [35/50] - Train Loss: 1.2480, Test Loss: 2.6450\n",
      "Epoch [36/50] - Train Loss: 1.2475, Test Loss: 2.6452\n",
      "Epoch [37/50] - Train Loss: 1.2471, Test Loss: 2.6451\n",
      "Epoch [38/50] - Train Loss: 1.2465, Test Loss: 2.6446\n",
      "Epoch [39/50] - Train Loss: 1.2460, Test Loss: 2.6435\n",
      "Epoch [40/50] - Train Loss: 1.2455, Test Loss: 2.6422\n",
      "Epoch [41/50] - Train Loss: 1.2450, Test Loss: 2.6405\n",
      "Epoch [42/50] - Train Loss: 1.2444, Test Loss: 2.6383\n",
      "Epoch [43/50] - Train Loss: 1.2437, Test Loss: 2.6359\n",
      "Epoch [44/50] - Train Loss: 1.2429, Test Loss: 2.6332\n",
      "Epoch [45/50] - Train Loss: 1.2421, Test Loss: 2.6303\n",
      "Epoch [46/50] - Train Loss: 1.2413, Test Loss: 2.6269\n",
      "Epoch [47/50] - Train Loss: 1.2404, Test Loss: 2.6227\n",
      "Epoch [48/50] - Train Loss: 1.2392, Test Loss: 2.6178\n",
      "Epoch [49/50] - Train Loss: 1.2369, Test Loss: 2.6127\n",
      "Epoch [50/50] - Train Loss: 1.2250, Test Loss: 2.6289\n",
      "Avg Test Loss: 2.6289\n",
      "Testing combination: (64, 1, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1007, Test Loss: 1.4739\n",
      "Epoch [2/50] - Train Loss: 1.0991, Test Loss: 1.4742\n",
      "Epoch [3/50] - Train Loss: 1.0980, Test Loss: 1.4744\n",
      "Epoch [4/50] - Train Loss: 1.0971, Test Loss: 1.4747\n",
      "Epoch [5/50] - Train Loss: 1.0962, Test Loss: 1.4749\n",
      "Epoch [6/50] - Train Loss: 1.0953, Test Loss: 1.4752\n",
      "Epoch [7/50] - Train Loss: 1.0945, Test Loss: 1.4755\n",
      "Epoch [8/50] - Train Loss: 1.0937, Test Loss: 1.4758\n",
      "Epoch [9/50] - Train Loss: 1.0929, Test Loss: 1.4761\n",
      "Epoch [10/50] - Train Loss: 1.0922, Test Loss: 1.4764\n",
      "Epoch [11/50] - Train Loss: 1.0914, Test Loss: 1.4768\n",
      "Epoch [12/50] - Train Loss: 1.0907, Test Loss: 1.4771\n",
      "Epoch [13/50] - Train Loss: 1.0900, Test Loss: 1.4774\n",
      "Epoch [14/50] - Train Loss: 1.0894, Test Loss: 1.4777\n",
      "Epoch [15/50] - Train Loss: 1.0887, Test Loss: 1.4780\n",
      "Epoch [16/50] - Train Loss: 1.0881, Test Loss: 1.4783\n",
      "Epoch [17/50] - Train Loss: 1.0875, Test Loss: 1.4786\n",
      "Epoch [18/50] - Train Loss: 1.0869, Test Loss: 1.4789\n",
      "Epoch [19/50] - Train Loss: 1.0863, Test Loss: 1.4792\n",
      "Epoch [20/50] - Train Loss: 1.0858, Test Loss: 1.4794\n",
      "Epoch [21/50] - Train Loss: 1.0853, Test Loss: 1.4797\n",
      "Epoch [22/50] - Train Loss: 1.0848, Test Loss: 1.4800\n",
      "Epoch [23/50] - Train Loss: 1.0844, Test Loss: 1.4802\n",
      "Epoch [24/50] - Train Loss: 1.0840, Test Loss: 1.4804\n",
      "Epoch [25/50] - Train Loss: 1.0836, Test Loss: 1.4806\n",
      "Epoch [26/50] - Train Loss: 1.0833, Test Loss: 1.4808\n",
      "Epoch [27/50] - Train Loss: 1.0830, Test Loss: 1.4810\n",
      "Epoch [28/50] - Train Loss: 1.0828, Test Loss: 1.4812\n",
      "Epoch [29/50] - Train Loss: 1.0826, Test Loss: 1.4813\n",
      "Epoch [30/50] - Train Loss: 1.0824, Test Loss: 1.4814\n",
      "Epoch [31/50] - Train Loss: 1.0823, Test Loss: 1.4815\n",
      "Epoch [32/50] - Train Loss: 1.0822, Test Loss: 1.4816\n",
      "Epoch [33/50] - Train Loss: 1.0821, Test Loss: 1.4817\n",
      "Epoch [34/50] - Train Loss: 1.0820, Test Loss: 1.4818\n",
      "Epoch [35/50] - Train Loss: 1.0820, Test Loss: 1.4818\n",
      "Epoch [36/50] - Train Loss: 1.0820, Test Loss: 1.4818\n",
      "Epoch [37/50] - Train Loss: 1.0819, Test Loss: 1.4819\n",
      "Epoch [38/50] - Train Loss: 1.0819, Test Loss: 1.4819\n",
      "Epoch [39/50] - Train Loss: 1.0819, Test Loss: 1.4819\n",
      "Epoch [40/50] - Train Loss: 1.0819, Test Loss: 1.4819\n",
      "Epoch [41/50] - Train Loss: 1.0818, Test Loss: 1.4819\n",
      "Epoch [42/50] - Train Loss: 1.0818, Test Loss: 1.4819\n",
      "Epoch [43/50] - Train Loss: 1.0818, Test Loss: 1.4819\n",
      "Epoch [44/50] - Train Loss: 1.0818, Test Loss: 1.4819\n",
      "Epoch [45/50] - Train Loss: 1.0817, Test Loss: 1.4819\n",
      "Epoch [46/50] - Train Loss: 1.0817, Test Loss: 1.4819\n",
      "Epoch [47/50] - Train Loss: 1.0817, Test Loss: 1.4819\n",
      "Epoch [48/50] - Train Loss: 1.0817, Test Loss: 1.4819\n",
      "Epoch [49/50] - Train Loss: 1.0816, Test Loss: 1.4820\n",
      "Epoch [50/50] - Train Loss: 1.0816, Test Loss: 1.4820\n",
      "Avg Test Loss: 1.4820\n",
      "Testing combination: (64, 1, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1203, Test Loss: 1.6475\n",
      "Epoch [2/50] - Train Loss: 1.1194, Test Loss: 1.6451\n",
      "Epoch [3/50] - Train Loss: 1.1187, Test Loss: 1.6427\n",
      "Epoch [4/50] - Train Loss: 1.1179, Test Loss: 1.6405\n",
      "Epoch [5/50] - Train Loss: 1.1173, Test Loss: 1.6384\n",
      "Epoch [6/50] - Train Loss: 1.1167, Test Loss: 1.6364\n",
      "Epoch [7/50] - Train Loss: 1.1161, Test Loss: 1.6345\n",
      "Epoch [8/50] - Train Loss: 1.1155, Test Loss: 1.6328\n",
      "Epoch [9/50] - Train Loss: 1.1150, Test Loss: 1.6311\n",
      "Epoch [10/50] - Train Loss: 1.1145, Test Loss: 1.6296\n",
      "Epoch [11/50] - Train Loss: 1.1141, Test Loss: 1.6281\n",
      "Epoch [12/50] - Train Loss: 1.1136, Test Loss: 1.6267\n",
      "Epoch [13/50] - Train Loss: 1.1132, Test Loss: 1.6254\n",
      "Epoch [14/50] - Train Loss: 1.1128, Test Loss: 1.6242\n",
      "Epoch [15/50] - Train Loss: 1.1124, Test Loss: 1.6231\n",
      "Epoch [16/50] - Train Loss: 1.1120, Test Loss: 1.6220\n",
      "Epoch [17/50] - Train Loss: 1.1116, Test Loss: 1.6209\n",
      "Epoch [18/50] - Train Loss: 1.1112, Test Loss: 1.6199\n",
      "Epoch [19/50] - Train Loss: 1.1108, Test Loss: 1.6190\n",
      "Epoch [20/50] - Train Loss: 1.1104, Test Loss: 1.6181\n",
      "Epoch [21/50] - Train Loss: 1.1101, Test Loss: 1.6173\n",
      "Epoch [22/50] - Train Loss: 1.1097, Test Loss: 1.6165\n",
      "Epoch [23/50] - Train Loss: 1.1094, Test Loss: 1.6158\n",
      "Epoch [24/50] - Train Loss: 1.1091, Test Loss: 1.6151\n",
      "Epoch [25/50] - Train Loss: 1.1088, Test Loss: 1.6145\n",
      "Epoch [26/50] - Train Loss: 1.1086, Test Loss: 1.6139\n",
      "Epoch [27/50] - Train Loss: 1.1083, Test Loss: 1.6133\n",
      "Epoch [28/50] - Train Loss: 1.1081, Test Loss: 1.6127\n",
      "Epoch [29/50] - Train Loss: 1.1079, Test Loss: 1.6122\n",
      "Epoch [30/50] - Train Loss: 1.1078, Test Loss: 1.6117\n",
      "Epoch [31/50] - Train Loss: 1.1076, Test Loss: 1.6113\n",
      "Epoch [32/50] - Train Loss: 1.1075, Test Loss: 1.6109\n",
      "Epoch [33/50] - Train Loss: 1.1074, Test Loss: 1.6105\n",
      "Epoch [34/50] - Train Loss: 1.1073, Test Loss: 1.6102\n",
      "Epoch [35/50] - Train Loss: 1.1073, Test Loss: 1.6098\n",
      "Epoch [36/50] - Train Loss: 1.1072, Test Loss: 1.6095\n",
      "Epoch [37/50] - Train Loss: 1.1071, Test Loss: 1.6093\n",
      "Epoch [38/50] - Train Loss: 1.1071, Test Loss: 1.6090\n",
      "Epoch [39/50] - Train Loss: 1.1070, Test Loss: 1.6088\n",
      "Epoch [40/50] - Train Loss: 1.1070, Test Loss: 1.6085\n",
      "Epoch [41/50] - Train Loss: 1.1069, Test Loss: 1.6083\n",
      "Epoch [42/50] - Train Loss: 1.1069, Test Loss: 1.6081\n",
      "Epoch [43/50] - Train Loss: 1.1068, Test Loss: 1.6080\n",
      "Epoch [44/50] - Train Loss: 1.1068, Test Loss: 1.6078\n",
      "Epoch [45/50] - Train Loss: 1.1067, Test Loss: 1.6077\n",
      "Epoch [46/50] - Train Loss: 1.1067, Test Loss: 1.6075\n",
      "Epoch [47/50] - Train Loss: 1.1066, Test Loss: 1.6074\n",
      "Epoch [48/50] - Train Loss: 1.1065, Test Loss: 1.6073\n",
      "Epoch [49/50] - Train Loss: 1.1065, Test Loss: 1.6071\n",
      "Epoch [50/50] - Train Loss: 1.1064, Test Loss: 1.6070\n",
      "Avg Test Loss: 1.6070\n",
      "Testing combination: (64, 1, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3115, Test Loss: 2.7216\n",
      "Epoch [2/50] - Train Loss: 1.3098, Test Loss: 2.7176\n",
      "Epoch [3/50] - Train Loss: 1.3085, Test Loss: 2.7138\n",
      "Epoch [4/50] - Train Loss: 1.3072, Test Loss: 2.7102\n",
      "Epoch [5/50] - Train Loss: 1.3060, Test Loss: 2.7068\n",
      "Epoch [6/50] - Train Loss: 1.3049, Test Loss: 2.7036\n",
      "Epoch [7/50] - Train Loss: 1.3039, Test Loss: 2.7005\n",
      "Epoch [8/50] - Train Loss: 1.3030, Test Loss: 2.6977\n",
      "Epoch [9/50] - Train Loss: 1.3021, Test Loss: 2.6951\n",
      "Epoch [10/50] - Train Loss: 1.3013, Test Loss: 2.6926\n",
      "Epoch [11/50] - Train Loss: 1.3006, Test Loss: 2.6903\n",
      "Epoch [12/50] - Train Loss: 1.2999, Test Loss: 2.6881\n",
      "Epoch [13/50] - Train Loss: 1.2993, Test Loss: 2.6861\n",
      "Epoch [14/50] - Train Loss: 1.2987, Test Loss: 2.6843\n",
      "Epoch [15/50] - Train Loss: 1.2981, Test Loss: 2.6825\n",
      "Epoch [16/50] - Train Loss: 1.2976, Test Loss: 2.6809\n",
      "Epoch [17/50] - Train Loss: 1.2971, Test Loss: 2.6794\n",
      "Epoch [18/50] - Train Loss: 1.2967, Test Loss: 2.6781\n",
      "Epoch [19/50] - Train Loss: 1.2962, Test Loss: 2.6768\n",
      "Epoch [20/50] - Train Loss: 1.2958, Test Loss: 2.6756\n",
      "Epoch [21/50] - Train Loss: 1.2954, Test Loss: 2.6745\n",
      "Epoch [22/50] - Train Loss: 1.2951, Test Loss: 2.6735\n",
      "Epoch [23/50] - Train Loss: 1.2947, Test Loss: 2.6726\n",
      "Epoch [24/50] - Train Loss: 1.2944, Test Loss: 2.6718\n",
      "Epoch [25/50] - Train Loss: 1.2940, Test Loss: 2.6710\n",
      "Epoch [26/50] - Train Loss: 1.2937, Test Loss: 2.6703\n",
      "Epoch [27/50] - Train Loss: 1.2935, Test Loss: 2.6697\n",
      "Epoch [28/50] - Train Loss: 1.2932, Test Loss: 2.6691\n",
      "Epoch [29/50] - Train Loss: 1.2929, Test Loss: 2.6686\n",
      "Epoch [30/50] - Train Loss: 1.2926, Test Loss: 2.6682\n",
      "Epoch [31/50] - Train Loss: 1.2924, Test Loss: 2.6678\n",
      "Epoch [32/50] - Train Loss: 1.2922, Test Loss: 2.6674\n",
      "Epoch [33/50] - Train Loss: 1.2919, Test Loss: 2.6671\n",
      "Epoch [34/50] - Train Loss: 1.2917, Test Loss: 2.6669\n",
      "Epoch [35/50] - Train Loss: 1.2915, Test Loss: 2.6667\n",
      "Epoch [36/50] - Train Loss: 1.2913, Test Loss: 2.6665\n",
      "Epoch [37/50] - Train Loss: 1.2911, Test Loss: 2.6664\n",
      "Epoch [38/50] - Train Loss: 1.2910, Test Loss: 2.6663\n",
      "Epoch [39/50] - Train Loss: 1.2908, Test Loss: 2.6662\n",
      "Epoch [40/50] - Train Loss: 1.2907, Test Loss: 2.6661\n",
      "Epoch [41/50] - Train Loss: 1.2905, Test Loss: 2.6661\n",
      "Epoch [42/50] - Train Loss: 1.2904, Test Loss: 2.6661\n",
      "Epoch [43/50] - Train Loss: 1.2902, Test Loss: 2.6662\n",
      "Epoch [44/50] - Train Loss: 1.2901, Test Loss: 2.6662\n",
      "Epoch [45/50] - Train Loss: 1.2900, Test Loss: 2.6663\n",
      "Epoch [46/50] - Train Loss: 1.2899, Test Loss: 2.6664\n",
      "Epoch [47/50] - Train Loss: 1.2898, Test Loss: 2.6665\n",
      "Epoch [48/50] - Train Loss: 1.2897, Test Loss: 2.6666\n",
      "Epoch [49/50] - Train Loss: 1.2896, Test Loss: 2.6667\n",
      "Epoch [50/50] - Train Loss: 1.2895, Test Loss: 2.6669\n",
      "Avg Test Loss: 2.6669\n",
      "Testing combination: (64, 2, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1446, Test Loss: 1.4888\n",
      "Epoch [2/50] - Train Loss: 1.0896, Test Loss: 1.4839\n",
      "Epoch [3/50] - Train Loss: 1.1103, Test Loss: 1.4847\n",
      "Epoch [4/50] - Train Loss: 1.0906, Test Loss: 1.4851\n",
      "Epoch [5/50] - Train Loss: 1.0846, Test Loss: 1.4833\n",
      "Epoch [6/50] - Train Loss: 1.0822, Test Loss: 1.4824\n",
      "Epoch [7/50] - Train Loss: 1.0765, Test Loss: 1.4835\n",
      "Epoch [8/50] - Train Loss: 1.0750, Test Loss: 1.4893\n",
      "Epoch [9/50] - Train Loss: 1.0593, Test Loss: 1.4873\n",
      "Epoch [10/50] - Train Loss: 1.0609, Test Loss: 1.4841\n",
      "Epoch [11/50] - Train Loss: 1.0878, Test Loss: 1.4883\n",
      "Epoch [12/50] - Train Loss: 1.0655, Test Loss: 1.4921\n",
      "Epoch [13/50] - Train Loss: 1.0596, Test Loss: 1.4907\n",
      "Epoch [14/50] - Train Loss: 1.0541, Test Loss: 1.4869\n",
      "Epoch [15/50] - Train Loss: 1.0541, Test Loss: 1.4868\n",
      "Epoch [16/50] - Train Loss: 1.0537, Test Loss: 1.4872\n",
      "Epoch [17/50] - Train Loss: 1.0533, Test Loss: 1.4872\n",
      "Epoch [18/50] - Train Loss: 1.0529, Test Loss: 1.4871\n",
      "Epoch [19/50] - Train Loss: 1.0520, Test Loss: 1.4854\n",
      "Epoch [20/50] - Train Loss: 1.0700, Test Loss: 1.4864\n",
      "Epoch [21/50] - Train Loss: 1.0891, Test Loss: 1.4860\n",
      "Epoch [22/50] - Train Loss: 1.0677, Test Loss: 1.4883\n",
      "Epoch [23/50] - Train Loss: 1.0547, Test Loss: 1.4886\n",
      "Epoch [24/50] - Train Loss: 1.0562, Test Loss: 1.4869\n",
      "Epoch [25/50] - Train Loss: 1.0581, Test Loss: 1.4864\n",
      "Epoch [26/50] - Train Loss: 1.0533, Test Loss: 1.4873\n",
      "Epoch [27/50] - Train Loss: 1.0536, Test Loss: 1.4872\n",
      "Epoch [28/50] - Train Loss: 1.0529, Test Loss: 1.4868\n",
      "Epoch [29/50] - Train Loss: 1.0528, Test Loss: 1.4869\n",
      "Epoch [30/50] - Train Loss: 1.0527, Test Loss: 1.4869\n",
      "Epoch [31/50] - Train Loss: 1.0527, Test Loss: 1.4869\n",
      "Epoch [32/50] - Train Loss: 1.0526, Test Loss: 1.4869\n",
      "Epoch [33/50] - Train Loss: 1.0525, Test Loss: 1.4869\n",
      "Epoch [34/50] - Train Loss: 1.0525, Test Loss: 1.4869\n",
      "Epoch [35/50] - Train Loss: 1.0525, Test Loss: 1.4869\n",
      "Epoch [36/50] - Train Loss: 1.0524, Test Loss: 1.4869\n",
      "Epoch [37/50] - Train Loss: 1.0524, Test Loss: 1.4869\n",
      "Epoch [38/50] - Train Loss: 1.0523, Test Loss: 1.4869\n",
      "Epoch [39/50] - Train Loss: 1.0523, Test Loss: 1.4869\n",
      "Epoch [40/50] - Train Loss: 1.0523, Test Loss: 1.4869\n",
      "Epoch [41/50] - Train Loss: 1.0523, Test Loss: 1.4869\n",
      "Epoch [42/50] - Train Loss: 1.0522, Test Loss: 1.4868\n",
      "Epoch [43/50] - Train Loss: 1.0522, Test Loss: 1.4868\n",
      "Epoch [44/50] - Train Loss: 1.0521, Test Loss: 1.4868\n",
      "Epoch [45/50] - Train Loss: 1.0521, Test Loss: 1.4868\n",
      "Epoch [46/50] - Train Loss: 1.0520, Test Loss: 1.4867\n",
      "Epoch [47/50] - Train Loss: 1.0519, Test Loss: 1.4867\n",
      "Epoch [48/50] - Train Loss: 1.0516, Test Loss: 1.4869\n",
      "Epoch [49/50] - Train Loss: 1.0499, Test Loss: 1.4932\n",
      "Epoch [50/50] - Train Loss: 1.0641, Test Loss: 1.5093\n",
      "Avg Test Loss: 1.5093\n",
      "Testing combination: (64, 2, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1282, Test Loss: 1.5985\n",
      "Epoch [2/50] - Train Loss: 1.1167, Test Loss: 1.6024\n",
      "Epoch [3/50] - Train Loss: 1.1122, Test Loss: 1.6056\n",
      "Epoch [4/50] - Train Loss: 1.1085, Test Loss: 1.6063\n",
      "Epoch [5/50] - Train Loss: 1.1199, Test Loss: 1.6062\n",
      "Epoch [6/50] - Train Loss: 1.1127, Test Loss: 1.6036\n",
      "Epoch [7/50] - Train Loss: 1.1086, Test Loss: 1.6059\n",
      "Epoch [8/50] - Train Loss: 1.0975, Test Loss: 1.6812\n",
      "Epoch [9/50] - Train Loss: 1.0859, Test Loss: 1.6443\n",
      "Epoch [10/50] - Train Loss: 1.1324, Test Loss: 1.6150\n",
      "Epoch [11/50] - Train Loss: 1.1137, Test Loss: 1.6030\n",
      "Epoch [12/50] - Train Loss: 1.1074, Test Loss: 1.6074\n",
      "Epoch [13/50] - Train Loss: 1.1017, Test Loss: 1.6093\n",
      "Epoch [14/50] - Train Loss: 1.0904, Test Loss: 1.6095\n",
      "Epoch [15/50] - Train Loss: 1.0834, Test Loss: 1.6117\n",
      "Epoch [16/50] - Train Loss: 1.0821, Test Loss: 1.6084\n",
      "Epoch [17/50] - Train Loss: 1.0806, Test Loss: 1.6141\n",
      "Epoch [18/50] - Train Loss: 1.0796, Test Loss: 1.6163\n",
      "Epoch [19/50] - Train Loss: 1.0787, Test Loss: 1.6142\n",
      "Epoch [20/50] - Train Loss: 1.0783, Test Loss: 1.6129\n",
      "Epoch [21/50] - Train Loss: 1.0773, Test Loss: 1.6117\n",
      "Epoch [22/50] - Train Loss: 1.0761, Test Loss: 1.6123\n",
      "Epoch [23/50] - Train Loss: 1.0752, Test Loss: 1.6160\n",
      "Epoch [24/50] - Train Loss: 1.0736, Test Loss: 1.6163\n",
      "Epoch [25/50] - Train Loss: 1.0814, Test Loss: 1.6137\n",
      "Epoch [26/50] - Train Loss: 1.0721, Test Loss: 1.6142\n",
      "Epoch [27/50] - Train Loss: 1.0732, Test Loss: 1.6169\n",
      "Epoch [28/50] - Train Loss: 1.0726, Test Loss: 1.6197\n",
      "Epoch [29/50] - Train Loss: 1.0688, Test Loss: 1.6186\n",
      "Epoch [30/50] - Train Loss: 1.0684, Test Loss: 1.6193\n",
      "Epoch [31/50] - Train Loss: 1.0677, Test Loss: 1.6202\n",
      "Epoch [32/50] - Train Loss: 1.0678, Test Loss: 1.6217\n",
      "Epoch [33/50] - Train Loss: 1.0672, Test Loss: 1.6212\n",
      "Epoch [34/50] - Train Loss: 1.0628, Test Loss: 1.6127\n",
      "Epoch [35/50] - Train Loss: 1.0872, Test Loss: 1.6410\n",
      "Epoch [36/50] - Train Loss: 1.1017, Test Loss: 1.6081\n",
      "Epoch [37/50] - Train Loss: 1.0783, Test Loss: 1.6018\n",
      "Epoch [38/50] - Train Loss: 1.0766, Test Loss: 1.6291\n",
      "Epoch [39/50] - Train Loss: 1.0699, Test Loss: 1.6194\n",
      "Epoch [40/50] - Train Loss: 1.0707, Test Loss: 1.6387\n",
      "Epoch [41/50] - Train Loss: 1.0666, Test Loss: 1.6172\n",
      "Epoch [42/50] - Train Loss: 1.0698, Test Loss: 1.6223\n",
      "Epoch [43/50] - Train Loss: 1.0684, Test Loss: 1.6368\n",
      "Epoch [44/50] - Train Loss: 1.0654, Test Loss: 1.6174\n",
      "Epoch [45/50] - Train Loss: 1.0680, Test Loss: 1.6133\n",
      "Epoch [46/50] - Train Loss: 1.0680, Test Loss: 1.6179\n",
      "Epoch [47/50] - Train Loss: 1.0700, Test Loss: 1.6393\n",
      "Epoch [48/50] - Train Loss: 1.0643, Test Loss: 1.6169\n",
      "Epoch [49/50] - Train Loss: 1.0650, Test Loss: 1.6127\n",
      "Epoch [50/50] - Train Loss: 1.0666, Test Loss: 1.6228\n",
      "Avg Test Loss: 1.6228\n",
      "Testing combination: (64, 2, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3230, Test Loss: 2.6523\n",
      "Epoch [2/50] - Train Loss: 1.3026, Test Loss: 2.6465\n",
      "Epoch [3/50] - Train Loss: 1.2961, Test Loss: 2.6593\n",
      "Epoch [4/50] - Train Loss: 1.2950, Test Loss: 2.6737\n",
      "Epoch [5/50] - Train Loss: 1.2932, Test Loss: 2.6739\n",
      "Epoch [6/50] - Train Loss: 1.2904, Test Loss: 2.6738\n",
      "Epoch [7/50] - Train Loss: 1.2831, Test Loss: 2.6739\n",
      "Epoch [8/50] - Train Loss: 1.2670, Test Loss: 2.6652\n",
      "Epoch [9/50] - Train Loss: 1.2568, Test Loss: 2.6491\n",
      "Epoch [10/50] - Train Loss: 1.2718, Test Loss: 2.6536\n",
      "Epoch [11/50] - Train Loss: 1.2545, Test Loss: 2.6666\n",
      "Epoch [12/50] - Train Loss: 1.2549, Test Loss: 2.6705\n",
      "Epoch [13/50] - Train Loss: 1.2533, Test Loss: 2.6565\n",
      "Epoch [14/50] - Train Loss: 1.2547, Test Loss: 2.6497\n",
      "Epoch [15/50] - Train Loss: 1.2530, Test Loss: 2.6441\n",
      "Epoch [16/50] - Train Loss: 1.2492, Test Loss: 2.6750\n",
      "Epoch [17/50] - Train Loss: 1.2682, Test Loss: 2.6500\n",
      "Epoch [18/50] - Train Loss: 1.2524, Test Loss: 2.6576\n",
      "Epoch [19/50] - Train Loss: 1.2549, Test Loss: 2.6623\n",
      "Epoch [20/50] - Train Loss: 1.2541, Test Loss: 2.6632\n",
      "Epoch [21/50] - Train Loss: 1.2541, Test Loss: 2.6611\n",
      "Epoch [22/50] - Train Loss: 1.2541, Test Loss: 2.6590\n",
      "Epoch [23/50] - Train Loss: 1.2539, Test Loss: 2.6587\n",
      "Epoch [24/50] - Train Loss: 1.2540, Test Loss: 2.6598\n",
      "Epoch [25/50] - Train Loss: 1.2539, Test Loss: 2.6608\n",
      "Epoch [26/50] - Train Loss: 1.2538, Test Loss: 2.6609\n",
      "Epoch [27/50] - Train Loss: 1.2538, Test Loss: 2.6604\n",
      "Epoch [28/50] - Train Loss: 1.2537, Test Loss: 2.6600\n",
      "Epoch [29/50] - Train Loss: 1.2537, Test Loss: 2.6599\n",
      "Epoch [30/50] - Train Loss: 1.2536, Test Loss: 2.6598\n",
      "Epoch [31/50] - Train Loss: 1.2536, Test Loss: 2.6597\n",
      "Epoch [32/50] - Train Loss: 1.2535, Test Loss: 2.6596\n",
      "Epoch [33/50] - Train Loss: 1.2533, Test Loss: 2.6594\n",
      "Epoch [34/50] - Train Loss: 1.2529, Test Loss: 2.6585\n",
      "Epoch [35/50] - Train Loss: 1.2523, Test Loss: 2.6560\n",
      "Epoch [36/50] - Train Loss: 1.2515, Test Loss: 2.6494\n",
      "Epoch [37/50] - Train Loss: 1.2518, Test Loss: 2.6393\n",
      "Epoch [38/50] - Train Loss: 1.2470, Test Loss: 2.6361\n",
      "Epoch [39/50] - Train Loss: 1.2470, Test Loss: 2.6342\n",
      "Epoch [40/50] - Train Loss: 1.2479, Test Loss: 2.6303\n",
      "Epoch [41/50] - Train Loss: 1.2439, Test Loss: 2.6373\n",
      "Epoch [42/50] - Train Loss: 1.2445, Test Loss: 2.6310\n",
      "Epoch [43/50] - Train Loss: 1.2459, Test Loss: 2.6203\n",
      "Epoch [44/50] - Train Loss: 1.2420, Test Loss: 2.6287\n",
      "Epoch [45/50] - Train Loss: 1.2422, Test Loss: 2.6209\n",
      "Epoch [46/50] - Train Loss: 1.2427, Test Loss: 2.6121\n",
      "Epoch [47/50] - Train Loss: 1.2401, Test Loss: 2.6156\n",
      "Epoch [48/50] - Train Loss: 1.2401, Test Loss: 2.6136\n",
      "Epoch [49/50] - Train Loss: 1.2402, Test Loss: 2.6114\n",
      "Epoch [50/50] - Train Loss: 1.2402, Test Loss: 2.6083\n",
      "Avg Test Loss: 2.6083\n",
      "Testing combination: (64, 2, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1023, Test Loss: 1.4874\n",
      "Epoch [2/50] - Train Loss: 1.0945, Test Loss: 1.4876\n",
      "Epoch [3/50] - Train Loss: 1.0928, Test Loss: 1.4866\n",
      "Epoch [4/50] - Train Loss: 1.0912, Test Loss: 1.4858\n",
      "Epoch [5/50] - Train Loss: 1.0888, Test Loss: 1.4851\n",
      "Epoch [6/50] - Train Loss: 1.0859, Test Loss: 1.4845\n",
      "Epoch [7/50] - Train Loss: 1.0846, Test Loss: 1.4835\n",
      "Epoch [8/50] - Train Loss: 1.0828, Test Loss: 1.4825\n",
      "Epoch [9/50] - Train Loss: 1.0814, Test Loss: 1.4823\n",
      "Epoch [10/50] - Train Loss: 1.0805, Test Loss: 1.4824\n",
      "Epoch [11/50] - Train Loss: 1.0780, Test Loss: 1.4834\n",
      "Epoch [12/50] - Train Loss: 1.0746, Test Loss: 1.4844\n",
      "Epoch [13/50] - Train Loss: 1.0650, Test Loss: 1.4859\n",
      "Epoch [14/50] - Train Loss: 1.0577, Test Loss: 1.4872\n",
      "Epoch [15/50] - Train Loss: 1.0534, Test Loss: 1.4878\n",
      "Epoch [16/50] - Train Loss: 1.0541, Test Loss: 1.4876\n",
      "Epoch [17/50] - Train Loss: 1.0546, Test Loss: 1.4872\n",
      "Epoch [18/50] - Train Loss: 1.0546, Test Loss: 1.4868\n",
      "Epoch [19/50] - Train Loss: 1.0523, Test Loss: 1.4869\n",
      "Epoch [20/50] - Train Loss: 1.0523, Test Loss: 1.4870\n",
      "Epoch [21/50] - Train Loss: 1.0519, Test Loss: 1.4869\n",
      "Epoch [22/50] - Train Loss: 1.0516, Test Loss: 1.4868\n",
      "Epoch [23/50] - Train Loss: 1.0513, Test Loss: 1.4867\n",
      "Epoch [24/50] - Train Loss: 1.0510, Test Loss: 1.4866\n",
      "Epoch [25/50] - Train Loss: 1.0503, Test Loss: 1.4866\n",
      "Epoch [26/50] - Train Loss: 1.0494, Test Loss: 1.4874\n",
      "Epoch [27/50] - Train Loss: 1.0487, Test Loss: 1.4890\n",
      "Epoch [28/50] - Train Loss: 1.0473, Test Loss: 1.4898\n",
      "Epoch [29/50] - Train Loss: 1.0460, Test Loss: 1.4898\n",
      "Epoch [30/50] - Train Loss: 1.0465, Test Loss: 1.4897\n",
      "Epoch [31/50] - Train Loss: 1.0451, Test Loss: 1.4880\n",
      "Epoch [32/50] - Train Loss: 1.0452, Test Loss: 1.4865\n",
      "Epoch [33/50] - Train Loss: 1.0466, Test Loss: 1.4856\n",
      "Epoch [34/50] - Train Loss: 1.0436, Test Loss: 1.4841\n",
      "Epoch [35/50] - Train Loss: 1.0523, Test Loss: 1.4896\n",
      "Epoch [36/50] - Train Loss: 1.0394, Test Loss: 1.4849\n",
      "Epoch [37/50] - Train Loss: 1.0407, Test Loss: 1.4916\n",
      "Epoch [38/50] - Train Loss: 1.0379, Test Loss: 1.4877\n",
      "Epoch [39/50] - Train Loss: 1.0327, Test Loss: 1.4851\n",
      "Epoch [40/50] - Train Loss: 1.0314, Test Loss: 1.4771\n",
      "Epoch [41/50] - Train Loss: 1.0366, Test Loss: 1.5233\n",
      "Epoch [42/50] - Train Loss: 1.1213, Test Loss: 1.4915\n",
      "Epoch [43/50] - Train Loss: 1.0732, Test Loss: 1.4874\n",
      "Epoch [44/50] - Train Loss: 1.0565, Test Loss: 1.4852\n",
      "Epoch [45/50] - Train Loss: 1.0521, Test Loss: 1.4851\n",
      "Epoch [46/50] - Train Loss: 1.0518, Test Loss: 1.4856\n",
      "Epoch [47/50] - Train Loss: 1.0513, Test Loss: 1.4860\n",
      "Epoch [48/50] - Train Loss: 1.0507, Test Loss: 1.4862\n",
      "Epoch [49/50] - Train Loss: 1.0502, Test Loss: 1.4863\n",
      "Epoch [50/50] - Train Loss: 1.0493, Test Loss: 1.4861\n",
      "Avg Test Loss: 1.4861\n",
      "Testing combination: (64, 2, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1223, Test Loss: 1.6219\n",
      "Epoch [2/50] - Train Loss: 1.1147, Test Loss: 1.6060\n",
      "Epoch [3/50] - Train Loss: 1.1139, Test Loss: 1.6032\n",
      "Epoch [4/50] - Train Loss: 1.1129, Test Loss: 1.6051\n",
      "Epoch [5/50] - Train Loss: 1.1115, Test Loss: 1.6073\n",
      "Epoch [6/50] - Train Loss: 1.1100, Test Loss: 1.6078\n",
      "Epoch [7/50] - Train Loss: 1.1087, Test Loss: 1.6071\n",
      "Epoch [8/50] - Train Loss: 1.1070, Test Loss: 1.6063\n",
      "Epoch [9/50] - Train Loss: 1.1047, Test Loss: 1.6059\n",
      "Epoch [10/50] - Train Loss: 1.1003, Test Loss: 1.6062\n",
      "Epoch [11/50] - Train Loss: 1.0993, Test Loss: 1.6086\n",
      "Epoch [12/50] - Train Loss: 1.0972, Test Loss: 1.6126\n",
      "Epoch [13/50] - Train Loss: 1.0832, Test Loss: 1.6147\n",
      "Epoch [14/50] - Train Loss: 1.0796, Test Loss: 1.6150\n",
      "Epoch [15/50] - Train Loss: 1.0787, Test Loss: 1.6148\n",
      "Epoch [16/50] - Train Loss: 1.0786, Test Loss: 1.6151\n",
      "Epoch [17/50] - Train Loss: 1.0780, Test Loss: 1.6149\n",
      "Epoch [18/50] - Train Loss: 1.0778, Test Loss: 1.6144\n",
      "Epoch [19/50] - Train Loss: 1.0775, Test Loss: 1.6145\n",
      "Epoch [20/50] - Train Loss: 1.0774, Test Loss: 1.6154\n",
      "Epoch [21/50] - Train Loss: 1.0771, Test Loss: 1.6161\n",
      "Epoch [22/50] - Train Loss: 1.0768, Test Loss: 1.6165\n",
      "Epoch [23/50] - Train Loss: 1.0765, Test Loss: 1.6171\n",
      "Epoch [24/50] - Train Loss: 1.0762, Test Loss: 1.6176\n",
      "Epoch [25/50] - Train Loss: 1.0757, Test Loss: 1.6181\n",
      "Epoch [26/50] - Train Loss: 1.0749, Test Loss: 1.6180\n",
      "Epoch [27/50] - Train Loss: 1.0736, Test Loss: 1.6152\n",
      "Epoch [28/50] - Train Loss: 1.0973, Test Loss: 1.6254\n",
      "Epoch [29/50] - Train Loss: 1.0981, Test Loss: 1.6268\n",
      "Epoch [30/50] - Train Loss: 1.0888, Test Loss: 1.6173\n",
      "Epoch [31/50] - Train Loss: 1.0822, Test Loss: 1.6124\n",
      "Epoch [32/50] - Train Loss: 1.0775, Test Loss: 1.6120\n",
      "Epoch [33/50] - Train Loss: 1.0773, Test Loss: 1.6132\n",
      "Epoch [34/50] - Train Loss: 1.0768, Test Loss: 1.6143\n",
      "Epoch [35/50] - Train Loss: 1.0764, Test Loss: 1.6152\n",
      "Epoch [36/50] - Train Loss: 1.0760, Test Loss: 1.6158\n",
      "Epoch [37/50] - Train Loss: 1.0756, Test Loss: 1.6158\n",
      "Epoch [38/50] - Train Loss: 1.0751, Test Loss: 1.6156\n",
      "Epoch [39/50] - Train Loss: 1.0745, Test Loss: 1.6159\n",
      "Epoch [40/50] - Train Loss: 1.0739, Test Loss: 1.6166\n",
      "Epoch [41/50] - Train Loss: 1.0731, Test Loss: 1.6177\n",
      "Epoch [42/50] - Train Loss: 1.0721, Test Loss: 1.6187\n",
      "Epoch [43/50] - Train Loss: 1.0708, Test Loss: 1.6195\n",
      "Epoch [44/50] - Train Loss: 1.0692, Test Loss: 1.6199\n",
      "Epoch [45/50] - Train Loss: 1.0670, Test Loss: 1.6190\n",
      "Epoch [46/50] - Train Loss: 1.0631, Test Loss: 1.6142\n",
      "Epoch [47/50] - Train Loss: 1.0628, Test Loss: 1.6134\n",
      "Epoch [48/50] - Train Loss: 1.0609, Test Loss: 1.6035\n",
      "Epoch [49/50] - Train Loss: 1.0225, Test Loss: 1.5051\n",
      "Epoch [50/50] - Train Loss: 1.1680, Test Loss: 1.6591\n",
      "Avg Test Loss: 1.6591\n",
      "Testing combination: (64, 2, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3228, Test Loss: 2.6391\n",
      "Epoch [2/50] - Train Loss: 1.3049, Test Loss: 2.6593\n",
      "Epoch [3/50] - Train Loss: 1.3011, Test Loss: 2.6741\n",
      "Epoch [4/50] - Train Loss: 1.3000, Test Loss: 2.6795\n",
      "Epoch [5/50] - Train Loss: 1.2986, Test Loss: 2.6782\n",
      "Epoch [6/50] - Train Loss: 1.2967, Test Loss: 2.6741\n",
      "Epoch [7/50] - Train Loss: 1.2947, Test Loss: 2.6701\n",
      "Epoch [8/50] - Train Loss: 1.2927, Test Loss: 2.6674\n",
      "Epoch [9/50] - Train Loss: 1.2911, Test Loss: 2.6663\n",
      "Epoch [10/50] - Train Loss: 1.2908, Test Loss: 2.6666\n",
      "Epoch [11/50] - Train Loss: 1.2905, Test Loss: 2.6677\n",
      "Epoch [12/50] - Train Loss: 1.2893, Test Loss: 2.6689\n",
      "Epoch [13/50] - Train Loss: 1.2887, Test Loss: 2.6700\n",
      "Epoch [14/50] - Train Loss: 1.2878, Test Loss: 2.6709\n",
      "Epoch [15/50] - Train Loss: 1.2864, Test Loss: 2.6714\n",
      "Epoch [16/50] - Train Loss: 1.2843, Test Loss: 2.6711\n",
      "Epoch [17/50] - Train Loss: 1.2805, Test Loss: 2.6700\n",
      "Epoch [18/50] - Train Loss: 1.2739, Test Loss: 2.6681\n",
      "Epoch [19/50] - Train Loss: 1.2658, Test Loss: 2.6650\n",
      "Epoch [20/50] - Train Loss: 1.2571, Test Loss: 2.6609\n",
      "Epoch [21/50] - Train Loss: 1.2550, Test Loss: 2.6574\n",
      "Epoch [22/50] - Train Loss: 1.2685, Test Loss: 2.6557\n",
      "Epoch [23/50] - Train Loss: 1.2549, Test Loss: 2.6548\n",
      "Epoch [24/50] - Train Loss: 1.2560, Test Loss: 2.6555\n",
      "Epoch [25/50] - Train Loss: 1.2551, Test Loss: 2.6576\n",
      "Epoch [26/50] - Train Loss: 1.2539, Test Loss: 2.6597\n",
      "Epoch [27/50] - Train Loss: 1.2535, Test Loss: 2.6606\n",
      "Epoch [28/50] - Train Loss: 1.2531, Test Loss: 2.6599\n",
      "Epoch [29/50] - Train Loss: 1.2529, Test Loss: 2.6582\n",
      "Epoch [30/50] - Train Loss: 1.2526, Test Loss: 2.6564\n",
      "Epoch [31/50] - Train Loss: 1.2523, Test Loss: 2.6552\n",
      "Epoch [32/50] - Train Loss: 1.2521, Test Loss: 2.6547\n",
      "Epoch [33/50] - Train Loss: 1.2519, Test Loss: 2.6545\n",
      "Epoch [34/50] - Train Loss: 1.2516, Test Loss: 2.6543\n",
      "Epoch [35/50] - Train Loss: 1.2514, Test Loss: 2.6535\n",
      "Epoch [36/50] - Train Loss: 1.2512, Test Loss: 2.6521\n",
      "Epoch [37/50] - Train Loss: 1.2509, Test Loss: 2.6508\n",
      "Epoch [38/50] - Train Loss: 1.2506, Test Loss: 2.6501\n",
      "Epoch [39/50] - Train Loss: 1.2504, Test Loss: 2.6500\n",
      "Epoch [40/50] - Train Loss: 1.2500, Test Loss: 2.6501\n",
      "Epoch [41/50] - Train Loss: 1.2496, Test Loss: 2.6502\n",
      "Epoch [42/50] - Train Loss: 1.2492, Test Loss: 2.6497\n",
      "Epoch [43/50] - Train Loss: 1.2488, Test Loss: 2.6487\n",
      "Epoch [44/50] - Train Loss: 1.2481, Test Loss: 2.6469\n",
      "Epoch [45/50] - Train Loss: 1.2471, Test Loss: 2.6442\n",
      "Epoch [46/50] - Train Loss: 1.2453, Test Loss: 2.6388\n",
      "Epoch [47/50] - Train Loss: 1.2419, Test Loss: 2.6263\n",
      "Epoch [48/50] - Train Loss: 1.2471, Test Loss: 2.6208\n",
      "Epoch [49/50] - Train Loss: 1.2616, Test Loss: 2.6442\n",
      "Epoch [50/50] - Train Loss: 1.2535, Test Loss: 2.6480\n",
      "Avg Test Loss: 2.6480\n",
      "Testing combination: (64, 2, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1152, Test Loss: 1.4744\n",
      "Epoch [2/50] - Train Loss: 1.1116, Test Loss: 1.4739\n",
      "Epoch [3/50] - Train Loss: 1.1090, Test Loss: 1.4735\n",
      "Epoch [4/50] - Train Loss: 1.1068, Test Loss: 1.4734\n",
      "Epoch [5/50] - Train Loss: 1.1048, Test Loss: 1.4734\n",
      "Epoch [6/50] - Train Loss: 1.1030, Test Loss: 1.4735\n",
      "Epoch [7/50] - Train Loss: 1.1014, Test Loss: 1.4737\n",
      "Epoch [8/50] - Train Loss: 1.0999, Test Loss: 1.4740\n",
      "Epoch [9/50] - Train Loss: 1.0986, Test Loss: 1.4744\n",
      "Epoch [10/50] - Train Loss: 1.0973, Test Loss: 1.4749\n",
      "Epoch [11/50] - Train Loss: 1.0962, Test Loss: 1.4754\n",
      "Epoch [12/50] - Train Loss: 1.0952, Test Loss: 1.4759\n",
      "Epoch [13/50] - Train Loss: 1.0943, Test Loss: 1.4765\n",
      "Epoch [14/50] - Train Loss: 1.0934, Test Loss: 1.4771\n",
      "Epoch [15/50] - Train Loss: 1.0926, Test Loss: 1.4778\n",
      "Epoch [16/50] - Train Loss: 1.0919, Test Loss: 1.4784\n",
      "Epoch [17/50] - Train Loss: 1.0912, Test Loss: 1.4790\n",
      "Epoch [18/50] - Train Loss: 1.0905, Test Loss: 1.4796\n",
      "Epoch [19/50] - Train Loss: 1.0899, Test Loss: 1.4802\n",
      "Epoch [20/50] - Train Loss: 1.0894, Test Loss: 1.4808\n",
      "Epoch [21/50] - Train Loss: 1.0889, Test Loss: 1.4813\n",
      "Epoch [22/50] - Train Loss: 1.0884, Test Loss: 1.4817\n",
      "Epoch [23/50] - Train Loss: 1.0879, Test Loss: 1.4822\n",
      "Epoch [24/50] - Train Loss: 1.0875, Test Loss: 1.4825\n",
      "Epoch [25/50] - Train Loss: 1.0871, Test Loss: 1.4829\n",
      "Epoch [26/50] - Train Loss: 1.0867, Test Loss: 1.4831\n",
      "Epoch [27/50] - Train Loss: 1.0864, Test Loss: 1.4834\n",
      "Epoch [28/50] - Train Loss: 1.0861, Test Loss: 1.4835\n",
      "Epoch [29/50] - Train Loss: 1.0858, Test Loss: 1.4837\n",
      "Epoch [30/50] - Train Loss: 1.0855, Test Loss: 1.4838\n",
      "Epoch [31/50] - Train Loss: 1.0853, Test Loss: 1.4838\n",
      "Epoch [32/50] - Train Loss: 1.0850, Test Loss: 1.4839\n",
      "Epoch [33/50] - Train Loss: 1.0848, Test Loss: 1.4839\n",
      "Epoch [34/50] - Train Loss: 1.0846, Test Loss: 1.4839\n",
      "Epoch [35/50] - Train Loss: 1.0843, Test Loss: 1.4838\n",
      "Epoch [36/50] - Train Loss: 1.0841, Test Loss: 1.4838\n",
      "Epoch [37/50] - Train Loss: 1.0839, Test Loss: 1.4838\n",
      "Epoch [38/50] - Train Loss: 1.0837, Test Loss: 1.4837\n",
      "Epoch [39/50] - Train Loss: 1.0834, Test Loss: 1.4837\n",
      "Epoch [40/50] - Train Loss: 1.0832, Test Loss: 1.4836\n",
      "Epoch [41/50] - Train Loss: 1.0829, Test Loss: 1.4836\n",
      "Epoch [42/50] - Train Loss: 1.0827, Test Loss: 1.4835\n",
      "Epoch [43/50] - Train Loss: 1.0824, Test Loss: 1.4835\n",
      "Epoch [44/50] - Train Loss: 1.0821, Test Loss: 1.4835\n",
      "Epoch [45/50] - Train Loss: 1.0818, Test Loss: 1.4834\n",
      "Epoch [46/50] - Train Loss: 1.0814, Test Loss: 1.4834\n",
      "Epoch [47/50] - Train Loss: 1.0811, Test Loss: 1.4834\n",
      "Epoch [48/50] - Train Loss: 1.0807, Test Loss: 1.4835\n",
      "Epoch [49/50] - Train Loss: 1.0803, Test Loss: 1.4835\n",
      "Epoch [50/50] - Train Loss: 1.0798, Test Loss: 1.4835\n",
      "Avg Test Loss: 1.4835\n",
      "Testing combination: (64, 2, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1145, Test Loss: 1.6160\n",
      "Epoch [2/50] - Train Loss: 1.1142, Test Loss: 1.6156\n",
      "Epoch [3/50] - Train Loss: 1.1141, Test Loss: 1.6151\n",
      "Epoch [4/50] - Train Loss: 1.1140, Test Loss: 1.6147\n",
      "Epoch [5/50] - Train Loss: 1.1139, Test Loss: 1.6143\n",
      "Epoch [6/50] - Train Loss: 1.1138, Test Loss: 1.6139\n",
      "Epoch [7/50] - Train Loss: 1.1137, Test Loss: 1.6135\n",
      "Epoch [8/50] - Train Loss: 1.1136, Test Loss: 1.6132\n",
      "Epoch [9/50] - Train Loss: 1.1135, Test Loss: 1.6129\n",
      "Epoch [10/50] - Train Loss: 1.1134, Test Loss: 1.6126\n",
      "Epoch [11/50] - Train Loss: 1.1133, Test Loss: 1.6124\n",
      "Epoch [12/50] - Train Loss: 1.1131, Test Loss: 1.6121\n",
      "Epoch [13/50] - Train Loss: 1.1130, Test Loss: 1.6119\n",
      "Epoch [14/50] - Train Loss: 1.1129, Test Loss: 1.6117\n",
      "Epoch [15/50] - Train Loss: 1.1128, Test Loss: 1.6116\n",
      "Epoch [16/50] - Train Loss: 1.1126, Test Loss: 1.6114\n",
      "Epoch [17/50] - Train Loss: 1.1125, Test Loss: 1.6113\n",
      "Epoch [18/50] - Train Loss: 1.1123, Test Loss: 1.6111\n",
      "Epoch [19/50] - Train Loss: 1.1122, Test Loss: 1.6110\n",
      "Epoch [20/50] - Train Loss: 1.1120, Test Loss: 1.6108\n",
      "Epoch [21/50] - Train Loss: 1.1118, Test Loss: 1.6107\n",
      "Epoch [22/50] - Train Loss: 1.1116, Test Loss: 1.6106\n",
      "Epoch [23/50] - Train Loss: 1.1114, Test Loss: 1.6105\n",
      "Epoch [24/50] - Train Loss: 1.1111, Test Loss: 1.6104\n",
      "Epoch [25/50] - Train Loss: 1.1109, Test Loss: 1.6103\n",
      "Epoch [26/50] - Train Loss: 1.1106, Test Loss: 1.6102\n",
      "Epoch [27/50] - Train Loss: 1.1104, Test Loss: 1.6100\n",
      "Epoch [28/50] - Train Loss: 1.1101, Test Loss: 1.6099\n",
      "Epoch [29/50] - Train Loss: 1.1098, Test Loss: 1.6098\n",
      "Epoch [30/50] - Train Loss: 1.1095, Test Loss: 1.6097\n",
      "Epoch [31/50] - Train Loss: 1.1092, Test Loss: 1.6095\n",
      "Epoch [32/50] - Train Loss: 1.1089, Test Loss: 1.6094\n",
      "Epoch [33/50] - Train Loss: 1.1087, Test Loss: 1.6092\n",
      "Epoch [34/50] - Train Loss: 1.1084, Test Loss: 1.6091\n",
      "Epoch [35/50] - Train Loss: 1.1081, Test Loss: 1.6089\n",
      "Epoch [36/50] - Train Loss: 1.1079, Test Loss: 1.6087\n",
      "Epoch [37/50] - Train Loss: 1.1076, Test Loss: 1.6085\n",
      "Epoch [38/50] - Train Loss: 1.1074, Test Loss: 1.6083\n",
      "Epoch [39/50] - Train Loss: 1.1071, Test Loss: 1.6082\n",
      "Epoch [40/50] - Train Loss: 1.1069, Test Loss: 1.6080\n",
      "Epoch [41/50] - Train Loss: 1.1066, Test Loss: 1.6078\n",
      "Epoch [42/50] - Train Loss: 1.1063, Test Loss: 1.6077\n",
      "Epoch [43/50] - Train Loss: 1.1060, Test Loss: 1.6075\n",
      "Epoch [44/50] - Train Loss: 1.1057, Test Loss: 1.6074\n",
      "Epoch [45/50] - Train Loss: 1.1053, Test Loss: 1.6073\n",
      "Epoch [46/50] - Train Loss: 1.1049, Test Loss: 1.6072\n",
      "Epoch [47/50] - Train Loss: 1.1044, Test Loss: 1.6072\n",
      "Epoch [48/50] - Train Loss: 1.1038, Test Loss: 1.6071\n",
      "Epoch [49/50] - Train Loss: 1.1031, Test Loss: 1.6071\n",
      "Epoch [50/50] - Train Loss: 1.1023, Test Loss: 1.6072\n",
      "Avg Test Loss: 1.6072\n",
      "Testing combination: (64, 2, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3021, Test Loss: 2.6564\n",
      "Epoch [2/50] - Train Loss: 1.3019, Test Loss: 2.6569\n",
      "Epoch [3/50] - Train Loss: 1.3017, Test Loss: 2.6573\n",
      "Epoch [4/50] - Train Loss: 1.3016, Test Loss: 2.6577\n",
      "Epoch [5/50] - Train Loss: 1.3014, Test Loss: 2.6580\n",
      "Epoch [6/50] - Train Loss: 1.3013, Test Loss: 2.6584\n",
      "Epoch [7/50] - Train Loss: 1.3012, Test Loss: 2.6587\n",
      "Epoch [8/50] - Train Loss: 1.3011, Test Loss: 2.6590\n",
      "Epoch [9/50] - Train Loss: 1.3010, Test Loss: 2.6593\n",
      "Epoch [10/50] - Train Loss: 1.3008, Test Loss: 2.6596\n",
      "Epoch [11/50] - Train Loss: 1.3007, Test Loss: 2.6598\n",
      "Epoch [12/50] - Train Loss: 1.3006, Test Loss: 2.6601\n",
      "Epoch [13/50] - Train Loss: 1.3005, Test Loss: 2.6603\n",
      "Epoch [14/50] - Train Loss: 1.3003, Test Loss: 2.6605\n",
      "Epoch [15/50] - Train Loss: 1.3002, Test Loss: 2.6607\n",
      "Epoch [16/50] - Train Loss: 1.3001, Test Loss: 2.6609\n",
      "Epoch [17/50] - Train Loss: 1.2999, Test Loss: 2.6611\n",
      "Epoch [18/50] - Train Loss: 1.2998, Test Loss: 2.6613\n",
      "Epoch [19/50] - Train Loss: 1.2996, Test Loss: 2.6615\n",
      "Epoch [20/50] - Train Loss: 1.2995, Test Loss: 2.6617\n",
      "Epoch [21/50] - Train Loss: 1.2993, Test Loss: 2.6618\n",
      "Epoch [22/50] - Train Loss: 1.2991, Test Loss: 2.6620\n",
      "Epoch [23/50] - Train Loss: 1.2989, Test Loss: 2.6621\n",
      "Epoch [24/50] - Train Loss: 1.2988, Test Loss: 2.6623\n",
      "Epoch [25/50] - Train Loss: 1.2986, Test Loss: 2.6624\n",
      "Epoch [26/50] - Train Loss: 1.2983, Test Loss: 2.6626\n",
      "Epoch [27/50] - Train Loss: 1.2981, Test Loss: 2.6627\n",
      "Epoch [28/50] - Train Loss: 1.2979, Test Loss: 2.6629\n",
      "Epoch [29/50] - Train Loss: 1.2976, Test Loss: 2.6630\n",
      "Epoch [30/50] - Train Loss: 1.2974, Test Loss: 2.6632\n",
      "Epoch [31/50] - Train Loss: 1.2971, Test Loss: 2.6633\n",
      "Epoch [32/50] - Train Loss: 1.2968, Test Loss: 2.6634\n",
      "Epoch [33/50] - Train Loss: 1.2966, Test Loss: 2.6636\n",
      "Epoch [34/50] - Train Loss: 1.2962, Test Loss: 2.6637\n",
      "Epoch [35/50] - Train Loss: 1.2959, Test Loss: 2.6638\n",
      "Epoch [36/50] - Train Loss: 1.2956, Test Loss: 2.6640\n",
      "Epoch [37/50] - Train Loss: 1.2952, Test Loss: 2.6641\n",
      "Epoch [38/50] - Train Loss: 1.2949, Test Loss: 2.6643\n",
      "Epoch [39/50] - Train Loss: 1.2945, Test Loss: 2.6644\n",
      "Epoch [40/50] - Train Loss: 1.2941, Test Loss: 2.6646\n",
      "Epoch [41/50] - Train Loss: 1.2937, Test Loss: 2.6647\n",
      "Epoch [42/50] - Train Loss: 1.2933, Test Loss: 2.6649\n",
      "Epoch [43/50] - Train Loss: 1.2929, Test Loss: 2.6650\n",
      "Epoch [44/50] - Train Loss: 1.2925, Test Loss: 2.6652\n",
      "Epoch [45/50] - Train Loss: 1.2921, Test Loss: 2.6654\n",
      "Epoch [46/50] - Train Loss: 1.2918, Test Loss: 2.6656\n",
      "Epoch [47/50] - Train Loss: 1.2914, Test Loss: 2.6658\n",
      "Epoch [48/50] - Train Loss: 1.2911, Test Loss: 2.6660\n",
      "Epoch [49/50] - Train Loss: 1.2908, Test Loss: 2.6662\n",
      "Epoch [50/50] - Train Loss: 1.2905, Test Loss: 2.6664\n",
      "Avg Test Loss: 2.6664\n",
      "Testing combination: (64, 3, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1386, Test Loss: 1.4777\n",
      "Epoch [2/50] - Train Loss: 1.0985, Test Loss: 1.4785\n",
      "Epoch [3/50] - Train Loss: 1.0975, Test Loss: 1.4811\n",
      "Epoch [4/50] - Train Loss: 1.0966, Test Loss: 1.4830\n",
      "Epoch [5/50] - Train Loss: 1.0951, Test Loss: 1.4837\n",
      "Epoch [6/50] - Train Loss: 1.1045, Test Loss: 1.4825\n",
      "Epoch [7/50] - Train Loss: 1.0942, Test Loss: 1.4819\n",
      "Epoch [8/50] - Train Loss: 1.0936, Test Loss: 1.4820\n",
      "Epoch [9/50] - Train Loss: 1.0880, Test Loss: 1.4820\n",
      "Epoch [10/50] - Train Loss: 1.0896, Test Loss: 1.4816\n",
      "Epoch [11/50] - Train Loss: 1.0876, Test Loss: 1.4813\n",
      "Epoch [12/50] - Train Loss: 1.0816, Test Loss: 1.4812\n",
      "Epoch [13/50] - Train Loss: 1.1404, Test Loss: 1.4788\n",
      "Epoch [14/50] - Train Loss: 1.0883, Test Loss: 1.4791\n",
      "Epoch [15/50] - Train Loss: 1.0846, Test Loss: 1.4806\n",
      "Epoch [16/50] - Train Loss: 1.0828, Test Loss: 1.4837\n",
      "Epoch [17/50] - Train Loss: 1.0810, Test Loss: 2.3840\n",
      "Epoch [18/50] - Train Loss: 1.3495, Test Loss: 1.4933\n",
      "Epoch [19/50] - Train Loss: 1.0932, Test Loss: 1.4748\n",
      "Epoch [20/50] - Train Loss: 1.0982, Test Loss: 1.5130\n",
      "Epoch [21/50] - Train Loss: 1.0843, Test Loss: 1.4825\n",
      "Epoch [22/50] - Train Loss: 1.0708, Test Loss: 1.4817\n",
      "Epoch [23/50] - Train Loss: 1.0794, Test Loss: 1.4784\n",
      "Epoch [24/50] - Train Loss: 1.0819, Test Loss: 1.4967\n",
      "Epoch [25/50] - Train Loss: 1.0654, Test Loss: 1.4856\n",
      "Epoch [26/50] - Train Loss: 1.0629, Test Loss: 1.4793\n",
      "Epoch [27/50] - Train Loss: 1.0629, Test Loss: 1.4780\n",
      "Epoch [28/50] - Train Loss: 1.0616, Test Loss: 1.4789\n",
      "Epoch [29/50] - Train Loss: 1.0616, Test Loss: 1.4840\n",
      "Epoch [30/50] - Train Loss: 1.0578, Test Loss: 1.4806\n",
      "Epoch [31/50] - Train Loss: 1.0605, Test Loss: 1.4780\n",
      "Epoch [32/50] - Train Loss: 1.0596, Test Loss: 1.4774\n",
      "Epoch [33/50] - Train Loss: 1.0530, Test Loss: 1.4925\n",
      "Epoch [34/50] - Train Loss: 1.0514, Test Loss: 1.4970\n",
      "Epoch [35/50] - Train Loss: 1.0495, Test Loss: 1.4867\n",
      "Epoch [36/50] - Train Loss: 1.0493, Test Loss: 1.4858\n",
      "Epoch [37/50] - Train Loss: 1.0480, Test Loss: 1.4903\n",
      "Epoch [38/50] - Train Loss: 1.0479, Test Loss: 1.4957\n",
      "Epoch [39/50] - Train Loss: 1.0477, Test Loss: 1.5006\n",
      "Epoch [40/50] - Train Loss: 1.0471, Test Loss: 1.5027\n",
      "Epoch [41/50] - Train Loss: 1.0452, Test Loss: 1.4947\n",
      "Epoch [42/50] - Train Loss: 1.0518, Test Loss: 1.4811\n",
      "Epoch [43/50] - Train Loss: 1.0433, Test Loss: 1.4816\n",
      "Epoch [44/50] - Train Loss: 1.0383, Test Loss: 1.4842\n",
      "Epoch [45/50] - Train Loss: 1.0374, Test Loss: 1.4875\n",
      "Epoch [46/50] - Train Loss: 1.0364, Test Loss: 1.4900\n",
      "Epoch [47/50] - Train Loss: 1.0357, Test Loss: 1.4914\n",
      "Epoch [48/50] - Train Loss: 1.0352, Test Loss: 1.4921\n",
      "Epoch [49/50] - Train Loss: 1.0349, Test Loss: 1.4924\n",
      "Epoch [50/50] - Train Loss: 1.0346, Test Loss: 1.4923\n",
      "Avg Test Loss: 1.4923\n",
      "Testing combination: (64, 3, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1294, Test Loss: 1.5944\n",
      "Epoch [2/50] - Train Loss: 1.1167, Test Loss: 1.5989\n",
      "Epoch [3/50] - Train Loss: 1.1188, Test Loss: 1.6047\n",
      "Epoch [4/50] - Train Loss: 1.1144, Test Loss: 1.6069\n",
      "Epoch [5/50] - Train Loss: 1.1137, Test Loss: 1.6058\n",
      "Epoch [6/50] - Train Loss: 1.1108, Test Loss: 1.6048\n",
      "Epoch [7/50] - Train Loss: 1.1076, Test Loss: 1.6233\n",
      "Epoch [8/50] - Train Loss: 1.1009, Test Loss: 1.6140\n",
      "Epoch [9/50] - Train Loss: 1.0824, Test Loss: 1.6149\n",
      "Epoch [10/50] - Train Loss: 1.1124, Test Loss: 1.6152\n",
      "Epoch [11/50] - Train Loss: 1.0856, Test Loss: 1.6088\n",
      "Epoch [12/50] - Train Loss: 1.1092, Test Loss: 1.6147\n",
      "Epoch [13/50] - Train Loss: 1.1183, Test Loss: 1.6048\n",
      "Epoch [14/50] - Train Loss: 1.1090, Test Loss: 1.6011\n",
      "Epoch [15/50] - Train Loss: 1.1097, Test Loss: 1.6043\n",
      "Epoch [16/50] - Train Loss: 1.1077, Test Loss: 1.6054\n",
      "Epoch [17/50] - Train Loss: 1.1054, Test Loss: 1.6073\n",
      "Epoch [18/50] - Train Loss: 1.1017, Test Loss: 1.6086\n",
      "Epoch [19/50] - Train Loss: 1.0852, Test Loss: 1.6106\n",
      "Epoch [20/50] - Train Loss: 1.1367, Test Loss: 1.6054\n",
      "Epoch [21/50] - Train Loss: 1.1162, Test Loss: 1.6046\n",
      "Epoch [22/50] - Train Loss: 1.1229, Test Loss: 1.5986\n",
      "Epoch [23/50] - Train Loss: 1.0942, Test Loss: 1.6059\n",
      "Epoch [24/50] - Train Loss: 1.0827, Test Loss: 1.6234\n",
      "Epoch [25/50] - Train Loss: 1.0801, Test Loss: 1.6144\n",
      "Epoch [26/50] - Train Loss: 1.0794, Test Loss: 1.6085\n",
      "Epoch [27/50] - Train Loss: 1.0796, Test Loss: 1.6113\n",
      "Epoch [28/50] - Train Loss: 1.0790, Test Loss: 1.6129\n",
      "Epoch [29/50] - Train Loss: 1.0787, Test Loss: 1.6133\n",
      "Epoch [30/50] - Train Loss: 1.0786, Test Loss: 1.6135\n",
      "Epoch [31/50] - Train Loss: 1.0786, Test Loss: 1.6132\n",
      "Epoch [32/50] - Train Loss: 1.0785, Test Loss: 1.6127\n",
      "Epoch [33/50] - Train Loss: 1.0785, Test Loss: 1.6128\n",
      "Epoch [34/50] - Train Loss: 1.0785, Test Loss: 1.6131\n",
      "Epoch [35/50] - Train Loss: 1.0784, Test Loss: 1.6132\n",
      "Epoch [36/50] - Train Loss: 1.0784, Test Loss: 1.6132\n",
      "Epoch [37/50] - Train Loss: 1.0784, Test Loss: 1.6132\n",
      "Epoch [38/50] - Train Loss: 1.0784, Test Loss: 1.6132\n",
      "Epoch [39/50] - Train Loss: 1.0783, Test Loss: 1.6132\n",
      "Epoch [40/50] - Train Loss: 1.0783, Test Loss: 1.6133\n",
      "Epoch [41/50] - Train Loss: 1.0783, Test Loss: 1.6133\n",
      "Epoch [42/50] - Train Loss: 1.0783, Test Loss: 1.6133\n",
      "Epoch [43/50] - Train Loss: 1.0782, Test Loss: 1.6133\n",
      "Epoch [44/50] - Train Loss: 1.0782, Test Loss: 1.6133\n",
      "Epoch [45/50] - Train Loss: 1.0783, Test Loss: 1.6137\n",
      "Epoch [46/50] - Train Loss: 1.0782, Test Loss: 1.6139\n",
      "Epoch [47/50] - Train Loss: 1.0782, Test Loss: 1.6137\n",
      "Epoch [48/50] - Train Loss: 1.0782, Test Loss: 1.6133\n",
      "Epoch [49/50] - Train Loss: 1.0782, Test Loss: 1.6133\n",
      "Epoch [50/50] - Train Loss: 1.0782, Test Loss: 1.6134\n",
      "Avg Test Loss: 1.6134\n",
      "Testing combination: (64, 3, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3446, Test Loss: 2.7255\n",
      "Epoch [2/50] - Train Loss: 1.3099, Test Loss: 2.6921\n",
      "Epoch [3/50] - Train Loss: 1.3041, Test Loss: 2.6670\n",
      "Epoch [4/50] - Train Loss: 1.3029, Test Loss: 2.6588\n",
      "Epoch [5/50] - Train Loss: 1.3004, Test Loss: 2.6618\n",
      "Epoch [6/50] - Train Loss: 1.2959, Test Loss: 2.6670\n",
      "Epoch [7/50] - Train Loss: 1.2888, Test Loss: 2.6716\n",
      "Epoch [8/50] - Train Loss: 1.2875, Test Loss: 2.6737\n",
      "Epoch [9/50] - Train Loss: 1.2821, Test Loss: 2.6636\n",
      "Epoch [10/50] - Train Loss: 1.3254, Test Loss: 2.6546\n",
      "Epoch [11/50] - Train Loss: 1.2772, Test Loss: 2.6564\n",
      "Epoch [12/50] - Train Loss: 1.2826, Test Loss: 2.6541\n",
      "Epoch [13/50] - Train Loss: 1.2668, Test Loss: 2.6527\n",
      "Epoch [14/50] - Train Loss: 1.2581, Test Loss: 2.6579\n",
      "Epoch [15/50] - Train Loss: 1.2623, Test Loss: 2.6663\n",
      "Epoch [16/50] - Train Loss: 1.2580, Test Loss: 2.6667\n",
      "Epoch [17/50] - Train Loss: 1.2549, Test Loss: 2.6616\n",
      "Epoch [18/50] - Train Loss: 1.2571, Test Loss: 2.6600\n",
      "Epoch [19/50] - Train Loss: 1.2541, Test Loss: 2.6648\n",
      "Epoch [20/50] - Train Loss: 1.2788, Test Loss: 2.7038\n",
      "Epoch [21/50] - Train Loss: 1.2604, Test Loss: 2.6618\n",
      "Epoch [22/50] - Train Loss: 1.2666, Test Loss: 2.6622\n",
      "Epoch [23/50] - Train Loss: 1.2569, Test Loss: 2.6592\n",
      "Epoch [24/50] - Train Loss: 1.2548, Test Loss: 2.6563\n",
      "Epoch [25/50] - Train Loss: 1.2542, Test Loss: 2.6572\n",
      "Epoch [26/50] - Train Loss: 1.2545, Test Loss: 2.6603\n",
      "Epoch [27/50] - Train Loss: 1.2542, Test Loss: 2.6627\n",
      "Epoch [28/50] - Train Loss: 1.2540, Test Loss: 2.6628\n",
      "Epoch [29/50] - Train Loss: 1.2538, Test Loss: 2.6613\n",
      "Epoch [30/50] - Train Loss: 1.2539, Test Loss: 2.6599\n",
      "Epoch [31/50] - Train Loss: 1.2539, Test Loss: 2.6598\n",
      "Epoch [32/50] - Train Loss: 1.2538, Test Loss: 2.6606\n",
      "Epoch [33/50] - Train Loss: 1.2538, Test Loss: 2.6613\n",
      "Epoch [34/50] - Train Loss: 1.2538, Test Loss: 2.6614\n",
      "Epoch [35/50] - Train Loss: 1.2537, Test Loss: 2.6610\n",
      "Epoch [36/50] - Train Loss: 1.2537, Test Loss: 2.6605\n",
      "Epoch [37/50] - Train Loss: 1.2537, Test Loss: 2.6604\n",
      "Epoch [38/50] - Train Loss: 1.2537, Test Loss: 2.6605\n",
      "Epoch [39/50] - Train Loss: 1.2537, Test Loss: 2.6606\n",
      "Epoch [40/50] - Train Loss: 1.2536, Test Loss: 2.6606\n",
      "Epoch [41/50] - Train Loss: 1.2536, Test Loss: 2.6604\n",
      "Epoch [42/50] - Train Loss: 1.2536, Test Loss: 2.6601\n",
      "Epoch [43/50] - Train Loss: 1.2535, Test Loss: 2.6598\n",
      "Epoch [44/50] - Train Loss: 1.2534, Test Loss: 2.6592\n",
      "Epoch [45/50] - Train Loss: 1.2533, Test Loss: 2.6579\n",
      "Epoch [46/50] - Train Loss: 1.2530, Test Loss: 2.6549\n",
      "Epoch [47/50] - Train Loss: 1.2526, Test Loss: 2.6494\n",
      "Epoch [48/50] - Train Loss: 1.2505, Test Loss: 2.6445\n",
      "Epoch [49/50] - Train Loss: 1.2652, Test Loss: 2.6486\n",
      "Epoch [50/50] - Train Loss: 1.2517, Test Loss: 2.6653\n",
      "Avg Test Loss: 2.6653\n",
      "Testing combination: (64, 3, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1100, Test Loss: 1.5126\n",
      "Epoch [2/50] - Train Loss: 1.0972, Test Loss: 1.4960\n",
      "Epoch [3/50] - Train Loss: 1.0941, Test Loss: 1.4882\n",
      "Epoch [4/50] - Train Loss: 1.0935, Test Loss: 1.4852\n",
      "Epoch [5/50] - Train Loss: 1.0930, Test Loss: 1.4844\n",
      "Epoch [6/50] - Train Loss: 1.0917, Test Loss: 1.4843\n",
      "Epoch [7/50] - Train Loss: 1.0894, Test Loss: 1.4841\n",
      "Epoch [8/50] - Train Loss: 1.0867, Test Loss: 1.4838\n",
      "Epoch [9/50] - Train Loss: 1.0828, Test Loss: 1.4834\n",
      "Epoch [10/50] - Train Loss: 1.0800, Test Loss: 1.4832\n",
      "Epoch [11/50] - Train Loss: 1.0830, Test Loss: 1.4835\n",
      "Epoch [12/50] - Train Loss: 1.1000, Test Loss: 1.4845\n",
      "Epoch [13/50] - Train Loss: 1.0766, Test Loss: 1.4867\n",
      "Epoch [14/50] - Train Loss: 1.0666, Test Loss: 1.4864\n",
      "Epoch [15/50] - Train Loss: 1.0592, Test Loss: 1.4857\n",
      "Epoch [16/50] - Train Loss: 1.0561, Test Loss: 1.4871\n",
      "Epoch [17/50] - Train Loss: 1.0546, Test Loss: 1.4886\n",
      "Epoch [18/50] - Train Loss: 1.0533, Test Loss: 1.4882\n",
      "Epoch [19/50] - Train Loss: 1.0529, Test Loss: 1.4875\n",
      "Epoch [20/50] - Train Loss: 1.0527, Test Loss: 1.4872\n",
      "Epoch [21/50] - Train Loss: 1.0526, Test Loss: 1.4870\n",
      "Epoch [22/50] - Train Loss: 1.0525, Test Loss: 1.4871\n",
      "Epoch [23/50] - Train Loss: 1.0523, Test Loss: 1.4871\n",
      "Epoch [24/50] - Train Loss: 1.0521, Test Loss: 1.4871\n",
      "Epoch [25/50] - Train Loss: 1.0519, Test Loss: 1.4871\n",
      "Epoch [26/50] - Train Loss: 1.0515, Test Loss: 1.4871\n",
      "Epoch [27/50] - Train Loss: 1.0511, Test Loss: 1.4872\n",
      "Epoch [28/50] - Train Loss: 1.0507, Test Loss: 1.4878\n",
      "Epoch [29/50] - Train Loss: 1.0502, Test Loss: 1.4886\n",
      "Epoch [30/50] - Train Loss: 1.0494, Test Loss: 1.4894\n",
      "Epoch [31/50] - Train Loss: 1.0483, Test Loss: 1.4898\n",
      "Epoch [32/50] - Train Loss: 1.0469, Test Loss: 1.4891\n",
      "Epoch [33/50] - Train Loss: 1.0444, Test Loss: 1.4866\n",
      "Epoch [34/50] - Train Loss: 1.0502, Test Loss: 1.4901\n",
      "Epoch [35/50] - Train Loss: 1.0702, Test Loss: 1.4893\n",
      "Epoch [36/50] - Train Loss: 1.0704, Test Loss: 1.4875\n",
      "Epoch [37/50] - Train Loss: 1.0513, Test Loss: 1.4897\n",
      "Epoch [38/50] - Train Loss: 1.0475, Test Loss: 1.4887\n",
      "Epoch [39/50] - Train Loss: 1.0462, Test Loss: 1.4880\n",
      "Epoch [40/50] - Train Loss: 1.0454, Test Loss: 1.4885\n",
      "Epoch [41/50] - Train Loss: 1.0439, Test Loss: 1.4886\n",
      "Epoch [42/50] - Train Loss: 1.0415, Test Loss: 1.4868\n",
      "Epoch [43/50] - Train Loss: 1.0371, Test Loss: 1.4801\n",
      "Epoch [44/50] - Train Loss: 1.0497, Test Loss: 1.4890\n",
      "Epoch [45/50] - Train Loss: 1.1352, Test Loss: 1.4955\n",
      "Epoch [46/50] - Train Loss: 1.0697, Test Loss: 1.4916\n",
      "Epoch [47/50] - Train Loss: 1.0655, Test Loss: 1.4892\n",
      "Epoch [48/50] - Train Loss: 1.0575, Test Loss: 1.4888\n",
      "Epoch [49/50] - Train Loss: 1.0531, Test Loss: 1.4888\n",
      "Epoch [50/50] - Train Loss: 1.0517, Test Loss: 1.4882\n",
      "Avg Test Loss: 1.4882\n",
      "Testing combination: (64, 3, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1226, Test Loss: 1.6280\n",
      "Epoch [2/50] - Train Loss: 1.1152, Test Loss: 1.6095\n",
      "Epoch [3/50] - Train Loss: 1.1150, Test Loss: 1.6045\n",
      "Epoch [4/50] - Train Loss: 1.1151, Test Loss: 1.6055\n",
      "Epoch [5/50] - Train Loss: 1.1148, Test Loss: 1.6079\n",
      "Epoch [6/50] - Train Loss: 1.1143, Test Loss: 1.6094\n",
      "Epoch [7/50] - Train Loss: 1.1135, Test Loss: 1.6096\n",
      "Epoch [8/50] - Train Loss: 1.1123, Test Loss: 1.6088\n",
      "Epoch [9/50] - Train Loss: 1.1105, Test Loss: 1.6074\n",
      "Epoch [10/50] - Train Loss: 1.1070, Test Loss: 1.6063\n",
      "Epoch [11/50] - Train Loss: 1.1044, Test Loss: 1.6073\n",
      "Epoch [12/50] - Train Loss: 1.1174, Test Loss: 1.6098\n",
      "Epoch [13/50] - Train Loss: 1.1135, Test Loss: 1.6090\n",
      "Epoch [14/50] - Train Loss: 1.1100, Test Loss: 1.6075\n",
      "Epoch [15/50] - Train Loss: 1.1056, Test Loss: 1.6062\n",
      "Epoch [16/50] - Train Loss: 1.0989, Test Loss: 1.6063\n",
      "Epoch [17/50] - Train Loss: 1.0878, Test Loss: 1.6095\n",
      "Epoch [18/50] - Train Loss: 1.0862, Test Loss: 1.6153\n",
      "Epoch [19/50] - Train Loss: 1.1111, Test Loss: 1.6172\n",
      "Epoch [20/50] - Train Loss: 1.0788, Test Loss: 1.6124\n",
      "Epoch [21/50] - Train Loss: 1.0811, Test Loss: 1.6123\n",
      "Epoch [22/50] - Train Loss: 1.0789, Test Loss: 1.6139\n",
      "Epoch [23/50] - Train Loss: 1.0784, Test Loss: 1.6149\n",
      "Epoch [24/50] - Train Loss: 1.0782, Test Loss: 1.6149\n",
      "Epoch [25/50] - Train Loss: 1.0780, Test Loss: 1.6147\n",
      "Epoch [26/50] - Train Loss: 1.0778, Test Loss: 1.6147\n",
      "Epoch [27/50] - Train Loss: 1.0776, Test Loss: 1.6147\n",
      "Epoch [28/50] - Train Loss: 1.0773, Test Loss: 1.6147\n",
      "Epoch [29/50] - Train Loss: 1.0770, Test Loss: 1.6147\n",
      "Epoch [30/50] - Train Loss: 1.0765, Test Loss: 1.6151\n",
      "Epoch [31/50] - Train Loss: 1.0760, Test Loss: 1.6170\n",
      "Epoch [32/50] - Train Loss: 1.0756, Test Loss: 1.6205\n",
      "Epoch [33/50] - Train Loss: 1.0747, Test Loss: 1.6223\n",
      "Epoch [34/50] - Train Loss: 1.0738, Test Loss: 1.6223\n",
      "Epoch [35/50] - Train Loss: 1.0731, Test Loss: 1.6219\n",
      "Epoch [36/50] - Train Loss: 1.0722, Test Loss: 1.6214\n",
      "Epoch [37/50] - Train Loss: 1.0714, Test Loss: 1.6209\n",
      "Epoch [38/50] - Train Loss: 1.0704, Test Loss: 1.6202\n",
      "Epoch [39/50] - Train Loss: 1.0689, Test Loss: 1.6192\n",
      "Epoch [40/50] - Train Loss: 1.0679, Test Loss: 1.6188\n",
      "Epoch [41/50] - Train Loss: 1.0654, Test Loss: 1.6191\n",
      "Epoch [42/50] - Train Loss: 1.0630, Test Loss: 1.6176\n",
      "Epoch [43/50] - Train Loss: 1.0756, Test Loss: 1.6224\n",
      "Epoch [44/50] - Train Loss: 1.0723, Test Loss: 1.6194\n",
      "Epoch [45/50] - Train Loss: 1.0686, Test Loss: 1.6193\n",
      "Epoch [46/50] - Train Loss: 1.0652, Test Loss: 1.6188\n",
      "Epoch [47/50] - Train Loss: 1.0658, Test Loss: 1.6244\n",
      "Epoch [48/50] - Train Loss: 1.0650, Test Loss: 1.6255\n",
      "Epoch [49/50] - Train Loss: 1.0629, Test Loss: 1.6209\n",
      "Epoch [50/50] - Train Loss: 1.0617, Test Loss: 1.6171\n",
      "Avg Test Loss: 1.6171\n",
      "Testing combination: (64, 3, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3085, Test Loss: 2.6586\n",
      "Epoch [2/50] - Train Loss: 1.3030, Test Loss: 2.6691\n",
      "Epoch [3/50] - Train Loss: 1.3023, Test Loss: 2.6717\n",
      "Epoch [4/50] - Train Loss: 1.3018, Test Loss: 2.6701\n",
      "Epoch [5/50] - Train Loss: 1.3013, Test Loss: 2.6674\n",
      "Epoch [6/50] - Train Loss: 1.3007, Test Loss: 2.6649\n",
      "Epoch [7/50] - Train Loss: 1.3001, Test Loss: 2.6633\n",
      "Epoch [8/50] - Train Loss: 1.2993, Test Loss: 2.6628\n",
      "Epoch [9/50] - Train Loss: 1.2981, Test Loss: 2.6633\n",
      "Epoch [10/50] - Train Loss: 1.2965, Test Loss: 2.6647\n",
      "Epoch [11/50] - Train Loss: 1.2947, Test Loss: 2.6668\n",
      "Epoch [12/50] - Train Loss: 1.2930, Test Loss: 2.6691\n",
      "Epoch [13/50] - Train Loss: 1.2914, Test Loss: 2.6709\n",
      "Epoch [14/50] - Train Loss: 1.2893, Test Loss: 2.6716\n",
      "Epoch [15/50] - Train Loss: 1.2871, Test Loss: 2.6715\n",
      "Epoch [16/50] - Train Loss: 1.2842, Test Loss: 2.6708\n",
      "Epoch [17/50] - Train Loss: 1.2799, Test Loss: 2.6695\n",
      "Epoch [18/50] - Train Loss: 1.2758, Test Loss: 2.6675\n",
      "Epoch [19/50] - Train Loss: 1.2722, Test Loss: 2.6637\n",
      "Epoch [20/50] - Train Loss: 1.2587, Test Loss: 2.6596\n",
      "Epoch [21/50] - Train Loss: 1.2575, Test Loss: 2.6562\n",
      "Epoch [22/50] - Train Loss: 1.2543, Test Loss: 2.6542\n",
      "Epoch [23/50] - Train Loss: 1.2545, Test Loss: 2.6543\n",
      "Epoch [24/50] - Train Loss: 1.2538, Test Loss: 2.6559\n",
      "Epoch [25/50] - Train Loss: 1.2532, Test Loss: 2.6577\n",
      "Epoch [26/50] - Train Loss: 1.2530, Test Loss: 2.6585\n",
      "Epoch [27/50] - Train Loss: 1.2526, Test Loss: 2.6578\n",
      "Epoch [28/50] - Train Loss: 1.2521, Test Loss: 2.6557\n",
      "Epoch [29/50] - Train Loss: 1.2518, Test Loss: 2.6532\n",
      "Epoch [30/50] - Train Loss: 1.2516, Test Loss: 2.6512\n",
      "Epoch [31/50] - Train Loss: 1.2513, Test Loss: 2.6503\n",
      "Epoch [32/50] - Train Loss: 1.2511, Test Loss: 2.6504\n",
      "Epoch [33/50] - Train Loss: 1.2507, Test Loss: 2.6507\n",
      "Epoch [34/50] - Train Loss: 1.2504, Test Loss: 2.6507\n",
      "Epoch [35/50] - Train Loss: 1.2500, Test Loss: 2.6500\n",
      "Epoch [36/50] - Train Loss: 1.2495, Test Loss: 2.6488\n",
      "Epoch [37/50] - Train Loss: 1.2486, Test Loss: 2.6466\n",
      "Epoch [38/50] - Train Loss: 1.2470, Test Loss: 2.6448\n",
      "Epoch [39/50] - Train Loss: 1.2444, Test Loss: 2.6453\n",
      "Epoch [40/50] - Train Loss: 1.2495, Test Loss: 2.6465\n",
      "Epoch [41/50] - Train Loss: 1.2489, Test Loss: 2.6496\n",
      "Epoch [42/50] - Train Loss: 1.2481, Test Loss: 2.6499\n",
      "Epoch [43/50] - Train Loss: 1.2452, Test Loss: 2.6472\n",
      "Epoch [44/50] - Train Loss: 1.2554, Test Loss: 2.6374\n",
      "Epoch [45/50] - Train Loss: 1.2509, Test Loss: 2.6451\n",
      "Epoch [46/50] - Train Loss: 1.2571, Test Loss: 2.6509\n",
      "Epoch [47/50] - Train Loss: 1.2522, Test Loss: 2.6589\n",
      "Epoch [48/50] - Train Loss: 1.2523, Test Loss: 2.6641\n",
      "Epoch [49/50] - Train Loss: 1.2509, Test Loss: 2.6624\n",
      "Epoch [50/50] - Train Loss: 1.2493, Test Loss: 2.6559\n",
      "Avg Test Loss: 2.6559\n",
      "Testing combination: (64, 3, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.0975, Test Loss: 1.4762\n",
      "Epoch [2/50] - Train Loss: 1.0964, Test Loss: 1.4767\n",
      "Epoch [3/50] - Train Loss: 1.0959, Test Loss: 1.4771\n",
      "Epoch [4/50] - Train Loss: 1.0955, Test Loss: 1.4775\n",
      "Epoch [5/50] - Train Loss: 1.0952, Test Loss: 1.4780\n",
      "Epoch [6/50] - Train Loss: 1.0949, Test Loss: 1.4784\n",
      "Epoch [7/50] - Train Loss: 1.0946, Test Loss: 1.4788\n",
      "Epoch [8/50] - Train Loss: 1.0944, Test Loss: 1.4792\n",
      "Epoch [9/50] - Train Loss: 1.0942, Test Loss: 1.4796\n",
      "Epoch [10/50] - Train Loss: 1.0940, Test Loss: 1.4799\n",
      "Epoch [11/50] - Train Loss: 1.0938, Test Loss: 1.4803\n",
      "Epoch [12/50] - Train Loss: 1.0936, Test Loss: 1.4807\n",
      "Epoch [13/50] - Train Loss: 1.0935, Test Loss: 1.4810\n",
      "Epoch [14/50] - Train Loss: 1.0934, Test Loss: 1.4813\n",
      "Epoch [15/50] - Train Loss: 1.0932, Test Loss: 1.4816\n",
      "Epoch [16/50] - Train Loss: 1.0931, Test Loss: 1.4819\n",
      "Epoch [17/50] - Train Loss: 1.0930, Test Loss: 1.4822\n",
      "Epoch [18/50] - Train Loss: 1.0929, Test Loss: 1.4824\n",
      "Epoch [19/50] - Train Loss: 1.0927, Test Loss: 1.4827\n",
      "Epoch [20/50] - Train Loss: 1.0926, Test Loss: 1.4829\n",
      "Epoch [21/50] - Train Loss: 1.0925, Test Loss: 1.4831\n",
      "Epoch [22/50] - Train Loss: 1.0924, Test Loss: 1.4833\n",
      "Epoch [23/50] - Train Loss: 1.0922, Test Loss: 1.4835\n",
      "Epoch [24/50] - Train Loss: 1.0921, Test Loss: 1.4837\n",
      "Epoch [25/50] - Train Loss: 1.0920, Test Loss: 1.4839\n",
      "Epoch [26/50] - Train Loss: 1.0918, Test Loss: 1.4840\n",
      "Epoch [27/50] - Train Loss: 1.0916, Test Loss: 1.4842\n",
      "Epoch [28/50] - Train Loss: 1.0914, Test Loss: 1.4843\n",
      "Epoch [29/50] - Train Loss: 1.0912, Test Loss: 1.4844\n",
      "Epoch [30/50] - Train Loss: 1.0910, Test Loss: 1.4845\n",
      "Epoch [31/50] - Train Loss: 1.0908, Test Loss: 1.4847\n",
      "Epoch [32/50] - Train Loss: 1.0905, Test Loss: 1.4848\n",
      "Epoch [33/50] - Train Loss: 1.0902, Test Loss: 1.4849\n",
      "Epoch [34/50] - Train Loss: 1.0899, Test Loss: 1.4849\n",
      "Epoch [35/50] - Train Loss: 1.0895, Test Loss: 1.4850\n",
      "Epoch [36/50] - Train Loss: 1.0891, Test Loss: 1.4851\n",
      "Epoch [37/50] - Train Loss: 1.0887, Test Loss: 1.4851\n",
      "Epoch [38/50] - Train Loss: 1.0883, Test Loss: 1.4851\n",
      "Epoch [39/50] - Train Loss: 1.0878, Test Loss: 1.4851\n",
      "Epoch [40/50] - Train Loss: 1.0873, Test Loss: 1.4851\n",
      "Epoch [41/50] - Train Loss: 1.0868, Test Loss: 1.4851\n",
      "Epoch [42/50] - Train Loss: 1.0863, Test Loss: 1.4850\n",
      "Epoch [43/50] - Train Loss: 1.0858, Test Loss: 1.4849\n",
      "Epoch [44/50] - Train Loss: 1.0853, Test Loss: 1.4848\n",
      "Epoch [45/50] - Train Loss: 1.0848, Test Loss: 1.4847\n",
      "Epoch [46/50] - Train Loss: 1.0843, Test Loss: 1.4846\n",
      "Epoch [47/50] - Train Loss: 1.0838, Test Loss: 1.4845\n",
      "Epoch [48/50] - Train Loss: 1.0833, Test Loss: 1.4843\n",
      "Epoch [49/50] - Train Loss: 1.0828, Test Loss: 1.4842\n",
      "Epoch [50/50] - Train Loss: 1.0822, Test Loss: 1.4841\n",
      "Avg Test Loss: 1.4841\n",
      "Testing combination: (64, 3, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1181, Test Loss: 1.6377\n",
      "Epoch [2/50] - Train Loss: 1.1173, Test Loss: 1.6349\n",
      "Epoch [3/50] - Train Loss: 1.1168, Test Loss: 1.6323\n",
      "Epoch [4/50] - Train Loss: 1.1163, Test Loss: 1.6299\n",
      "Epoch [5/50] - Train Loss: 1.1159, Test Loss: 1.6277\n",
      "Epoch [6/50] - Train Loss: 1.1156, Test Loss: 1.6258\n",
      "Epoch [7/50] - Train Loss: 1.1153, Test Loss: 1.6240\n",
      "Epoch [8/50] - Train Loss: 1.1151, Test Loss: 1.6225\n",
      "Epoch [9/50] - Train Loss: 1.1149, Test Loss: 1.6211\n",
      "Epoch [10/50] - Train Loss: 1.1148, Test Loss: 1.6199\n",
      "Epoch [11/50] - Train Loss: 1.1146, Test Loss: 1.6187\n",
      "Epoch [12/50] - Train Loss: 1.1145, Test Loss: 1.6178\n",
      "Epoch [13/50] - Train Loss: 1.1144, Test Loss: 1.6169\n",
      "Epoch [14/50] - Train Loss: 1.1144, Test Loss: 1.6161\n",
      "Epoch [15/50] - Train Loss: 1.1143, Test Loss: 1.6154\n",
      "Epoch [16/50] - Train Loss: 1.1142, Test Loss: 1.6147\n",
      "Epoch [17/50] - Train Loss: 1.1141, Test Loss: 1.6142\n",
      "Epoch [18/50] - Train Loss: 1.1141, Test Loss: 1.6137\n",
      "Epoch [19/50] - Train Loss: 1.1140, Test Loss: 1.6132\n",
      "Epoch [20/50] - Train Loss: 1.1140, Test Loss: 1.6128\n",
      "Epoch [21/50] - Train Loss: 1.1139, Test Loss: 1.6124\n",
      "Epoch [22/50] - Train Loss: 1.1138, Test Loss: 1.6121\n",
      "Epoch [23/50] - Train Loss: 1.1138, Test Loss: 1.6118\n",
      "Epoch [24/50] - Train Loss: 1.1137, Test Loss: 1.6116\n",
      "Epoch [25/50] - Train Loss: 1.1136, Test Loss: 1.6113\n",
      "Epoch [26/50] - Train Loss: 1.1135, Test Loss: 1.6111\n",
      "Epoch [27/50] - Train Loss: 1.1134, Test Loss: 1.6109\n",
      "Epoch [28/50] - Train Loss: 1.1133, Test Loss: 1.6107\n",
      "Epoch [29/50] - Train Loss: 1.1132, Test Loss: 1.6105\n",
      "Epoch [30/50] - Train Loss: 1.1130, Test Loss: 1.6104\n",
      "Epoch [31/50] - Train Loss: 1.1129, Test Loss: 1.6102\n",
      "Epoch [32/50] - Train Loss: 1.1127, Test Loss: 1.6101\n",
      "Epoch [33/50] - Train Loss: 1.1125, Test Loss: 1.6099\n",
      "Epoch [34/50] - Train Loss: 1.1123, Test Loss: 1.6098\n",
      "Epoch [35/50] - Train Loss: 1.1121, Test Loss: 1.6096\n",
      "Epoch [36/50] - Train Loss: 1.1118, Test Loss: 1.6095\n",
      "Epoch [37/50] - Train Loss: 1.1115, Test Loss: 1.6094\n",
      "Epoch [38/50] - Train Loss: 1.1112, Test Loss: 1.6092\n",
      "Epoch [39/50] - Train Loss: 1.1108, Test Loss: 1.6090\n",
      "Epoch [40/50] - Train Loss: 1.1105, Test Loss: 1.6089\n",
      "Epoch [41/50] - Train Loss: 1.1100, Test Loss: 1.6087\n",
      "Epoch [42/50] - Train Loss: 1.1096, Test Loss: 1.6085\n",
      "Epoch [43/50] - Train Loss: 1.1090, Test Loss: 1.6083\n",
      "Epoch [44/50] - Train Loss: 1.1085, Test Loss: 1.6081\n",
      "Epoch [45/50] - Train Loss: 1.1078, Test Loss: 1.6079\n",
      "Epoch [46/50] - Train Loss: 1.1071, Test Loss: 1.6077\n",
      "Epoch [47/50] - Train Loss: 1.1063, Test Loss: 1.6075\n",
      "Epoch [48/50] - Train Loss: 1.1053, Test Loss: 1.6072\n",
      "Epoch [49/50] - Train Loss: 1.1042, Test Loss: 1.6070\n",
      "Epoch [50/50] - Train Loss: 1.1028, Test Loss: 1.6067\n",
      "Avg Test Loss: 1.6067\n",
      "Testing combination: (64, 3, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3321, Test Loss: 2.7826\n",
      "Epoch [2/50] - Train Loss: 1.3289, Test Loss: 2.7744\n",
      "Epoch [3/50] - Train Loss: 1.3262, Test Loss: 2.7666\n",
      "Epoch [4/50] - Train Loss: 1.3236, Test Loss: 2.7592\n",
      "Epoch [5/50] - Train Loss: 1.3212, Test Loss: 2.7521\n",
      "Epoch [6/50] - Train Loss: 1.3190, Test Loss: 2.7454\n",
      "Epoch [7/50] - Train Loss: 1.3169, Test Loss: 2.7389\n",
      "Epoch [8/50] - Train Loss: 1.3150, Test Loss: 2.7328\n",
      "Epoch [9/50] - Train Loss: 1.3132, Test Loss: 2.7270\n",
      "Epoch [10/50] - Train Loss: 1.3116, Test Loss: 2.7214\n",
      "Epoch [11/50] - Train Loss: 1.3102, Test Loss: 2.7161\n",
      "Epoch [12/50] - Train Loss: 1.3088, Test Loss: 2.7111\n",
      "Epoch [13/50] - Train Loss: 1.3076, Test Loss: 2.7064\n",
      "Epoch [14/50] - Train Loss: 1.3066, Test Loss: 2.7020\n",
      "Epoch [15/50] - Train Loss: 1.3056, Test Loss: 2.6978\n",
      "Epoch [16/50] - Train Loss: 1.3047, Test Loss: 2.6940\n",
      "Epoch [17/50] - Train Loss: 1.3040, Test Loss: 2.6904\n",
      "Epoch [18/50] - Train Loss: 1.3033, Test Loss: 2.6871\n",
      "Epoch [19/50] - Train Loss: 1.3028, Test Loss: 2.6840\n",
      "Epoch [20/50] - Train Loss: 1.3023, Test Loss: 2.6813\n",
      "Epoch [21/50] - Train Loss: 1.3018, Test Loss: 2.6788\n",
      "Epoch [22/50] - Train Loss: 1.3015, Test Loss: 2.6765\n",
      "Epoch [23/50] - Train Loss: 1.3012, Test Loss: 2.6745\n",
      "Epoch [24/50] - Train Loss: 1.3009, Test Loss: 2.6727\n",
      "Epoch [25/50] - Train Loss: 1.3007, Test Loss: 2.6711\n",
      "Epoch [26/50] - Train Loss: 1.3005, Test Loss: 2.6697\n",
      "Epoch [27/50] - Train Loss: 1.3003, Test Loss: 2.6685\n",
      "Epoch [28/50] - Train Loss: 1.3001, Test Loss: 2.6675\n",
      "Epoch [29/50] - Train Loss: 1.2999, Test Loss: 2.6666\n",
      "Epoch [30/50] - Train Loss: 1.2998, Test Loss: 2.6658\n",
      "Epoch [31/50] - Train Loss: 1.2996, Test Loss: 2.6652\n",
      "Epoch [32/50] - Train Loss: 1.2994, Test Loss: 2.6646\n",
      "Epoch [33/50] - Train Loss: 1.2993, Test Loss: 2.6642\n",
      "Epoch [34/50] - Train Loss: 1.2991, Test Loss: 2.6638\n",
      "Epoch [35/50] - Train Loss: 1.2989, Test Loss: 2.6634\n",
      "Epoch [36/50] - Train Loss: 1.2987, Test Loss: 2.6632\n",
      "Epoch [37/50] - Train Loss: 1.2985, Test Loss: 2.6629\n",
      "Epoch [38/50] - Train Loss: 1.2983, Test Loss: 2.6628\n",
      "Epoch [39/50] - Train Loss: 1.2981, Test Loss: 2.6626\n",
      "Epoch [40/50] - Train Loss: 1.2979, Test Loss: 2.6625\n",
      "Epoch [41/50] - Train Loss: 1.2977, Test Loss: 2.6624\n",
      "Epoch [42/50] - Train Loss: 1.2975, Test Loss: 2.6624\n",
      "Epoch [43/50] - Train Loss: 1.2972, Test Loss: 2.6623\n",
      "Epoch [44/50] - Train Loss: 1.2970, Test Loss: 2.6623\n",
      "Epoch [45/50] - Train Loss: 1.2967, Test Loss: 2.6623\n",
      "Epoch [46/50] - Train Loss: 1.2964, Test Loss: 2.6623\n",
      "Epoch [47/50] - Train Loss: 1.2962, Test Loss: 2.6623\n",
      "Epoch [48/50] - Train Loss: 1.2959, Test Loss: 2.6624\n",
      "Epoch [49/50] - Train Loss: 1.2956, Test Loss: 2.6624\n",
      "Epoch [50/50] - Train Loss: 1.2953, Test Loss: 2.6625\n",
      "Avg Test Loss: 2.6625\n",
      "Testing combination: (64, 4, 0.01, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1452, Test Loss: 1.4993\n",
      "Epoch [2/50] - Train Loss: 1.1062, Test Loss: 1.4889\n",
      "Epoch [3/50] - Train Loss: 1.0965, Test Loss: 1.4877\n",
      "Epoch [4/50] - Train Loss: 1.0956, Test Loss: 1.4862\n",
      "Epoch [5/50] - Train Loss: 1.0953, Test Loss: 1.4857\n",
      "Epoch [6/50] - Train Loss: 1.0951, Test Loss: 1.4858\n",
      "Epoch [7/50] - Train Loss: 1.0949, Test Loss: 1.4859\n",
      "Epoch [8/50] - Train Loss: 1.0942, Test Loss: 1.4859\n",
      "Epoch [9/50] - Train Loss: 1.0968, Test Loss: 1.4862\n",
      "Epoch [10/50] - Train Loss: 1.0942, Test Loss: 1.4862\n",
      "Epoch [11/50] - Train Loss: 1.0916, Test Loss: 1.4850\n",
      "Epoch [12/50] - Train Loss: 1.0832, Test Loss: 1.4830\n",
      "Epoch [13/50] - Train Loss: 1.0861, Test Loss: 1.4665\n",
      "Epoch [14/50] - Train Loss: 1.1790, Test Loss: 1.5245\n",
      "Epoch [15/50] - Train Loss: 1.1844, Test Loss: 1.4735\n",
      "Epoch [16/50] - Train Loss: 1.1024, Test Loss: 1.4763\n",
      "Epoch [17/50] - Train Loss: 1.0920, Test Loss: 1.4797\n",
      "Epoch [18/50] - Train Loss: 1.0869, Test Loss: 1.4811\n",
      "Epoch [19/50] - Train Loss: 1.0840, Test Loss: 1.4822\n",
      "Epoch [20/50] - Train Loss: 1.0819, Test Loss: 1.4814\n",
      "Epoch [21/50] - Train Loss: 1.0788, Test Loss: 1.4803\n",
      "Epoch [22/50] - Train Loss: 1.0732, Test Loss: 1.4781\n",
      "Epoch [23/50] - Train Loss: 1.0708, Test Loss: 1.4923\n",
      "Epoch [24/50] - Train Loss: 1.0629, Test Loss: 1.4850\n",
      "Epoch [25/50] - Train Loss: 1.0582, Test Loss: 1.5006\n",
      "Epoch [26/50] - Train Loss: 1.0452, Test Loss: 1.4723\n",
      "Epoch [27/50] - Train Loss: 1.0626, Test Loss: 1.4714\n",
      "Epoch [28/50] - Train Loss: 1.0447, Test Loss: 1.4993\n",
      "Epoch [29/50] - Train Loss: 1.0455, Test Loss: 1.4890\n",
      "Epoch [30/50] - Train Loss: 1.0426, Test Loss: 1.4843\n",
      "Epoch [31/50] - Train Loss: 1.0284, Test Loss: 1.4203\n",
      "Epoch [32/50] - Train Loss: 1.0197, Test Loss: 1.4688\n",
      "Epoch [33/50] - Train Loss: 1.0073, Test Loss: 1.5167\n",
      "Epoch [34/50] - Train Loss: 1.0177, Test Loss: 1.5189\n",
      "Epoch [35/50] - Train Loss: 0.9983, Test Loss: 1.3431\n",
      "Epoch [36/50] - Train Loss: 1.0740, Test Loss: 1.3619\n",
      "Epoch [37/50] - Train Loss: 1.0295, Test Loss: 1.3984\n",
      "Epoch [38/50] - Train Loss: 1.0133, Test Loss: 1.3749\n",
      "Epoch [39/50] - Train Loss: 1.0017, Test Loss: 1.3210\n",
      "Epoch [40/50] - Train Loss: 0.9843, Test Loss: 1.3182\n",
      "Epoch [41/50] - Train Loss: 0.9772, Test Loss: 1.3276\n",
      "Epoch [42/50] - Train Loss: 0.9703, Test Loss: 1.3449\n",
      "Epoch [43/50] - Train Loss: 0.9868, Test Loss: 1.4148\n",
      "Epoch [44/50] - Train Loss: 0.9719, Test Loss: 1.3457\n",
      "Epoch [45/50] - Train Loss: 1.0425, Test Loss: 1.3808\n",
      "Epoch [46/50] - Train Loss: 0.9739, Test Loss: 1.3932\n",
      "Epoch [47/50] - Train Loss: 0.9787, Test Loss: 1.4518\n",
      "Epoch [48/50] - Train Loss: 0.9695, Test Loss: 1.4020\n",
      "Epoch [49/50] - Train Loss: 0.9641, Test Loss: 1.3816\n",
      "Epoch [50/50] - Train Loss: 0.9684, Test Loss: 1.4937\n",
      "Avg Test Loss: 1.4937\n",
      "Testing combination: (64, 4, 0.01, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1380, Test Loss: 1.5912\n",
      "Epoch [2/50] - Train Loss: 1.1206, Test Loss: 1.6086\n",
      "Epoch [3/50] - Train Loss: 1.1167, Test Loss: 1.6120\n",
      "Epoch [4/50] - Train Loss: 1.1159, Test Loss: 1.6108\n",
      "Epoch [5/50] - Train Loss: 1.1155, Test Loss: 1.6093\n",
      "Epoch [6/50] - Train Loss: 1.1153, Test Loss: 1.6088\n",
      "Epoch [7/50] - Train Loss: 1.1148, Test Loss: 1.6087\n",
      "Epoch [8/50] - Train Loss: 1.1141, Test Loss: 1.6075\n",
      "Epoch [9/50] - Train Loss: 1.1569, Test Loss: 1.6116\n",
      "Epoch [10/50] - Train Loss: 1.1169, Test Loss: 1.6130\n",
      "Epoch [11/50] - Train Loss: 1.1124, Test Loss: 1.6072\n",
      "Epoch [12/50] - Train Loss: 1.1131, Test Loss: 1.6102\n",
      "Epoch [13/50] - Train Loss: 1.0961, Test Loss: 1.6093\n",
      "Epoch [14/50] - Train Loss: 1.1162, Test Loss: 1.6167\n",
      "Epoch [15/50] - Train Loss: 1.0945, Test Loss: 1.6175\n",
      "Epoch [16/50] - Train Loss: 1.0855, Test Loss: 1.6152\n",
      "Epoch [17/50] - Train Loss: 1.0830, Test Loss: 1.6108\n",
      "Epoch [18/50] - Train Loss: 1.1171, Test Loss: 1.6083\n",
      "Epoch [19/50] - Train Loss: 1.0989, Test Loss: 1.6117\n",
      "Epoch [20/50] - Train Loss: 1.0811, Test Loss: 1.6119\n",
      "Epoch [21/50] - Train Loss: 1.0858, Test Loss: 1.6160\n",
      "Epoch [22/50] - Train Loss: 1.0790, Test Loss: 1.6126\n",
      "Epoch [23/50] - Train Loss: 1.0788, Test Loss: 1.6113\n",
      "Epoch [24/50] - Train Loss: 1.0780, Test Loss: 1.6124\n",
      "Epoch [25/50] - Train Loss: 1.0777, Test Loss: 1.6160\n",
      "Epoch [26/50] - Train Loss: 1.0746, Test Loss: 1.6173\n",
      "Epoch [27/50] - Train Loss: 1.0755, Test Loss: 1.6157\n",
      "Epoch [28/50] - Train Loss: 1.0718, Test Loss: 1.6149\n",
      "Epoch [29/50] - Train Loss: 1.0736, Test Loss: 1.6124\n",
      "Epoch [30/50] - Train Loss: 1.0708, Test Loss: 1.6133\n",
      "Epoch [31/50] - Train Loss: 1.0733, Test Loss: 1.6135\n",
      "Epoch [32/50] - Train Loss: 1.0700, Test Loss: 1.6148\n",
      "Epoch [33/50] - Train Loss: 1.0714, Test Loss: 1.6150\n",
      "Epoch [34/50] - Train Loss: 1.0707, Test Loss: 1.6091\n",
      "Epoch [35/50] - Train Loss: 1.0970, Test Loss: 1.6453\n",
      "Epoch [36/50] - Train Loss: 1.1001, Test Loss: 1.6305\n",
      "Epoch [37/50] - Train Loss: 1.0775, Test Loss: 1.5999\n",
      "Epoch [38/50] - Train Loss: 1.0781, Test Loss: 1.6081\n",
      "Epoch [39/50] - Train Loss: 1.0791, Test Loss: 1.6168\n",
      "Epoch [40/50] - Train Loss: 1.0727, Test Loss: 1.6178\n",
      "Epoch [41/50] - Train Loss: 1.0731, Test Loss: 1.6159\n",
      "Epoch [42/50] - Train Loss: 1.0715, Test Loss: 1.6157\n",
      "Epoch [43/50] - Train Loss: 1.0713, Test Loss: 1.6156\n",
      "Epoch [44/50] - Train Loss: 1.0709, Test Loss: 1.6152\n",
      "Epoch [45/50] - Train Loss: 1.0700, Test Loss: 1.6145\n",
      "Epoch [46/50] - Train Loss: 1.1410, Test Loss: 1.6111\n",
      "Epoch [47/50] - Train Loss: 1.1309, Test Loss: 1.6445\n",
      "Epoch [48/50] - Train Loss: 1.1149, Test Loss: 1.6126\n",
      "Epoch [49/50] - Train Loss: 1.1041, Test Loss: 1.5988\n",
      "Epoch [50/50] - Train Loss: 1.1032, Test Loss: 1.6122\n",
      "Avg Test Loss: 1.6122\n",
      "Testing combination: (64, 4, 0.01, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3267, Test Loss: 2.6572\n",
      "Epoch [2/50] - Train Loss: 1.3046, Test Loss: 2.6472\n",
      "Epoch [3/50] - Train Loss: 1.3044, Test Loss: 2.6533\n",
      "Epoch [4/50] - Train Loss: 1.3027, Test Loss: 2.6618\n",
      "Epoch [5/50] - Train Loss: 1.3013, Test Loss: 2.6680\n",
      "Epoch [6/50] - Train Loss: 1.2960, Test Loss: 2.6723\n",
      "Epoch [7/50] - Train Loss: 1.3148, Test Loss: 2.6692\n",
      "Epoch [8/50] - Train Loss: 1.2950, Test Loss: 2.6637\n",
      "Epoch [9/50] - Train Loss: 1.2835, Test Loss: 2.6635\n",
      "Epoch [10/50] - Train Loss: 1.2648, Test Loss: 2.6578\n",
      "Epoch [11/50] - Train Loss: 1.3177, Test Loss: 2.6454\n",
      "Epoch [12/50] - Train Loss: 1.2847, Test Loss: 2.6485\n",
      "Epoch [13/50] - Train Loss: 1.2781, Test Loss: 2.6670\n",
      "Epoch [14/50] - Train Loss: 1.2666, Test Loss: 2.6649\n",
      "Epoch [15/50] - Train Loss: 1.2564, Test Loss: 2.8501\n",
      "Epoch [16/50] - Train Loss: 1.2912, Test Loss: 2.6622\n",
      "Epoch [17/50] - Train Loss: 1.2549, Test Loss: 2.6630\n",
      "Epoch [18/50] - Train Loss: 1.2539, Test Loss: 2.6594\n",
      "Epoch [19/50] - Train Loss: 1.2542, Test Loss: 2.6577\n",
      "Epoch [20/50] - Train Loss: 1.2548, Test Loss: 2.6567\n",
      "Epoch [21/50] - Train Loss: 1.2894, Test Loss: 2.6627\n",
      "Epoch [22/50] - Train Loss: 1.2580, Test Loss: 2.6665\n",
      "Epoch [23/50] - Train Loss: 1.2549, Test Loss: 2.6495\n",
      "Epoch [24/50] - Train Loss: 1.2543, Test Loss: 2.6367\n",
      "Epoch [25/50] - Train Loss: 1.2520, Test Loss: 2.6481\n",
      "Epoch [26/50] - Train Loss: 1.2529, Test Loss: 2.6585\n",
      "Epoch [27/50] - Train Loss: 1.2507, Test Loss: 2.6570\n",
      "Epoch [28/50] - Train Loss: 1.2495, Test Loss: 2.6492\n",
      "Epoch [29/50] - Train Loss: 1.2508, Test Loss: 2.6315\n",
      "Epoch [30/50] - Train Loss: 1.2458, Test Loss: 2.6248\n",
      "Epoch [31/50] - Train Loss: 1.2461, Test Loss: 2.6251\n",
      "Epoch [32/50] - Train Loss: 1.2435, Test Loss: 2.6457\n",
      "Epoch [33/50] - Train Loss: 1.2467, Test Loss: 2.6460\n",
      "Epoch [34/50] - Train Loss: 1.2448, Test Loss: 2.6543\n",
      "Epoch [35/50] - Train Loss: 1.2453, Test Loss: 2.6342\n",
      "Epoch [36/50] - Train Loss: 1.2436, Test Loss: 2.6206\n",
      "Epoch [37/50] - Train Loss: 1.2400, Test Loss: 2.6385\n",
      "Epoch [38/50] - Train Loss: 1.2414, Test Loss: 2.6212\n",
      "Epoch [39/50] - Train Loss: 1.2503, Test Loss: 2.6458\n",
      "Epoch [40/50] - Train Loss: 1.2538, Test Loss: 2.6594\n",
      "Epoch [41/50] - Train Loss: 1.2573, Test Loss: 2.6596\n",
      "Epoch [42/50] - Train Loss: 1.2548, Test Loss: 2.6593\n",
      "Epoch [43/50] - Train Loss: 1.2540, Test Loss: 2.6615\n",
      "Epoch [44/50] - Train Loss: 1.2538, Test Loss: 2.6623\n",
      "Epoch [45/50] - Train Loss: 1.2537, Test Loss: 2.6610\n",
      "Epoch [46/50] - Train Loss: 1.2536, Test Loss: 2.6591\n",
      "Epoch [47/50] - Train Loss: 1.2535, Test Loss: 2.6579\n",
      "Epoch [48/50] - Train Loss: 1.2533, Test Loss: 2.6577\n",
      "Epoch [49/50] - Train Loss: 1.2530, Test Loss: 2.6580\n",
      "Epoch [50/50] - Train Loss: 1.2525, Test Loss: 2.6579\n",
      "Avg Test Loss: 2.6579\n",
      "Testing combination: (64, 4, 0.001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1027, Test Loss: 1.4985\n",
      "Epoch [2/50] - Train Loss: 1.0956, Test Loss: 1.4917\n",
      "Epoch [3/50] - Train Loss: 1.0945, Test Loss: 1.4879\n",
      "Epoch [4/50] - Train Loss: 1.0943, Test Loss: 1.4861\n",
      "Epoch [5/50] - Train Loss: 1.0944, Test Loss: 1.4855\n",
      "Epoch [6/50] - Train Loss: 1.0943, Test Loss: 1.4853\n",
      "Epoch [7/50] - Train Loss: 1.0940, Test Loss: 1.4854\n",
      "Epoch [8/50] - Train Loss: 1.0936, Test Loss: 1.4854\n",
      "Epoch [9/50] - Train Loss: 1.0929, Test Loss: 1.4852\n",
      "Epoch [10/50] - Train Loss: 1.0915, Test Loss: 1.4850\n",
      "Epoch [11/50] - Train Loss: 1.0885, Test Loss: 1.4845\n",
      "Epoch [12/50] - Train Loss: 1.0845, Test Loss: 1.4841\n",
      "Epoch [13/50] - Train Loss: 1.0823, Test Loss: 1.4838\n",
      "Epoch [14/50] - Train Loss: 1.0928, Test Loss: 1.4863\n",
      "Epoch [15/50] - Train Loss: 1.0795, Test Loss: 1.4856\n",
      "Epoch [16/50] - Train Loss: 1.0742, Test Loss: 1.4852\n",
      "Epoch [17/50] - Train Loss: 1.0669, Test Loss: 1.4863\n",
      "Epoch [18/50] - Train Loss: 1.0579, Test Loss: 1.4873\n",
      "Epoch [19/50] - Train Loss: 1.0539, Test Loss: 1.4880\n",
      "Epoch [20/50] - Train Loss: 1.0538, Test Loss: 1.4875\n",
      "Epoch [21/50] - Train Loss: 1.0529, Test Loss: 1.4872\n",
      "Epoch [22/50] - Train Loss: 1.0526, Test Loss: 1.4870\n",
      "Epoch [23/50] - Train Loss: 1.0524, Test Loss: 1.4869\n",
      "Epoch [24/50] - Train Loss: 1.0523, Test Loss: 1.4869\n",
      "Epoch [25/50] - Train Loss: 1.0521, Test Loss: 1.4869\n",
      "Epoch [26/50] - Train Loss: 1.0518, Test Loss: 1.4868\n",
      "Epoch [27/50] - Train Loss: 1.0515, Test Loss: 1.4866\n",
      "Epoch [28/50] - Train Loss: 1.0509, Test Loss: 1.4863\n",
      "Epoch [29/50] - Train Loss: 1.0502, Test Loss: 1.4863\n",
      "Epoch [30/50] - Train Loss: 1.0496, Test Loss: 1.4869\n",
      "Epoch [31/50] - Train Loss: 1.0489, Test Loss: 1.4877\n",
      "Epoch [32/50] - Train Loss: 1.0481, Test Loss: 1.4883\n",
      "Epoch [33/50] - Train Loss: 1.0473, Test Loss: 1.4886\n",
      "Epoch [34/50] - Train Loss: 1.0465, Test Loss: 1.4887\n",
      "Epoch [35/50] - Train Loss: 1.0452, Test Loss: 1.4865\n",
      "Epoch [36/50] - Train Loss: 1.0503, Test Loss: 1.5164\n",
      "Epoch [37/50] - Train Loss: 1.0574, Test Loss: 1.4913\n",
      "Epoch [38/50] - Train Loss: 1.0604, Test Loss: 1.4891\n",
      "Epoch [39/50] - Train Loss: 1.0463, Test Loss: 1.4861\n",
      "Epoch [40/50] - Train Loss: 1.0452, Test Loss: 1.4888\n",
      "Epoch [41/50] - Train Loss: 1.0448, Test Loss: 1.4926\n",
      "Epoch [42/50] - Train Loss: 1.0426, Test Loss: 1.4907\n",
      "Epoch [43/50] - Train Loss: 1.0427, Test Loss: 1.4891\n",
      "Epoch [44/50] - Train Loss: 1.0397, Test Loss: 1.4902\n",
      "Epoch [45/50] - Train Loss: 1.0388, Test Loss: 1.4888\n",
      "Epoch [46/50] - Train Loss: 1.0351, Test Loss: 1.4790\n",
      "Epoch [47/50] - Train Loss: 1.0481, Test Loss: 1.4851\n",
      "Epoch [48/50] - Train Loss: 1.0441, Test Loss: 1.4901\n",
      "Epoch [49/50] - Train Loss: 1.0378, Test Loss: 1.4841\n",
      "Epoch [50/50] - Train Loss: 1.0413, Test Loss: 1.4786\n",
      "Avg Test Loss: 1.4786\n",
      "Testing combination: (64, 4, 0.001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1210, Test Loss: 1.6104\n",
      "Epoch [2/50] - Train Loss: 1.1158, Test Loss: 1.6130\n",
      "Epoch [3/50] - Train Loss: 1.1152, Test Loss: 1.6116\n",
      "Epoch [4/50] - Train Loss: 1.1150, Test Loss: 1.6099\n",
      "Epoch [5/50] - Train Loss: 1.1149, Test Loss: 1.6089\n",
      "Epoch [6/50] - Train Loss: 1.1148, Test Loss: 1.6086\n",
      "Epoch [7/50] - Train Loss: 1.1147, Test Loss: 1.6087\n",
      "Epoch [8/50] - Train Loss: 1.1143, Test Loss: 1.6090\n",
      "Epoch [9/50] - Train Loss: 1.1136, Test Loss: 1.6092\n",
      "Epoch [10/50] - Train Loss: 1.1118, Test Loss: 1.6094\n",
      "Epoch [11/50] - Train Loss: 1.1076, Test Loss: 1.6100\n",
      "Epoch [12/50] - Train Loss: 1.1027, Test Loss: 1.6108\n",
      "Epoch [13/50] - Train Loss: 1.1371, Test Loss: 1.6110\n",
      "Epoch [14/50] - Train Loss: 1.1173, Test Loss: 1.6128\n",
      "Epoch [15/50] - Train Loss: 1.1117, Test Loss: 1.6138\n",
      "Epoch [16/50] - Train Loss: 1.1085, Test Loss: 1.6158\n",
      "Epoch [17/50] - Train Loss: 1.1079, Test Loss: 1.6208\n",
      "Epoch [18/50] - Train Loss: 1.1045, Test Loss: 1.6213\n",
      "Epoch [19/50] - Train Loss: 1.1042, Test Loss: 1.6209\n",
      "Epoch [20/50] - Train Loss: 1.1026, Test Loss: 1.6204\n",
      "Epoch [21/50] - Train Loss: 1.0989, Test Loss: 1.6193\n",
      "Epoch [22/50] - Train Loss: 1.0961, Test Loss: 1.6195\n",
      "Epoch [23/50] - Train Loss: 1.0910, Test Loss: 1.6198\n",
      "Epoch [24/50] - Train Loss: 1.0860, Test Loss: 1.6198\n",
      "Epoch [25/50] - Train Loss: 1.0827, Test Loss: 1.6197\n",
      "Epoch [26/50] - Train Loss: 1.0839, Test Loss: 1.6192\n",
      "Epoch [27/50] - Train Loss: 1.1076, Test Loss: 1.6164\n",
      "Epoch [28/50] - Train Loss: 1.0828, Test Loss: 1.6142\n",
      "Epoch [29/50] - Train Loss: 1.0831, Test Loss: 1.6198\n",
      "Epoch [30/50] - Train Loss: 1.0768, Test Loss: 1.6196\n",
      "Epoch [31/50] - Train Loss: 1.0752, Test Loss: 1.6202\n",
      "Epoch [32/50] - Train Loss: 1.0735, Test Loss: 1.6176\n",
      "Epoch [33/50] - Train Loss: 1.0699, Test Loss: 1.6144\n",
      "Epoch [34/50] - Train Loss: 1.0675, Test Loss: 1.6157\n",
      "Epoch [35/50] - Train Loss: 1.0611, Test Loss: 1.6012\n",
      "Epoch [36/50] - Train Loss: 1.0577, Test Loss: 1.5970\n",
      "Epoch [37/50] - Train Loss: 1.0427, Test Loss: 1.5560\n",
      "Epoch [38/50] - Train Loss: 1.0635, Test Loss: 1.5916\n",
      "Epoch [39/50] - Train Loss: 1.1005, Test Loss: 1.6291\n",
      "Epoch [40/50] - Train Loss: 1.0867, Test Loss: 1.6382\n",
      "Epoch [41/50] - Train Loss: 1.0805, Test Loss: 1.6276\n",
      "Epoch [42/50] - Train Loss: 1.0751, Test Loss: 1.6149\n",
      "Epoch [43/50] - Train Loss: 1.0710, Test Loss: 1.6068\n",
      "Epoch [44/50] - Train Loss: 1.0676, Test Loss: 1.6047\n",
      "Epoch [45/50] - Train Loss: 1.0650, Test Loss: 1.6230\n",
      "Epoch [46/50] - Train Loss: 1.0609, Test Loss: 1.6271\n",
      "Epoch [47/50] - Train Loss: 1.0530, Test Loss: 1.6139\n",
      "Epoch [48/50] - Train Loss: 1.0485, Test Loss: 1.6023\n",
      "Epoch [49/50] - Train Loss: 1.0436, Test Loss: 1.6005\n",
      "Epoch [50/50] - Train Loss: 1.0105, Test Loss: 1.4901\n",
      "Avg Test Loss: 1.4901\n",
      "Testing combination: (64, 4, 0.001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3057, Test Loss: 2.6627\n",
      "Epoch [2/50] - Train Loss: 1.3028, Test Loss: 2.6684\n",
      "Epoch [3/50] - Train Loss: 1.3024, Test Loss: 2.6689\n",
      "Epoch [4/50] - Train Loss: 1.3021, Test Loss: 2.6672\n",
      "Epoch [5/50] - Train Loss: 1.3019, Test Loss: 2.6651\n",
      "Epoch [6/50] - Train Loss: 1.3017, Test Loss: 2.6634\n",
      "Epoch [7/50] - Train Loss: 1.3016, Test Loss: 2.6623\n",
      "Epoch [8/50] - Train Loss: 1.3014, Test Loss: 2.6619\n",
      "Epoch [9/50] - Train Loss: 1.3010, Test Loss: 2.6622\n",
      "Epoch [10/50] - Train Loss: 1.3004, Test Loss: 2.6629\n",
      "Epoch [11/50] - Train Loss: 1.2994, Test Loss: 2.6641\n",
      "Epoch [12/50] - Train Loss: 1.2979, Test Loss: 2.6658\n",
      "Epoch [13/50] - Train Loss: 1.2952, Test Loss: 2.6678\n",
      "Epoch [14/50] - Train Loss: 1.2931, Test Loss: 2.6703\n",
      "Epoch [15/50] - Train Loss: 1.3037, Test Loss: 2.6699\n",
      "Epoch [16/50] - Train Loss: 1.2938, Test Loss: 2.6677\n",
      "Epoch [17/50] - Train Loss: 1.2941, Test Loss: 2.6670\n",
      "Epoch [18/50] - Train Loss: 1.2930, Test Loss: 2.6676\n",
      "Epoch [19/50] - Train Loss: 1.2898, Test Loss: 2.6692\n",
      "Epoch [20/50] - Train Loss: 1.2882, Test Loss: 2.6705\n",
      "Epoch [21/50] - Train Loss: 1.2861, Test Loss: 2.6692\n",
      "Epoch [22/50] - Train Loss: 1.2822, Test Loss: 2.6667\n",
      "Epoch [23/50] - Train Loss: 1.2741, Test Loss: 2.6645\n",
      "Epoch [24/50] - Train Loss: 1.2667, Test Loss: 2.6607\n",
      "Epoch [25/50] - Train Loss: 1.2612, Test Loss: 2.6585\n",
      "Epoch [26/50] - Train Loss: 1.2716, Test Loss: 2.6583\n",
      "Epoch [27/50] - Train Loss: 1.2559, Test Loss: 2.6554\n",
      "Epoch [28/50] - Train Loss: 1.2563, Test Loss: 2.6579\n",
      "Epoch [29/50] - Train Loss: 1.2546, Test Loss: 2.6618\n",
      "Epoch [30/50] - Train Loss: 1.2548, Test Loss: 2.6620\n",
      "Epoch [31/50] - Train Loss: 1.2535, Test Loss: 2.6596\n",
      "Epoch [32/50] - Train Loss: 1.2534, Test Loss: 2.6574\n",
      "Epoch [33/50] - Train Loss: 1.2533, Test Loss: 2.6565\n",
      "Epoch [34/50] - Train Loss: 1.2529, Test Loss: 2.6565\n",
      "Epoch [35/50] - Train Loss: 1.2526, Test Loss: 2.6565\n",
      "Epoch [36/50] - Train Loss: 1.2524, Test Loss: 2.6558\n",
      "Epoch [37/50] - Train Loss: 1.2521, Test Loss: 2.6546\n",
      "Epoch [38/50] - Train Loss: 1.2517, Test Loss: 2.6533\n",
      "Epoch [39/50] - Train Loss: 1.2514, Test Loss: 2.6524\n",
      "Epoch [40/50] - Train Loss: 1.2512, Test Loss: 2.6519\n",
      "Epoch [41/50] - Train Loss: 1.2509, Test Loss: 2.6513\n",
      "Epoch [42/50] - Train Loss: 1.2506, Test Loss: 2.6504\n",
      "Epoch [43/50] - Train Loss: 1.2502, Test Loss: 2.6496\n",
      "Epoch [44/50] - Train Loss: 1.2499, Test Loss: 2.6495\n",
      "Epoch [45/50] - Train Loss: 1.2495, Test Loss: 2.6496\n",
      "Epoch [46/50] - Train Loss: 1.2491, Test Loss: 2.6497\n",
      "Epoch [47/50] - Train Loss: 1.2485, Test Loss: 2.6492\n",
      "Epoch [48/50] - Train Loss: 1.2477, Test Loss: 2.6479\n",
      "Epoch [49/50] - Train Loss: 1.2463, Test Loss: 2.6449\n",
      "Epoch [50/50] - Train Loss: 1.2439, Test Loss: 2.6381\n",
      "Avg Test Loss: 2.6381\n",
      "Testing combination: (64, 4, 0.0001, 6)\n",
      "Epoch [1/50] - Train Loss: 1.1065, Test Loss: 1.5251\n",
      "Epoch [2/50] - Train Loss: 1.1043, Test Loss: 1.5211\n",
      "Epoch [3/50] - Train Loss: 1.1026, Test Loss: 1.5174\n",
      "Epoch [4/50] - Train Loss: 1.1011, Test Loss: 1.5140\n",
      "Epoch [5/50] - Train Loss: 1.0998, Test Loss: 1.5109\n",
      "Epoch [6/50] - Train Loss: 1.0987, Test Loss: 1.5082\n",
      "Epoch [7/50] - Train Loss: 1.0977, Test Loss: 1.5056\n",
      "Epoch [8/50] - Train Loss: 1.0969, Test Loss: 1.5034\n",
      "Epoch [9/50] - Train Loss: 1.0963, Test Loss: 1.5014\n",
      "Epoch [10/50] - Train Loss: 1.0957, Test Loss: 1.4995\n",
      "Epoch [11/50] - Train Loss: 1.0952, Test Loss: 1.4979\n",
      "Epoch [12/50] - Train Loss: 1.0948, Test Loss: 1.4964\n",
      "Epoch [13/50] - Train Loss: 1.0945, Test Loss: 1.4952\n",
      "Epoch [14/50] - Train Loss: 1.0942, Test Loss: 1.4940\n",
      "Epoch [15/50] - Train Loss: 1.0940, Test Loss: 1.4930\n",
      "Epoch [16/50] - Train Loss: 1.0938, Test Loss: 1.4921\n",
      "Epoch [17/50] - Train Loss: 1.0936, Test Loss: 1.4913\n",
      "Epoch [18/50] - Train Loss: 1.0935, Test Loss: 1.4906\n",
      "Epoch [19/50] - Train Loss: 1.0934, Test Loss: 1.4899\n",
      "Epoch [20/50] - Train Loss: 1.0933, Test Loss: 1.4894\n",
      "Epoch [21/50] - Train Loss: 1.0932, Test Loss: 1.4889\n",
      "Epoch [22/50] - Train Loss: 1.0931, Test Loss: 1.4885\n",
      "Epoch [23/50] - Train Loss: 1.0930, Test Loss: 1.4881\n",
      "Epoch [24/50] - Train Loss: 1.0929, Test Loss: 1.4877\n",
      "Epoch [25/50] - Train Loss: 1.0928, Test Loss: 1.4874\n",
      "Epoch [26/50] - Train Loss: 1.0927, Test Loss: 1.4872\n",
      "Epoch [27/50] - Train Loss: 1.0926, Test Loss: 1.4869\n",
      "Epoch [28/50] - Train Loss: 1.0925, Test Loss: 1.4867\n",
      "Epoch [29/50] - Train Loss: 1.0923, Test Loss: 1.4865\n",
      "Epoch [30/50] - Train Loss: 1.0922, Test Loss: 1.4863\n",
      "Epoch [31/50] - Train Loss: 1.0920, Test Loss: 1.4861\n",
      "Epoch [32/50] - Train Loss: 1.0918, Test Loss: 1.4859\n",
      "Epoch [33/50] - Train Loss: 1.0916, Test Loss: 1.4858\n",
      "Epoch [34/50] - Train Loss: 1.0914, Test Loss: 1.4856\n",
      "Epoch [35/50] - Train Loss: 1.0911, Test Loss: 1.4854\n",
      "Epoch [36/50] - Train Loss: 1.0908, Test Loss: 1.4853\n",
      "Epoch [37/50] - Train Loss: 1.0905, Test Loss: 1.4851\n",
      "Epoch [38/50] - Train Loss: 1.0900, Test Loss: 1.4849\n",
      "Epoch [39/50] - Train Loss: 1.0895, Test Loss: 1.4848\n",
      "Epoch [40/50] - Train Loss: 1.0889, Test Loss: 1.4846\n",
      "Epoch [41/50] - Train Loss: 1.0880, Test Loss: 1.4844\n",
      "Epoch [42/50] - Train Loss: 1.0870, Test Loss: 1.4841\n",
      "Epoch [43/50] - Train Loss: 1.0860, Test Loss: 1.4839\n",
      "Epoch [44/50] - Train Loss: 1.0849, Test Loss: 1.4836\n",
      "Epoch [45/50] - Train Loss: 1.0838, Test Loss: 1.4833\n",
      "Epoch [46/50] - Train Loss: 1.0828, Test Loss: 1.4830\n",
      "Epoch [47/50] - Train Loss: 1.0819, Test Loss: 1.4827\n",
      "Epoch [48/50] - Train Loss: 1.0810, Test Loss: 1.4824\n",
      "Epoch [49/50] - Train Loss: 1.0802, Test Loss: 1.4822\n",
      "Epoch [50/50] - Train Loss: 1.0794, Test Loss: 1.4819\n",
      "Avg Test Loss: 1.4819\n",
      "Testing combination: (64, 4, 0.0001, 8)\n",
      "Epoch [1/50] - Train Loss: 1.1252, Test Loss: 1.5812\n",
      "Epoch [2/50] - Train Loss: 1.1231, Test Loss: 1.5830\n",
      "Epoch [3/50] - Train Loss: 1.1215, Test Loss: 1.5849\n",
      "Epoch [4/50] - Train Loss: 1.1202, Test Loss: 1.5868\n",
      "Epoch [5/50] - Train Loss: 1.1191, Test Loss: 1.5886\n",
      "Epoch [6/50] - Train Loss: 1.1182, Test Loss: 1.5905\n",
      "Epoch [7/50] - Train Loss: 1.1174, Test Loss: 1.5923\n",
      "Epoch [8/50] - Train Loss: 1.1168, Test Loss: 1.5941\n",
      "Epoch [9/50] - Train Loss: 1.1162, Test Loss: 1.5958\n",
      "Epoch [10/50] - Train Loss: 1.1158, Test Loss: 1.5974\n",
      "Epoch [11/50] - Train Loss: 1.1155, Test Loss: 1.5990\n",
      "Epoch [12/50] - Train Loss: 1.1152, Test Loss: 1.6004\n",
      "Epoch [13/50] - Train Loss: 1.1150, Test Loss: 1.6017\n",
      "Epoch [14/50] - Train Loss: 1.1148, Test Loss: 1.6028\n",
      "Epoch [15/50] - Train Loss: 1.1147, Test Loss: 1.6038\n",
      "Epoch [16/50] - Train Loss: 1.1146, Test Loss: 1.6048\n",
      "Epoch [17/50] - Train Loss: 1.1145, Test Loss: 1.6056\n",
      "Epoch [18/50] - Train Loss: 1.1145, Test Loss: 1.6063\n",
      "Epoch [19/50] - Train Loss: 1.1144, Test Loss: 1.6069\n",
      "Epoch [20/50] - Train Loss: 1.1144, Test Loss: 1.6074\n",
      "Epoch [21/50] - Train Loss: 1.1143, Test Loss: 1.6078\n",
      "Epoch [22/50] - Train Loss: 1.1143, Test Loss: 1.6082\n",
      "Epoch [23/50] - Train Loss: 1.1143, Test Loss: 1.6085\n",
      "Epoch [24/50] - Train Loss: 1.1142, Test Loss: 1.6087\n",
      "Epoch [25/50] - Train Loss: 1.1142, Test Loss: 1.6090\n",
      "Epoch [26/50] - Train Loss: 1.1142, Test Loss: 1.6092\n",
      "Epoch [27/50] - Train Loss: 1.1142, Test Loss: 1.6093\n",
      "Epoch [28/50] - Train Loss: 1.1141, Test Loss: 1.6095\n",
      "Epoch [29/50] - Train Loss: 1.1141, Test Loss: 1.6096\n",
      "Epoch [30/50] - Train Loss: 1.1141, Test Loss: 1.6097\n",
      "Epoch [31/50] - Train Loss: 1.1141, Test Loss: 1.6098\n",
      "Epoch [32/50] - Train Loss: 1.1140, Test Loss: 1.6099\n",
      "Epoch [33/50] - Train Loss: 1.1140, Test Loss: 1.6099\n",
      "Epoch [34/50] - Train Loss: 1.1140, Test Loss: 1.6100\n",
      "Epoch [35/50] - Train Loss: 1.1139, Test Loss: 1.6101\n",
      "Epoch [36/50] - Train Loss: 1.1139, Test Loss: 1.6101\n",
      "Epoch [37/50] - Train Loss: 1.1138, Test Loss: 1.6102\n",
      "Epoch [38/50] - Train Loss: 1.1138, Test Loss: 1.6102\n",
      "Epoch [39/50] - Train Loss: 1.1137, Test Loss: 1.6103\n",
      "Epoch [40/50] - Train Loss: 1.1137, Test Loss: 1.6103\n",
      "Epoch [41/50] - Train Loss: 1.1136, Test Loss: 1.6104\n",
      "Epoch [42/50] - Train Loss: 1.1135, Test Loss: 1.6104\n",
      "Epoch [43/50] - Train Loss: 1.1134, Test Loss: 1.6105\n",
      "Epoch [44/50] - Train Loss: 1.1134, Test Loss: 1.6106\n",
      "Epoch [45/50] - Train Loss: 1.1132, Test Loss: 1.6106\n",
      "Epoch [46/50] - Train Loss: 1.1131, Test Loss: 1.6107\n",
      "Epoch [47/50] - Train Loss: 1.1129, Test Loss: 1.6108\n",
      "Epoch [48/50] - Train Loss: 1.1127, Test Loss: 1.6109\n",
      "Epoch [49/50] - Train Loss: 1.1125, Test Loss: 1.6110\n",
      "Epoch [50/50] - Train Loss: 1.1122, Test Loss: 1.6112\n",
      "Avg Test Loss: 1.6112\n",
      "Testing combination: (64, 4, 0.0001, 16)\n",
      "Epoch [1/50] - Train Loss: 1.3020, Test Loss: 2.6588\n",
      "Epoch [2/50] - Train Loss: 1.3018, Test Loss: 2.6592\n",
      "Epoch [3/50] - Train Loss: 1.3018, Test Loss: 2.6595\n",
      "Epoch [4/50] - Train Loss: 1.3018, Test Loss: 2.6598\n",
      "Epoch [5/50] - Train Loss: 1.3017, Test Loss: 2.6600\n",
      "Epoch [6/50] - Train Loss: 1.3017, Test Loss: 2.6602\n",
      "Epoch [7/50] - Train Loss: 1.3017, Test Loss: 2.6604\n",
      "Epoch [8/50] - Train Loss: 1.3017, Test Loss: 2.6606\n",
      "Epoch [9/50] - Train Loss: 1.3017, Test Loss: 2.6608\n",
      "Epoch [10/50] - Train Loss: 1.3017, Test Loss: 2.6610\n",
      "Epoch [11/50] - Train Loss: 1.3017, Test Loss: 2.6611\n",
      "Epoch [12/50] - Train Loss: 1.3016, Test Loss: 2.6612\n",
      "Epoch [13/50] - Train Loss: 1.3016, Test Loss: 2.6614\n",
      "Epoch [14/50] - Train Loss: 1.3016, Test Loss: 2.6615\n",
      "Epoch [15/50] - Train Loss: 1.3016, Test Loss: 2.6616\n",
      "Epoch [16/50] - Train Loss: 1.3016, Test Loss: 2.6617\n",
      "Epoch [17/50] - Train Loss: 1.3016, Test Loss: 2.6618\n",
      "Epoch [18/50] - Train Loss: 1.3016, Test Loss: 2.6618\n",
      "Epoch [19/50] - Train Loss: 1.3016, Test Loss: 2.6619\n",
      "Epoch [20/50] - Train Loss: 1.3016, Test Loss: 2.6620\n",
      "Epoch [21/50] - Train Loss: 1.3016, Test Loss: 2.6620\n",
      "Epoch [22/50] - Train Loss: 1.3015, Test Loss: 2.6621\n",
      "Epoch [23/50] - Train Loss: 1.3015, Test Loss: 2.6622\n",
      "Epoch [24/50] - Train Loss: 1.3015, Test Loss: 2.6622\n",
      "Epoch [25/50] - Train Loss: 1.3015, Test Loss: 2.6622\n",
      "Epoch [26/50] - Train Loss: 1.3015, Test Loss: 2.6623\n",
      "Epoch [27/50] - Train Loss: 1.3015, Test Loss: 2.6623\n",
      "Epoch [28/50] - Train Loss: 1.3015, Test Loss: 2.6624\n",
      "Epoch [29/50] - Train Loss: 1.3014, Test Loss: 2.6624\n",
      "Epoch [30/50] - Train Loss: 1.3014, Test Loss: 2.6624\n",
      "Epoch [31/50] - Train Loss: 1.3014, Test Loss: 2.6624\n",
      "Epoch [32/50] - Train Loss: 1.3014, Test Loss: 2.6625\n",
      "Epoch [33/50] - Train Loss: 1.3014, Test Loss: 2.6625\n",
      "Epoch [34/50] - Train Loss: 1.3013, Test Loss: 2.6625\n",
      "Epoch [35/50] - Train Loss: 1.3013, Test Loss: 2.6625\n",
      "Epoch [36/50] - Train Loss: 1.3013, Test Loss: 2.6626\n",
      "Epoch [37/50] - Train Loss: 1.3013, Test Loss: 2.6626\n",
      "Epoch [38/50] - Train Loss: 1.3012, Test Loss: 2.6626\n",
      "Epoch [39/50] - Train Loss: 1.3012, Test Loss: 2.6626\n",
      "Epoch [40/50] - Train Loss: 1.3012, Test Loss: 2.6626\n",
      "Epoch [41/50] - Train Loss: 1.3011, Test Loss: 2.6626\n",
      "Epoch [42/50] - Train Loss: 1.3011, Test Loss: 2.6626\n",
      "Epoch [43/50] - Train Loss: 1.3010, Test Loss: 2.6627\n",
      "Epoch [44/50] - Train Loss: 1.3010, Test Loss: 2.6627\n",
      "Epoch [45/50] - Train Loss: 1.3009, Test Loss: 2.6627\n",
      "Epoch [46/50] - Train Loss: 1.3008, Test Loss: 2.6627\n",
      "Epoch [47/50] - Train Loss: 1.3007, Test Loss: 2.6627\n",
      "Epoch [48/50] - Train Loss: 1.3006, Test Loss: 2.6628\n",
      "Epoch [49/50] - Train Loss: 1.3005, Test Loss: 2.6628\n",
      "Epoch [50/50] - Train Loss: 1.3004, Test Loss: 2.6628\n",
      "Avg Test Loss: 2.6628\n",
      "Best Hyperparameters: (8, 4, 0.01, 6)\n",
      "Best Loss: 1.4661\n"
     ]
    }
   ],
   "source": [
    "# Function to train and evaluate the model\n",
    "hyperparameter_combinations = list(itertools.product(\n",
    "    hyperparameter_space['hidden_size'],\n",
    "    hyperparameter_space['num_layers'],\n",
    "    hyperparameter_space['learning_rate'],\n",
    "    hyperparameter_space['batch_size']\n",
    "))\n",
    "\n",
    "# Store results\n",
    "best_params = None\n",
    "best_loss = float('inf')\n",
    "all_train_losses = []\n",
    "all_test_losses = []\n",
    "num_epochs = 50\n",
    "\n",
    "# Hyperparameter tuning\n",
    "for params in hyperparameter_combinations:\n",
    "    params_dict = {\n",
    "        'hidden_size': params[0],\n",
    "        'num_layers': params[1],\n",
    "        'learning_rate': params[2],\n",
    "        'batch_size': params[3],\n",
    "    }\n",
    "    print(f\"Testing combination: {params}\")\n",
    "\n",
    "    train_losses, test_losses, avg_loss = train_and_evaluate(params_dict, train_X_new, train_y_new, test_X_new, test_y_new, num_epochs)\n",
    "    all_train_losses.append(train_losses)\n",
    "    all_test_losses.append(test_losses)\n",
    "\n",
    "    print(f\"Avg Test Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        best_params = params\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Loss: {best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500] - Train Loss: 1.1577, Test Loss: 1.5045\n",
      "Epoch [2/500] - Train Loss: 1.0972, Test Loss: 1.4771\n",
      "Epoch [3/500] - Train Loss: 1.0999, Test Loss: 1.4811\n",
      "Epoch [4/500] - Train Loss: 1.0969, Test Loss: 1.4861\n",
      "Epoch [5/500] - Train Loss: 1.0941, Test Loss: 1.4862\n",
      "Epoch [6/500] - Train Loss: 1.0917, Test Loss: 1.4839\n",
      "Epoch [7/500] - Train Loss: 1.0898, Test Loss: 1.4823\n",
      "Epoch [8/500] - Train Loss: 1.0882, Test Loss: 1.4819\n",
      "Epoch [9/500] - Train Loss: 1.0869, Test Loss: 1.4820\n",
      "Epoch [10/500] - Train Loss: 1.0861, Test Loss: 1.4820\n",
      "Epoch [11/500] - Train Loss: 1.0855, Test Loss: 1.4819\n",
      "Epoch [12/500] - Train Loss: 1.0851, Test Loss: 1.4818\n",
      "Epoch [13/500] - Train Loss: 1.0846, Test Loss: 1.4818\n",
      "Epoch [14/500] - Train Loss: 1.0840, Test Loss: 1.4818\n",
      "Epoch [15/500] - Train Loss: 1.0831, Test Loss: 1.4818\n",
      "Epoch [16/500] - Train Loss: 1.0818, Test Loss: 1.4819\n",
      "Epoch [17/500] - Train Loss: 1.0801, Test Loss: 1.4820\n",
      "Epoch [18/500] - Train Loss: 1.0830, Test Loss: 1.4822\n",
      "Epoch [19/500] - Train Loss: 1.0756, Test Loss: 1.4826\n",
      "Epoch [20/500] - Train Loss: 1.0777, Test Loss: 1.4834\n",
      "Epoch [21/500] - Train Loss: 1.0706, Test Loss: 1.4845\n",
      "Epoch [22/500] - Train Loss: 1.0665, Test Loss: 1.4846\n",
      "Epoch [23/500] - Train Loss: 1.0703, Test Loss: 1.4873\n",
      "Epoch [24/500] - Train Loss: 1.0574, Test Loss: 1.4909\n",
      "Epoch [25/500] - Train Loss: 1.0551, Test Loss: 1.4859\n",
      "Epoch [26/500] - Train Loss: 1.0532, Test Loss: 1.4814\n",
      "Epoch [27/500] - Train Loss: 1.0538, Test Loss: 1.4869\n",
      "Epoch [28/500] - Train Loss: 1.0519, Test Loss: 1.4959\n",
      "Epoch [29/500] - Train Loss: 1.0492, Test Loss: 1.4960\n",
      "Epoch [30/500] - Train Loss: 1.0478, Test Loss: 1.4961\n",
      "Epoch [31/500] - Train Loss: 1.0464, Test Loss: 1.4934\n",
      "Epoch [32/500] - Train Loss: 1.0459, Test Loss: 1.4925\n",
      "Epoch [33/500] - Train Loss: 1.0449, Test Loss: 1.4911\n",
      "Epoch [34/500] - Train Loss: 1.0439, Test Loss: 1.4899\n",
      "Epoch [35/500] - Train Loss: 1.0427, Test Loss: 1.4892\n",
      "Epoch [36/500] - Train Loss: 1.0421, Test Loss: 1.4888\n",
      "Epoch [37/500] - Train Loss: 1.0412, Test Loss: 1.4897\n",
      "Epoch [38/500] - Train Loss: 1.0408, Test Loss: 1.4872\n",
      "Epoch [39/500] - Train Loss: 1.0405, Test Loss: 1.4887\n",
      "Epoch [40/500] - Train Loss: 1.0393, Test Loss: 1.4802\n",
      "Epoch [41/500] - Train Loss: 1.0456, Test Loss: 1.4898\n",
      "Epoch [42/500] - Train Loss: 1.0400, Test Loss: 1.4831\n",
      "Epoch [43/500] - Train Loss: 1.0449, Test Loss: 1.4828\n",
      "Epoch [44/500] - Train Loss: 1.0446, Test Loss: 1.4897\n",
      "Epoch [45/500] - Train Loss: 1.0416, Test Loss: 1.4937\n",
      "Epoch [46/500] - Train Loss: 1.0412, Test Loss: 1.4946\n",
      "Epoch [47/500] - Train Loss: 1.0375, Test Loss: 1.4875\n",
      "Epoch [48/500] - Train Loss: 1.0395, Test Loss: 1.4932\n",
      "Epoch [49/500] - Train Loss: 1.0360, Test Loss: 1.4748\n",
      "Epoch [50/500] - Train Loss: 1.0439, Test Loss: 1.4791\n",
      "Epoch [51/500] - Train Loss: 1.0422, Test Loss: 1.4849\n",
      "Epoch [52/500] - Train Loss: 1.0353, Test Loss: 1.4821\n",
      "Epoch [53/500] - Train Loss: 1.0318, Test Loss: 1.4501\n",
      "Epoch [54/500] - Train Loss: 1.0245, Test Loss: 1.5094\n",
      "Epoch [55/500] - Train Loss: 1.0281, Test Loss: 1.5059\n",
      "Epoch [56/500] - Train Loss: 1.0231, Test Loss: 1.6093\n",
      "Epoch [57/500] - Train Loss: 0.9787, Test Loss: 1.5454\n",
      "Epoch [58/500] - Train Loss: 0.9777, Test Loss: 1.3213\n",
      "Epoch [59/500] - Train Loss: 1.0361, Test Loss: 1.4068\n",
      "Epoch [60/500] - Train Loss: 1.0045, Test Loss: 1.5581\n",
      "Epoch [61/500] - Train Loss: 0.9444, Test Loss: 1.5081\n",
      "Epoch [62/500] - Train Loss: 0.9365, Test Loss: 1.3565\n",
      "Epoch [63/500] - Train Loss: 0.9595, Test Loss: 1.2943\n",
      "Epoch [64/500] - Train Loss: 1.0661, Test Loss: 1.5420\n",
      "Epoch [65/500] - Train Loss: 0.9476, Test Loss: 1.4699\n",
      "Epoch [66/500] - Train Loss: 0.8816, Test Loss: 1.5604\n",
      "Epoch [67/500] - Train Loss: 0.9795, Test Loss: 2.0427\n",
      "Epoch [68/500] - Train Loss: 0.9080, Test Loss: 1.8126\n",
      "Epoch [69/500] - Train Loss: 0.8523, Test Loss: 1.4847\n",
      "Epoch [70/500] - Train Loss: 0.8222, Test Loss: 1.4566\n",
      "Epoch [71/500] - Train Loss: 0.8269, Test Loss: 1.2785\n",
      "Epoch [72/500] - Train Loss: 1.0976, Test Loss: 1.8691\n",
      "Epoch [73/500] - Train Loss: 0.8618, Test Loss: 1.3597\n",
      "Epoch [74/500] - Train Loss: 0.9295, Test Loss: 2.0479\n",
      "Epoch [75/500] - Train Loss: 0.8559, Test Loss: 1.8282\n",
      "Epoch [76/500] - Train Loss: 0.8576, Test Loss: 1.2487\n",
      "Epoch [77/500] - Train Loss: 1.0017, Test Loss: 1.9488\n",
      "Epoch [78/500] - Train Loss: 0.8150, Test Loss: 1.5155\n",
      "Epoch [79/500] - Train Loss: 0.7081, Test Loss: 2.5042\n",
      "Epoch [80/500] - Train Loss: 0.6693, Test Loss: 2.6777\n",
      "Epoch [81/500] - Train Loss: 0.6875, Test Loss: 2.2888\n",
      "Epoch [82/500] - Train Loss: 0.7475, Test Loss: 1.2460\n",
      "Epoch [83/500] - Train Loss: 1.1767, Test Loss: 1.6386\n",
      "Epoch [84/500] - Train Loss: 0.8460, Test Loss: 2.4033\n",
      "Epoch [85/500] - Train Loss: 0.7575, Test Loss: 2.4835\n",
      "Epoch [86/500] - Train Loss: 0.6348, Test Loss: 2.6023\n",
      "Epoch [87/500] - Train Loss: 0.5851, Test Loss: 2.5149\n",
      "Epoch [88/500] - Train Loss: 0.5925, Test Loss: 2.0865\n",
      "Epoch [89/500] - Train Loss: 0.5885, Test Loss: 2.4650\n",
      "Epoch [90/500] - Train Loss: 0.6042, Test Loss: 2.4362\n",
      "Epoch [91/500] - Train Loss: 0.5636, Test Loss: 2.5903\n",
      "Epoch [92/500] - Train Loss: 0.6267, Test Loss: 2.2846\n",
      "Epoch [93/500] - Train Loss: 0.6253, Test Loss: 1.5269\n",
      "Epoch [94/500] - Train Loss: 0.5575, Test Loss: 2.5088\n",
      "Epoch [95/500] - Train Loss: 0.6030, Test Loss: 2.8413\n",
      "Epoch [96/500] - Train Loss: 0.6276, Test Loss: 1.6575\n",
      "Epoch [97/500] - Train Loss: 0.6022, Test Loss: 2.8201\n",
      "Epoch [98/500] - Train Loss: 0.8665, Test Loss: 1.4080\n",
      "Epoch [99/500] - Train Loss: 0.5876, Test Loss: 2.0260\n",
      "Epoch [100/500] - Train Loss: 0.5647, Test Loss: 2.1787\n",
      "Epoch [101/500] - Train Loss: 0.5254, Test Loss: 2.4105\n",
      "Epoch [102/500] - Train Loss: 0.5251, Test Loss: 2.5690\n",
      "Epoch [103/500] - Train Loss: 0.5118, Test Loss: 2.5817\n",
      "Epoch [104/500] - Train Loss: 0.5011, Test Loss: 2.6911\n",
      "Epoch [105/500] - Train Loss: 0.5029, Test Loss: 2.6703\n",
      "Epoch [106/500] - Train Loss: 0.4961, Test Loss: 2.6355\n",
      "Epoch [107/500] - Train Loss: 0.4891, Test Loss: 2.7420\n",
      "Epoch [108/500] - Train Loss: 0.4922, Test Loss: 2.7072\n",
      "Epoch [109/500] - Train Loss: 0.4851, Test Loss: 2.7124\n",
      "Epoch [110/500] - Train Loss: 0.4813, Test Loss: 2.7768\n",
      "Epoch [111/500] - Train Loss: 0.4834, Test Loss: 2.7588\n",
      "Epoch [112/500] - Train Loss: 0.4778, Test Loss: 2.7171\n",
      "Epoch [113/500] - Train Loss: 0.4722, Test Loss: 2.8357\n",
      "Epoch [114/500] - Train Loss: 0.4742, Test Loss: 2.8207\n",
      "Epoch [115/500] - Train Loss: 0.4676, Test Loss: 2.7136\n",
      "Epoch [116/500] - Train Loss: 0.4584, Test Loss: 2.8270\n",
      "Epoch [117/500] - Train Loss: 0.4665, Test Loss: 2.9484\n",
      "Epoch [118/500] - Train Loss: 0.4717, Test Loss: 3.3224\n",
      "Epoch [119/500] - Train Loss: 0.5180, Test Loss: 2.9783\n",
      "Epoch [120/500] - Train Loss: 0.6166, Test Loss: 1.9784\n",
      "Epoch [121/500] - Train Loss: 0.5831, Test Loss: 2.9767\n",
      "Epoch [122/500] - Train Loss: 0.5886, Test Loss: 3.0922\n",
      "Epoch [123/500] - Train Loss: 0.5966, Test Loss: 2.2019\n",
      "Epoch [124/500] - Train Loss: 0.5549, Test Loss: 2.9736\n",
      "Epoch [125/500] - Train Loss: 0.6282, Test Loss: 2.2234\n",
      "Epoch [126/500] - Train Loss: 0.4995, Test Loss: 2.6090\n",
      "Epoch [127/500] - Train Loss: 0.4810, Test Loss: 2.9679\n",
      "Epoch [128/500] - Train Loss: 0.5129, Test Loss: 2.4365\n",
      "Epoch [129/500] - Train Loss: 0.4909, Test Loss: 2.9930\n",
      "Epoch [130/500] - Train Loss: 0.4980, Test Loss: 2.7434\n",
      "Epoch [131/500] - Train Loss: 0.4751, Test Loss: 2.5818\n",
      "Epoch [132/500] - Train Loss: 0.4641, Test Loss: 2.9418\n",
      "Epoch [133/500] - Train Loss: 0.4807, Test Loss: 2.4517\n",
      "Epoch [134/500] - Train Loss: 0.4620, Test Loss: 3.1186\n",
      "Epoch [135/500] - Train Loss: 0.4843, Test Loss: 2.7783\n",
      "Epoch [136/500] - Train Loss: 0.4533, Test Loss: 2.4902\n",
      "Epoch [137/500] - Train Loss: 0.4610, Test Loss: 3.3785\n",
      "Epoch [138/500] - Train Loss: 0.4952, Test Loss: 2.4477\n",
      "Epoch [139/500] - Train Loss: 0.4581, Test Loss: 3.1276\n",
      "Epoch [140/500] - Train Loss: 0.5182, Test Loss: 3.2974\n",
      "Epoch [141/500] - Train Loss: 0.6051, Test Loss: 1.6596\n",
      "Epoch [142/500] - Train Loss: 0.6887, Test Loss: 3.3427\n",
      "Epoch [143/500] - Train Loss: 0.7121, Test Loss: 2.0084\n",
      "Epoch [144/500] - Train Loss: 0.5990, Test Loss: 2.5711\n",
      "Epoch [145/500] - Train Loss: 0.6513, Test Loss: 2.3207\n",
      "Epoch [146/500] - Train Loss: 0.5547, Test Loss: 2.8012\n",
      "Epoch [147/500] - Train Loss: 0.6166, Test Loss: 2.0370\n",
      "Epoch [148/500] - Train Loss: 0.5937, Test Loss: 2.6693\n",
      "Epoch [149/500] - Train Loss: 0.6497, Test Loss: 2.1323\n",
      "Epoch [150/500] - Train Loss: 0.6353, Test Loss: 2.3642\n",
      "Epoch [151/500] - Train Loss: 0.5563, Test Loss: 2.2939\n",
      "Epoch [152/500] - Train Loss: 0.5335, Test Loss: 2.1957\n",
      "Epoch [153/500] - Train Loss: 0.5043, Test Loss: 2.5574\n",
      "Epoch [154/500] - Train Loss: 0.4887, Test Loss: 2.5401\n",
      "Epoch [155/500] - Train Loss: 0.4809, Test Loss: 2.5139\n",
      "Epoch [156/500] - Train Loss: 0.4726, Test Loss: 2.2377\n",
      "Epoch [157/500] - Train Loss: 0.4412, Test Loss: 2.1464\n",
      "Epoch [158/500] - Train Loss: 0.4286, Test Loss: 2.4674\n",
      "Epoch [159/500] - Train Loss: 0.4375, Test Loss: 2.0844\n",
      "Epoch [160/500] - Train Loss: 0.4310, Test Loss: 2.4263\n",
      "Epoch [161/500] - Train Loss: 0.4357, Test Loss: 3.1775\n",
      "Epoch [162/500] - Train Loss: 0.5758, Test Loss: 1.9744\n",
      "Epoch [163/500] - Train Loss: 0.6975, Test Loss: 2.4206\n",
      "Epoch [164/500] - Train Loss: 0.5501, Test Loss: 2.4575\n",
      "Epoch [165/500] - Train Loss: 0.5054, Test Loss: 2.4527\n",
      "Epoch [166/500] - Train Loss: 0.4404, Test Loss: 2.5335\n",
      "Epoch [167/500] - Train Loss: 0.4384, Test Loss: 2.2349\n",
      "Epoch [168/500] - Train Loss: 0.4084, Test Loss: 2.3821\n",
      "Epoch [169/500] - Train Loss: 0.3930, Test Loss: 2.3060\n",
      "Epoch [170/500] - Train Loss: 0.3724, Test Loss: 2.3579\n",
      "Epoch [171/500] - Train Loss: 0.3680, Test Loss: 2.3936\n",
      "Epoch [172/500] - Train Loss: 0.3585, Test Loss: 2.3470\n",
      "Epoch [173/500] - Train Loss: 0.3628, Test Loss: 2.1743\n",
      "Epoch [174/500] - Train Loss: 0.3718, Test Loss: 4.0409\n",
      "Epoch [175/500] - Train Loss: 1.1841, Test Loss: 1.8543\n",
      "Epoch [176/500] - Train Loss: 0.8460, Test Loss: 2.0954\n",
      "Epoch [177/500] - Train Loss: 0.6424, Test Loss: 2.1567\n",
      "Epoch [178/500] - Train Loss: 0.6335, Test Loss: 2.5554\n",
      "Epoch [179/500] - Train Loss: 0.5770, Test Loss: 2.5006\n",
      "Epoch [180/500] - Train Loss: 0.5305, Test Loss: 2.8001\n",
      "Epoch [181/500] - Train Loss: 0.5247, Test Loss: 2.5867\n",
      "Epoch [182/500] - Train Loss: 0.5054, Test Loss: 2.6564\n",
      "Epoch [183/500] - Train Loss: 0.5028, Test Loss: 2.7348\n",
      "Epoch [184/500] - Train Loss: 0.4996, Test Loss: 2.6097\n",
      "Epoch [185/500] - Train Loss: 0.4913, Test Loss: 2.7222\n",
      "Epoch [186/500] - Train Loss: 0.5024, Test Loss: 2.9709\n",
      "Epoch [187/500] - Train Loss: 0.5213, Test Loss: 2.5940\n",
      "Epoch [188/500] - Train Loss: 0.5300, Test Loss: 2.4261\n",
      "Epoch [189/500] - Train Loss: 0.5298, Test Loss: 2.8693\n",
      "Epoch [190/500] - Train Loss: 0.5328, Test Loss: 2.5708\n",
      "Epoch [191/500] - Train Loss: 0.4922, Test Loss: 2.5778\n",
      "Epoch [192/500] - Train Loss: 0.4853, Test Loss: 3.0597\n",
      "Epoch [193/500] - Train Loss: 0.4865, Test Loss: 2.6330\n",
      "Epoch [194/500] - Train Loss: 0.4602, Test Loss: 2.7837\n",
      "Epoch [195/500] - Train Loss: 0.4576, Test Loss: 3.0455\n",
      "Epoch [196/500] - Train Loss: 0.4348, Test Loss: 2.8343\n",
      "Epoch [197/500] - Train Loss: 0.4129, Test Loss: 3.3815\n",
      "Epoch [198/500] - Train Loss: 0.4662, Test Loss: 2.3884\n",
      "Epoch [199/500] - Train Loss: 0.4710, Test Loss: 3.8006\n",
      "Epoch [200/500] - Train Loss: 0.4473, Test Loss: 2.6309\n",
      "Epoch [201/500] - Train Loss: 0.4533, Test Loss: 3.7483\n",
      "Epoch [202/500] - Train Loss: 0.5042, Test Loss: 2.2334\n",
      "Epoch [203/500] - Train Loss: 0.4372, Test Loss: 3.2901\n",
      "Epoch [204/500] - Train Loss: 0.4214, Test Loss: 2.1055\n",
      "Epoch [205/500] - Train Loss: 0.4700, Test Loss: 3.1181\n",
      "Epoch [206/500] - Train Loss: 0.4346, Test Loss: 2.2898\n",
      "Epoch [207/500] - Train Loss: 0.4147, Test Loss: 2.9004\n",
      "Epoch [208/500] - Train Loss: 0.3905, Test Loss: 2.0427\n",
      "Epoch [209/500] - Train Loss: 0.4605, Test Loss: 2.8191\n",
      "Epoch [210/500] - Train Loss: 0.4551, Test Loss: 2.6707\n",
      "Epoch [211/500] - Train Loss: 0.3650, Test Loss: 2.6269\n",
      "Epoch [212/500] - Train Loss: 0.4391, Test Loss: 3.6535\n",
      "Epoch [213/500] - Train Loss: 0.5639, Test Loss: 2.1505\n",
      "Epoch [214/500] - Train Loss: 0.6880, Test Loss: 2.6774\n",
      "Epoch [215/500] - Train Loss: 0.5565, Test Loss: 2.6190\n",
      "Epoch [216/500] - Train Loss: 0.4643, Test Loss: 2.0933\n",
      "Epoch [217/500] - Train Loss: 0.4512, Test Loss: 3.0038\n",
      "Epoch [218/500] - Train Loss: 0.3993, Test Loss: 2.3221\n",
      "Epoch [219/500] - Train Loss: 0.4192, Test Loss: 3.3544\n",
      "Epoch [220/500] - Train Loss: 0.3956, Test Loss: 1.9864\n",
      "Epoch [221/500] - Train Loss: 0.4603, Test Loss: 3.0030\n",
      "Epoch [222/500] - Train Loss: 0.3781, Test Loss: 2.3693\n",
      "Epoch [223/500] - Train Loss: 0.4349, Test Loss: 3.8235\n",
      "Epoch [224/500] - Train Loss: 0.3677, Test Loss: 2.1740\n",
      "Epoch [225/500] - Train Loss: 0.3771, Test Loss: 2.6948\n",
      "Epoch [226/500] - Train Loss: 0.3472, Test Loss: 3.1074\n",
      "Epoch [227/500] - Train Loss: 0.3375, Test Loss: 3.3624\n",
      "Epoch [228/500] - Train Loss: 0.3815, Test Loss: 2.3363\n",
      "Epoch [229/500] - Train Loss: 0.3786, Test Loss: 2.4619\n",
      "Epoch [230/500] - Train Loss: 0.3557, Test Loss: 3.3576\n",
      "Epoch [231/500] - Train Loss: 0.3979, Test Loss: 3.2728\n",
      "Epoch [232/500] - Train Loss: 0.4594, Test Loss: 2.1419\n",
      "Epoch [233/500] - Train Loss: 0.3705, Test Loss: 3.0852\n",
      "Epoch [234/500] - Train Loss: 0.4100, Test Loss: 2.5074\n",
      "Epoch [235/500] - Train Loss: 0.4257, Test Loss: 2.3741\n",
      "Epoch [236/500] - Train Loss: 0.3586, Test Loss: 2.7576\n",
      "Epoch [237/500] - Train Loss: 0.3845, Test Loss: 2.0474\n",
      "Epoch [238/500] - Train Loss: 0.3659, Test Loss: 2.9123\n",
      "Epoch [239/500] - Train Loss: 0.3625, Test Loss: 2.0831\n",
      "Epoch [240/500] - Train Loss: 0.3917, Test Loss: 2.9833\n",
      "Epoch [241/500] - Train Loss: 0.3297, Test Loss: 2.0745\n",
      "Epoch [242/500] - Train Loss: 0.3617, Test Loss: 3.7333\n",
      "Epoch [243/500] - Train Loss: 0.3907, Test Loss: 2.6531\n",
      "Epoch [244/500] - Train Loss: 0.6462, Test Loss: 2.4632\n",
      "Epoch [245/500] - Train Loss: 0.5063, Test Loss: 2.3897\n",
      "Epoch [246/500] - Train Loss: 0.3637, Test Loss: 2.5109\n",
      "Epoch [247/500] - Train Loss: 0.4119, Test Loss: 2.6640\n",
      "Epoch [248/500] - Train Loss: 0.5070, Test Loss: 2.2521\n",
      "Epoch [249/500] - Train Loss: 0.5181, Test Loss: 1.6889\n",
      "Epoch [250/500] - Train Loss: 0.4184, Test Loss: 2.1512\n",
      "Epoch [251/500] - Train Loss: 0.3367, Test Loss: 2.6197\n",
      "Epoch [252/500] - Train Loss: 0.3871, Test Loss: 2.1284\n",
      "Epoch [253/500] - Train Loss: 0.4220, Test Loss: 2.4243\n",
      "Epoch [254/500] - Train Loss: 0.3705, Test Loss: 2.3460\n",
      "Epoch [255/500] - Train Loss: 0.3379, Test Loss: 2.7456\n",
      "Epoch [256/500] - Train Loss: 0.3270, Test Loss: 2.4113\n",
      "Epoch [257/500] - Train Loss: 0.3140, Test Loss: 3.0196\n",
      "Epoch [258/500] - Train Loss: 0.3884, Test Loss: 1.7822\n",
      "Epoch [259/500] - Train Loss: 0.5428, Test Loss: 4.1703\n",
      "Epoch [260/500] - Train Loss: 0.4851, Test Loss: 2.1324\n",
      "Epoch [261/500] - Train Loss: 0.3768, Test Loss: 2.1624\n",
      "Epoch [262/500] - Train Loss: 0.3041, Test Loss: 2.4206\n",
      "Epoch [263/500] - Train Loss: 0.2881, Test Loss: 2.4493\n",
      "Epoch [264/500] - Train Loss: 0.3037, Test Loss: 2.2583\n",
      "Epoch [265/500] - Train Loss: 0.3100, Test Loss: 2.6903\n",
      "Epoch [266/500] - Train Loss: 0.3028, Test Loss: 1.9501\n",
      "Epoch [267/500] - Train Loss: 0.4034, Test Loss: 3.0947\n",
      "Epoch [268/500] - Train Loss: 0.3118, Test Loss: 2.1672\n",
      "Epoch [269/500] - Train Loss: 0.3067, Test Loss: 3.2065\n",
      "Epoch [270/500] - Train Loss: 0.3116, Test Loss: 1.7679\n",
      "Epoch [271/500] - Train Loss: 0.4237, Test Loss: 3.3391\n",
      "Epoch [272/500] - Train Loss: 0.3940, Test Loss: 1.7259\n",
      "Epoch [273/500] - Train Loss: 0.5317, Test Loss: 3.9257\n",
      "Epoch [274/500] - Train Loss: 0.4079, Test Loss: 1.7008\n",
      "Epoch [275/500] - Train Loss: 0.4315, Test Loss: 3.2780\n",
      "Epoch [276/500] - Train Loss: 0.4333, Test Loss: 1.7478\n",
      "Epoch [277/500] - Train Loss: 0.5067, Test Loss: 2.9727\n",
      "Epoch [278/500] - Train Loss: 0.3642, Test Loss: 2.3930\n",
      "Epoch [279/500] - Train Loss: 0.2857, Test Loss: 2.3762\n",
      "Epoch [280/500] - Train Loss: 0.2772, Test Loss: 2.2908\n",
      "Epoch [281/500] - Train Loss: 0.2666, Test Loss: 2.4501\n",
      "Epoch [282/500] - Train Loss: 0.2706, Test Loss: 2.5002\n",
      "Epoch [283/500] - Train Loss: 0.2558, Test Loss: 2.7807\n",
      "Epoch [284/500] - Train Loss: 0.2510, Test Loss: 2.6810\n",
      "Epoch [285/500] - Train Loss: 0.2430, Test Loss: 2.8976\n",
      "Epoch [286/500] - Train Loss: 0.2648, Test Loss: 2.4734\n",
      "Epoch [287/500] - Train Loss: 0.2731, Test Loss: 2.5248\n",
      "Epoch [288/500] - Train Loss: 0.2440, Test Loss: 2.6743\n",
      "Epoch [289/500] - Train Loss: 0.2465, Test Loss: 2.5185\n",
      "Epoch [290/500] - Train Loss: 0.2504, Test Loss: 2.6183\n",
      "Epoch [291/500] - Train Loss: 0.2222, Test Loss: 2.7378\n",
      "Epoch [292/500] - Train Loss: 0.2137, Test Loss: 2.4990\n",
      "Epoch [293/500] - Train Loss: 0.2066, Test Loss: 3.0192\n",
      "Epoch [294/500] - Train Loss: 0.1794, Test Loss: 3.1261\n",
      "Epoch [295/500] - Train Loss: 0.1880, Test Loss: 2.4253\n",
      "Epoch [296/500] - Train Loss: 0.2480, Test Loss: 3.4897\n",
      "Epoch [297/500] - Train Loss: 0.2176, Test Loss: 2.8774\n",
      "Epoch [298/500] - Train Loss: 0.2551, Test Loss: 2.6581\n",
      "Epoch [299/500] - Train Loss: 0.1905, Test Loss: 3.7867\n",
      "Epoch [300/500] - Train Loss: 0.2751, Test Loss: 2.3624\n",
      "Epoch [301/500] - Train Loss: 0.2714, Test Loss: 3.2161\n",
      "Epoch [302/500] - Train Loss: 0.2244, Test Loss: 3.3829\n",
      "Epoch [303/500] - Train Loss: 0.2159, Test Loss: 3.0806\n",
      "Epoch [304/500] - Train Loss: 0.1982, Test Loss: 3.5613\n",
      "Epoch [305/500] - Train Loss: 0.1798, Test Loss: 3.2329\n",
      "Epoch [306/500] - Train Loss: 0.1830, Test Loss: 3.4419\n",
      "Epoch [307/500] - Train Loss: 0.1961, Test Loss: 3.9359\n",
      "Epoch [308/500] - Train Loss: 0.2002, Test Loss: 2.7286\n",
      "Epoch [309/500] - Train Loss: 0.4230, Test Loss: 2.8335\n",
      "Epoch [310/500] - Train Loss: 0.3300, Test Loss: 2.7073\n",
      "Epoch [311/500] - Train Loss: 0.3178, Test Loss: 3.5822\n",
      "Epoch [312/500] - Train Loss: 0.3278, Test Loss: 2.3049\n",
      "Epoch [313/500] - Train Loss: 0.3001, Test Loss: 3.3539\n",
      "Epoch [314/500] - Train Loss: 0.2310, Test Loss: 2.7801\n",
      "Epoch [315/500] - Train Loss: 0.2011, Test Loss: 3.2341\n",
      "Epoch [316/500] - Train Loss: 0.1974, Test Loss: 3.4355\n",
      "Epoch [317/500] - Train Loss: 0.1831, Test Loss: 2.8797\n",
      "Epoch [318/500] - Train Loss: 0.1825, Test Loss: 3.1128\n",
      "Epoch [319/500] - Train Loss: 0.2514, Test Loss: 2.4002\n",
      "Epoch [320/500] - Train Loss: 0.2357, Test Loss: 3.6909\n",
      "Epoch [321/500] - Train Loss: 0.1953, Test Loss: 3.3692\n",
      "Epoch [322/500] - Train Loss: 0.1763, Test Loss: 3.2135\n",
      "Epoch [323/500] - Train Loss: 0.2126, Test Loss: 3.6953\n",
      "Epoch [324/500] - Train Loss: 0.1804, Test Loss: 3.5006\n",
      "Epoch [325/500] - Train Loss: 0.1690, Test Loss: 3.9396\n",
      "Epoch [326/500] - Train Loss: 0.1540, Test Loss: 3.5800\n",
      "Epoch [327/500] - Train Loss: 0.1650, Test Loss: 3.6244\n",
      "Epoch [328/500] - Train Loss: 0.1498, Test Loss: 3.8061\n",
      "Epoch [329/500] - Train Loss: 0.1494, Test Loss: 3.6612\n",
      "Epoch [330/500] - Train Loss: 0.1380, Test Loss: 4.0917\n",
      "Epoch [331/500] - Train Loss: 0.1627, Test Loss: 3.7754\n",
      "Epoch [332/500] - Train Loss: 0.2343, Test Loss: 2.3455\n",
      "Epoch [333/500] - Train Loss: 0.3706, Test Loss: 4.1039\n",
      "Epoch [334/500] - Train Loss: 0.2604, Test Loss: 4.4034\n",
      "Epoch [335/500] - Train Loss: 0.2354, Test Loss: 2.6388\n",
      "Epoch [336/500] - Train Loss: 0.2596, Test Loss: 3.6799\n",
      "Epoch [337/500] - Train Loss: 0.1766, Test Loss: 3.6440\n",
      "Epoch [338/500] - Train Loss: 0.1572, Test Loss: 3.8212\n",
      "Epoch [339/500] - Train Loss: 0.1575, Test Loss: 3.9074\n",
      "Epoch [340/500] - Train Loss: 0.1575, Test Loss: 3.6035\n",
      "Epoch [341/500] - Train Loss: 0.1971, Test Loss: 4.2596\n",
      "Epoch [342/500] - Train Loss: 0.1943, Test Loss: 3.6628\n",
      "Epoch [343/500] - Train Loss: 0.1573, Test Loss: 4.0872\n",
      "Epoch [344/500] - Train Loss: 0.1551, Test Loss: 3.7245\n",
      "Epoch [345/500] - Train Loss: 0.1307, Test Loss: 3.6397\n",
      "Epoch [346/500] - Train Loss: 0.1250, Test Loss: 3.8378\n",
      "Epoch [347/500] - Train Loss: 0.1200, Test Loss: 3.8843\n",
      "Epoch [348/500] - Train Loss: 0.1316, Test Loss: 4.1562\n",
      "Epoch [349/500] - Train Loss: 0.1275, Test Loss: 3.7834\n",
      "Epoch [350/500] - Train Loss: 0.1068, Test Loss: 3.9031\n",
      "Epoch [351/500] - Train Loss: 0.1240, Test Loss: 3.4420\n",
      "Epoch [352/500] - Train Loss: 0.2639, Test Loss: 3.9108\n",
      "Epoch [353/500] - Train Loss: 0.2143, Test Loss: 3.5538\n",
      "Epoch [354/500] - Train Loss: 0.1398, Test Loss: 3.6620\n",
      "Epoch [355/500] - Train Loss: 0.1759, Test Loss: 3.5616\n",
      "Epoch [356/500] - Train Loss: 0.1253, Test Loss: 4.2691\n",
      "Epoch [357/500] - Train Loss: 0.1215, Test Loss: 4.0046\n",
      "Epoch [358/500] - Train Loss: 0.1795, Test Loss: 3.5907\n",
      "Epoch [359/500] - Train Loss: 0.2369, Test Loss: 3.6645\n",
      "Epoch [360/500] - Train Loss: 0.3243, Test Loss: 2.5919\n",
      "Epoch [361/500] - Train Loss: 0.3064, Test Loss: 3.7061\n",
      "Epoch [362/500] - Train Loss: 0.3357, Test Loss: 3.7116\n",
      "Epoch [363/500] - Train Loss: 0.2747, Test Loss: 3.3331\n",
      "Epoch [364/500] - Train Loss: 0.2027, Test Loss: 3.3547\n",
      "Epoch [365/500] - Train Loss: 0.1713, Test Loss: 3.6086\n",
      "Epoch [366/500] - Train Loss: 0.1474, Test Loss: 3.5306\n",
      "Epoch [367/500] - Train Loss: 0.1315, Test Loss: 3.4196\n",
      "Epoch [368/500] - Train Loss: 0.1183, Test Loss: 3.9670\n",
      "Epoch [369/500] - Train Loss: 0.1239, Test Loss: 4.0240\n",
      "Epoch [370/500] - Train Loss: 0.1383, Test Loss: 3.5654\n",
      "Epoch [371/500] - Train Loss: 0.1696, Test Loss: 4.1427\n",
      "Epoch [372/500] - Train Loss: 0.1474, Test Loss: 3.8034\n",
      "Epoch [373/500] - Train Loss: 0.1631, Test Loss: 3.8114\n",
      "Epoch [374/500] - Train Loss: 0.1343, Test Loss: 3.9713\n",
      "Epoch [375/500] - Train Loss: 0.1483, Test Loss: 4.4666\n",
      "Epoch [376/500] - Train Loss: 0.1359, Test Loss: 4.0356\n",
      "Epoch [377/500] - Train Loss: 0.1294, Test Loss: 3.7837\n",
      "Epoch [378/500] - Train Loss: 0.1487, Test Loss: 3.5652\n",
      "Epoch [379/500] - Train Loss: 0.1354, Test Loss: 4.1096\n",
      "Epoch [380/500] - Train Loss: 0.1341, Test Loss: 4.1021\n",
      "Epoch [381/500] - Train Loss: 0.1165, Test Loss: 3.7630\n",
      "Epoch [382/500] - Train Loss: 0.0996, Test Loss: 4.1192\n",
      "Epoch [383/500] - Train Loss: 0.1017, Test Loss: 4.0893\n",
      "Epoch [384/500] - Train Loss: 0.0951, Test Loss: 3.8713\n",
      "Epoch [385/500] - Train Loss: 0.0960, Test Loss: 3.9010\n",
      "Epoch [386/500] - Train Loss: 0.0919, Test Loss: 3.9107\n",
      "Epoch [387/500] - Train Loss: 0.0960, Test Loss: 3.9362\n",
      "Epoch [388/500] - Train Loss: 0.0947, Test Loss: 3.8950\n",
      "Epoch [389/500] - Train Loss: 0.1075, Test Loss: 4.0571\n",
      "Epoch [390/500] - Train Loss: 0.1078, Test Loss: 4.0664\n",
      "Epoch [391/500] - Train Loss: 0.1125, Test Loss: 4.0957\n",
      "Epoch [392/500] - Train Loss: 0.1003, Test Loss: 3.9703\n",
      "Epoch [393/500] - Train Loss: 0.1161, Test Loss: 4.2541\n",
      "Epoch [394/500] - Train Loss: 0.1101, Test Loss: 4.1792\n",
      "Epoch [395/500] - Train Loss: 0.1144, Test Loss: 4.3465\n",
      "Epoch [396/500] - Train Loss: 0.1058, Test Loss: 4.2619\n",
      "Epoch [397/500] - Train Loss: 0.1122, Test Loss: 4.4829\n",
      "Epoch [398/500] - Train Loss: 0.1055, Test Loss: 4.3223\n",
      "Epoch [399/500] - Train Loss: 0.1163, Test Loss: 4.3889\n",
      "Epoch [400/500] - Train Loss: 0.1096, Test Loss: 4.2943\n",
      "Epoch [401/500] - Train Loss: 0.1121, Test Loss: 4.7823\n",
      "Epoch [402/500] - Train Loss: 0.1049, Test Loss: 4.4872\n",
      "Epoch [403/500] - Train Loss: 0.1179, Test Loss: 4.9362\n",
      "Epoch [404/500] - Train Loss: 0.1074, Test Loss: 4.5622\n",
      "Epoch [405/500] - Train Loss: 0.1152, Test Loss: 5.0979\n",
      "Epoch [406/500] - Train Loss: 0.1329, Test Loss: 4.0282\n",
      "Epoch [407/500] - Train Loss: 0.1139, Test Loss: 4.4628\n",
      "Epoch [408/500] - Train Loss: 0.2291, Test Loss: 4.1618\n",
      "Epoch [409/500] - Train Loss: 0.3089, Test Loss: 3.8235\n",
      "Epoch [410/500] - Train Loss: 0.1532, Test Loss: 3.9213\n",
      "Epoch [411/500] - Train Loss: 0.1963, Test Loss: 3.6652\n",
      "Epoch [412/500] - Train Loss: 0.2343, Test Loss: 3.6946\n",
      "Epoch [413/500] - Train Loss: 0.4688, Test Loss: 4.7088\n",
      "Epoch [414/500] - Train Loss: 0.4530, Test Loss: 2.3703\n",
      "Epoch [415/500] - Train Loss: 0.2921, Test Loss: 3.3812\n",
      "Epoch [416/500] - Train Loss: 0.2178, Test Loss: 3.4230\n",
      "Epoch [417/500] - Train Loss: 0.1745, Test Loss: 3.8158\n",
      "Epoch [418/500] - Train Loss: 0.1501, Test Loss: 4.0701\n",
      "Epoch [419/500] - Train Loss: 0.1326, Test Loss: 4.1513\n",
      "Epoch [420/500] - Train Loss: 0.1947, Test Loss: 3.7349\n",
      "Epoch [421/500] - Train Loss: 0.1482, Test Loss: 4.0768\n",
      "Epoch [422/500] - Train Loss: 0.1469, Test Loss: 4.0596\n",
      "Epoch [423/500] - Train Loss: 0.1330, Test Loss: 3.9397\n",
      "Epoch [424/500] - Train Loss: 0.1325, Test Loss: 4.1169\n",
      "Epoch [425/500] - Train Loss: 0.1229, Test Loss: 4.1487\n",
      "Epoch [426/500] - Train Loss: 0.1019, Test Loss: 4.1765\n",
      "Epoch [427/500] - Train Loss: 0.0987, Test Loss: 4.2193\n",
      "Epoch [428/500] - Train Loss: 0.0966, Test Loss: 4.2446\n",
      "Epoch [429/500] - Train Loss: 0.0940, Test Loss: 4.1162\n",
      "Epoch [430/500] - Train Loss: 0.0909, Test Loss: 4.1095\n",
      "Epoch [431/500] - Train Loss: 0.0876, Test Loss: 4.1849\n",
      "Epoch [432/500] - Train Loss: 0.0860, Test Loss: 4.0820\n",
      "Epoch [433/500] - Train Loss: 0.0824, Test Loss: 4.1267\n",
      "Epoch [434/500] - Train Loss: 0.0815, Test Loss: 4.1002\n",
      "Epoch [435/500] - Train Loss: 0.0751, Test Loss: 4.0513\n",
      "Epoch [436/500] - Train Loss: 0.0750, Test Loss: 4.2541\n",
      "Epoch [437/500] - Train Loss: 0.0731, Test Loss: 4.0511\n",
      "Epoch [438/500] - Train Loss: 0.0735, Test Loss: 4.1025\n",
      "Epoch [439/500] - Train Loss: 0.0676, Test Loss: 4.0726\n",
      "Epoch [440/500] - Train Loss: 0.0643, Test Loss: 4.0801\n",
      "Epoch [441/500] - Train Loss: 0.0635, Test Loss: 4.0791\n",
      "Epoch [442/500] - Train Loss: 0.0595, Test Loss: 4.0229\n",
      "Epoch [443/500] - Train Loss: 0.0575, Test Loss: 4.0037\n",
      "Epoch [444/500] - Train Loss: 0.0582, Test Loss: 4.0419\n",
      "Epoch [445/500] - Train Loss: 0.0563, Test Loss: 3.9600\n",
      "Epoch [446/500] - Train Loss: 0.0522, Test Loss: 4.0089\n",
      "Epoch [447/500] - Train Loss: 0.0511, Test Loss: 3.9549\n",
      "Epoch [448/500] - Train Loss: 0.0523, Test Loss: 4.0269\n",
      "Epoch [449/500] - Train Loss: 0.0569, Test Loss: 4.0287\n",
      "Epoch [450/500] - Train Loss: 0.0502, Test Loss: 3.9025\n",
      "Epoch [451/500] - Train Loss: 0.0509, Test Loss: 4.0945\n",
      "Epoch [452/500] - Train Loss: 0.0650, Test Loss: 4.0782\n",
      "Epoch [453/500] - Train Loss: 0.0625, Test Loss: 3.9738\n",
      "Epoch [454/500] - Train Loss: 0.0610, Test Loss: 3.8439\n",
      "Epoch [455/500] - Train Loss: 0.0567, Test Loss: 3.9746\n",
      "Epoch [456/500] - Train Loss: 0.0599, Test Loss: 4.1704\n",
      "Epoch [457/500] - Train Loss: 0.0593, Test Loss: 3.8271\n",
      "Epoch [458/500] - Train Loss: 0.0584, Test Loss: 4.0429\n",
      "Epoch [459/500] - Train Loss: 0.0638, Test Loss: 4.0545\n",
      "Epoch [460/500] - Train Loss: 0.0544, Test Loss: 3.8963\n",
      "Epoch [461/500] - Train Loss: 0.0568, Test Loss: 3.7900\n",
      "Epoch [462/500] - Train Loss: 0.0543, Test Loss: 4.1337\n",
      "Epoch [463/500] - Train Loss: 0.0506, Test Loss: 4.0382\n",
      "Epoch [464/500] - Train Loss: 0.0523, Test Loss: 3.9955\n",
      "Epoch [465/500] - Train Loss: 0.0560, Test Loss: 4.2928\n",
      "Epoch [466/500] - Train Loss: 0.0481, Test Loss: 4.1589\n",
      "Epoch [467/500] - Train Loss: 0.0518, Test Loss: 4.1693\n",
      "Epoch [468/500] - Train Loss: 0.0584, Test Loss: 4.2772\n",
      "Epoch [469/500] - Train Loss: 0.0553, Test Loss: 4.2444\n",
      "Epoch [470/500] - Train Loss: 0.8352, Test Loss: 1.2574\n",
      "Epoch [471/500] - Train Loss: 1.2497, Test Loss: 2.6978\n",
      "Epoch [472/500] - Train Loss: 0.8658, Test Loss: 2.7802\n",
      "Epoch [473/500] - Train Loss: 0.8691, Test Loss: 1.5257\n",
      "Epoch [474/500] - Train Loss: 0.7976, Test Loss: 3.2896\n",
      "Epoch [475/500] - Train Loss: 0.9403, Test Loss: 1.6604\n",
      "Epoch [476/500] - Train Loss: 0.7970, Test Loss: 2.2225\n",
      "Epoch [477/500] - Train Loss: 1.0787, Test Loss: 3.3545\n",
      "Epoch [478/500] - Train Loss: 0.9962, Test Loss: 1.6548\n",
      "Epoch [479/500] - Train Loss: 0.9601, Test Loss: 1.7404\n",
      "Epoch [480/500] - Train Loss: 0.8790, Test Loss: 1.8258\n",
      "Epoch [481/500] - Train Loss: 0.8257, Test Loss: 1.8514\n",
      "Epoch [482/500] - Train Loss: 0.7815, Test Loss: 1.7820\n",
      "Epoch [483/500] - Train Loss: 0.7357, Test Loss: 1.9091\n",
      "Epoch [484/500] - Train Loss: 0.6889, Test Loss: 1.7678\n",
      "Epoch [485/500] - Train Loss: 0.6559, Test Loss: 1.7633\n",
      "Epoch [486/500] - Train Loss: 0.6417, Test Loss: 1.7892\n",
      "Epoch [487/500] - Train Loss: 0.6072, Test Loss: 2.0318\n",
      "Epoch [488/500] - Train Loss: 0.5554, Test Loss: 1.7834\n",
      "Epoch [489/500] - Train Loss: 0.5592, Test Loss: 2.3175\n",
      "Epoch [490/500] - Train Loss: 0.5979, Test Loss: 2.0840\n",
      "Epoch [491/500] - Train Loss: 0.7436, Test Loss: 1.6713\n",
      "Epoch [492/500] - Train Loss: 0.5437, Test Loss: 1.7021\n",
      "Epoch [493/500] - Train Loss: 0.7453, Test Loss: 1.5868\n",
      "Epoch [494/500] - Train Loss: 0.5722, Test Loss: 1.5536\n",
      "Epoch [495/500] - Train Loss: 0.5489, Test Loss: 1.5891\n",
      "Epoch [496/500] - Train Loss: 0.5131, Test Loss: 1.7369\n",
      "Epoch [497/500] - Train Loss: 0.5410, Test Loss: 1.7064\n",
      "Epoch [498/500] - Train Loss: 0.5189, Test Loss: 1.9480\n",
      "Epoch [499/500] - Train Loss: 0.8943, Test Loss: 2.0255\n",
      "Epoch [500/500] - Train Loss: 0.7375, Test Loss: 1.9128\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_size = 8\n",
    "num_layers = 2\n",
    "learning_rate = 0.01\n",
    "batch_size = 6\n",
    "num_epochs = 500\n",
    "\n",
    "params = {\n",
    "        'hidden_size': hidden_size,\n",
    "        'num_layers': num_layers,\n",
    "        'learning_rate': learning_rate,\n",
    "        'batch_size': batch_size,\n",
    "    }\n",
    "\n",
    "train_losses, test_losses, avg_loss = train_and_evaluate(params, \n",
    "                                                         train_X_new, \n",
    "                                                         train_y_new, \n",
    "                                                         test_X_new, \n",
    "                                                         test_y_new, \n",
    "                                                         num_epochs)\n",
    "\n",
    "# Plotting the training and testing losses\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, len(test_losses) + 1), test_losses, label='Testing Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Testing Loss over Epochs (CNN-LSTM)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
