{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#pd.set_option('display.max_rows', None)\n",
    "#coaching_time_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitbit data\n",
    "wear_time = pd.read_csv(\"D:\\\\EIC-Code\\\\00-Python\\\\2024-08-Objective-identification-on-mental-health_CNN_LSTM\\\\data\\\\fitbitWearTimeViaHR_merged.csv\")\n",
    "dailyactivity = pd.read_csv(\"D:\\\\EIC-Code\\\\00-Python\\\\2024-08-Objective-identification-on-mental-health_CNN_LSTM\\\\data\\\\dailyActivity_merged.csv\")\n",
    "dailyFitbitActiveZoneMinutes = pd.read_csv(\"D:\\\\EIC-Code\\\\00-Python\\\\2024-08-Objective-identification-on-mental-health_CNN_LSTM\\\\data\\\\dailyFitbitActiveZoneMinutes_merged.csv\")\n",
    "dailyHRV = pd.read_csv(\"D:\\\\EIC-Code\\\\00-Python\\\\2024-08-Objective-identification-on-mental-health_CNN_LSTM\\\\data\\\\fitbitDailyHRV_merged.csv\")\n",
    "fitbitBreathingRate = pd.read_csv(\"D:\\\\EIC-Code\\\\00-Python\\\\2024-08-Objective-identification-on-mental-health_CNN_LSTM\\\\data\\\\fitbitBreathingRate_merged.csv\")\n",
    "fitbitSkinTemperature = pd.read_csv(\"D:\\\\EIC-Code\\\\00-Python\\\\2024-08-Objective-identification-on-mental-health_CNN_LSTM\\\\data\\\\fitbitSkinTemperature_merged.csv\")\n",
    "sleepDay = pd.read_csv(\"D:\\\\EIC-Code\\\\00-Python\\\\2024-08-Objective-identification-on-mental-health_CNN_LSTM\\\\data\\\\sleepDay_merged.csv\")\n",
    "heartrate_15min = pd.read_csv(\"D:\\\\EIC-Code\\\\00-Python\\\\2024-08-Objective-identification-on-mental-health_CNN_LSTM\\\\data\\\\heartrate_15min_merged.csv\")\n",
    "sleepStageLogInfo = pd.read_csv(\"D:\\\\EIC-Code\\\\00-Python\\\\2024-08-Objective-identification-on-mental-health_CNN_LSTM\\\\data\\\\sleepStagesDay_merged.csv\")\n",
    "\n",
    "#survey data\n",
    "survey_data = pd.read_csv(\"D:\\\\EIC-Code\\\\00-Python\\\\2024-08-Objective-identification-on-mental-health_CNN_LSTM\\\\data\\\\ABriefInterventionTo_DATA_2024-09-22_1540.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karri\\AppData\\Local\\Temp\\ipykernel_6164\\987032928.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  d['date'] = pd.to_datetime(d['date'], errors = 'coerce')\n",
      "C:\\Users\\karri\\AppData\\Local\\Temp\\ipykernel_6164\\987032928.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  d['date'] = pd.to_datetime(d['date'], errors = 'coerce')\n",
      "C:\\Users\\karri\\AppData\\Local\\Temp\\ipykernel_6164\\987032928.py:16: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  d['date'] = pd.to_datetime(d['date'], errors = 'coerce')\n"
     ]
    }
   ],
   "source": [
    "dailyactivity.rename(columns = {'ActivityDate':'date'}, inplace=True)\n",
    "wear_time.rename(columns = {'Day':'date'}, inplace=True)\n",
    "dailyFitbitActiveZoneMinutes.rename(columns = {'Date':'date'}, inplace=True)\n",
    "dailyHRV.rename(columns = {'SleepDay':'date'}, inplace=True)\n",
    "fitbitBreathingRate.rename(columns = {'SleepDay':'date'}, inplace = True)\n",
    "fitbitSkinTemperature.rename(columns = {'SleepDay':'date'}, inplace=True)\n",
    "sleepDay.rename(columns = {'SleepDay':'date'}, inplace=True)\n",
    "sleepStageLogInfo.rename(columns = {'SleepDay':'date'}, inplace=True)\n",
    "heartrate_15min.rename(columns = {'Time':'date'}, inplace=True)\n",
    "\n",
    "#transfer date\n",
    "total_data = [wear_time, dailyactivity, dailyFitbitActiveZoneMinutes, dailyHRV, fitbitBreathingRate, \n",
    "              fitbitSkinTemperature, sleepDay, sleepStageLogInfo, heartrate_15min]\n",
    "\n",
    "for d in total_data:\n",
    "    d['date'] = pd.to_datetime(d['date'], errors = 'coerce')\n",
    "    d['date'] = d['date'].dt.date #.strftime('%m/%d/%Y').str.replace('/0', '/')\n",
    "\n",
    "#transfer heart_rate_15 min\n",
    "heartrate_15min = heartrate_15min.groupby(by = ['Id','date']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged1 = pd.merge(wear_time, dailyactivity, on=['Id','date'], how='left')  # inner join only keeps common dates\n",
    "merged2 = pd.merge(merged1, sleepDay, on=['Id','date'], how='left')\n",
    "merged3 = pd.merge(merged2, sleepStageLogInfo, on=['Id','date'], how='left')\n",
    "merged4 = pd.merge(merged3, heartrate_15min, on=['Id','date'], how='left')\n",
    "merged5 = pd.merge(merged4, dailyFitbitActiveZoneMinutes, on=['Id','date'], how='left')\n",
    "merged6 = pd.merge(merged5, dailyHRV, on=['Id','date'], how='left')\n",
    "merged7 = pd.merge(merged6, fitbitBreathingRate, on=['Id','date'], how='left')\n",
    "merged_final = pd.merge(merged7, fitbitSkinTemperature, on=['Id','date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_final_10 = merged_final[(merged_final['TotalMinutesWearTime'] >= 10*60)] #10hour, what's the meaning of four days a week, is this for calendar week or four consecutive days\n",
    "merged_0_3000steps = merged_final[(merged_final['TotalMinutesWearTime'] == 0) & (merged_final['TotalSteps'] >= 3000)]\n",
    "\n",
    "merged_final = pd.concat([merged_final_10, merged_0_3000steps])\n",
    "merged_final = merged_final.sort_values(by=['Id', 'date']) \n",
    "\n",
    "#rename ID\n",
    "merged_final['Id'] = [items[-3:] for items in merged_final['Id']]\n",
    "merged_final['Id'] = [int(digit) for digit in merged_final['Id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Survey data, find sepecific coaching time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#survey data preprocessing\n",
    "survey_data['health_coach_survey_complete'].unique()\n",
    "\n",
    "#select people who complete the second follow-up\n",
    "survey_data_clean = survey_data[survey_data['weeks_followup_survey_complete'] == 2] #96 participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karri\\AppData\\Local\\Temp\\ipykernel_6164\\2381098113.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  select_survey.rename(columns = {\"record_id\":'Id'}, inplace=True)\n",
      "C:\\Users\\karri\\AppData\\Local\\Temp\\ipykernel_6164\\2381098113.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  select_survey['weeks_followup_survey_timestamp'] = pd.to_datetime(select_survey['weeks_followup_survey_timestamp'], errors = 'coerce' )\n",
      "C:\\Users\\karri\\AppData\\Local\\Temp\\ipykernel_6164\\2381098113.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  select_survey['weeks_followup_survey_timestamp'] = select_survey['weeks_followup_survey_timestamp'].dt.date\n",
      "C:\\Users\\karri\\AppData\\Local\\Temp\\ipykernel_6164\\2381098113.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  select_survey['weeks_followup_survey_96ac_timestamp'] = pd.to_datetime(select_survey['weeks_followup_survey_96ac_timestamp'], errors = 'coerce' )\n",
      "C:\\Users\\karri\\AppData\\Local\\Temp\\ipykernel_6164\\2381098113.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  select_survey['weeks_followup_survey_96ac_timestamp'] = select_survey['weeks_followup_survey_96ac_timestamp'].dt.date\n"
     ]
    }
   ],
   "source": [
    "#select variables from \n",
    "uses_vars_of_survey = ['record_id','current_status',\n",
    "'demographics_age','demographics_sex','demographics_sexorient','demographics_ethnicity','demographics_immigration',\n",
    "'demographics_race___1', 'demographics_race___2', 'demographics_race___3', 'demographics_race___4', 'demographics_race___5', \n",
    "'demographics_race___6', 'demographics_race___7', 'demographics_education', 'demographics_sorority',\n",
    "'nervous_v1', 'down_v1', 'calm_v1', 'blue_v1', 'happy_v1',\n",
    "'nervous_v2', 'down_v2', 'calm_v2', 'blue_v2', 'happy_v2',\n",
    "'weeks_followup_survey_timestamp', 'weeks_followup_survey_96ac_timestamp'\n",
    "]\n",
    "select_survey = survey_data_clean[uses_vars_of_survey]\n",
    "\n",
    "#rename the name of record_id\n",
    "select_survey.rename(columns = {\"record_id\":'Id'}, inplace=True)\n",
    "\n",
    "#reframe the date time format\n",
    "select_survey['weeks_followup_survey_timestamp'] = pd.to_datetime(select_survey['weeks_followup_survey_timestamp'], errors = 'coerce' )\n",
    "select_survey['weeks_followup_survey_timestamp'] = select_survey['weeks_followup_survey_timestamp'].dt.date\n",
    "select_survey['weeks_followup_survey_96ac_timestamp'] = pd.to_datetime(select_survey['weeks_followup_survey_96ac_timestamp'], errors = 'coerce' )\n",
    "select_survey['weeks_followup_survey_96ac_timestamp'] = select_survey['weeks_followup_survey_96ac_timestamp'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge Fitbit data with coaching time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karri\\AppData\\Local\\Temp\\ipykernel_6164\\3520426913.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  used_fitbit_data.rename(columns = {'TotalMinutesAsleep_x':'TotalMinutesAsleep','TotalTimeInBed_x':'TotalMinutesinbed',\n"
     ]
    }
   ],
   "source": [
    "fitbit_data = merged_final.copy()\n",
    "\n",
    "#replace code 98 as 107 because the code of this participant is 107 in survey\n",
    "fitbit_data.loc[fitbit_data['Id'] == 98, 'Id'] = 107\n",
    "\n",
    "used_var = ['Id','date','TotalMinutesWearTime', 'TotalSteps', 'VeryActiveMinutes', 'FairlyActiveMinutes',\n",
    "       'LightlyActiveMinutes', 'SedentaryMinutes', 'Calories', 'RestingHeartRate','TotalActiveZoneMinutes', 'FatBurnActiveZoneMinutes',\n",
    "       'CardioActiveZoneMinutes', 'PeakActiveZoneMinutes', 'DailyRMSSD', 'DeepRMSSD',\n",
    "       'AvgBreathsPerMinute', 'LightSleepAvgBreathsPerMinute','DeepSleepAvgBreathsPerMinute', 'REMSleepAvgBreathsPerMinute',\n",
    "       'TotalMinutesAsleep_x', 'TotalTimeInBed_x', 'TotalTimeAwake', 'TotalMinutesLight', \n",
    "       'TotalMinutesDeep','TotalMinutesREM', 'NightlyRelative', 'Value'] #delete 'Above', 'Below', Custom Zone; NightlyRelative: ski temparature\n",
    "\n",
    "used_fitbit_data = fitbit_data[used_var]\n",
    "\n",
    "used_fitbit_data.rename(columns = {'TotalMinutesAsleep_x':'TotalMinutesAsleep','TotalTimeInBed_x':'TotalMinutesinbed',\n",
    "                                   'TotalTimeAwake': 'TotalMinutesAwake',\n",
    "                                   'Value': 'HR',\n",
    "                                   'NightlyRelative': 'skin_temparature'}, \n",
    "                                   inplace = True)\n",
    "\n",
    "#select participants matched with survey\n",
    "all_survey_id = select_survey['Id'].unique()\n",
    "used_fitbit_data = used_fitbit_data[used_fitbit_data['Id'].isin(all_survey_id)]\n",
    "\n",
    "#add another column Fitbit data\n",
    "used_fitbit_data.insert(loc = 2, column = 'survey_date', value = np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40      42\n",
       "46      48\n",
       "67      69\n",
       "107    109\n",
       "112    114\n",
       "123    125\n",
       "129    131\n",
       "132    134\n",
       "149    151\n",
       "Name: Id, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the individual who did not complete second follow-up survey\n",
    "select_survey[pd.isna(select_survey['weeks_followup_survey_96ac_timestamp'])]['Id']\n",
    "# 40      42\n",
    "# 46      48\n",
    "# 67      69\n",
    "# 107    109dd\n",
    "# 112    114\n",
    "# 123    125\n",
    "# 129    131\n",
    "# 132    134\n",
    "# 149    151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_survey_date(row, followup1_time, followup2_time):\n",
    "    time = row['date']\n",
    "    \n",
    "    if pd.isna(followup2_time):\n",
    "        if pd.notna(time) and time <= followup1_time:\n",
    "            return \"follow_up1\"\n",
    "    \n",
    "    elif pd.notna(followup2_time):\n",
    "        if pd.notna(time) and time <= followup2_time:\n",
    "            return \"follow_up2\" #follow_up2\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fitbit_id = used_fitbit_data['Id'].unique()\n",
    "\n",
    "for i in range(len(all_fitbit_id)):\n",
    "\n",
    "    fitbit_id = all_fitbit_id[i]\n",
    "\n",
    "    #outcome variable\n",
    "    individual_survey = select_survey[select_survey['Id']==fitbit_id]\n",
    "    followup1_time = individual_survey['weeks_followup_survey_timestamp'].iloc[0] if not individual_survey['weeks_followup_survey_timestamp'].empty else pd.NaT\n",
    "    followup2_time = individual_survey['weeks_followup_survey_96ac_timestamp'].iloc[0] if not individual_survey['weeks_followup_survey_96ac_timestamp'].empty else pd.NaT\n",
    "    \n",
    "    #predictors\n",
    "    individual_fitbit = used_fitbit_data[used_fitbit_data['Id']==fitbit_id].copy()\n",
    "\n",
    "    individual_fitbit['survey_date'] = individual_fitbit.apply(\n",
    "        lambda row: assign_survey_date(row, followup1_time, followup2_time), axis=1\n",
    "        )\n",
    "    used_fitbit_data.loc[used_fitbit_data['Id'] == fitbit_id, 'survey_date'] = individual_fitbit['survey_date'] #replace with new define\n",
    "\n",
    "\n",
    "used_fitbit_data = used_fitbit_data.dropna(subset=['survey_date']) #4957"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time sequence complement\n",
    "time_sequency = used_fitbit_data.copy()\n",
    "all_fitbit_id = time_sequency['Id'].unique()\n",
    "new_data_frame = pd.DataFrame()\n",
    "\n",
    "for i in range(len(all_fitbit_id)):\n",
    "\n",
    "    fitbit_id = all_fitbit_id[i]\n",
    "\n",
    "    sorted_individual = time_sequency[time_sequency['Id'] == fitbit_id].sort_values(by = 'date')\n",
    "    \n",
    "    #outcome variable\n",
    "    individual_survey = select_survey[select_survey['Id']==fitbit_id]\n",
    "    followup1_time = individual_survey['weeks_followup_survey_timestamp'].iloc[0] if not individual_survey['weeks_followup_survey_timestamp'].empty else pd.NaT\n",
    "    followup2_time = individual_survey['weeks_followup_survey_96ac_timestamp'].iloc[0] if not individual_survey['weeks_followup_survey_96ac_timestamp'].empty else pd.NaT\n",
    "    \n",
    "    start_date = sorted_individual['date'].iloc[0]\n",
    "\n",
    "    if 'follow_up1' in sorted_individual['survey_date'].values:\n",
    "        end_date = followup1_time\n",
    "    else:\n",
    "        end_date = followup2_time\n",
    "    \n",
    "    full_date_range = pd.date_range(start=start_date, end=end_date)\n",
    "\n",
    "    sorted_individual.set_index('date', inplace=True)\n",
    "    \n",
    "    sorted_individual_reindexed = sorted_individual.reindex(full_date_range).reset_index() #reset the wrong index\n",
    "    sorted_individual_reindexed.rename(columns = {'index':'date'}, inplace = True)\n",
    "\n",
    "    if 'follow_up1' in sorted_individual_reindexed['survey_date'].values:\n",
    "        sorted_individual_reindexed['survey_date'] = 'follow_up1'\n",
    "        sorted_individual_reindexed['Id'] = fitbit_id\n",
    "    else:\n",
    "        sorted_individual_reindexed['survey_date'] = 'follow_up2'\n",
    "        sorted_individual_reindexed['Id'] = fitbit_id\n",
    "\n",
    "    new_data_frame = pd.concat([new_data_frame, sorted_individual_reindexed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data_frame = pd.DataFrame()\n",
    "\n",
    "for i1 in range(len(all_fitbit_id)):\n",
    "\n",
    "    fitbit_id = all_fitbit_id[i1]\n",
    "    select_data = new_data_frame[new_data_frame['Id'] == fitbit_id]\n",
    "\n",
    "    len_select_data = len(select_data)\n",
    "\n",
    "    process_series = pd.Series(dtype = 'object')\n",
    "\n",
    "    for i2 in range(len_select_data):\n",
    "\n",
    "        row_select_data = select_data.iloc[i2].copy()\n",
    "        row_select_data.index = [str(col) + '_' + str(i2) for col in row_select_data.index] #revise the name\n",
    "        process_series = pd.concat([process_series, row_select_data])\n",
    "\n",
    "    trans_process_series = pd.DataFrame(process_series).T\n",
    "\n",
    "    final_data_frame = pd.concat([final_data_frame, trans_process_series], axis = 0, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karri\\AppData\\Local\\Temp\\ipykernel_6164\\271520716.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data_frame.reset_index(inplace=True) #reset_index\n",
      "C:\\Users\\karri\\AppData\\Local\\Temp\\ipykernel_6164\\271520716.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  final_data_frame.reset_index(inplace=True) #reset_index\n"
     ]
    }
   ],
   "source": [
    "final_data_frame = final_data_frame.set_index(['Id_0','date_0'])#set ID and date as index\n",
    "final_data_frame = final_data_frame.drop(final_data_frame.filter(regex = 'date|Id|survey_date|TotalMinutesWearTime').columns, axis = 1) #delete column with the same format\n",
    "final_data_frame.reset_index(inplace=True) #reset_index\n",
    "final_data_frame.rename(columns = {'Id_0':'Id', 'date_0':'startdate'}, inplace = True) #renamei d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge fitbit data with survey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karri\\AppData\\Local\\Temp\\ipykernel_6164\\2290105134.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fitbit_survey[[ 'nervous', 'down', 'calm','blue', 'happy','enddate']] = np.nan\n",
      "C:\\Users\\karri\\AppData\\Local\\Temp\\ipykernel_6164\\2290105134.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fitbit_survey[[ 'nervous', 'down', 'calm','blue', 'happy','enddate']] = np.nan\n",
      "C:\\Users\\karri\\AppData\\Local\\Temp\\ipykernel_6164\\2290105134.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fitbit_survey[[ 'nervous', 'down', 'calm','blue', 'happy','enddate']] = np.nan\n",
      "C:\\Users\\karri\\AppData\\Local\\Temp\\ipykernel_6164\\2290105134.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fitbit_survey[[ 'nervous', 'down', 'calm','blue', 'happy','enddate']] = np.nan\n",
      "C:\\Users\\karri\\AppData\\Local\\Temp\\ipykernel_6164\\2290105134.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fitbit_survey[[ 'nervous', 'down', 'calm','blue', 'happy','enddate']] = np.nan\n",
      "C:\\Users\\karri\\AppData\\Local\\Temp\\ipykernel_6164\\2290105134.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  fitbit_survey[[ 'nervous', 'down', 'calm','blue', 'happy','enddate']] = np.nan\n"
     ]
    }
   ],
   "source": [
    "#merge survey data with fitbit data\n",
    "fitbit_survey = pd.merge(final_data_frame, select_survey, on = 'Id', how = 'left')\n",
    "\n",
    "fitbit_survey[[ 'nervous', 'down', 'calm','blue', 'happy','enddate']] = np.nan\n",
    "\n",
    "all_ids = fitbit_survey['Id'].unique()\n",
    "\n",
    "for i in range(len(all_ids)):\n",
    "\n",
    "    id = all_ids[i]\n",
    "    individual_data = fitbit_survey[fitbit_survey['Id'] == id]\n",
    "\n",
    "    if pd.isna(individual_data['weeks_followup_survey_96ac_timestamp'].iloc[0]):\n",
    "        \n",
    "        fitbit_survey.loc[fitbit_survey['Id'] == id, 'nervous'] = individual_data['nervous_v1']\n",
    "        fitbit_survey.loc[fitbit_survey['Id'] == id, 'down'] = individual_data['down_v1']\n",
    "        fitbit_survey.loc[fitbit_survey['Id'] == id, 'calm'] = individual_data['calm_v1']\n",
    "        fitbit_survey.loc[fitbit_survey['Id'] == id, 'blue'] = individual_data['blue_v1']\n",
    "        fitbit_survey.loc[fitbit_survey['Id'] == id, 'happy'] = individual_data['happy_v1']\n",
    "        fitbit_survey.loc[fitbit_survey['Id'] == id, 'enddate'] = individual_data['weeks_followup_survey_timestamp'].iloc[0]\n",
    "    else:\n",
    "        fitbit_survey.loc[fitbit_survey['Id'] == id, 'nervous'] = individual_data['nervous_v2']\n",
    "        fitbit_survey.loc[fitbit_survey['Id'] == id, 'down'] = individual_data['down_v2']\n",
    "        fitbit_survey.loc[fitbit_survey['Id'] == id, 'calm'] = individual_data['calm_v2']\n",
    "        fitbit_survey.loc[fitbit_survey['Id'] == id, 'blue'] = individual_data['blue_v2']\n",
    "        fitbit_survey.loc[fitbit_survey['Id'] == id, 'happy'] = individual_data['happy_v2']\n",
    "        fitbit_survey.loc[fitbit_survey['Id'] == id, 'enddate']= individual_data['weeks_followup_survey_96ac_timestamp'].iloc[0]\n",
    "\n",
    "fitbit_survey.drop(columns = ['weeks_followup_survey_timestamp', 'weeks_followup_survey_96ac_timestamp',\n",
    "                              'nervous_v1', 'down_v1', 'calm_v1', 'blue_v1', 'happy_v1', \n",
    "                              'nervous_v2', 'down_v2', 'calm_v2', 'blue_v2','happy_v2'], inplace = True) #drop another two columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to remvoe column 1 to -2\n",
    "move_col = fitbit_survey.columns[1]\n",
    "\n",
    "#remove col from original col\n",
    "cols = list(fitbit_survey.columns)\n",
    "cols.remove(move_col)\n",
    "\n",
    "#insert column\n",
    "cols.insert(-1, move_col)\n",
    "\n",
    "#reorder new col\n",
    "fitbit_survey = fitbit_survey[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitbit_survey.to_csv('final_survey_fitbit_time_series.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the participants have the same time frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_difference = pd.to_datetime(fitbit_survey['enddate']) - fitbit_survey['startdate']\n",
    "mean_total_days = np.mean(time_difference).days\n",
    "columns = final_data_frame.columns\n",
    "add_column = list(fitbit_survey.columns[-22:])\n",
    "add_column.append('Id')\n",
    "\n",
    "suffix_range_rest = [f\"_{i}\" for i in range(mean_total_days)]\n",
    "set_all_columns_the_same = [col for col in columns if any(col.endswith(suffix) for suffix in suffix_range_rest)]\n",
    "\n",
    "reorganize_data = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_i = len(time_difference)\n",
    "\n",
    "for i in range(num_i):\n",
    "    i = i\n",
    "    difference_i = time_difference[i]\n",
    "    n_days = time_difference[i].days\n",
    "\n",
    "    if n_days <= mean_total_days:\n",
    "        suffix_range = [f\"_{i}\" for i in range(mean_total_days)]\n",
    "        select_fitbit_columns = [col for col in columns if any(col.endswith(suffix) for suffix in suffix_range)]\n",
    "        used_data = pd.DataFrame(fitbit_survey.iloc[i]).T[select_fitbit_columns]\n",
    "\n",
    "    else:\n",
    "        nan_day = []\n",
    "        suffix_range_new = [f\"_{i}\" for i in range(mean_total_days+1, n_days)]\n",
    "\n",
    "        for suffixs in suffix_range_new:\n",
    "            suffix_columns = [col for col in columns if col.endswith(suffixs)]\n",
    "            \n",
    "            #print(len(suffix_columns))\n",
    "            suffix_data = fitbit_survey.iloc[i][suffix_columns]\n",
    "\n",
    "            if suffix_data.isna().all():\n",
    "                #print(True)\n",
    "                nan_day.append(suffixs)\n",
    "\n",
    "        #select data after 65\n",
    "        filter_suffix_range = [item for item in suffix_range_new if item not in nan_day]\n",
    "\n",
    "        if len(filter_suffix_range) >= mean_total_days:\n",
    "            new_filter_suffix_range = filter_suffix_range[-mean_total_days:]\n",
    "            columns_65 = [col for col in columns if any(col.endswith(suffix) for suffix in new_filter_suffix_range)]\n",
    "            columns_65_data = pd.DataFrame(fitbit_survey.iloc[i]).T[columns_65]\n",
    "            used_data = columns_65_data\n",
    "\n",
    "        else:\n",
    "            #select data before 65\n",
    "            #number of columns before 65\n",
    "            n_col = mean_total_days-len(filter_suffix_range)\n",
    "            start_number = mean_total_days-n_col\n",
    "            end_number = mean_total_days\n",
    "\n",
    "            suffix_range = [f\"_{i}\" for i in range(start_number+1, end_number+1)]\n",
    "            select_fitbit_columns = [col for col in columns if any(col.endswith(suffix) for suffix in suffix_range)]\n",
    "            before_65_data = pd.DataFrame(fitbit_survey.iloc[i]).T[select_fitbit_columns]\n",
    "\n",
    "            #select dat aafter 65\n",
    "\n",
    "            after_65_columns = [col for col in columns if any(col.endswith(suffix) for suffix in filter_suffix_range)]\n",
    "            after_65_data = pd.DataFrame(fitbit_survey.iloc[i]).T[after_65_columns]\n",
    "\n",
    "            used_data = pd.concat([before_65_data, after_65_data], axis = 1) #combine two\n",
    "\n",
    "        used_data.columns = set_all_columns_the_same\n",
    "\n",
    "    #append survey data\n",
    "    survey_data = pd.DataFrame(fitbit_survey.iloc[i]).T[add_column]\n",
    "\n",
    "    new_fitbit_survey = pd.concat([used_data, survey_data], axis = 1)\n",
    "        \n",
    "    reorganize_data = pd.concat([reorganize_data, new_fitbit_survey], axis = 0, ignore_index=True) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "reorganize_data.to_csv('final_survey_fitbit_time_series_v2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
